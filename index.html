<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-04-27T01:30:00Z">04-27</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">How can NLP Help Revitalize Endangered Languages? A Case Study and Roadmap for the Cherokee Language. (arXiv:2204.11909v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11909">
<div class="article-summary-box-inner">
<span><p>More than 43% of the languages spoken in the world are endangered, and
language loss currently occurs at an accelerated rate because of globalization
and neocolonialism. Saving and revitalizing endangered languages has become
very important for maintaining the cultural diversity on our planet. In this
work, we focus on discussing how NLP can help revitalize endangered languages.
We first suggest three principles that may help NLP practitioners to foster
mutual understanding and collaboration with language communities, and we
discuss three ways in which NLP can potentially assist in language education.
We then take Cherokee, a severely-endangered Native American language, as a
case study. After reviewing the language's history, linguistic features, and
existing resources, we (in collaboration with Cherokee community members)
arrive at a few meaningful ways NLP practitioners can collaborate with
community partners. We suggest two approaches to enrich the Cherokee language's
resources with machine-in-the-loop processing, and discuss several NLP tools
that people from the Cherokee community have shown interest in. We hope that
our work serves not only to inform the NLP community about Cherokee, but also
to provide inspiration for future work on endangered languages in general. Our
code and data will be open-sourced at
https://github.com/ZhangShiyue/RevitalizeCherokee
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Super-Prompting: Utilizing Model-Independent Contextual Data to Reduce Data Annotation Required in Visual Commonsense Tasks. (arXiv:2204.11922v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11922">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models have shown excellent results in few-shot learning
scenarios using in-context learning. Although it is impressive, the size of
language models can be prohibitive to make them usable in on-device
applications, such as sensors or smartphones. With smaller language models,
task-specific data annotation is needed to fine-tune the language model for a
specific purpose. However, data annotation can have a substantial financial and
time burden for small research groups, startups, and even companies. In this
paper, we analyze different prompt-based fine-tuning techniques to improve
results on both language and multimodal causal transformer models. To evaluate
our results, we use a dataset focusing on visual commonsense reasoning in time.
Our results show that by simple model-agnostic prompt-based fine-tuning,
comparable results can be reached by only using 35%-40% of the fine-tuning
training dataset. The proposed approaches result in significant time and
financial savings. As the proposed methods make minimal architectural
assumptions, other researchers can use the results in their transformer models
with minimal adaptations. We plan to release the source code freely to make it
easier for the community to use and contribute to our work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">C3: Continued Pretraining with Contrastive Weak Supervision for Cross Language Ad-Hoc Retrieval. (arXiv:2204.11989v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11989">
<div class="article-summary-box-inner">
<span><p>Pretrained language models have improved effectiveness on numerous tasks,
including ad-hoc retrieval. Recent work has shown that continuing to pretrain a
language model with auxiliary objectives before fine-tuning on the retrieval
task can further improve retrieval effectiveness. Unlike monolingual retrieval,
designing an appropriate auxiliary task for cross-language mappings is
challenging. To address this challenge, we use comparable Wikipedia articles in
different languages to further pretrain off-the-shelf multilingual pretrained
models before fine-tuning on the retrieval task. We show that our approach
yields improvements in retrieval effectiveness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI Personification: Estimating the Personality of Language Models. (arXiv:2204.12000v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12000">
<div class="article-summary-box-inner">
<span><p>Technology for open-ended language generation, a key application of
artificial intelligence, has advanced to a great extent in recent years.
Large-scale language models, which are trained on large corpora of text, are
being used in a wide range of applications everywhere, from virtual assistants
to conversational bots. While these language models output fluent text,
existing research shows that these models can and do capture human biases. Many
of these biases, especially those that could potentially cause harm, are being
well investigated. On the other hand, studies that infer and change personality
traits inherited by these models have been scarce or non-existent. In this
work, we explore the personality traits of several large-scale language models
designed for open-ended text generation and the datasets used for training
them. Our work builds on the popular Big Five factors and develops robust
methods that quantify the personality traits of these models and their
underlying datasets. In particular, we trigger the models with a questionnaire
designed for personality assessment and subsequently classify the text
responses into quantifiable traits using a Zero-shot classifier. Our
classification sheds light on an important anthropomorphic element found in
such AI models and can help stakeholders decide how they should be applied and
how society could perceive them. We augment our analysis by studying approaches
that can alter these personalities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reprint: a randomized extrapolation based on principal components for data augmentation. (arXiv:2204.12024v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12024">
<div class="article-summary-box-inner">
<span><p>Data scarcity and data imbalance have attracted a lot of attention in many
fields. Data augmentation, explored as an effective approach to tackle them,
can improve the robustness and efficiency of classification models by
generating new samples. This paper presents REPRINT, a simple and effective
hidden-space data augmentation method for imbalanced data classification. Given
hidden-space representations of samples in each class, REPRINT extrapolates, in
a randomized fashion, augmented examples for target class by using subspaces
spanned by principal components to summarize distribution structure of both
source and target class. Consequently, the examples generated would diversify
the target while maintaining the original geometry of target distribution.
Besides, this method involves a label refinement component which allows to
synthesize new soft labels for augmented examples. Compared with different NLP
data augmentation approaches under a range of data imbalanced scenarios on four
text classification benchmark, REPRINT shows prominent improvements. Moreover,
through comprehensive ablation studies, we show that label refinement is better
than label-preserving for augmented examples, and that our method suggests
stable and consistent improvements in terms of suitable choices of principal
components. Moreover, REPRINT is appealing for its easy-to-use since it
contains only one hyperparameter determining the dimension of subspace and
requires low computational resource.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boundary Smoothing for Named Entity Recognition. (arXiv:2204.12031v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12031">
<div class="article-summary-box-inner">
<span><p>Neural named entity recognition (NER) models may easily encounter the
over-confidence issue, which degrades the performance and calibration. Inspired
by label smoothing and driven by the ambiguity of boundary annotation in NER
engineering, we propose boundary smoothing as a regularization technique for
span-based neural NER models. It re-assigns entity probabilities from annotated
spans to the surrounding ones. Built on a simple but strong baseline, our model
achieves results better than or competitive with previous state-of-the-art
systems on eight well-known NER benchmarks. Further empirical analysis suggests
that boundary smoothing effectively mitigates over-confidence, improves model
calibration, and brings flatter neural minima and more smoothed loss
landscapes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pretraining Chinese BERT for Detecting Word Insertion and Deletion Errors. (arXiv:2204.12052v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12052">
<div class="article-summary-box-inner">
<span><p>Chinese BERT models achieve remarkable progress in dealing with grammatical
errors of word substitution. However, they fail to handle word insertion and
deletion because BERT assumes the existence of a word at each position. To
address this, we present a simple and effective Chinese pretrained model. The
basic idea is to enable the model to determine whether a word exists at a
particular position. We achieve this by introducing a special token
\texttt{[null]}, the prediction of which stands for the non-existence of a
word. In the training stage, we design pretraining tasks such that the model
learns to predict \texttt{[null]} and real words jointly given the surrounding
context. In the inference stage, the model readily detects whether a word
should be inserted or deleted with the standard masked language modeling
function. We further create an evaluation dataset to foster research on word
insertion and deletion. It includes human-annotated corrections for 7,726
erroneous sentences. Results show that existing Chinese BERT performs poorly on
detecting insertion and deletion errors. Our approach significantly improves
the F1 scores from 24.1\% to 78.1\% for word insertion and from 26.5\% to
68.5\% for word deletion, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PLOD: An Abbreviation Detection Dataset for Scientific Documents. (arXiv:2204.12061v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12061">
<div class="article-summary-box-inner">
<span><p>The detection and extraction of abbreviations from unstructured texts can
help to improve the performance of Natural Language Processing tasks, such as
machine translation and information retrieval. However, in terms of publicly
available datasets, there is not enough data for training
deep-neural-networks-based models to the point of generalising well over data.
This paper presents PLOD, a large-scale dataset for abbreviation detection and
extraction that contains 160k+ segments automatically annotated with
abbreviations and their long forms. We performed manual validation over a set
of instances and a complete automatic validation for this dataset. We then used
it to generate several baseline models for detecting abbreviations and long
forms. The best models achieved an F1-score of 0.92 for abbreviations and 0.89
for detecting their corresponding long forms. We release this dataset along
with our code and all the models publicly in
https://github.com/surrey-nlp/AbbreviationDetRepo.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Suggesting Relevant Questions for a Query Using Statistical Natural Language Processing Technique. (arXiv:2204.12069v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12069">
<div class="article-summary-box-inner">
<span><p>Suggesting similar questions for a user query has many applications ranging
from reducing search time of users on e-commerce websites, training of
employees in companies to holistic learning for students. The use of Natural
Language Processing techniques for suggesting similar questions is prevalent
over the existing architecture. Mainly two approaches are studied for finding
text similarity namely syntactic and semantic, however each has its draw-backs
and fail to provide the desired outcome. In this article, a self-learning
combined approach is proposed for determining textual similarity that
introduces a robust weighted syntactic and semantic similarity index for
determining similar questions from a predetermined database, this approach
learns the optimal combination of the mentioned approaches for a database under
consideration. Comprehensive analysis has been carried out to justify the
efficiency and efficacy of the proposed approach over the existing literature.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Symlink: A New Dataset for Scientific Symbol-Description Linking. (arXiv:2204.12070v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12070">
<div class="article-summary-box-inner">
<span><p>Mathematical symbols and descriptions appear in various forms across document
section boundaries without explicit markup. In this paper, we present a new
large-scale dataset that emphasizes extracting symbols and descriptions in
scientific documents. Symlink annotates scientific papers of 5 different
domains (i.e., computer science, biology, physics, mathematics, and economics).
Our experiments on Symlink demonstrate the challenges of the symbol-description
linking task for existing models and call for further research effort in this
area. We will publicly release Symlink to facilitate future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Approach to Predicting News -- A Precise Multi-LSTM Network With BERT. (arXiv:2204.12093v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12093">
<div class="article-summary-box-inner">
<span><p>Varieties of Democracy (V-Dem) is a new approach to conceptualizing and
measuring democracy and politics. It has information for 200 countries and is
one of the biggest databases for political science. According to the V-Dem
annual democracy report 2019, Taiwan is one of the two countries that got
disseminated false information from foreign governments the most. It also shows
that the "made-up news" has caused a great deal of confusion in Taiwanese
society and has serious impacts on global stability. Although there are several
applications helping distinguish the false information, we found out that the
pre-processing of categorizing the news is still done by human labor. However,
human labor may cause mistakes and cannot work for a long time. The growing
demands for automatic machines in the near decades show that while the machine
can do as good as humans or even better, using machines can reduce humans'
burden and cut down costs. Therefore, in this work, we build a predictive model
to classify the category of news. The corpora we used contains 28358 news and
200 news scraped from the online newspaper Liberty Times Net (LTN) website and
includes 8 categories: Technology, Entertainment, Fashion, Politics, Sports,
International, Finance, and Health. At first, we use Bidirectional Encoder
Representations from Transformers (BERT) for word embeddings which transform
each Chinese character into a (1,768) vector. Then, we use a Long Short-Term
Memory (LSTM) layer to transform word embeddings into sentence embeddings and
add another LSTM layer to transform them into document embeddings. Each
document embedding is an input for the final predicting model, which contains
two Dense layers and one Activation layer. And each document embedding is
transformed into 1 vector with 8 real numbers, then the highest one will
correspond to the 8 news categories with up to 99% accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Function-words Enhanced Attention Networks for Few-Shot Inverse Relation Classification. (arXiv:2204.12111v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12111">
<div class="article-summary-box-inner">
<span><p>The relation classification is to identify semantic relations between two
entities in a given text. While existing models perform well for classifying
inverse relations with large datasets, their performance is significantly
reduced for few-shot learning. In this paper, we propose a function words
adaptively enhanced attention framework (FAEA) for few-shot inverse relation
classification, in which a hybrid attention model is designed to attend
class-related function words based on meta-learning. As the involvement of
function words brings in significant intra-class redundancy, an adaptive
message passing mechanism is introduced to capture and transfer inter-class
differences.We mathematically analyze the negative impact of function words
from dot-product measurement, which explains why message passing mechanism
effectively reduces the impact. Our experimental results show that FAEA
outperforms strong baselines, especially the inverse relation accuracy is
improved by 14.33% under 1-shot setting in FewRel1.0.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Robust Contrastive Alignment Method For Multi-Domain Text Classification. (arXiv:2204.12125v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12125">
<div class="article-summary-box-inner">
<span><p>Multi-domain text classification can automatically classify texts in various
scenarios. Due to the diversity of human languages, texts with the same label
in different domains may differ greatly, which brings challenges to the
multi-domain text classification. Current advanced methods use the
private-shared paradigm, capturing domain-shared features by a shared encoder,
and training a private encoder for each domain to extract domain-specific
features. However, in realistic scenarios, these methods suffer from
inefficiency as new domains are constantly emerging. In this paper, we propose
a robust contrastive alignment method to align text classification features of
various domains in the same feature space by supervised contrastive learning.
By this means, we only need two universal feature extractors to achieve
multi-domain text classification. Extensive experimental results show that our
method performs on par with or sometimes better than the state-of-the-art
method, which uses the complex multi-classifier in a private-shared framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LM-Debugger: An Interactive Tool for Inspection and Intervention in Transformer-Based Language Models. (arXiv:2204.12130v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12130">
<div class="article-summary-box-inner">
<span><p>The opaque nature and unexplained behavior of transformer-based language
models (LMs) have spurred a wide interest in interpreting their predictions.
However, current interpretation methods mostly focus on probing models from
outside, executing behavioral tests, and analyzing salience input features,
while the internal prediction construction process is largely not understood.
In this work, we introduce LM-Debugger, an interactive debugger tool for
transformer-based LMs, which provides a fine-grained interpretation of the
model's internal prediction process, as well as a powerful framework for
intervening in LM behavior. For its backbone, LM-Debugger relies on a recent
method that interprets the inner token representations and their updates by the
feed-forward layers in the vocabulary space. We demonstrate the utility of
LM-Debugger for single-prediction debugging, by inspecting the internal
disambiguation process done by GPT2. Moreover, we show how easily LM-Debugger
allows to shift model behavior in a direction of the user's choice, by
identifying a few vectors in the network and inducing effective interventions
to the prediction process. We release LM-Debugger as an open-source tool and a
demo over GPT2 models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-determinsitic algebraic rewriting as adjunction. (arXiv:2204.12133v1 [math.LO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12133">
<div class="article-summary-box-inner">
<span><p>We develop a general model theoretic semantics to rewriting beyond the usual
confluence and termination assumptions. This is based on preordered algebra
which is a model theory that extends many sorted algebra. In this framework we
characterise rewriting in arbitrary algebras rather than term algebras (called
algebraic rewriting) as a persistent adjunction and use this result, on the one
hand for proving the soundness and the completeness of an abstract
computational model of rewriting that underlies the non-deterministic
programming with Maude and CafeOBJ, and on the other hand for developing a
compositionality result for algebraic rewriting in the context of the
pushout-based modularisation technique.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoVERT: A Corpus of Fact-checked Biomedical COVID-19 Tweets. (arXiv:2204.12164v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12164">
<div class="article-summary-box-inner">
<span><p>Over the course of the COVID-19 pandemic, large volumes of biomedical
information concerning this new disease have been published on social media.
Some of this information can pose a real danger to people's health,
particularly when false information is shared, for instance recommendations on
how to treat diseases without professional medical advice. Therefore, automatic
fact-checking resources and systems developed specifically for the medical
domain are crucial. While existing fact-checking resources cover
COVID-19-related information in news or quantify the amount of misinformation
in tweets, there is no dataset providing fact-checked COVID-19-related Twitter
posts with detailed annotations for biomedical entities, relations and relevant
evidence. We contribute CoVERT, a fact-checked corpus of tweets with a focus on
the domain of biomedicine and COVID-19-related (mis)information. The corpus
consists of 300 tweets, each annotated with medical named entities and
relations. We employ a novel crowdsourcing methodology to annotate all tweets
with fact-checking labels and supporting evidence, which crowdworkers search
for online. This methodology results in moderate inter-annotator agreement.
Furthermore, we use the retrieved evidence extracts as part of a fact-checking
pipeline, finding that the real-world evidence is more useful than the
knowledge indirectly available in pretrained language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When do Contrastive Word Alignments Improve Many-to-many Neural Machine Translation?. (arXiv:2204.12165v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12165">
<div class="article-summary-box-inner">
<span><p>Word alignment has proven to benefit many-to-many neural machine translation
(NMT). However, high-quality ground-truth bilingual dictionaries were used for
pre-editing in previous methods, which are unavailable for most language pairs.
Meanwhile, the contrastive objective can implicitly utilize automatically
learned word alignment, which has not been explored in many-to-many NMT. This
work proposes a word-level contrastive objective to leverage word alignments
for many-to-many NMT. Empirical results show that this leads to 0.8 BLEU gains
for several language pairs. Analyses reveal that in many-to-many NMT, the
encoder's sentence retrieval performance highly correlates with the translation
quality, which explains when the proposed method impacts translation. This
motivates future exploration for many-to-many NMT to improve the encoder's
sentence retrieval performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Machine Learning to Fuse Verbal Autopsy Narratives and Binary Features in the Analysis of Deaths from Hyperglycaemia. (arXiv:2204.12169v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12169">
<div class="article-summary-box-inner">
<span><p>Lower-and-middle income countries are faced with challenges arising from a
lack of data on cause of death (COD), which can limit decisions on population
health and disease management. A verbal autopsy(VA) can provide information
about a COD in areas without robust death registration systems. A VA consists
of structured data, combining numeric and binary features, and unstructured
data as part of an open-ended narrative text. This study assesses the
performance of various machine learning approaches when analyzing both the
structured and unstructured components of the VA report. The algorithms were
trained and tested via cross-validation in the three settings of binary
features, text features and a combination of binary and text features derived
from VA reports from rural South Africa. The results obtained indicate
narrative text features contain valuable information for determining COD and
that a combination of binary and text features improves the automated COD
classification task.
</p>
<p>Keywords: Diabetes Mellitus, Verbal Autopsy, Cause of Death, Machine
Learning, Natural Language Processing
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SkillNet-NLG: General-Purpose Natural Language Generation with a Sparsely Activated Approach. (arXiv:2204.12184v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12184">
<div class="article-summary-box-inner">
<span><p>We present SkillNet-NLG, a sparsely activated approach that handles many
natural language generation tasks with one model. Different from traditional
dense models that always activate all the parameters, SkillNet-NLG selectively
activates relevant parts of the parameters to accomplish a task, where the
relevance is controlled by a set of predefined skills. The strength of such
model design is that it provides an opportunity to precisely adapt relevant
skills to learn new tasks effectively. We evaluate on Chinese natural language
generation tasks. Results show that, with only one model file, SkillNet-NLG
outperforms previous best performance methods on four of five tasks.
SkillNet-NLG performs better than two multi-task learning baselines (a dense
model and a Mixture-of-Expert model) and achieves comparable performance to
task-specific models. Lastly, SkillNet-NLG surpasses baseline systems when
being adapted to new tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Faster and Better Grammar-based Text-to-SQL Parsing via Clause-level Parallel Decoding and Alignment Loss. (arXiv:2204.12186v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12186">
<div class="article-summary-box-inner">
<span><p>Grammar-based parsers have achieved high performance in the cross-domain
text-to-SQL parsing task, but suffer from low decoding efficiency due to the
much larger number of actions for grammar selection than that of tokens in SQL
queries. Meanwhile, how to better align SQL clauses and question segments has
been a key challenge for parsing performance. Therefore, this paper proposes
clause-level parallel decoding and alignment loss to enhance two
high-performance grammar-based parsers, i.e., RATSQL and LGESQL. Experimental
results of two parsers show that our method obtains consistent improvements
both in accuracy and decoding speed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EmpHi: Generating Empathetic Responses with Human-like Intents. (arXiv:2204.12191v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12191">
<div class="article-summary-box-inner">
<span><p>In empathetic conversations, humans express their empathy to others with
empathetic intents. However, most existing empathetic conversational methods
suffer from a lack of empathetic intents, which leads to monotonous empathy. To
address the bias of the empathetic intents distribution between empathetic
dialogue models and humans, we propose a novel model to generate empathetic
responses with human-consistent empathetic intents, EmpHi for short. Precisely,
EmpHi learns the distribution of potential empathetic intents with a discrete
latent variable, then combines both implicit and explicit intent representation
to generate responses with various empathetic intents. Experiments show that
EmpHi outperforms state-of-the-art models in terms of empathy, relevance, and
diversity on both automatic and human evaluation. Moreover, the case studies
demonstrate the high interpretability and outstanding performance of our model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Flow-Adapter Architecture for Unsupervised Machine Translation. (arXiv:2204.12225v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12225">
<div class="article-summary-box-inner">
<span><p>In this work, we propose a flow-adapter architecture for unsupervised NMT. It
leverages normalizing flows to explicitly model the distributions of
sentence-level latent representations, which are subsequently used in
conjunction with the attention mechanism for the translation task. The primary
novelties of our model are: (a) capturing language-specific sentence
representations separately for each language using normalizing flows and (b)
using a simple transformation of these latent representations for translating
from one language to another. This architecture allows for unsupervised
training of each language independently. While there is prior work on latent
variables for supervised MT, to the best of our knowledge, this is the first
work that uses latent variables and normalizing flows for unsupervised MT. We
obtain competitive results on several unsupervised MT benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Science Checker: Extractive-Boolean Question Answering For Scientific Fact Checking. (arXiv:2204.12263v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12263">
<div class="article-summary-box-inner">
<span><p>With the explosive growth of scientific publications, making the synthesis of
scientific knowledge and fact checking becomes an increasingly complex task. In
this paper, we propose a multi-task approach for verifying the scientific
questions based on a joint reasoning from facts and evidence in research
articles. We propose an intelligent combination of (1) an automatic information
summarization and (2) a Boolean Question Answering which allows to generate an
answer to a scientific question from only extracts obtained after
summarization. Thus on a given topic, our proposed approach conducts structured
content modeling based on paper abstracts to answer a scientific question while
highlighting texts from paper that discuss the topic. We based our final system
on an end-to-end Extractive Question Answering (EQA) combined with a three
outputs classification model to perform in-depth semantic understanding of a
question to illustrate the aggregation of multiple responses. With our light
and fast proposed architecture, we achieved an average error rate of 4% and a
F1-score of 95.6%. Our results are supported via experiments with two QA models
(BERT, RoBERTa) over 3 Million Open Access (OA) articles in the medical and
health domains on Europe PMC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentiment Analysis of Cybersecurity Content on Twitter and Reddit. (arXiv:2204.12267v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12267">
<div class="article-summary-box-inner">
<span><p>Sentiment Analysis provides an opportunity to understand the subject(s),
especially in the digital age, due to an abundance of public data and effective
algorithms. Cybersecurity is a subject where opinions are plentiful and
differing in the public domain. This descriptive research analyzed
cybersecurity content on Twitter and Reddit to measure its sentiment, positive
or negative, or neutral. The data from Twitter and Reddit was amassed via
technology-specific APIs during a selected timeframe to create datasets, which
were then analyzed individually for their sentiment by VADER, an NLP (Natural
Language Processing) algorithm. A random sample of cybersecurity content (ten
tweets and posts) was also classified for sentiments by twenty human annotators
to evaluate the performance of VADER. Cybersecurity content on Twitter was at
least 48% positive, and Reddit was at least 26.5% positive. The positive or
neutral content far outweighed negative sentiments across both platforms. When
compared to human classification, which was considered the standard or source
of truth, VADER produced 60% accuracy for Twitter and 70% for Reddit in
assessing the sentiment; in other words, some agreement between algorithm and
human classifiers. Overall, the goal was to explore an uninhibited research
topic about cybersecurity sentiment
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low-dimensional representation of infant and adult vocalization acoustics. (arXiv:2204.12279v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12279">
<div class="article-summary-box-inner">
<span><p>During the first years of life, infant vocalizations change considerably, as
infants develop the vocalization skills that enable them to produce speech
sounds. Characterizations based on specific acoustic features, protophone
categories, or phonetic transcription are able to provide a representation of
the sounds infants make at different ages and in different contexts but do not
fully describe how sounds are perceived by listeners, can be inefficient to
obtain at large scales, and are difficult to visualize in two dimensions
without additional statistical processing. Machine-learning-based approaches
provide the opportunity to complement these characterizations with purely
data-driven representations of infant sounds. Here, we use spectral features
extraction and unsupervised machine learning, specifically Uniform Manifold
Approximation (UMAP), to obtain a novel 2-dimensional spatial representation of
infant and caregiver vocalizations extracted from day-long home recordings.
UMAP yields a continuous and well-distributed space conducive to certain
analyses of infant vocal development. For instance, we found that the
dispersion of infant vocalization acoustics within the 2-D space over a day
increased from 3 to 9 months, and then decreased from 9 to 18 months. The
method also permits analysis of similarity between infant and adult
vocalizations, which also shows changes with infant age.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Monant Medical Misinformation Dataset: Mapping Articles to Fact-Checked Claims. (arXiv:2204.12294v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12294">
<div class="article-summary-box-inner">
<span><p>False information has a significant negative influence on individuals as well
as on the whole society. Especially in the current COVID-19 era, we witness an
unprecedented growth of medical misinformation. To help tackle this problem
with machine learning approaches, we are publishing a feature-rich dataset of
approx. 317k medical news articles/blogs and 3.5k fact-checked claims. It also
contains 573 manually and more than 51k automatically labelled mappings between
claims and articles. Mappings consist of claim presence, i.e., whether a claim
is contained in a given article, and article stance towards the claim. We
provide several baselines for these two tasks and evaluate them on the manually
labelled part of the dataset. The dataset enables a number of additional tasks
related to medical misinformation, such as misinformation characterisation
studies or studies of misinformation diffusion between sources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Supervised Attention in Sequence-to-Sequence Models for Speech Recognition. (arXiv:2204.12308v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12308">
<div class="article-summary-box-inner">
<span><p>Attention mechanism in sequence-to-sequence models is designed to model the
alignments between acoustic features and output tokens in speech recognition.
However, attention weights produced by models trained end to end do not always
correspond well with actual alignments, and several studies have further argued
that attention weights might not even correspond well with the relevance
attribution of frames. Regardless, visual similarity between attention weights
and alignments is widely used during training as an indicator of the models
quality. In this paper, we treat the correspondence between attention weights
and alignments as a learning problem by imposing a supervised attention loss.
Experiments have shown significant improved performance, suggesting that
learning the alignments well during training critically determines the
performance of sequence-to-sequence models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Systematicity, Compositionality and Transitivity of Deep NLP Models: a Metamorphic Testing Perspective. (arXiv:2204.12316v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12316">
<div class="article-summary-box-inner">
<span><p>Metamorphic testing has recently been used to check the safety of neural NLP
models. Its main advantage is that it does not rely on a ground truth to
generate test cases. However, existing studies are mostly concerned with
robustness-like metamorphic relations, limiting the scope of linguistic
properties they can test. We propose three new classes of metamorphic
relations, which address the properties of systematicity, compositionality and
transitivity. Unlike robustness, our relations are defined over multiple source
inputs, thus increasing the number of test cases that we can produce by a
polynomial factor. With them, we test the internal consistency of
state-of-the-art NLP models, and show that they do not always behave according
to their expected linguistic properties. Lastly, we introduce a novel graphical
notation that efficiently summarises the inner structure of metamorphic
relations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Meta Word Embeddings by Unsupervised Weighted Concatenation of Source Embeddings. (arXiv:2204.12386v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12386">
<div class="article-summary-box-inner">
<span><p>Given multiple source word embeddings learnt using diverse algorithms and
lexical resources, meta word embedding learning methods attempt to learn more
accurate and wide-coverage word embeddings.
</p>
<p>Prior work on meta-embedding has repeatedly discovered that simple vector
concatenation of the source embeddings to be a competitive baseline.
</p>
<p>However, it remains unclear as to why and when simple vector concatenation
can produce accurate meta-embeddings.
</p>
<p>We show that weighted concatenation can be seen as a spectrum matching
operation between each source embedding and the meta-embedding, minimising the
pairwise inner-product loss.
</p>
<p>Following this theoretical analysis, we propose two \emph{unsupervised}
methods to learn the optimal concatenation weights for creating meta-embeddings
from a given set of source embeddings.
</p>
<p>Experimental results on multiple benchmark datasets show that the proposed
weighted concatenated meta-embedding methods outperform previously proposed
meta-embedding learning methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disambiguation of morpho-syntactic features of African American English -- the case of habitual be. (arXiv:2204.12421v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12421">
<div class="article-summary-box-inner">
<span><p>Recent research has highlighted that natural language processing (NLP)
systems exhibit a bias against African American speakers. The bias errors are
often caused by poor representation of linguistic features unique to African
American English (AAE), due to the relatively low probability of occurrence of
many such features in training data. We present a workflow to overcome such
bias in the case of habitual "be". Habitual "be" is isomorphic, and therefore
ambiguous, with other forms of "be" found in both AAE and other varieties of
English. This creates a clear challenge for bias in NLP technologies. To
overcome the scarcity, we employ a combination of rule-based filters and data
augmentation that generate a corpus balanced between habitual and non-habitual
instances. With this balanced corpus, we train unbiased machine learning
classifiers, as demonstrated on a corpus of AAE transcribed texts, achieving
.65 F$_1$ score disambiguating habitual "be".
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Event Detection Explorer: An Interactive Tool for Event Detection Exploration. (arXiv:2204.12456v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12456">
<div class="article-summary-box-inner">
<span><p>Event Detection (ED) is an important task in natural language processing. In
the past few years, many datasets have been introduced for advancing ED machine
learning models. However, most of these datasets are under-explored because not
many tools are available for people to study events, trigger words, and event
mention instances systematically and efficiently. In this paper, we present an
interactive and easy-to-use tool, namely ED Explorer, for ED dataset and model
exploration. ED Explorer consists of an interactive web application, an API,
and an NLP toolkit, which can help both domain experts and non-experts to
better understand the ED task. We use ED Explorer to analyze a recent proposed
large-scale ED datasets (referred to as MAVEN), and discover several underlying
problems, including sparsity, label bias, label imbalance, and debatable
annotations, which provide us with directions to improve the MAVEN dataset. The
ED Explorer can be publicly accessed through <a href="http://edx.leafnlp.org/.">this http URL</a> The
demonstration video is available here
https://www.youtube.com/watch?v=6QPnxPwxg50.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Hyperbolic Geometry Back to Word Embeddings. (arXiv:2204.12481v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12481">
<div class="article-summary-box-inner">
<span><p>We choose random points in the hyperbolic disc and claim that these points
are already word representations. However, it is yet to be uncovered which
point corresponds to which word of the human language of interest. This
correspondence can be approximately established using a pointwise mutual
information between words and recent alignment techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Large-Scale Chinese Short-Text Conversation Dataset. (arXiv:2008.03946v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.03946">
<div class="article-summary-box-inner">
<span><p>The advancements of neural dialogue generation models show promising results
on modeling short-text conversations. However, training such models usually
needs a large-scale high-quality dialogue corpus, which is hard to access. In
this paper, we present a large-scale cleaned Chinese conversation dataset,
LCCC, which contains a base version (6.8million dialogues) and a large version
(12.0 million dialogues). The quality of our dataset is ensured by a rigorous
data cleaning pipeline, which is built based on a set of rules and a classifier
that is trained on manually annotated 110K dialogue pairs. We also release
pre-training dialogue models which are trained on LCCC-base and LCCC-large
respectively. The cleaned dataset and the pre-training models will facilitate
the research of short-text conversation modeling. All the models and datasets
are available at https://github.com/thu-coai/CDial-GPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Inheritance for Pre-trained Language Models. (arXiv:2105.13880v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13880">
<div class="article-summary-box-inner">
<span><p>Recent explorations of large-scale pre-trained language models (PLMs) have
revealed the power of PLMs with huge amounts of parameters, setting off a wave
of training ever-larger PLMs. However, it requires tremendous computational
resources to train a large-scale PLM, which may be practically unaffordable. In
addition, existing large-scale PLMs are mainly trained from scratch
individually, ignoring that many well-trained PLMs are available. To this end,
we explore the question how could existing PLMs benefit training large-scale
PLMs in future. Specifically, we introduce a pre-training framework named
"knowledge inheritance" (KI) and explore how could knowledge distillation serve
as auxiliary supervision during pre-training to efficiently learn larger PLMs.
Experimental results demonstrate the superiority of KI in training efficiency.
We also conduct empirical analyses to explore the effects of teacher PLMs'
pre-training settings, including model architecture, pre-training data, etc.
Finally, we show that KI could be applied to domain adaptation and knowledge
transfer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rejuvenating Low-Frequency Words: Making the Most of Parallel Data in Non-Autoregressive Translation. (arXiv:2106.00903v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00903">
<div class="article-summary-box-inner">
<span><p>Knowledge distillation (KD) is commonly used to construct synthetic data for
training non-autoregressive translation (NAT) models. However, there exists a
discrepancy on low-frequency words between the distilled and the original data,
leading to more errors on predicting low-frequency words. To alleviate the
problem, we directly expose the raw data into NAT by leveraging pretraining. By
analyzing directed alignments, we found that KD makes low-frequency source
words aligned with targets more deterministically but fails to align sufficient
low-frequency words from target to source. Accordingly, we propose reverse KD
to rejuvenate more alignments for low-frequency target words. To make the most
of authentic and synthetic data, we combine these complementary approaches as a
new training strategy for further boosting NAT performance. We conduct
experiments on five translation benchmarks over two advanced architectures.
Results demonstrate that the proposed approach can significantly and
universally improve translation quality by reducing translation errors on
low-frequency words. Encouragingly, our approach achieves 28.2 and 33.9 BLEU
points on the WMT14 English-German and WMT16 Romanian-English datasets,
respectively. Our code, data, and trained models are available at
\url{https://github.com/alphadl/RLFW-NAT}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tell Me How to Survey: Literature Review Made Simple with Automatic Reading Path Generation. (arXiv:2110.06354v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06354">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed the dramatic growth of paper volumes with plenty
of new research papers published every day, especially in the area of computer
science. How to glean papers worth reading from the massive literature to do a
quick survey or keep up with the latest advancement about a specific research
topic has become a challenging task. Existing academic search engines such as
Google Scholar return relevant papers by individually calculating the relevance
between each paper and query. However, such systems usually omit the
prerequisite chains of a research topic and cannot form a meaningful reading
path. In this paper, we introduce a new task named Reading Path Generation
(RPG) which aims at automatically producing a path of papers to read for a
given query. To serve as a research benchmark, we further propose SurveyBank, a
dataset consisting of large quantities of survey papers in the field of
computer science as well as their citation relationships. Each survey paper
contains key phrases extracted from its title and multi-level reading lists
inferred from its references. Furthermore, we propose a
graph-optimization-based approach for reading path generation which takes the
relationship between papers into account. Extensive evaluations demonstrate
that our approach outperforms other baselines. A Real-time Reading Path
Generation System (RePaGer) has been also implemented with our designed model.
To the best of our knowledge, we are the first to target this important
research problem. Our source code of RePaGer system and SurveyBank dataset can
be found on here.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Curriculum Learning for AMR Parsing. (arXiv:2110.07855v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07855">
<div class="article-summary-box-inner">
<span><p>Abstract Meaning Representation (AMR) parsing aims to translate sentences to
semantic representation with a hierarchical structure, and is recently
empowered by pretrained sequence-to-sequence models. However, there exists a
gap between their flat training objective (i.e., equally treats all output
tokens) and the hierarchical AMR structure, which limits the model
generalization. To bridge this gap, we propose a Hierarchical Curriculum
Learning (HCL) framework with Structure-level (SC) and Instance-level Curricula
(IC). SC switches progressively from core to detail AMR semantic elements while
IC transits from structure-simple to -complex AMR instances during training.
Through these two warming-up processes, HCL reduces the difficulty of learning
complex structures, thus the flat model can better adapt to the AMR hierarchy.
Extensive experiments on AMR2.0, AMR3.0, structure-complex and
out-of-distribution situations verify the effectiveness of HCL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Don't speak too fast: The impact of data bias on self-supervised speech models. (arXiv:2110.07957v3 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07957">
<div class="article-summary-box-inner">
<span><p>Self-supervised Speech Models (S3Ms) have been proven successful in many
speech downstream tasks, like ASR. However, how pre-training data affects S3Ms'
downstream behavior remains an unexplored issue. In this paper, we study how
pre-training data affects S3Ms by pre-training models on biased datasets
targeting different factors of speech, including gender, content, and prosody,
and evaluate these pre-trained S3Ms on selected downstream tasks in SUPERB
Benchmark. Our experiments show that S3Ms have tolerance toward gender bias.
Moreover, we find that the content of speech has little impact on the
performance of S3Ms across downstream tasks, but S3Ms do show a preference
toward a slower speech rate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Self-Rationalization with Natural Language Prompts. (arXiv:2111.08284v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.08284">
<div class="article-summary-box-inner">
<span><p>Self-rationalization models that predict task labels and generate free-text
elaborations for their predictions could enable more intuitive interaction with
NLP systems. These models are, however, currently trained with a large amount
of human-written free-text explanations for each task which hinders their
broader usage. We propose to study a more realistic setting of
self-rationalization using few training examples. We present FEB -- a
standardized collection of four existing English-language datasets and
associated metrics. We identify the right prompting approach by extensively
exploring natural language prompts on FEB. Then, by using this prompt and
scaling the model size, we demonstrate that making progress on few-shot
self-rationalization is possible. We show there is still ample room for
improvement in this task: the average plausibility of generated explanations
assessed by human annotators is at most 51% (with GPT-3), while plausibility of
human explanations is 76%. We hope that FEB and our proposed approach will spur
the community to take on the few-shot self-rationalization challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">High Quality Rather than High Model Probability: Minimum Bayes Risk Decoding with Neural Metrics. (arXiv:2111.09388v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.09388">
<div class="article-summary-box-inner">
<span><p>In Neural Machine Translation, it is typically assumed that the sentence with
the highest estimated probability should also be the translation with the
highest quality as measured by humans. In this work, we question this
assumption and show that model estimates and translation quality only vaguely
correlate. We apply Minimum Bayes Risk (MBR) decoding on unbiased samples to
optimize diverse automated metrics of translation quality as an alternative
inference strategy to beam search. Instead of targeting the hypotheses with the
highest model probability, MBR decoding extracts the hypotheses with the
highest estimated quality. Our experiments show that the combination of a
neural translation model with a neural reference-based metric, BLEURT, results
in significant improvement in human evaluations. This improvement is obtained
with translations different from classical beam-search output: these
translations have much lower model likelihood and are less favored by surface
metrics like BLEU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SLUE: New Benchmark Tasks for Spoken Language Understanding Evaluation on Natural Speech. (arXiv:2111.10367v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.10367">
<div class="article-summary-box-inner">
<span><p>Progress in speech processing has been facilitated by shared datasets and
benchmarks. Historically these have focused on automatic speech recognition
(ASR), speaker identification, or other lower-level tasks. Interest has been
growing in higher-level spoken language understanding tasks, including using
end-to-end models, but there are fewer annotated datasets for such tasks. At
the same time, recent work shows the possibility of pre-training generic
representations and then fine-tuning for several tasks using relatively little
labeled data. We propose to create a suite of benchmark tasks for Spoken
Language Understanding Evaluation (SLUE) consisting of limited-size labeled
training sets and corresponding evaluation sets. This resource would allow the
research community to track progress, evaluate pre-trained representations for
higher-level tasks, and study open questions such as the utility of pipeline
versus end-to-end approaches. We present the first phase of the SLUE benchmark
suite, consisting of named entity recognition, sentiment analysis, and ASR on
the corresponding datasets. We focus on naturally produced (not read or
synthesized) speech, and freely available datasets. We provide new
transcriptions and annotations on subsets of the VoxCeleb and VoxPopuli
datasets, evaluation metrics and results for baseline models, and an
open-source toolkit to reproduce the baselines and evaluate new models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Surfer100: Generating Surveys From Web Resources, Wikipedia-style. (arXiv:2112.06377v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06377">
<div class="article-summary-box-inner">
<span><p>Fast-developing fields such as Artificial Intelligence (AI) often outpace the
efforts of encyclopedic sources such as Wikipedia, which either do not
completely cover recently-introduced topics or lack such content entirely. As a
result, methods for automatically producing content are valuable tools to
address this information overload. We show that recent advances in pretrained
language modeling can be combined for a two-stage extractive and abstractive
approach for Wikipedia lead paragraph generation. We extend this approach to
generate longer Wikipedia-style summaries with sections and examine how such
methods struggle in this application through detailed studies with 100
reference human-collected surveys. This is the first study on utilizing web
resources for long Wikipedia-style summaries to the best of our knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Unified Approach to Entity-Centric Context Tracking in Social Conversations. (arXiv:2201.12409v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.12409">
<div class="article-summary-box-inner">
<span><p>In human-human conversations, Context Tracking deals with identifying
important entities and keeping track of their properties and relationships.
This is a challenging problem that encompasses several subtasks such as slot
tagging, coreference resolution, resolving plural mentions and entity linking.
We approach this problem as an end-to-end modeling task where the
conversational context is represented by an entity repository containing the
entity references mentioned so far, their properties and the relationships
between them. The repository is updated turn-by-turn, thus making training and
inference computationally efficient even for long conversations. This paper
lays the groundwork for an investigation of this framework in two ways. First,
we release Contrack, a large scale human-human conversation corpus for context
tracking with people and location annotations. It contains over 7000
conversations with an average of 11.8 turns, 5.8 entities and 15.2 references
per conversation. Second, we open-source a neural network architecture for
context tracking. Finally we compare this network to state-of-the-art
approaches for the subtasks it subsumes and report results on the involved
tradeoffs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Direct parsing to sentiment graphs. (arXiv:2203.13209v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.13209">
<div class="article-summary-box-inner">
<span><p>This paper demonstrates how a graph-based semantic parser can be applied to
the task of structured sentiment analysis, directly predicting sentiment graphs
from text. We advance the state of the art on 4 out of 5 standard benchmark
sets. We release the source code, models and predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CharacterBERT and Self-Teaching for Improving the Robustness of Dense Retrievers on Queries with Typos. (arXiv:2204.00716v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.00716">
<div class="article-summary-box-inner">
<span><p>Current dense retrievers are not robust to out-of-domain and outlier queries,
i.e. their effectiveness on these queries is much poorer than what one would
expect. In this paper, we consider a specific instance of such queries: queries
that contain typos. We show that a small character level perturbation in
queries (as caused by typos) highly impacts the effectiveness of dense
retrievers. We then demonstrate that the root cause of this resides in the
input tokenization strategy employed by BERT. In BERT, tokenization is
performed using the BERT's WordPiece tokenizer and we show that a token with a
typo will significantly change the token distributions obtained after
tokenization. This distribution change translates to changes in the input
embeddings passed to the BERT-based query encoder of dense retrievers. We then
turn our attention to devising dense retriever methods that are robust to such
queries with typos, while still being as performant as previous methods on
queries without typos. For this, we use CharacterBERT as the backbone encoder
and an efficient yet effective training method, called Self-Teaching (ST), that
distills knowledge from queries without typos into the queries with typos.
Experimental results show that CharacterBERT in combination with ST achieves
significantly higher effectiveness on queries with typos compared to previous
methods. Along with these results and the open-sourced implementation of the
methods, we also provide a new passage retrieval dataset consisting of
real-world queries with typos and associated relevance assessments on the MS
MARCO corpus, thus supporting the research community in the investigation of
effective and robust dense retrievers. Code, experimental results and dataset
are made available at https://github.com/ielab/CharacterBERT-DR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PERFECT: Prompt-free and Efficient Few-shot Learning with Language Models. (arXiv:2204.01172v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.01172">
<div class="article-summary-box-inner">
<span><p>Current methods for few-shot fine-tuning of pretrained masked language models
(PLMs) require carefully engineered prompts and verbalizers for each new task
to convert examples into a cloze-format that the PLM can score. In this work,
we propose PERFECT, a simple and efficient method for few-shot fine-tuning of
PLMs without relying on any such handcrafting, which is highly effective given
as few as 32 data points. PERFECT makes two key design choices: First, we show
that manually engineered task prompts can be replaced with task-specific
adapters that enable sample-efficient fine-tuning and reduce memory and storage
costs by roughly factors of 5 and 100, respectively. Second, instead of using
handcrafted verbalizers, we learn new multi-token label embeddings during
fine-tuning, which are not tied to the model vocabulary and which allow us to
avoid complex auto-regressive decoding. These embeddings are not only learnable
from limited data but also enable nearly 100x faster training and inference.
Experiments on a wide range of few-shot NLP tasks demonstrate that PERFECT,
while being simple and efficient, also outperforms existing state-of-the-art
few-shot learning methods. Our code is publicly available at
https://github.com/facebookresearch/perfect.git.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LaMemo: Language Modeling with Look-Ahead Memory. (arXiv:2204.07341v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.07341">
<div class="article-summary-box-inner">
<span><p>Although Transformers with fully connected self-attentions are powerful to
model long-term dependencies, they are struggling to scale to long texts with
thousands of words in language modeling. One of the solutions is to equip the
model with a recurrence memory. However, existing approaches directly reuse
hidden states from the previous segment that encodes contexts in a
uni-directional way. As a result, this prohibits the memory to dynamically
interact with the current context that provides up-to-date information for
token prediction. To remedy this issue, we propose Look-Ahead Memory (LaMemo)
that enhances the recurrence memory by incrementally attending to the
right-side tokens, and interpolating with the old memory states to maintain
long-term information in the history. LaMemo embraces bi-directional attention
and segment recurrence with an additional computation overhead only linearly
proportional to the memory length. Experiments on widely used language modeling
benchmarks demonstrate its superiority over the baselines equipped with
different types of memory.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Doctor XAvIer: Explainable Diagnosis on Physician-Patient Dialogues and XAI Evaluation. (arXiv:2204.10178v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.10178">
<div class="article-summary-box-inner">
<span><p>We introduce Doctor XAvIer, a BERT-based diagnostic system that extracts
relevant clinical data from transcribed patient-doctor dialogues and explains
predictions using feature attribution methods. We present a novel performance
plot and evaluation metric for feature attribution methods: Feature Attribution
Dropping (FAD) curve and its Normalized Area Under the Curve (N-AUC). FAD curve
analysis shows that integrated gradients outperforms Shapley values in
explaining diagnosis classification. Doctor XAvIer outperforms the baseline
with 0.97 F1-score in named entity recognition and symptom pertinence
classification and 0.91 F1-score in diagnosis classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Locally Aggregated Feature Attribution on Natural Language Model Understanding. (arXiv:2204.10893v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.10893">
<div class="article-summary-box-inner">
<span><p>With the growing popularity of deep-learning models, model understanding
becomes more important. Much effort has been devoted to demystify deep neural
networks for better interpretability. Some feature attribution methods have
shown promising results in computer vision, especially the gradient-based
methods where effectively smoothing the gradients with reference data is key to
a robust and faithful result. However, direct application of these
gradient-based methods to NLP tasks is not trivial due to the fact that the
input consists of discrete tokens and the "reference" tokens are not explicitly
defined. In this work, we propose Locally Aggregated Feature Attribution
(LAFA), a novel gradient-based feature attribution method for NLP models.
Instead of relying on obscure reference tokens, it smooths gradients by
aggregating similar reference texts derived from language model embeddings. For
evaluation purpose, we also design experiments on different NLP tasks including
Entity Recognition and Sentiment Analysis on public datasets as well as key
feature detection on a constructed Amazon catalogue dataset. The superior
performance of the proposed method is demonstrated through experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multi-level Alignment Training Scheme for Video-and-Language Grounding. (arXiv:2204.10938v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.10938">
<div class="article-summary-box-inner">
<span><p>To solve video-and-language grounding tasks, the key is for the network to
understand the connection between the two modalities. For a pair of video and
language description, their semantic relation is reflected by their encodings'
similarity. A good multi-modality encoder should be able to well capture both
inputs' semantics and encode them in the shared feature space where embedding
distance gets properly translated into their semantic similarity. In this work,
we focused on this semantic connection between video and language, and
developed a multi-level alignment training scheme to directly shape the
encoding process. Global and segment levels of video-language alignment pairs
were designed, based on the information similarity ranging from high-level
context to fine-grained semantics. The contrastive loss was used to contrast
the encodings' similarities between the positive and negative alignment pairs,
and to ensure the network is trained in such a way that similar information is
encoded closely in the shared feature space while information of different
semantics is kept apart. Our multi-level alignment training can be applied to
various video-and-language grounding tasks. Together with the task-specific
training loss, our framework achieved comparable performance to previous
state-of-the-arts on multiple video QA and retrieval datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Translation between Molecules and Natural Language. (arXiv:2204.11817v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11817">
<div class="article-summary-box-inner">
<span><p>Joint representations between images and text have been deeply investigated
in the literature. In computer vision, the benefits of incorporating natural
language have become clear for enabling semantic-level control of images. In
this work, we present $\textbf{MolT5}-$a self-supervised learning framework for
pretraining models on a vast amount of unlabeled natural language text and
molecule strings. $\textbf{MolT5}$ allows for new, useful, and challenging
analogs of traditional vision-language tasks, such as molecule captioning and
text-based de novo molecule generation (altogether: translation between
molecules and language), which we explore for the first time. Furthermore,
since $\textbf{MolT5}$ pretrains models on single-modal data, it helps overcome
the chemistry domain shortcoming of data scarcity. Additionally, we consider
several metrics, including a new cross-modal embedding-based metric, to
evaluate the tasks of molecule captioning and text-based molecule generation.
By interfacing molecules with natural language, we enable a higher semantic
level of control over molecule discovery and understanding--a critical task for
scientific domains such as drug discovery and material design. Our results show
that $\textbf{MolT5}$-based models are able to generate outputs, both molecule
and text, which in many cases are high quality and match the input modality. On
molecule generation, our best model achieves 30% exact matching test accuracy
(i.e., it generates the correct structure for about one-third of the captions
in our held-out test set).
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">A Closer Look at Personalization in Federated Image Classification. (arXiv:2204.11841v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11841">
<div class="article-summary-box-inner">
<span><p>Federated Learning (FL) is developed to learn a single global model across
the decentralized data, while is susceptible when realizing client-specific
personalization in the presence of statistical heterogeneity. However, studies
focus on learning a robust global model or personalized classifiers, which
yield divergence due to inconsistent objectives. This paper shows that it is
possible to achieve flexible personalization after the convergence of the
global model by introducing representation learning. In this paper, we first
analyze and determine that non-IID data harms representation learning of the
global model. Existing FL methods adhere to the scheme of jointly learning
representations and classifiers, where the global model is an average of
classification-based local models that are consistently subject to
heterogeneity from non-IID data. As a solution, we separate representation
learning from classification learning in FL and propose RepPer, an independent
two-stage personalized FL framework.We first learn the client-side feature
representation models that are robust to non-IID data and aggregate them into a
global common representation model. After that, we achieve personalization by
learning a classifier head for each client, based on the common representation
obtained at the former stage. Notably, the proposed two-stage learning scheme
of RepPer can be potentially used for lightweight edge computing that involves
devices with constrained computation power.Experiments on various datasets
(CIFAR-10/100, CINIC-10) and heterogeneous data setup show that RepPer
outperforms alternatives in flexibility and personalization on non-IID data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Leveraging Variational Graph Embeddings for Open World Compositional Zero-Shot Learning. (arXiv:2204.11848v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11848">
<div class="article-summary-box-inner">
<span><p>Humans are able to identify and categorize novel compositions of known
concepts. The task in Compositional Zero-Shot learning (CZSL) is to learn
composition of primitive concepts, i.e. objects and states, in such a way that
even their novel compositions can be zero-shot classified. In this work, we do
not assume any prior knowledge on the feasibility of novel compositions
i.e.open-world setting, where infeasible compositions dominate the search
space. We propose a Compositional Variational Graph Autoencoder (CVGAE)
approach for learning the variational embeddings of the primitive concepts
(nodes) as well as feasibility of their compositions (via edges). Such
modelling makes CVGAE scalable to real-world application scenarios. This is in
contrast to SOTA method, CGE, which is computationally very expensive. e.g.for
benchmark C-GQA dataset, CGE requires 3.94 x 10^5 nodes, whereas CVGAE requires
only 1323 nodes. We learn a mapping of the graph and image embeddings onto a
common embedding space. CVGAE adopts a deep metric learning approach and learns
a similarity metric in this space via bi-directional contrastive loss between
projected graph and image embeddings. We validate the effectiveness of our
approach on three benchmark datasets.We also demonstrate via an image retrieval
task that the representations learnt by CVGAE are better suited for
compositional generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real or Virtual: A Video Conferencing Background Manipulation-Detection System. (arXiv:2204.11853v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11853">
<div class="article-summary-box-inner">
<span><p>Recently, the popularity and wide use of the last-generation video
conferencing technologies created an exponential growth in its market size.
Such technology allows participants in different geographic regions to have a
virtual face-to-face meeting. Additionally, it enables users to employ a
virtual background to conceal their own environment due to privacy concerns or
to reduce distractions, particularly in professional settings. Nevertheless, in
scenarios where the users should not hide their actual locations, they may
mislead other participants by claiming their virtual background as a real one.
Therefore, it is crucial to develop tools and strategies to detect the
authenticity of the considered virtual background. In this paper, we present a
detection strategy to distinguish between real and virtual video conferencing
user backgrounds. We demonstrate that our detector is robust against two attack
scenarios. The first scenario considers the case where the detector is unaware
about the attacks and inn the second scenario, we make the detector aware of
the adversarial attacks, which we refer to Adversarial Multimedia Forensics
(i.e, the forensically-edited frames are included in the training set). Given
the lack of publicly available dataset of virtual and real backgrounds for
video conferencing, we created our own dataset and made them publicly available
[1]. Then, we demonstrate the robustness of our detector against different
adversarial attacks that the adversary considers. Ultimately, our detector's
performance is significant against the CRSPAM1372 [2] features, and
post-processing operations such as geometric transformations with different
quality factors that the attacker may choose. Moreover, our performance results
shows that we can perfectly identify a real from a virtual background with an
accuracy of 99.80%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evolutionary latent space search for driving human portrait generation. (arXiv:2204.11887v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11887">
<div class="article-summary-box-inner">
<span><p>This article presents an evolutionary approach for synthetic human portraits
generation based on the latent space exploration of a generative adversarial
network. The idea is to produce different human face images very similar to a
given target portrait. The approach applies StyleGAN2 for portrait generation
and FaceNet for face similarity evaluation. The evolutionary search is based on
exploring the real-coded latent space of StyleGAN2. The main results over both
synthetic and real images indicate that the proposed approach generates
accurate and diverse solutions, which represent realistic human portraits. The
proposed research can contribute to improving the security of face recognition
systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ProCST: Boosting Semantic Segmentation using Progressive Cyclic Style-Transfer. (arXiv:2204.11891v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11891">
<div class="article-summary-box-inner">
<span><p>Using synthetic data for training neural networks that achieve good
performance on real-world data is an important task as it has the potential to
reduce the need for costly data annotation. Yet, a network that is trained on
synthetic data alone does not perform well on real data due to the domain gap
between the two. Reducing this gap, also known as domain adaptation, has been
widely studied in recent years. In the unsupervised domain adaptation (UDA)
framework, unlabeled real data is used during training with labeled synthetic
data to obtain a neural network that performs well on real data. In this work,
we focus on image data. For the semantic segmentation task, it has been shown
that performing image-to-image translation from source to target, and then
training a network for segmentation on source annotations - leads to poor
results. Therefore a joint training of both is essential, which has been a
common practice in many techniques. Yet, closing the large domain gap between
the source and the target by directly performing the adaptation between the two
is challenging. In this work, we propose a novel two-stage framework for
improving domain adaptation techniques. In the first step, we progressively
train a multi-scale neural network to perform an initial transfer between the
source data to the target data. We denote the new transformed data as "Source
in Target" (SiT). Then, we use the generated SiT data as the input to any
standard UDA approach. This new data has a reduced domain gap from the desired
target domain, and the applied UDA approach further closes the gap. We
demonstrate the improvement achieved by our framework with two state-of-the-art
methods for semantic segmentation, DAFormer and ProDA, on two UDA tasks, GTA5
to Cityscapes and Synthia to Cityscapes. Code and state-of-the-art checkpoints
of ProCST+DAFormer are provided.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DArch: Dental Arch Prior-assisted 3D Tooth Instance Segmentation. (arXiv:2204.11911v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11911">
<div class="article-summary-box-inner">
<span><p>Automatic tooth instance segmentation on 3D dental models is a fundamental
task for computer-aided orthodontic treatments. Existing learning-based methods
rely heavily on expensive point-wise annotations. To alleviate this problem, we
are the first to explore a low-cost annotation way for 3D tooth instance
segmentation, i.e., labeling all tooth centroids and only a few teeth for each
dental model. Regarding the challenge when only weak annotation is provided, we
present a dental arch prior-assisted 3D tooth segmentation method, namely
DArch. Our DArch consists of two stages, including tooth centroid detection and
tooth instance segmentation. Accurately detecting the tooth centroids can help
locate the individual tooth, thus benefiting the segmentation. Thus, our DArch
proposes to leverage the dental arch prior to assist the detection.
Specifically, we firstly propose a coarse-to-fine method to estimate the dental
arch, in which the dental arch is initially generated by Bezier curve
regression, and then a graph-based convolutional network (GCN) is trained to
refine it. With the estimated dental arch, we then propose a novel Arch-aware
Point Sampling (APS) method to assist the tooth centroid proposal generation.
Meantime, a segmentor is independently trained using a patch-based training
strategy, aiming to segment a tooth instance from a 3D patch centered at the
tooth centroid. Experimental results on $4,773$ dental models have shown our
DArch can accurately segment each tooth of a dental model, and its performance
is superior to the state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Temporal Relevance Analysis for Video Action Models. (arXiv:2204.11929v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11929">
<div class="article-summary-box-inner">
<span><p>In this paper, we provide a deep analysis of temporal modeling for action
recognition, an important but underexplored problem in the literature. We first
propose a new approach to quantify the temporal relationships between frames
captured by CNN-based action models based on layer-wise relevance propagation.
We then conduct comprehensive experiments and in-depth analysis to provide a
better understanding of how temporal modeling is affected by various factors
such as dataset, network architecture, and input frames. With this, we further
study some important questions for action recognition that lead to interesting
findings. Our analysis shows that there is no strong correlation between
temporal relevance and model performance; and action models tend to capture
local temporal information, but less long-range dependencies. Our codes and
models will be publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Dual-Graph Regularized Moving Object Detection. (arXiv:2204.11939v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11939">
<div class="article-summary-box-inner">
<span><p>Moving object detection and its associated background-foreground separation
have been widely used in a lot of applications, including computer vision,
transportation and surveillance. Due to the presence of the static background,
a video can be naturally decomposed into a low-rank background and a sparse
foreground. Many regularization techniques, such as matrix nuclear norm, have
been imposed on the background. In the meanwhile, sparsity or smoothness based
regularizations, such as total variation and $\ell_1$, can be imposed on the
foreground. Moreover, graph Laplacians are further imposed to capture the
complicated geometry of background images. Recently, weighted regularization
techniques including the weighted nuclear norm regularization have been
proposed in the image processing community to promote adaptive sparsity while
achieving efficient performance. In this paper, we propose a robust dual-graph
regularized moving object detection model based on the weighted nuclear norm
regularization, which is solved by the alternating direction method of
multipliers (ADMM). Numerical experiments on body movement data sets have
demonstrated the effectiveness of this method in separating moving objects from
background, and the great potential in robotic applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SceneTrilogy: On Scene Sketches and its Relationship with Text and Photo. (arXiv:2204.11964v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11964">
<div class="article-summary-box-inner">
<span><p>We for the first time extend multi-modal scene understanding to include that
of free-hand scene sketches. This uniquely results in a trilogy of scene data
modalities (sketch, text, and photo), where each offers unique perspectives for
scene understanding, and together enable a series of novel scene-specific
applications across discriminative (retrieval) and generative (captioning)
tasks. Our key objective is to learn a common three-way embedding space that
enables many-to-many modality interactions (e.g, sketch+text $\rightarrow$
photo retrieval). We importantly leverage the information bottleneck theory to
achieve this goal, where we (i) decouple intra-modality information by
minimising the mutual information between modality-specific and
modality-agnostic components via a conditional invertible neural network, and
(ii) align \textit{cross-modalities information} by maximising the mutual
information between their modality-agnostic components using InfoNCE, with a
specific multihead attention mechanism to allow many-to-many modality
interactions. We spell out a few insights on the complementarity of each
modality for scene understanding, and study for the first time a series of
scene-specific applications like joint sketch- and text-based image retrieval,
sketch captioning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual Acuity Prediction on Real-Life Patient Data Using a Machine Learning Based Multistage System. (arXiv:2204.11970v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11970">
<div class="article-summary-box-inner">
<span><p>In ophthalmology, intravitreal operative medication therapy (IVOM) is
widespread treatment for diseases such as the age-related macular degeneration
(AMD), the diabetic macular edema (DME), as well as the retinal vein occlusion
(RVO). However, in real-world settings, patients often suffer from loss of
vision on time scales of years despite therapy, whereas the prediction of the
visual acuity (VA) and the earliest possible detection of deterioration under
real-life conditions is challenging due to heterogeneous and incomplete data.
In this contribution, we present a workflow for the development of a
research-compatible data corpus fusing different IT systems of the department
of ophthalmology of a German maximum care hospital. The extensive data corpus
allows predictive statements of the expected progression of a patient and his
or her VA in each of the three diseases. Within our proposed multistage system,
we classify the VA progression into the three groups of therapy "winners",
"stabilizers", and "losers" (WSL scheme). Our OCT biomarker classification
using an ensemble of deep neural networks results in a classification accuracy
(F1-score) of over 98 %, enabling us to complete incomplete OCT documentations
while allowing us to exploit them for a more precise VA modelling process. Our
VA prediction requires at least four VA examinations and optionally OCT
biomarkers from the same time period to predict the VA progression within a
forecasted time frame. While achieving a prediction accuracy of up to 69 %
(macro average F1-score) when considering all three WSL-based progression
groups, this corresponds to an improvement by 11 % in comparison to our
ophthalmic expertise (58 %).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BronchoPose: an analysis of data and model configuration for vision-based bronchoscopy pose estimation. (arXiv:2204.11982v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11982">
<div class="article-summary-box-inner">
<span><p>Vision-based bronchoscopy (VB) models require the registration of the virtual
lung model with the frames from the video bronchoscopy to provide effective
guidance during the biopsy. The registration can be achieved by either tracking
the position and orientation of the bronchoscopy camera or by calibrating its
deviation from the pose (position and orientation) simulated in the virtual
lung model. Recent advances in neural networks and temporal image processing
have provided new opportunities for guided bronchoscopy. However, such progress
has been hindered by the lack of comparative experimental conditions.
</p>
<p>In the present paper, we share a novel synthetic dataset allowing for a fair
comparison of methods. Moreover, this paper investigates several neural network
architectures for the learning of temporal information at different levels of
subject personalization. In order to improve orientation measurement, we also
present a standardized comparison framework and a novel metric for camera
orientation learning. Results on the dataset show that the proposed metric and
architectures, as well as the standardized conditions, provide notable
improvements to current state-of-the-art camera pose estimation in video
bronchoscopy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive learning-based computational histopathology predict differential expression of cancer driver genes. (arXiv:2204.11994v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11994">
<div class="article-summary-box-inner">
<span><p>Digital pathological analysis is run as the main examination used for cancer
diagnosis. Recently, deep learning-driven feature extraction from pathology
images is able to detect genetic variations and tumor environment, but few
studies focus on differential gene expression in tumor cells. In this paper, we
propose a self-supervised contrastive learning framework, HistCode, to infer
differential gene expressions from whole slide images (WSIs). We leveraged
contrastive learning on large-scale unannotated WSIs to derive slide-level
histopathological feature in latent space, and then transfer it to tumor
diagnosis and prediction of differentially expressed cancer driver genes. Our
extensive experiments showed that our method outperformed other
state-of-the-art models in tumor diagnosis tasks, and also effectively
predicted differential gene expressions. Interestingly, we found the higher
fold-changed genes can be more precisely predicted. To intuitively illustrate
the ability to extract informative features from pathological images, we
spatially visualized the WSIs colored by the attentive scores of image tiles.
We found that the tumor and necrosis areas were highly consistent with the
annotations of experienced pathologists. Moreover, the spatial heatmap
generated by lymphocyte-specific gene expression patterns was also consistent
with the manually labeled WSI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing the ability of generative adversarial networks to learn canonical medical image statistics. (arXiv:2204.12007v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12007">
<div class="article-summary-box-inner">
<span><p>In recent years, generative adversarial networks (GANs) have gained
tremendous popularity for potential applications in medical imaging, such as
medical image synthesis, restoration, reconstruction, translation, as well as
objective image quality assessment. Despite the impressive progress in
generating high-resolution, perceptually realistic images, it is not clear if
modern GANs reliably learn the statistics that are meaningful to a downstream
medical imaging application. In this work, the ability of a state-of-the-art
GAN to learn the statistics of canonical stochastic image models (SIMs) that
are relevant to objective assessment of image quality is investigated. It is
shown that although the employed GAN successfully learned several basic first-
and second-order statistics of the specific medical SIMs under consideration
and generated images with high perceptual quality, it failed to correctly learn
several per-image statistics pertinent to the these SIMs, highlighting the
urgent need to assess medical image GANs in terms of objective measures of
image quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Estimating the Resize Parameter in End-to-end Learned Image Compression. (arXiv:2204.12022v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12022">
<div class="article-summary-box-inner">
<span><p>We describe a search-free resizing framework that can further improve the
rate-distortion tradeoff of recent learned image compression models. Our
approach is simple: compose a pair of differentiable downsampling/upsampling
layers that sandwich a neural compression model. To determine resize factors
for different inputs, we utilize another neural network jointly trained with
the compression model, with the end goal of minimizing the rate-distortion
objective. Our results suggest that "compression friendly" downsampled
representations can be quickly determined during encoding by using an auxiliary
network and differentiable image warping. By conducting extensive experimental
tests on existing deep image compression models, we show results that our new
resizing parameter estimation framework can provide Bj{\o}ntegaard-Delta rate
(BD-rate) improvement of about 10% against leading perceptual quality engines.
We also carried out a subjective quality study, the results of which show that
our new approach yields favorable compressed images. To facilitate reproducible
research in this direction, the implementation used in this paper is being made
freely available online at: https://github.com/treammm/ResizeCompression.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Information Fusion: Scaling Subspace-Driven Approaches. (arXiv:2204.12035v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12035">
<div class="article-summary-box-inner">
<span><p>In this work, we seek to exploit the deep structure of multi-modal data to
robustly exploit the group subspace distribution of the information using the
Convolutional Neural Network (CNN) formalism. Upon unfolding the set of
subspaces constituting each data modality, and learning their corresponding
encoders, an optimized integration of the generated inherent information is
carried out to yield a characterization of various classes. Referred to as deep
Multimodal Robust Group Subspace Clustering (DRoGSuRe), this approach is
compared against the independently developed state-of-the-art approach named
Deep Multimodal Subspace Clustering (DMSC). Experiments on different multimodal
datasets show that our approach is competitive and more robust in the presence
of noise.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causal Reasoning with Spatial-temporal Representation Learning: A Prospective Study. (arXiv:2204.12037v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12037">
<div class="article-summary-box-inner">
<span><p>Spatial-temporal representation learning is ubiquitous in various real-world
applications, including visual comprehension, video understanding, multi-modal
analysis, human-computer interaction, and urban computing. Due to the emergence
of huge amounts of multi-modal heterogeneous spatial/temporal/spatial-temporal
data in big data era, the existing visual methods rely heavily on large-scale
data annotations and supervised learning to learn a powerful big model.
However, the lack of interpretability, robustness, and out-of-distribution
generalization are becoming the bottleneck problems of these models, which
hinders the progress of interpretable and reliable artificial intelligence. The
majority of the existing methods are based on correlation learning with the
assumption that the data are independent and identically distributed, which
lack an unified guidance and analysis about why modern spatial-temporal
representation learning methods have limited interpretability and easily
collapse into dataset bias. Inspired by the strong inference ability of
human-level agents, recent years have therefore witnessed great effort in
developing causal reasoning paradigms to realize robust representation and
model learning with good interpretability. In this paper, we conduct a
comprehensive review of existing causal reasoning methods for spatial-temporal
representation learning, covering fundamental theories, models, and datasets.
The limitations of current methods and datasets are also discussed. Moreover,
we propose some primary challenges, opportunities, and future research
directions for benchmarking causal reasoning algorithms in spatial-temporal
representation learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Weighting Map for Bit-Depth Expansion within a Rational Range. (arXiv:2204.12039v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12039">
<div class="article-summary-box-inner">
<span><p>Bit-depth expansion (BDE) is one of the emerging technologies to display high
bit-depth (HBD) image from low bit-depth (LBD) source. Existing BDE methods
have no unified solution for various BDE situations, and directly learn a
mapping for each pixel from LBD image to the desired value in HBD image, which
may change the given high-order bits and lead to a huge deviation from the
ground truth. In this paper, we design a bit restoration network (BRNet) to
learn a weight for each pixel, which indicates the ratio of the replenished
value within a rational range, invoking an accurate solution without modifying
the given high-order bit information. To make the network adaptive for any
bit-depth degradation, we investigate the issue in an optimization perspective
and train the network under progressive training strategy for better
performance. Moreover, we employ Wasserstein distance as a visual quality
indicator to evaluate the difference of color distribution between restored
image and the ground truth. Experimental results show our method can restore
colorful images with fewer artifacts and false contours, and outperforms
state-of-the-art methods with higher PSNR/SSIM results and lower Wasserstein
distance. The source code will be made available at
https://github.com/yuqing-liu-dut/bit-depth-expansion
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-recoverable Adversarial Examples: A New Effective Protection Mechanism in Social Networks. (arXiv:2204.12050v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12050">
<div class="article-summary-box-inner">
<span><p>Malicious intelligent algorithms greatly threaten the security of social
users' privacy by detecting and analyzing the uploaded photos to social network
platforms. The destruction to DNNs brought by the adversarial attack sparks the
potential that adversarial examples serve as a new protection mechanism for
privacy security in social networks. However, the existing adversarial example
does not have recoverability for serving as an effective protection mechanism.
To address this issue, we propose a recoverable generative adversarial network
to generate self-recoverable adversarial examples. By modeling the adversarial
attack and recovery as a united task, our method can minimize the error of the
recovered examples while maximizing the attack ability, resulting in better
recoverability of adversarial examples. To further boost the recoverability of
these examples, we exploit a dimension reducer to optimize the distribution of
adversarial perturbation. The experimental results prove that the adversarial
examples generated by the proposed method present superior recoverability,
attack ability, and robustness on different datasets and network architectures,
which ensure its effectiveness as a protection mechanism in social networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Overview of Recent Work in Media Forensics: Methods and Threats. (arXiv:2204.12067v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12067">
<div class="article-summary-box-inner">
<span><p>In this paper, we review recent work in media forensics for digital images,
video, audio (specifically speech), and documents. For each data modality, we
discuss synthesis and manipulation techniques that can be used to create and
modify digital media. We then review technological advancements for detecting
and quantifying such manipulations. Finally, we consider open issues and
suggest directions for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AAU-net: An Adaptive Attention U-net for Breast Lesions Segmentation in Ultrasound Images. (arXiv:2204.12077v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12077">
<div class="article-summary-box-inner">
<span><p>Various deep learning methods have been proposed to segment breast lesion
from ultrasound images. However, similar intensity distributions, variable
tumor morphology and blurred boundaries present challenges for breast lesions
segmentation, especially for malignant tumors with irregular shapes.
Considering the complexity of ultrasound images, we develop an adaptive
attention U-net (AAU-net) to segment breast lesions automatically and stably
from ultrasound images. Specifically, we introduce a hybrid adaptive attention
module, which mainly consists of a channel self-attention block and a spatial
self-attention block, to replace the traditional convolution operation.
Compared with the conventional convolution operation, the design of the hybrid
adaptive attention module can help us capture more features under different
receptive fields. Different from existing attention mechanisms, the hybrid
adaptive attention module can guide the network to adaptively select more
robust representation in channel and space dimensions to cope with more complex
breast lesions segmentation. Extensive experiments with several
state-of-the-art deep learning segmentation methods on three public breast
ultrasound datasets show that our method has better performance on breast
lesion segmentation. Furthermore, robustness analysis and external experiments
demonstrate that our proposed AAU-net has better generalization performance on
the segmentation of breast lesions. Moreover, the hybrid adaptive attention
module can be flexibly applied to existing network frameworks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">U-Net with ResNet Backbone for Garment Landmarking Purpose. (arXiv:2204.12084v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12084">
<div class="article-summary-box-inner">
<span><p>We build a heatmap-based landmark detection model to locate important
landmarks on 2D RGB garment images. The main goal is to detect edges, corners
and suitable interior region of the garments. This let us re-create 3D garments
in modern 3D editing software by incorporate landmark detection model and
texture unwrapping. We use a U-net architecture with ResNet backbone to build
the model. With an appropriate loss function, we are able to train a moderately
robust model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Acquiring a Dynamic Light Field through a Single-Shot Coded Image. (arXiv:2204.12089v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12089">
<div class="article-summary-box-inner">
<span><p>We propose a method for compressively acquiring a dynamic light field (a 5-D
volume) through a single-shot coded image (a 2-D measurement). We designed an
imaging model that synchronously applies aperture coding and pixel-wise
exposure coding within a single exposure time. This coding scheme enables us to
effectively embed the original information into a single observed image. The
observed image is then fed to a convolutional neural network (CNN) for
light-field reconstruction, which is jointly trained with the camera-side
coding patterns. We also developed a hardware prototype to capture a real 3-D
scene moving over time. We succeeded in acquiring a dynamic light field with
5x5 viewpoints over 4 temporal sub-frames (100 views in total) from a single
observed image. Repeating capture and reconstruction processes over time, we
can acquire a dynamic light field at 4x the frame rate of the camera. To our
knowledge, our method is the first to achieve a finer temporal resolution than
the camera itself in compressive light-field acquisition. Our software is
available from our project webpage
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Dual-Pixel Alignment for Defocus Deblurring. (arXiv:2204.12105v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12105">
<div class="article-summary-box-inner">
<span><p>It is a challenging task to recover all-in-focus image from a single defocus
blurry image in real-world applications. On many modern cameras, dual-pixel
(DP) sensors create two-image views, based on which stereo information can be
exploited to benefit defocus deblurring. Despite existing DP defocus deblurring
methods achieving impressive results, they directly take naive concatenation of
DP views as input, while neglecting the disparity between left and right views
in the regions out of camera's depth of field (DoF). In this work, we propose a
Dual-Pixel Alignment Network (DPANet) for defocus deblurring. Generally, DPANet
is an encoder-decoder with skip-connections, where two branches with shared
parameters in the encoder are employed to extract and align deep features from
left and right views, and one decoder is adopted to fuse aligned features for
predicting the all-in-focus image. Due to that DP views suffer from different
blur amounts, it is not trivial to align left and right views. To this end, we
propose novel encoder alignment module (EAM) and decoder alignment module
(DAM). In particular, a correlation layer is suggested in EAM to measure the
disparity between DP views, whose deep features can then be accordingly aligned
using deformable convolutions. And DAM can further enhance the alignment of
skip-connected features from encoder and deep features in decoder. By
introducing several EAMs and DAMs, DP views in DPANet can be well aligned for
better predicting latent all-in-focus image. Experimental results on real-world
datasets show that our DPANet is notably superior to state-of-the-art
deblurring methods in reducing defocus blur while recovering visually plausible
sharp structures and textures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Instance-Specific Feature Propagation for Referring Segmentation. (arXiv:2204.12109v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12109">
<div class="article-summary-box-inner">
<span><p>Referring segmentation aims to generate a segmentation mask for the target
instance indicated by a natural language expression. There are typically two
kinds of existing methods: one-stage methods that directly perform segmentation
on the fused vision and language features; and two-stage methods that first
utilize an instance segmentation model for instance proposal and then select
one of these instances via matching them with language features. In this work,
we propose a novel framework that simultaneously detects the target-of-interest
via feature propagation and generates a fine-grained segmentation mask. In our
framework, each instance is represented by an Instance-Specific Feature (ISF),
and the target-of-referring is identified by exchanging information among all
ISFs using our proposed Feature Propagation Module (FPM). Our instance-aware
approach learns the relationship among all objects, which helps to better
locate the target-of-interest than one-stage methods. Comparing to two-stage
methods, our approach collaboratively and interactively utilizes both vision
and language information for synchronous identification and segmentation. In
the experimental tests, our method outperforms previous state-of-the-art
methods on all three RefCOCO series datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Maximum A Posteriori Estimation on Unpaired Data for Motion Deblurring. (arXiv:2204.12139v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12139">
<div class="article-summary-box-inner">
<span><p>Real-world dynamic scene deblurring has long been a challenging task since
paired blurry-sharp training data is unavailable. Conventional Maximum A
Posteriori estimation and deep learning-based deblurring methods are restricted
by handcrafted priors and synthetic blurry-sharp training pairs respectively,
thereby failing to generalize to real dynamic blurriness. To this end, we
propose a Neural Maximum A Posteriori (NeurMAP) estimation framework for
training neural networks to recover blind motion information and sharp content
from unpaired data. The proposed NeruMAP consists of a motion estimation
network and a deblurring network which are trained jointly to model the
(re)blurring process (i.e. likelihood function). Meanwhile, the motion
estimation network is trained to explore the motion information in images by
applying implicit dynamic motion prior, and in return enforces the deblurring
network training (i.e. providing sharp image prior). The proposed NeurMAP is an
orthogonal approach to existing deblurring neural networks, and is the first
framework that enables training image deblurring networks on unpaired datasets.
Experiments demonstrate our superiority on both quantitative metrics and visual
quality over state-of-the-art methods. Codes are available on
https://github.com/yjzhang96/NeurMAP-deblur.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deeper Insights into ViTs Robustness towards Common Corruptions. (arXiv:2204.12143v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12143">
<div class="article-summary-box-inner">
<span><p>Recent literature have shown design strategies from Convolutions Neural
Networks (CNNs) benefit Vision Transformers (ViTs) in various vision tasks.
However, it remains unclear how these design choices impact on robustness when
transferred to ViTs. In this paper, we make the first attempt to investigate
how CNN-like architectural designs and CNN-based data augmentation strategies
impact on ViTs' robustness towards common corruptions through an extensive and
rigorous benchmarking. We demonstrate that overlapping patch embedding and
convolutional Feed-Forward Network (FFN) boost performance on robustness.
Furthermore, adversarial noise training is powerful on ViTs while
fourier-domain augmentation fails. Moreover, we introduce a novel conditional
method enabling input-varied augmentations from two angles: (1) Generating
dynamic augmentation parameters conditioned on input images. It conduces to
state-of-the-art performance on robustness through conditional convolutions;
(2) Selecting most suitable augmentation strategy by an extra predictor helps
to achieve the best trade-off between clean accuracy and robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Where and What: Driver Attention-based Object Detection. (arXiv:2204.12150v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12150">
<div class="article-summary-box-inner">
<span><p>Human drivers use their attentional mechanisms to focus on critical objects
and make decisions while driving. As human attention can be revealed from gaze
data, capturing and analyzing gaze information has emerged in recent years to
benefit autonomous driving technology. Previous works in this context have
primarily aimed at predicting "where" human drivers look at and lack knowledge
of "what" objects drivers focus on. Our work bridges the gap between
pixel-level and object-level attention prediction. Specifically, we propose to
integrate an attention prediction module into a pretrained object detection
framework and predict the attention in a grid-based style. Furthermore,
critical objects are recognized based on predicted attended-to areas. We
evaluate our proposed method on two driver attention datasets, BDD-A and
DR(eye)VE. Our framework achieves competitive state-of-the-art performance in
the attention prediction on both pixel-level and object-level but is far more
efficient (75.3 GFLOPs less) in computation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ClothFormer:Taming Video Virtual Try-on in All Module. (arXiv:2204.12151v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12151">
<div class="article-summary-box-inner">
<span><p>The task of video virtual try-on aims to fit the target clothes to a person
in the video with spatio-temporal consistency. Despite tremendous progress of
image virtual try-on, they lead to inconsistency between frames when applied to
videos. Limited work also explored the task of video-based virtual try-on but
failed to produce visually pleasing and temporally coherent results. Moreover,
there are two other key challenges: 1) how to generate accurate warping when
occlusions appear in the clothing region; 2) how to generate clothes and
non-target body parts (e.g. arms, neck) in harmony with the complicated
background; To address them, we propose a novel video virtual try-on framework,
ClothFormer, which successfully synthesizes realistic, harmonious, and
spatio-temporal consistent results in complicated environment. In particular,
ClothFormer involves three major modules. First, a two-stage anti-occlusion
warping module that predicts an accurate dense flow mapping between the body
regions and the clothing regions. Second, an appearance-flow tracking module
utilizes ridge regression and optical flow correction to smooth the dense flow
sequence and generate a temporally smooth warped clothing sequence. Third, a
dual-stream transformer extracts and fuses clothing textures, person features,
and environment information to generate realistic try-on videos. Through
rigorous experiments, we demonstrate that our method highly surpasses the
baselines in terms of synthesized video quality both qualitatively and
quantitatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comparative Study on Approaches to Acoustic Scene Classification using CNNs. (arXiv:2204.12177v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12177">
<div class="article-summary-box-inner">
<span><p>Acoustic scene classification is a process of characterizing and classifying
the environments from sound recordings. The first step is to generate features
(representations) from the recorded sound and then classify the background
environments. However, different kinds of representations have dramatic effects
on the accuracy of the classification. In this paper, we explored the three
such representations on classification accuracy using neural networks. We
investigated the spectrograms, MFCCs, and embeddings representations using
different CNN networks and autoencoders. Our dataset consists of sounds from
three settings of indoors and outdoors environments - thus the dataset contains
sound from six different kinds of environments. We found that the spectrogram
representation has the highest classification accuracy while MFCC has the
lowest classification accuracy. We reported our findings, insights as well as
some guidelines to achieve better accuracy for environment classification using
sounds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TranSiam: Fusing Multimodal Visual Features Using Transformer for Medical Image Segmentation. (arXiv:2204.12185v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12185">
<div class="article-summary-box-inner">
<span><p>Automatic segmentation of medical images based on multi-modality is an
important topic for disease diagnosis. Although the convolutional neural
network (CNN) has been proven to have excellent performance in image
segmentation tasks, it is difficult to obtain global information. The lack of
global information will seriously affect the accuracy of the segmentation
results of the lesion area. In addition, there are visual representation
differences between multimodal data of the same patient. These differences will
affect the results of the automatic segmentation methods. To solve these
problems, we propose a segmentation method suitable for multimodal medical
images that can capture global information, named TranSiam. TranSiam is a 2D
dual path network that extracts features of different modalities. In each path,
we utilize convolution to extract detailed information in low level stage, and
design a ICMT block to extract global information in high level stage. ICMT
block embeds convolution in the transformer, which can extract global
information while retaining spatial and detailed information. Furthermore, we
design a novel fusion mechanism based on cross attention and selfattention,
called TMM block, which can effectively fuse features between different
modalities. On the BraTS 2019 and BraTS 2020 multimodal datasets, we have a
significant improvement in accuracy over other popular methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Stochastic Coherence Over Attention Trajectory For Continuous Learning In Video Streams. (arXiv:2204.12193v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12193">
<div class="article-summary-box-inner">
<span><p>Devising intelligent agents able to live in an environment and learn by
observing the surroundings is a longstanding goal of Artificial Intelligence.
From a bare Machine Learning perspective, challenges arise when the agent is
prevented from leveraging large fully-annotated dataset, but rather the
interactions with supervisory signals are sparsely distributed over space and
time. This paper proposes a novel neural-network-based approach to
progressively and autonomously develop pixel-wise representations in a video
stream. The proposed method is based on a human-like attention mechanism that
allows the agent to learn by observing what is moving in the attended
locations. Spatio-temporal stochastic coherence along the attention trajectory,
paired with a contrastive term, leads to an unsupervised learning criterion
that naturally copes with the considered setting. Differently from most
existing works, the learned representations are used in open-set
class-incremental classification of each frame pixel, relying on few
supervisions. Our experiments leverage 3D virtual environments and they show
that the proposed agents can learn to distinguish objects just by observing the
video stream. Inheriting features from state-of-the art models is not as
powerful as one might expect.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Split-Fusion Transformer. (arXiv:2204.12196v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12196">
<div class="article-summary-box-inner">
<span><p>Neural networks for visual content understanding have recently evolved from
convolutional ones (CNNs) to transformers. The prior (CNN) relies on
small-windowed kernels to capture the regional clues, demonstrating solid local
expressiveness. On the contrary, the latter (transformer) establishes
long-range global connections between localities for holistic learning.
Inspired by this complementary nature, there is a growing interest in designing
hybrid models to best utilize each technique. Current hybrids merely replace
convolutions as simple approximations of linear projection or juxtapose a
convolution branch with attention, without concerning the importance of
local/global modeling. To tackle this, we propose a new hybrid named Adaptive
Split-Fusion Transformer (ASF-former) to treat convolutional and attention
branches differently with adaptive weights. Specifically, an ASF-former encoder
equally splits feature channels into half to fit dual-path inputs. Then, the
outputs of dual-path are fused with weighting scalars calculated from visual
cues. We also design the convolutional path compactly for efficiency concerns.
Extensive experiments on standard benchmarks, such as ImageNet-1K, CIFAR-10,
and CIFAR-100, show that our ASF-former outperforms its CNN, transformer
counterparts, and hybrid pilots in terms of accuracy (83.9% on ImageNet-1K),
under similar conditions (12.9G MACs/56.7M Params, without large-scale
pre-training). The code is available at:
https://github.com/szx503045266/ASF-former.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Urban Change Detection Using a Dual-Task Siamese Network and Semi-Supervised Learning. (arXiv:2204.12202v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12202">
<div class="article-summary-box-inner">
<span><p>In this study, a Semi-Supervised Learning (SSL) method for improving urban
change detection from bi-temporal image pairs was presented. The proposed
method adapted a Dual-Task Siamese Difference network that not only predicts
changes with the difference decoder, but also segments buildings for both
images with a semantics decoder. First, the architecture was modified to
produce a second change prediction derived from the semantics predictions.
Second, SSL was adopted to improve supervised change detection. For unlabeled
data, we introduced a loss that encourages the network to predict consistent
changes across the two change outputs. The proposed method was tested on urban
change detection using the SpaceNet7 dataset. SSL achieved improved results
compared to three fully supervised benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Adversarial Transferability of MLP-Mixer. (arXiv:2204.12204v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12204">
<div class="article-summary-box-inner">
<span><p>The security of models based on new architectures such as MLP-Mixer and ViTs
needs to be studied urgently. However, most of the current researches are
mainly aimed at the adversarial attack against ViTs, and there is still
relatively little adversarial work on MLP-mixer. We propose an adversarial
attack method against MLP-Mixer called Maxwell's demon Attack (MA). MA breaks
the channel-mixing and token-mixing mechanism of MLP-Mixer by controlling the
part input of MLP-Mixer's each Mixer layer, and disturbs MLP-Mixer to obtain
the main information of images. Our method can mask the part input of the Mixer
layer, avoid overfitting of the adversarial examples to the source model, and
improve the transferability of cross-architecture. Extensive experimental
evaluation demonstrates the effectiveness and superior performance of the
proposed MA. Our method can be easily combined with existing methods and can
improve the transferability by up to 38.0% on MLP-based ResMLP. Adversarial
examples produced by our method on MLP-Mixer are able to exceed the
transferability of adversarial examples produced using DenseNet against CNNs.
To the best of our knowledge, we are the first work to study adversarial
transferability of MLP-Mixer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Context-Aware Sequence Alignment using 4D Skeletal Augmentation. (arXiv:2204.12223v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12223">
<div class="article-summary-box-inner">
<span><p>Temporal alignment of fine-grained human actions in videos is important for
numerous applications in computer vision, robotics, and mixed reality.
State-of-the-art methods directly learn image-based embedding space by
leveraging powerful deep convolutional neural networks. While being
straightforward, their results are far from satisfactory, the aligned videos
exhibit severe temporal discontinuity without additional post-processing steps.
The recent advancements in human body and hand pose estimation in the wild
promise new ways of addressing the task of human action alignment in videos. In
this work, based on off-the-shelf human pose estimators, we propose a novel
context-aware self-supervised learning architecture to align sequences of
actions. We name it CASA. Specifically, CASA employs self-attention and
cross-attention mechanisms to incorporate the spatial and temporal context of
human actions, which can solve the temporal discontinuity problem. Moreover, we
introduce a self-supervised learning scheme that is empowered by novel 4D
augmentation techniques for 3D skeleton representations. We systematically
evaluate the key components of our method. Our experiments on three public
datasets demonstrate CASA significantly improves phase progress and Kendall's
Tau scores over the previous state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Intercategorical Label Interpolation for Emotional Face Generation with Conditional Generative Adversarial Networks. (arXiv:2204.12237v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12237">
<div class="article-summary-box-inner">
<span><p>Generative adversarial networks offer the possibility to generate deceptively
real images that are almost indistinguishable from actual photographs. Such
systems however rely on the presence of large datasets to realistically
replicate the corresponding domain. This is especially a problem if not only
random new images are to be generated, but specific (continuous) features are
to be co-modeled. A particularly important use case in \emph{Human-Computer
Interaction} (HCI) research is the generation of emotional images of human
faces, which can be used for various use cases, such as the automatic
generation of avatars. The problem hereby lies in the availability of training
data. Most suitable datasets for this task rely on categorical emotion models
and therefore feature only discrete annotation labels. This greatly hinders the
learning and modeling of smooth transitions between displayed affective states.
To overcome this challenge, we explore the potential of label interpolation to
enhance networks trained on categorical datasets with the ability to generate
images conditioned on continuous features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attentive Fine-Grained Structured Sparsity for Image Restoration. (arXiv:2204.12266v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12266">
<div class="article-summary-box-inner">
<span><p>Image restoration tasks have witnessed great performance improvement in
recent years by developing large deep models. Despite the outstanding
performance, the heavy computation demanded by the deep models has restricted
the application of image restoration. To lift the restriction, it is required
to reduce the size of the networks while maintaining accuracy. Recently, N:M
structured pruning has appeared as one of the effective and practical pruning
approaches for making the model efficient with the accuracy constraint.
However, it fails to account for different computational complexities and
performance requirements for different layers of an image restoration network.
To further optimize the trade-off between the efficiency and the restoration
accuracy, we propose a novel pruning method that determines the pruning ratio
for N:M structured sparsity at each layer. Extensive experimental results on
super-resolution and deblurring tasks demonstrate the efficacy of our method
which outperforms previous pruning methods significantly. PyTorch
implementation for the proposed methods will be publicly available at
https://github.com/JungHunOh/SLS_CVPR2022.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-Efficient Backdoor Attacks. (arXiv:2204.12281v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12281">
<div class="article-summary-box-inner">
<span><p>Recent studies have proven that deep neural networks are vulnerable to
backdoor attacks. Specifically, by mixing a small number of poisoned samples
into the training set, the behavior of the trained model can be maliciously
controlled. Existing attack methods construct such adversaries by randomly
selecting some clean data from the benign set and then embedding a trigger into
them. However, this selection strategy ignores the fact that each poisoned
sample contributes inequally to the backdoor injection, which reduces the
efficiency of poisoning. In this paper, we formulate improving the poisoned
data efficiency by the selection as an optimization problem and propose a
Filtering-and-Updating Strategy (FUS) to solve it. The experimental results on
CIFAR-10 and ImageNet-10 indicate that the proposed method is effective: the
same attack success rate can be achieved with only 47% to 75% of the poisoned
sample volume compared to the random selection strategy. More importantly, the
adversaries selected according to one setting can generalize well to other
settings, exhibiting strong transferability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Framework for Quantification of Immune Cell Density and Characterization of Tumor-Immune Spatial Relationships in Tumor Microenvironment. (arXiv:2204.12283v1 [q-bio.QM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12283">
<div class="article-summary-box-inner">
<span><p>Understanding the impact of tumor biology on the composition of nearby cells
often requires characterizing the impact of biologically distinct tumor
regions. Biomarkers have been developed to label biologically distinct tumor
regions, but challenges arise because of differences in the spatial extent and
distribution of differentially labeled regions. In this work, we present a
framework for systematically investigating the impact of distinct tumor regions
on cells near the tumor borders, accounting their cross spatial distributions.
We apply the framework to multiplex immunohistochemistry (mIHC) studies of
pancreatic cancer and show its efficacy in demonstrating how biologically
different tumor regions impact the immune response in the tumor
microenvironment. Furthermore, we show that the proposed framework can be
extended to largescale whole slide image analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Language-Action Pre-training for Temporal Localization. (arXiv:2204.12293v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12293">
<div class="article-summary-box-inner">
<span><p>Long-form video understanding requires designing approaches that are able to
temporally localize activities or language. End-to-end training for such tasks
is limited by the compute device memory constraints and lack of temporal
annotations at large-scale. These limitations can be addressed by pre-training
on large datasets of temporally trimmed videos supervised by class annotations.
Once the video encoder is pre-trained, it is common practice to freeze it
during fine-tuning. Therefore, the video encoder does not learn temporal
boundaries and unseen classes, causing a domain gap with respect to the
downstream tasks. Moreover, using temporally trimmed videos prevents to capture
the relations between different action categories and the background context in
a video clip which results in limited generalization capacity. To address these
limitations, we propose a novel post-pre-training approach without freezing the
video encoder which leverages language. We introduce a masked contrastive
learning loss to capture visio-linguistic relations between activities,
background video clips and language in the form of captions. Our experiments
show that the proposed approach improves the state-of-the-art on temporal
action localization, few-shot temporal action localization, and video language
grounding tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Segmentation of Hyperspectral Remote Sensing Images with Superpixels. (arXiv:2204.12296v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12296">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose an unsupervised method for hyperspectral remote
sensing image segmentation. The method exploits the mean-shift clustering
algorithm that takes as input a preliminary hyperspectral superpixels
segmentation together with the spectral pixel information. The proposed method
does not require the number of segmentation classes as input parameter, and it
does not exploit any a-priori knowledge about the type of land-cover or
land-use to be segmented (e.g. water, vegetation, building etc.). Experiments
on Salinas, SalinasA, Pavia Center and Pavia University datasets are carried
out. Performance are measured in terms of normalized mutual information,
adjusted Rand index and F1-score. Results demonstrate the validity of the
proposed method in comparison with the state of the art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified GCNs: Towards Connecting GCNs with CNNs. (arXiv:2204.12300v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12300">
<div class="article-summary-box-inner">
<span><p>Graph Convolutional Networks (GCNs) have been widely demonstrated their
powerful ability in graph data representation and learning. Existing graph
convolution layers are mainly designed based on graph signal processing and
transform aspect which usually suffer from some limitations, such as
over-smoothing, over-squashing and non-robustness, etc. As we all know that
Convolution Neural Networks (CNNs) have received great success in many computer
vision and machine learning. One main aspect is that CNNs leverage many
learnable convolution filters (kernels) to obtain rich feature descriptors and
thus can have high capacity to encode complex patterns in visual data analysis.
Also, CNNs are flexible in designing their network architecture, such as
MobileNet, ResNet, Xception, etc. Therefore, it is natural to arise a question:
can we design graph convolutional layer as flexibly as that in CNNs?
Innovatively, in this paper, we consider connecting GCNs with CNNs deeply from
a general perspective of depthwise separable convolution operation.
Specifically, we show that GCN and GAT indeed perform some specific depthwise
separable convolution operations. This novel interpretation enables us to
better understand the connections between GCNs (GCN, GAT) and CNNs and further
inspires us to design more Unified GCNs (UGCNs). As two showcases, we implement
two UGCNs, i.e., Separable UGCN (S-UGCN) and General UGCN (G-UGCN) for graph
data representation and learning. Promising experiments on several graph
representation benchmarks demonstrate the effectiveness and advantages of the
proposed UGCNs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating the Quality of a Synthesized Motion with the Fr\'echet Motion Distance. (arXiv:2204.12318v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12318">
<div class="article-summary-box-inner">
<span><p>Evaluating the Quality of a Synthesized Motion with the Fr\'echet Motion
Distance
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RAPQ: Rescuing Accuracy for Power-of-Two Low-bit Post-training Quantization. (arXiv:2204.12322v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12322">
<div class="article-summary-box-inner">
<span><p>We introduce a Power-of-Two post-training quantization( PTQ) method for deep
neural network that meets hardware requirements and does not call for long-time
retraining. PTQ requires a small set of calibration data and is easier for
deployment, but results in lower accuracy than Quantization-Aware Training(
QAT). Power-of-Two quantization can convert the multiplication introduced by
quantization and dequantization to bit-shift that is adopted by many efficient
accelerators. However, the Power-of-Two scale has fewer candidate values, which
leads to more rounding or clipping errors. We propose a novel Power-of-Two PTQ
framework, dubbed RAPQ, which dynamically adjusts the Power-of-Two scales of
the whole network instead of statically determining them layer by layer. It can
theoretically trade off the rounding error and clipping error of the whole
network. Meanwhile, the reconstruction method in RAPQ is based on the BN
information of every unit. Extensive experiments on ImageNet prove the
excellent performance of our proposed method. Without bells and whistles, RAPQ
can reach accuracy of 65% and 48% on ResNet-18 and MobileNetV2 respectively
with weight INT2 activation INT4. We are the first to propose PTQ for the more
constrained but hardware-friendly Power-of-Two quantization and prove that it
can achieve nearly the same accuracy as SOTA PTQ method. The code will be
released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Algorithm for the Labeling and Interactive Visualization of the Cerebrovascular System of Ischemic Strokes. (arXiv:2204.12333v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12333">
<div class="article-summary-box-inner">
<span><p>During the diagnosis of ischemic strokes, the Circle of Willis and its
surrounding vessels are the arteries of interest. Their visualization in case
of an acute stroke is often enabled by Computed Tomography Angiography (CTA).
Still, the identification and analysis of the cerebral arteries remain time
consuming in such scans due to a large number of peripheral vessels which may
disturb the visual impression. In previous work we proposed VirtualDSA++, an
algorithm designed to segment and label the cerebrovascular tree on CTA scans.
Especially with stroke patients, labeling is a delicate procedure, as in the
worst case whole hemispheres may not be present due to impeded perfusion.
Hence, we extended the labeling mechanism for the cerebral arteries to identify
occluded vessels. In the work at hand, we place the algorithm in a clinical
context by evaluating the labeling and occlusion detection on stroke patients,
where we have achieved labeling sensitivities comparable to other works between
92\,\% and 95\,\%. To the best of our knowledge, ours is the first work to
address labeling and occlusion detection at once, whereby a sensitivity of
67\,\% and a specificity of 81\,\% were obtained for the latter. VirtualDSA++
also automatically segments and models the intracranial system, which we
further used in a deep learning driven follow up work. We present the generic
concept of iterative systematic search for pathways on all nodes of said model,
which enables new interactive features. Exemplary, we derive in detail,
firstly, the interactive planning of vascular interventions like the mechanical
thrombectomy and secondly, the interactive suppression of vessel structures
that are not of interest in diagnosing strokes (like veins). We discuss both
features as well as further possibilities emerging from the proposed concept.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Topological Structure of Floorplans from Room Attributes. (arXiv:2204.12338v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12338">
<div class="article-summary-box-inner">
<span><p>Analysis of indoor spaces requires topological information. In this paper, we
propose to extract topological information from room attributes using what we
call Iterative and adaptive graph Topology Learning (ITL). ITL progressively
predicts multiple relations between rooms; at each iteration, it improves node
embeddings, which in turn facilitates generation of a better topological graph
structure. This notion of iterative improvement of node embeddings and
topological graph structure is in the same spirit as \cite{chen2020iterative}.
However, while \cite{chen2020iterative} computes the adjacency matrix based on
node similarity, we learn the graph metric using a relational decoder to
extract room correlations. Experiments using a new challenging indoor dataset
validate our proposed method. Qualitative and quantitative evaluation for
layout topology prediction and floorplan generation applications also
demonstrate the effectiveness of ITL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Restricted Black-box Adversarial Attack Against DeepFake Face Swapping. (arXiv:2204.12347v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12347">
<div class="article-summary-box-inner">
<span><p>DeepFake face swapping presents a significant threat to online security and
social media, which can replace the source face in an arbitrary photo/video
with the target face of an entirely different person. In order to prevent this
fraud, some researchers have begun to study the adversarial methods against
DeepFake or face manipulation. However, existing works focus on the white-box
setting or the black-box setting driven by abundant queries, which severely
limits the practical application of these methods. To tackle this problem, we
introduce a practical adversarial attack that does not require any queries to
the facial image forgery model. Our method is built on a substitute model
persuing for face reconstruction and then transfers adversarial examples from
the substitute model directly to inaccessible black-box DeepFake models.
Specially, we propose the Transferable Cycle Adversary Generative Adversarial
Network (TCA-GAN) to construct the adversarial perturbation for disrupting
unknown DeepFake systems. We also present a novel post-regularization module
for enhancing the transferability of generated adversarial examples. To
comprehensively measure the effectiveness of our approaches, we construct a
challenging benchmark of DeepFake adversarial attacks for future development.
Extensive experiments impressively show that the proposed adversarial attack
method makes the visual quality of DeepFake face images plummet so that they
are easier to be detected by humans and algorithms. Moreover, we demonstrate
that the proposed algorithm can be generalized to offer face image protection
against various face translation methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causal Transportability for Visual Recognition. (arXiv:2204.12363v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12363">
<div class="article-summary-box-inner">
<span><p>Visual representations underlie object recognition tasks, but they often
contain both robust and non-robust features. Our main observation is that image
classifiers may perform poorly on out-of-distribution samples because spurious
correlations between non-robust features and labels can be changed in a new
environment. By analyzing procedures for out-of-distribution generalization
with a causal graph, we show that standard classifiers fail because the
association between images and labels is not transportable across settings.
However, we then show that the causal effect, which severs all sources of
confounding, remains invariant across domains. This motivates us to develop an
algorithm to estimate the causal effect for image classification, which is
transportable (i.e., invariant) across source and target environments. Without
observing additional variables, we show that we can derive an estimand for the
causal effect under empirical assumptions using representations in deep models
as proxies. Theoretical analysis, empirical results, and visualizations show
that our approach captures causal invariances and improves overall
generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ROMA: Cross-Domain Region Similarity Matching for Unpaired Nighttime Infrared to Daytime Visible Video Translation. (arXiv:2204.12367v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12367">
<div class="article-summary-box-inner">
<span><p>Infrared cameras are often utilized to enhance the night vision since the
visible light cameras exhibit inferior efficacy without sufficient
illumination. However, infrared data possesses inadequate color contrast and
representation ability attributed to its intrinsic heat-related imaging
principle. This makes it arduous to capture and analyze information for human
beings, meanwhile hindering its application. Although, the domain gaps between
unpaired nighttime infrared and daytime visible videos are even huger than
paired ones that captured at the same time, establishing an effective
translation mapping will greatly contribute to various fields. In this case,
the structural knowledge within nighttime infrared videos and semantic
information contained in the translated daytime visible pairs could be utilized
simultaneously. To this end, we propose a tailored framework ROMA that couples
with our introduced cRoss-domain regiOn siMilarity mAtching technique for
bridging the huge gaps. To be specific, ROMA could efficiently translate the
unpaired nighttime infrared videos into fine-grained daytime visible ones,
meanwhile maintain the spatiotemporal consistency via matching the cross-domain
region similarity. Furthermore, we design a multiscale region-wise
discriminator to distinguish the details from synthesized visible results and
real references. Extensive experiments and evaluations for specific
applications indicate ROMA outperforms the state-of-the-art methods. Moreover,
we provide a new and challenging dataset encouraging further research for
unpaired nighttime infrared and daytime visible video translation, named
InfraredCity. In particular, it consists of 9 long video clips including City,
Highway and Monitor scenarios. All clips could be split into 603,142 frames in
total, which are 20 times larger than the recently released daytime
infrared-to-visible dataset IRVI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Fragile Features and Batch Normalization in Adversarial Training. (arXiv:2204.12393v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12393">
<div class="article-summary-box-inner">
<span><p>Modern deep learning architecture utilize batch normalization (BN) to
stabilize training and improve accuracy. It has been shown that the BN layers
alone are surprisingly expressive. In the context of robustness against
adversarial examples, however, BN is argued to increase vulnerability. That is,
BN helps to learn fragile features. Nevertheless, BN is still used in
adversarial training, which is the de-facto standard to learn robust features.
In order to shed light on the role of BN in adversarial training, we
investigate to what extent the expressiveness of BN can be used to robustify
fragile features in comparison to random features. On CIFAR10, we find that
adversarially fine-tuning just the BN layers can result in non-trivial
adversarial robustness. Adversarially training only the BN layers from scratch,
in contrast, is not able to convey meaningful adversarial robustness. Our
results indicate that fragile features can be used to learn models with
moderate adversarial robustness, while random features cannot
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding the Impact of Edge Cases from Occluded Pedestrians for ML Systems. (arXiv:2204.12402v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12402">
<div class="article-summary-box-inner">
<span><p>Machine learning (ML)-enabled approaches are considered a substantial support
technique of detection and classification of obstacles of traffic participants
in self-driving vehicles. Major breakthroughs have been demonstrated the past
few years, even covering complete end-to-end data processing chain from sensory
inputs through perception and planning to vehicle control of acceleration,
breaking and steering. YOLO (you-only-look-once) is a state-of-the-art
perception neural network (NN) architecture providing object detection and
classification through bounding box estimations on camera images. As the NN is
trained on well annotated images, in this paper we study the variations of
confidence levels from the NN when tested on hand-crafted occlusion added to a
test set. We compare regular pedestrian detection to upper and lower body
detection. Our findings show that the two NN using only partial information
perform similarly well like the NN for the full body when the full body NN's
performance is 0.75 or better. Furthermore and as expected, the network, which
is only trained on the lower half body is least prone to disturbances from
occlusions of the upper half and vice versa.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A survey on attention mechanisms for medical applications: are we moving towards better algorithms?. (arXiv:2204.12406v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12406">
<div class="article-summary-box-inner">
<span><p>The increasing popularity of attention mechanisms in deep learning algorithms
for computer vision and natural language processing made these models
attractive to other research domains. In healthcare, there is a strong need for
tools that may improve the routines of the clinicians and the patients.
Naturally, the use of attention-based algorithms for medical applications
occurred smoothly. However, being healthcare a domain that depends on
high-stake decisions, the scientific community must ponder if these
high-performing algorithms fit the needs of medical applications. With this
motto, this paper extensively reviews the use of attention mechanisms in
machine learning (including Transformers) for several medical applications.
This work distinguishes itself from its predecessors by proposing a critical
analysis of the claims and potentialities of attention mechanisms presented in
the literature through an experimental case study on medical image
classification with three different use cases. These experiments focus on the
integrating process of attention mechanisms into established deep learning
architectures, the analysis of their predictive power, and a visual assessment
of their saliency maps generated by post-hoc explanation methods. This paper
concludes with a critical analysis of the claims and potentialities presented
in the literature about attention mechanisms and proposes future research lines
in medical applications that may benefit from these frameworks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MILES: Visual BERT Pre-training with Injected Language Semantics for Video-text Retrieval. (arXiv:2204.12408v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12408">
<div class="article-summary-box-inner">
<span><p>Dominant pre-training work for video-text retrieval mainly adopt the
"dual-encoder" architectures to enable efficient retrieval, where two separate
encoders are used to contrast global video and text representations, but ignore
detailed local semantics. The recent success of image BERT pre-training with
masked visual modeling that promotes the learning of local visual context,
motivates a possible solution to address the above limitation. In this work, we
for the first time investigate masked visual modeling in video-text
pre-training with the "dual-encoder" architecture. We perform Masked visual
modeling with Injected LanguagE Semantics (MILES) by employing an extra
snapshot video encoder as an evolving "tokenizer" to produce reconstruction
targets for masked video patch prediction. Given the corrupted video, the video
encoder is trained to recover text-aligned features of the masked patches via
reasoning with the visible regions along the spatial and temporal dimensions,
which enhances the discriminativeness of local visual features and the
fine-grained cross-modality alignment. Our method outperforms state-of-the-art
methods for text-to-video retrieval on four datasets with both zero-shot and
fine-tune evaluation protocols. Our approach also surpasses the baseline models
significantly on zero-shot action recognition, which can be cast as
video-to-text retrieval.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RadioPathomics: Multimodal Learning in Non-Small Cell Lung Cancer for Adaptive Radiotherapy. (arXiv:2204.12423v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12423">
<div class="article-summary-box-inner">
<span><p>The current cancer treatment practice collects multimodal data, such as
radiology images, histopathology slides, genomics and clinical data. The
importance of these data sources taken individually has fostered the recent
raise of radiomics and pathomics, i.e. the extraction of quantitative features
from radiology and histopathology images routinely collected to predict
clinical outcomes or to guide clinical decisions using artificial intelligence
algorithms. Nevertheless, how to combine them into a single multimodal
framework is still an open issue. In this work we therefore develop a
multimodal late fusion approach that combines hand-crafted features computed
from radiomics, pathomics and clinical data to predict radiation therapy
treatment outcomes for non-small-cell lung cancer patients. Within this
context, we investigate eight different late fusion rules (i.e. product,
maximum, minimum, mean, decision template, Dempster-Shafer, majority voting,
and confidence rule) and two patient-wise aggregation rules leveraging the
richness of information given by computer tomography images and whole-slide
scans. The experiments in leave-one-patient-out cross-validation on an in-house
cohort of 33 patients show that the proposed multimodal paradigm with an AUC
equal to $90.9\%$ outperforms each unimodal approach, suggesting that data
integration can advance precision medicine. As a further contribution, we also
compare the hand-crafted representations with features automatically computed
by deep networks, and the late fusion paradigm with early fusion, another
popular multimodal approach. In both cases, the experiments show that the
proposed multimodal approach provides the best results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding The Robustness in Vision Transformers. (arXiv:2204.12451v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12451">
<div class="article-summary-box-inner">
<span><p>Recent studies show that Vision Transformers(ViTs) exhibit strong robustness
against various corruptions. Although this property is partly attributed to the
self-attention mechanism, there is still a lack of systematic understanding. In
this paper, we examine the role of self-attention in learning robust
representations. Our study is motivated by the intriguing properties of the
emerging visual grouping in Vision Transformers, which indicates that
self-attention may promote robustness through improved mid-level
representations. We further propose a family of fully attentional networks
(FANs) that strengthen this capability by incorporating an attentional channel
processing design. We validate the design comprehensively on various
hierarchical backbones. Our model achieves a state of-the-art 87.1% accuracy
and 35.8% mCE on ImageNet-1k and ImageNet-C with 76.8M parameters. We also
demonstrate state-of-the-art accuracy and robustness in two downstream tasks:
semantic segmentation and object detection. Code will be available at
https://github.com/NVlabs/FAN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Differentiable Zooming for Multiple Instance Learning on Whole-Slide Images. (arXiv:2204.12454v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12454">
<div class="article-summary-box-inner">
<span><p>Multiple Instance Learning (MIL) methods have become increasingly popular for
classifying giga-pixel sized Whole-Slide Images (WSIs) in digital pathology.
Most MIL methods operate at a single WSI magnification, by processing all the
tissue patches. Such a formulation induces high computational requirements, and
constrains the contextualization of the WSI-level representation to a single
scale. A few MIL methods extend to multiple scales, but are computationally
more demanding. In this paper, inspired by the pathological diagnostic process,
we propose ZoomMIL, a method that learns to perform multi-level zooming in an
end-to-end manner. ZoomMIL builds WSI representations by aggregating
tissue-context information from multiple magnifications. The proposed method
outperforms the state-of-the-art MIL methods in WSI classification on two large
datasets, while significantly reducing the computational demands with regard to
Floating-Point Operations (FLOPs) and processing time by up to 40x.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Focal Sparse Convolutional Networks for 3D Object Detection. (arXiv:2204.12463v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12463">
<div class="article-summary-box-inner">
<span><p>Non-uniformed 3D sparse data, e.g., point clouds or voxels in different
spatial positions, make contribution to the task of 3D object detection in
different ways. Existing basic components in sparse convolutional networks
(Sparse CNNs) process all sparse data, regardless of regular or submanifold
sparse convolution. In this paper, we introduce two new modules to enhance the
capability of Sparse CNNs, both are based on making feature sparsity learnable
with position-wise importance prediction. They are focal sparse convolution
(Focals Conv) and its multi-modal variant of focal sparse convolution with
fusion, or Focals Conv-F for short. The new modules can readily substitute
their plain counterparts in existing Sparse CNNs and be jointly trained in an
end-to-end fashion. For the first time, we show that spatially learnable
sparsity in sparse convolution is essential for sophisticated 3D object
detection. Extensive experiments on the KITTI, nuScenes and Waymo benchmarks
validate the effectiveness of our approach. Without bells and whistles, our
results outperform all existing single-model entries on the nuScenes test
benchmark at the paper submission time. Code and models are at
https://github.com/dvlab-research/FocalsConv.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-free representation learning for few-shot learning via stochastic weight averaging. (arXiv:2204.12466v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12466">
<div class="article-summary-box-inner">
<span><p>Recent studies on few-shot classification using transfer learning pose
challenges to the effectiveness and efficiency of episodic meta-learning
algorithms. Transfer learning approaches are a natural alternative, but they
are restricted to few-shot classification. Moreover, little attention has been
on the development of probabilistic models with well-calibrated uncertainty
from few-shot samples, except for some Bayesian episodic learning algorithms.
To tackle the aforementioned issues, we propose a new transfer learning method
to obtain accurate and reliable models for few-shot regression and
classification. The resulting method does not require episodic meta-learning
and is called meta-free representation learning (MFRL). MFRL first finds
low-rank representation generalizing well on meta-test tasks. Given the learned
representation, probabilistic linear models are fine-tuned with few-shot
samples to obtain models with well-calibrated uncertainty. The proposed method
not only achieves the highest accuracy on a wide range of few-shot learning
benchmark datasets but also correctly quantifies the prediction uncertainty. In
addition, weight averaging and temperature scaling are effective in improving
the accuracy and reliability of few-shot learning in existing meta-learning
algorithms with a wide range of learning paradigms and model architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coarse-to-fine Q-attention with Tree Expansion. (arXiv:2204.12471v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12471">
<div class="article-summary-box-inner">
<span><p>Coarse-to-fine Q-attention enables sample-efficient robot manipulation by
discretizing the translation space in a coarse-to-fine manner, where the
resolution gradually increases at each layer in the hierarchy. Although
effective, Q-attention suffers from "coarse ambiguity" - when voxelization is
significantly coarse, it is not feasible to distinguish similar-looking objects
without first inspecting at a finer resolution. To combat this, we propose to
envision Q-attention as a tree that can be expanded and used to accumulate
value estimates across the top-k voxels at each Q-attention depth. When our
extension, Q-attention with Tree Expansion (QTE), replaces standard Q-attention
in the Attention-driven Robot Manipulation (ARM) system, we are able to
accomplish a larger set of tasks; especially on those that suffer from "coarse
ambiguity". In addition to evaluating our approach across 12 RLBench tasks, we
also show that the improved performance is visible in a real-world task
involving small objects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation. (arXiv:2204.12484v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12484">
<div class="article-summary-box-inner">
<span><p>Recently, customized vision transformers have been adapted for human pose
estimation and have achieved superior performance with elaborate structures.
However, it is still unclear whether plain vision transformers can facilitate
pose estimation. In this paper, we take the first step toward answering the
question by employing a plain and non-hierarchical vision transformer together
with simple deconvolution decoders termed ViTPose for human pose estimation. We
demonstrate that a plain vision transformer with MAE pretraining can obtain
superior performance after finetuning on human pose estimation datasets.
ViTPose has good scalability with respect to model size and flexibility
regarding input resolution and token number. Moreover, it can be easily
pretrained using the unlabeled pose data without the need for large-scale
upstream ImageNet data. Our biggest ViTPose model based on the ViTAE-G backbone
with 1 billion parameters obtains the best 80.9 mAP on the MS COCO test-dev
set, while the ensemble models further set a new state-of-the-art for human
pose estimation, i.e., 81.1 mAP. The source code and models will be released at
https://github.com/ViTAE-Transformer/ViTPose.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sound Localization by Self-Supervised Time Delay Estimation. (arXiv:2204.12489v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12489">
<div class="article-summary-box-inner">
<span><p>Sounds reach one microphone in a stereo pair sooner than the other, resulting
in an interaural time delay that conveys their directions. Estimating a sound's
time delay requires finding correspondences between the signals recorded by
each microphone. We propose to learn these correspondences through
self-supervision, drawing on recent techniques from visual tracking. We adapt
the contrastive random walk of Jabri et al. to learn a cycle-consistent
representation from unlabeled stereo sounds, resulting in a model that performs
on par with supervised methods on "in the wild" internet recordings. We also
propose a multimodal contrastive learning model that solves a visually-guided
localization task: estimating the time delay for a particular person in a
multi-speaker mixture, given a visual representation of their face. Project
site: https://ificl.github.io/stereocrw/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From One Hand to Multiple Hands: Imitation Learning for Dexterous Manipulation from Single-Camera Teleoperation. (arXiv:2204.12490v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.12490">
<div class="article-summary-box-inner">
<span><p>We propose to perform imitation learning for dexterous manipulation with
multi-finger robot hand from human demonstrations, and transfer the policy to
the real robot hand. We introduce a novel single-camera teleoperation system to
collect the 3D demonstrations efficiently with only an iPad and a computer. One
key contribution of our system is that we construct a customized robot hand for
each user in the physical simulator, which is a manipulator resembling the same
kinematics structure and shape of the operator's hand. This provides an
intuitive interface and avoid unstable human-robot hand retargeting for data
collection, leading to large-scale and high quality data. Once the data is
collected, the customized robot hand trajectories can be converted to different
specified robot hands (models that are manufactured) to generate training
demonstrations. With imitation learning using our data, we show large
improvement over baselines with multiple complex manipulation tasks.
Importantly, we show our learned policy is significantly more robust when
transferring to the real robot. More videos can be found in the
https://yzqin.github.io/dex-teleop-imitation .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GAMMA: A General Agent Motion Model for Autonomous Driving. (arXiv:1906.01566v6 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.01566">
<div class="article-summary-box-inner">
<span><p>This paper presents GAMMA, a general motion prediction model that enables
large-scale real-time simulation and planning for autonomous driving. GAMMA
models heterogeneous, interactive traffic agents. They operate under diverse
road conditions, with various geometric and kinematic constraints. GAMMA treats
the prediction task as constrained optimization in traffic agents' velocity
space. The objective is to optimize an agent's driving performance, while
obeying all the constraints resulting from the agent's kinematics, collision
avoidance with other agents, and the environmental context. Further, GAMMA
explicitly conditions the prediction on human behavioral states as parameters
of the optimization model, in order to account for versatile human behaviors.
We evaluated GAMMA on a set of real-world benchmark datasets. The results show
that GAMMA achieves high prediction accuracy on both homogeneous and
heterogeneous traffic datasets, with sub-millisecond execution time. Further,
the computational efficiency and the flexibility of GAMMA enable (i) simulation
of mixed urban traffic at many locations worldwide and (ii) planning for
autonomous driving in dense traffic with uncertain driver behaviors, both in
real-time. The open-source code of GAMMA is available online.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Weakly-Supervised Learning Methods for Classification and Localization in Histology Images: A Comparative Study. (arXiv:1909.03354v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.03354">
<div class="article-summary-box-inner">
<span><p>Using deep learning models to diagnose cancer from histology data presents
several challenges. Cancer grading and localization of regions of interest
(ROIs) in these images normally relies on both image- and pixel-level labels,
the latter requiring a costly annotation process. Deep weakly-supervised object
localization (WSOL) methods provide different strategies for low-cost training
of deep learning models. Using only image-class annotations, these methods can
be trained to classify an image, and yield class activation maps (CAMs) for ROI
localization. This paper provides a review of state-of-art DL methods for WSOL.
We propose a taxonomy where these methods are divided into bottom-up and
top-down methods according to the information flow in models. Although the
latter have seen limited progress, recent bottom-up methods are currently
driving much progress with deep WSOL methods. Early works focused on designing
different spatial pooling functions. However, these methods reached limited
localization accuracy, and unveiled a major limitation -- the under-activation
of CAMs which leads to high false negative localization. Subsequent works aimed
to alleviate this issue and recover complete object. Representative methods
from our taxonomy are evaluated and compared in terms of classification and
localization accuracy on two challenging histology datasets. Overall, the
results indicate poor localization performance, particularly for generic
methods that were initially designed to process natural images. Methods
designed to address the challenges of histology data yielded good results.
However, all methods suffer from high false positive/negative localization.
Four key challenges are identified for the application of deep WSOL methods in
histology -- under/over activation of CAMs, sensitivity to thresholding, and
model selection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PDE-based Group Equivariant Convolutional Neural Networks. (arXiv:2001.09046v5 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.09046">
<div class="article-summary-box-inner">
<span><p>We present a PDE-based framework that generalizes Group equivariant
Convolutional Neural Networks (G-CNNs). In this framework, a network layer is
seen as a set of PDE-solvers where geometrically meaningful PDE-coefficients
become the layer's trainable weights. Formulating our PDEs on homogeneous
spaces allows these networks to be designed with built-in symmetries such as
rotation in addition to the standard translation equivariance of CNNs.
</p>
<p>Having all the desired symmetries included in the design obviates the need to
include them by means of costly techniques such as data augmentation. We will
discuss our PDE-based G-CNNs (PDE-G-CNNs) in a general homogeneous space
setting while also going into the specifics of our primary case of interest:
roto-translation equivariance.
</p>
<p>We solve the PDE of interest by a combination of linear group convolutions
and non-linear morphological group convolutions with analytic kernel
approximations that we underpin with formal theorems. Our kernel approximations
allow for fast GPU-implementation of the PDE-solvers, we release our
implementation with this article in the form of the LieTorch extension to
PyTorch, available at https://gitlab.com/bsmetsjr/lietorch . Just like for
linear convolution a morphological convolution is specified by a kernel that we
train in our PDE-G-CNNs. In PDE-G-CNNs we do not use non-linearities such as
max/min-pooling and ReLUs as they are already subsumed by morphological
convolutions.
</p>
<p>We present a set of experiments to demonstrate the strength of the proposed
PDE-G-CNNs in increasing the performance of deep learning based imaging
applications with far fewer parameters than traditional CNNs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Benchmark for Point Clouds Registration Algorithms. (arXiv:2003.12841v3 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.12841">
<div class="article-summary-box-inner">
<span><p>Point clouds registration is a fundamental step of many point clouds
processing pipelines; however, most algorithms are tested on data that are
collected ad-hoc and not shared with the research community. These data often
cover only a very limited set of use cases; therefore, the results cannot be
generalised. Public datasets proposed until now, taken individually, cover only
a few kinds of environment and mostly a single sensor. For these reasons, we
developed a benchmark, for localization and mapping applications, using
multiple publicly available datasets. In this way, we are able to cover many
kinds of environment and many kinds of sensor that can produce point clouds.
Furthermore, the ground truth has been thoroughly inspected and evaluated to
ensure its quality. For some of the datasets, the accuracy of the ground truth
measuring system was not reported by the original authors, therefore we
estimated it with our own novel method, based on an iterative registration
algorithm. Along with the data, we provide a broad set of registration
problems, chosen to cover different types of initial misalignment, various
degrees of overlap, and different kinds of registration problems. Lastly, we
propose a metric to measure the performances of registration algorithms: it
combines the commonly used rotation and translation errors together, to allow
an objective comparison of the alignments. This work aims at encouraging
authors to use a public and shared benchmark, instead of data collected ad-hoc,
to ensure objectivity and repeatability, two fundamental characteristics in any
scientific field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Riemannian Gradient-Based Methods for Minimax Problems. (arXiv:2010.06097v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06097">
<div class="article-summary-box-inner">
<span><p>In the paper, we study a class of useful minimax optimization problems on
Riemanian manifolds and propose a class of Riemanian gradient-based methods to
solve these minimax problems. Specifically, we propose a Riemannian gradient
descent ascent (RGDA) algorithm for the deterministic minimax optimization.
Moreover, we prove that our RGDA has a sample complexity of
$O(\kappa^2\epsilon^{-2})$ for finding an $\epsilon$-stationary point of the
nonconvex strongly-concave minimax problems, where $\kappa$ denotes the
condition number. At the same time, we introduce a Riemannian stochastic
gradient descent ascent (RSGDA) algorithm for the stochastic minimax
optimization. In the theoretical analysis, we prove that our RSGDA can achieve
a sample complexity of $O(\kappa^4\epsilon^{-4})$. To further reduce the sample
complexity, we propose an accelerated Riemannian stochastic gradient descent
ascent (Acc-RSGDA) algorithm based on the variance-reduced technique. We prove
that our Acc-RSGDA algorithm achieves a lower sample complexity of
$\tilde{O}(\kappa^{4}\epsilon^{-3})$. Extensive experimental results on the
robust distributional optimization and Deep Neural Networks (DNNs) training
over Stiefel manifold demonstrate efficiency of our algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modular Action Concept Grounding in Semantic Video Prediction. (arXiv:2011.11201v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11201">
<div class="article-summary-box-inner">
<span><p>Recent works in video prediction have mainly focused on passive forecasting
and low-level action-conditional prediction, which sidesteps the learning of
interaction between agents and objects. We introduce the task of semantic
action-conditional video prediction, which uses semantic action labels to
describe those interactions and can be regarded as an inverse problem of action
recognition. The challenge of this new task primarily lies in how to
effectively inform the model of semantic action information. Inspired by the
idea of Mixture of Experts, we embody each abstract label by a structured
combination of various visual concept learners and propose a novel video
prediction model, Modular Action Concept Network (MAC). Our method is evaluated
on two newly designed synthetic datasets, CLEVR-Building-Blocks and
Sapien-Kitchen, and one real-world dataset called Tower-Creation. Extensive
experiments demonstrate that MAC can correctly condition on given instructions
and generate corresponding future frames without need of bounding boxes. We
further show that the trained model can make out-of-distribution
generalization, be quickly adapted to new object categories and exploit its
learnt features for object detection, showing the progression towards
higher-level cognitive abilities. More visualizations can be found at
<a href="http://www.pair.toronto.edu/mac/.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Framework for Fluid Motion Estimation using a Constraint-Based Refinement Approach. (arXiv:2011.12267v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12267">
<div class="article-summary-box-inner">
<span><p>The goal of this paper is to formulate a general framework for fluid motion
estimation using a constraint-based refinement approach. We demonstrate that
for a particular choice of the constraint, our results closely approximate the
continuity equation based fluid flow. This closeness is theoretically justified
through a modified augmented Lagrangian method and validated numerically.
Further, along with the continuity constraint, our model can include other
geometric constraints as demonstrated. The mathematical well-posedness is
studied in the Hilbert space setting. Moreover, a special feature of our system
is the possibility of a diagonalization by the Cauchy-Riemann operator and
transforming it to a diffusion process on the curl and the divergence of the
flow. Using the theory of semigroups on the decoupled system, we show that our
approach preserves the spatial characteristics of the divergence and the
vorticities. We perform several numerical experiments and show the results on
different datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simple multi-dataset detection. (arXiv:2102.13086v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13086">
<div class="article-summary-box-inner">
<span><p>How do we build a general and broad object detection system? We use all
labels of all concepts ever annotated. These labels span diverse datasets with
potentially inconsistent taxonomies. In this paper, we present a simple method
for training a unified detector on multiple large-scale datasets. We use
dataset-specific training protocols and losses, but share a common detection
architecture with dataset-specific outputs. We show how to automatically
integrate these dataset-specific outputs into a common semantic taxonomy. In
contrast to prior work, our approach does not require manual taxonomy
reconciliation. Experiments show our learned taxonomy outperforms a
expert-designed taxonomy in all datasets. Our multi-dataset detector performs
as well as dataset-specific models on each training domain, and can generalize
to new unseen dataset without fine-tuning on them. Code is available at
https://github.com/xingyizhou/UniDet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Solving Inverse Problems by Joint Posterior Maximization with Autoencoding Prior. (arXiv:2103.01648v4 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01648">
<div class="article-summary-box-inner">
<span><p>In this work we address the problem of solving ill-posed inverse problems in
imaging where the prior is a variational autoencoder (VAE). Specifically we
consider the decoupled case where the prior is trained once and can be reused
for many different log-concave degradation models without retraining. Whereas
previous MAP-based approaches to this problem lead to highly non-convex
optimization algorithms, our approach computes the joint (space-latent) MAP
that naturally leads to alternate optimization algorithms and to the use of a
stochastic encoder to accelerate computations. The resulting technique (JPMAP)
performs Joint Posterior Maximization using an Autoencoding Prior. We show
theoretical and experimental evidence that the proposed objective function is
quite close to bi-convex. Indeed it satisfies a weak bi-convexity property
which is sufficient to guarantee that our optimization scheme converges to a
stationary point. We also highlight the importance of correctly training the
VAE using a denoising criterion, in order to ensure that the encoder
generalizes well to out-of-distribution images, without affecting the quality
of the generative model. This simple modification is key to providing
robustness to the whole procedure. Finally we show how our joint MAP
methodology relates to more common MAP approaches, and we propose a
continuation scheme that makes use of our JPMAP algorithm to provide more
robust MAP estimates. Experimental results also show the higher quality of the
solutions obtained by our JPMAP approach with respect to other non-convex MAP
approaches which more often get stuck in spurious local optima.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Material Measurement Units for a Circular Economy: Foundations through a Review. (arXiv:2103.01997v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01997">
<div class="article-summary-box-inner">
<span><p>Long-term availability of minerals and industrial materials is a necessary
condition for sustainable development as they are the constituents of any
manufacturing product. To enhance the efficiency of material management, we
define a computer-vision-enabled material measurement system and provide a
review of works relevant to its development with particular emphasis on the
foundations. A network of such systems for wide-area material stock monitoring
is also covered. Finally, challenges and future research directions are
discussed. As the first article bridging industrial ecology and advanced
computer vision, this review is intended to support both research communities
towards more sustainable manufacturing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Efficient Multitask Neural Network for Face Alignment, Head Pose Estimation and Face Tracking. (arXiv:2103.07615v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07615">
<div class="article-summary-box-inner">
<span><p>While Convolutional Neural Networks (CNNs) have significantly boosted the
performance of face related algorithms, maintaining accuracy and efficiency
simultaneously in practical use remains challenging. The state-of-the-art
methods employ deeper networks for better performance, which makes it less
practical for mobile applications because of more parameters and higher
computational complexity. Therefore, we propose an efficient multitask neural
network, Alignment &amp; Tracking &amp; Pose Network (ATPN) for face alignment, face
tracking and head pose estimation. Specifically, to achieve better performance
with fewer layers for face alignment, we introduce a shortcut connection
between shallow-layer and deep-layer features. We find the shallow-layer
features are highly correspond to facial boundaries that can provide the
structural information of face and it is crucial for face alignment. Moreover,
we generate a cheap heatmap based on the face alignment result and fuse it with
features to improve the performance of the other two tasks. Based on the
heatmap, the network can utilize both geometric information of landmarks and
appearance information for head pose estimation. The heatmap also provides
attention clues for face tracking. The face tracking task also saves us the
face detection procedure for each frame, which also significantly boost the
real-time capability for video-based tasks. We experimentally validate ATPN on
four benchmark datasets, WFLW, 300VW, WIDER Face and 300W-LP. The experimental
results demonstrate that it achieves better performance with much less
parameters and lower computational complexity compared to other light models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SCALoss: Side and Corner Aligned Loss for Bounding Box Regression. (arXiv:2104.00462v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00462">
<div class="article-summary-box-inner">
<span><p>Bounding box regression is an important component in object detection. Recent
work achieves promising performance by optimizing the Intersection over
Union~(IoU). However, IoU-based loss has the gradient vanish problem in the
case of low overlapping bounding boxes, and the model could easily ignore these
simple cases. In this paper, we propose Side Overlap~(SO) loss by maximizing
the side overlap of two bounding boxes, which puts more penalty for low
overlapping bounding box cases. Besides, to speed up the convergence, the
Corner Distance~(CD) is added into the objective function. Combining the Side
Overlap and Corner Distance, we get a new regression objective function,
\textit{Side and Corner Align Loss~(SCALoss)}. The SCALoss is well-correlated
with IoU loss, which also benefits the evaluation metric but produces more
penalty for low-overlapping cases. It can serve as a comprehensive similarity
measure, leading to better localization performance and faster convergence
speed. Experiments on COCO, PASCAL VOC, and LVIS benchmarks show that SCALoss
can bring consistent improvement and outperform $\ell_n$ loss and IoU based
loss with popular object detectors such as YOLOV3, SSD, Faster-RCNN. Code is
available at: \url{https://github.com/Turoad/SCALoss}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hand Gesture Recognition Based on a Nonconvex Regularization. (arXiv:2104.14349v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14349">
<div class="article-summary-box-inner">
<span><p>Recognition of hand gestures is one of the most fundamental tasks in
human-robot interaction. Sparse representation based methods have been widely
used due to their efficiency and low demands on the training data. Recently,
nonconvex regularization techniques including the $\ell_{1-2}$ regularization
have been proposed in the image processing community to promote sparsity while
achieving efficient performance. In this paper, we propose a vision-based hand
gesture recognition model based on the $\ell_{1-2}$ regularization, which is
solved by the alternating direction method of multipliers (ADMM). Numerical
experiments on binary and gray-scale data sets have demonstrated the
effectiveness of this method in identifying hand gestures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Refined Inertial DC Algorithm for DC Programming. (arXiv:2104.14750v2 [math.OC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14750">
<div class="article-summary-box-inner">
<span><p>In this paper we consider the difference-of-convex (DC) programming problems,
whose objective function is the difference of two convex functions. The
classical DC Algorithm (DCA) is well-known for solving this kind of problems,
which generally returns a critical point. Recently, an inertial DC algorithm
(InDCA) equipped with heavy-ball inertial-force procedure was proposed in de
Oliveira et al. (Set-Valued and Variational Analysis 27(4):895--919, 2019),
which potentially helps to improve both the convergence speed and the solution
quality. Based on InDCA, we propose a refined inertial DC algorithm (RInDCA)
equipped with enlarged inertial step-size compared with InDCA. Empirically,
larger step-size accelerates the convergence. We demonstrate the subsequential
convergence of our refined version to a critical point. In addition, by
assuming the Kurdyka-{\L}ojasiewicz (KL) property of the objective function, we
establish the sequential convergence of RInDCA. Numerical simulations on
checking copositivity of matrices and image denoising problem show the benefit
of larger step-size.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Light-weight and Real-time Line Segment Detection. (arXiv:2106.00186v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00186">
<div class="article-summary-box-inner">
<span><p>Previous deep learning-based line segment detection (LSD) suffers from the
immense model size and high computational cost for line prediction. This
constrains them from real-time inference on computationally restricted
environments. In this paper, we propose a real-time and light-weight line
segment detector for resource-constrained environments named Mobile LSD
(M-LSD). We design an extremely efficient LSD architecture by minimizing the
backbone network and removing the typical multi-module process for line
prediction found in previous methods. To maintain competitive performance with
a light-weight network, we present novel training schemes: Segments of Line
segment (SoL) augmentation, matching and geometric loss. SoL augmentation
splits a line segment into multiple subparts, which are used to provide
auxiliary line data during the training process. Moreover, the matching and
geometric loss allow a model to capture additional geometric cues. Compared
with TP-LSD-Lite, previously the best real-time LSD method, our model
(M-LSD-tiny) achieves competitive performance with 2.5% of model size and an
increase of 130.5% in inference speed on GPU. Furthermore, our model runs at
56.8 FPS and 48.6 FPS on the latest Android and iPhone mobile devices,
respectively. To the best of our knowledge, this is the first real-time deep
LSD available on mobile devices. Our code is available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can An Image Classifier Suffice For Action Recognition?. (arXiv:2106.14104v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14104">
<div class="article-summary-box-inner">
<span><p>We explore a new perspective on video understanding by casting the video
recognition problem as an image recognition task. Our approach rearranges input
video frames into super images, which allow for training an image classifier
directly to fulfill the task of action recognition, in exactly the same way as
image classification. With such a simple idea, we show that transformer-based
image classifiers alone can suffice for action recognition. In particular, our
approach demonstrates strong and promising performance against SOTA methods on
several public datasets including Kinetics400, Moments In Time,
Something-Something V2 (SSV2), Jester and Diving48. We also experiment with the
prevalent ResNet image classifiers in computer vision to further validate our
idea. The results on both Kinetics400 and SSV2 are comparable to some of the
best-performed CNN approaches based on spatio-temporal modeling. Our source
codes and models are available at https://github.com/IBM/sifar-pytorch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Progressive and Coarse-to-fine Registration of Brain MRI via Deformation Field Integration and Non-Rigid Feature Fusion. (arXiv:2109.12384v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.12384">
<div class="article-summary-box-inner">
<span><p>Registration of brain MRI images requires to solve a deformation field, which
is extremely difficult in aligning intricate brain tissues, e.g., subcortical
nuclei, etc. Existing efforts resort to decomposing the target deformation
field into intermediate sub-fields with either tiny motions, i.e., progressive
registration stage by stage, or lower resolutions, i.e., coarse-to-fine
estimation of the full-size deformation field. In this paper, we argue that
those efforts are not mutually exclusive, and propose a unified framework for
robust brain MRI registration in both progressive and coarse-to-fine manners
simultaneously. Specifically, building on a dual-encoder U-Net, the
fixed-moving MRI pair is encoded and decoded into multi-scale deformation
sub-fields from coarse to fine. Each decoding block contains two proposed novel
modules: i) in Deformation Field Integration (DFI), a single integrated
sub-field is calculated, warping by which is equivalent to warping
progressively by sub-fields from all previous decoding blocks, and ii) in
Non-rigid Feature Fusion (NFF), features of the fixed-moving pair are aligned
by DFI-integrated sub-field, and then fused to predict a finer sub-field.
Leveraging both DFI and NFF, the target deformation field is factorized into
multi-scale sub-fields, where the coarser fields alleviate the estimate of a
finer one and the finer field learns to make up those misalignments insolvable
by previous coarser ones. The extensive and comprehensive experimental results
on both private and public datasets demonstrate a superior registration
performance of brain MRI images over progressive registration only and
coarse-to-fine estimation only, with an increase by at most 8% in the average
Dice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anchor-free Oriented Proposal Generator for Object Detection. (arXiv:2110.01931v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01931">
<div class="article-summary-box-inner">
<span><p>Oriented object detection is a practical and challenging task in remote
sensing image interpretation. Nowadays, oriented detectors mostly use
horizontal boxes as intermedium to derive oriented boxes from them. However,
the horizontal boxes are inclined to get small Intersection-over-Unions (IoUs)
with ground truths, which may have some undesirable effects, such as
introducing redundant noise, mismatching with ground truths, detracting from
the robustness of detectors, etc. In this paper, we propose a novel Anchor-free
Oriented Proposal Generator (AOPG) that abandons horizontal box-related
operations from the network architecture. AOPG first produces coarse oriented
boxes by a Coarse Location Module (CLM) in an anchor-free manner and then
refines them into high-quality oriented proposals. After AOPG, we apply a Fast
R-CNN head to produce the final detection results. Furthermore, the shortage of
large-scale datasets is also a hindrance to the development of oriented object
detection. To alleviate the data insufficiency, we release a new dataset on the
basis of our DIOR dataset and name it DIOR-R. Massive experiments demonstrate
the effectiveness of AOPG. Particularly, without bells and whistles, we achieve
the accuracy of 64.41%, 75.24% and 96.22% mAP on the DIOR-R, DOTA and HRSC2016
datasets respectively. Code and models are available at
https://github.com/jbwang1997/AOPG.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RPT++: Customized Feature Representation for Siamese Visual Tracking. (arXiv:2110.12194v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.12194">
<div class="article-summary-box-inner">
<span><p>While recent years have witnessed remarkable progress in the feature
representation of visual tracking, the problem of feature misalignment between
the classification and regression tasks is largely overlooked. The approaches
of feature extraction make no difference for these two tasks in most of
advanced trackers. We argue that the performance gain of visual tracking is
limited since features extracted from the salient area provide more
recognizable visual patterns for classification, while these around the
boundaries contribute to accurately estimating the target state.
</p>
<p>We address this problem by proposing two customized feature extractors, named
polar pooling and extreme pooling to capture task-specific visual patterns.
Polar pooling plays the role of enriching information collected from the
semantic keypoints for stronger classification, while extreme pooling
facilitates explicit visual patterns of the object boundary for accurate target
state estimation. We demonstrate the effectiveness of the task-specific feature
representation by integrating it into the recent and advanced tracker RPT.
Extensive experiments on several benchmarks show that our Customized Features
based RPT (RPT++) achieves new state-of-the-art performances on OTB-100,
VOT2018, VOT2019, GOT-10k, TrackingNet and LaSOT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LOLNeRF: Learn from One Look. (arXiv:2111.09996v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.09996">
<div class="article-summary-box-inner">
<span><p>We present a method for learning a generative 3D model based on neural
radiance fields, trained solely from data with only single views of each
object. While generating realistic images is no longer a difficult task,
producing the corresponding 3D structure such that they can be rendered from
different views is non-trivial. We show that, unlike existing methods, one does
not need multi-view data to achieve this goal. Specifically, we show that by
reconstructing many images aligned to an approximate canonical pose with a
single network conditioned on a shared latent space, you can learn a space of
radiance fields that models shape and appearance for a class of objects. We
demonstrate this by training models to reconstruct object categories using
datasets that contain only one view of each subject without depth or geometry
information. Our experiments show that we achieve state-of-the-art results in
novel view synthesis and high-quality results for monocular depth prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ESGN: Efficient Stereo Geometry Network for Fast 3D Object Detection. (arXiv:2111.14055v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.14055">
<div class="article-summary-box-inner">
<span><p>Fast stereo based 3D object detectors have made great progress recently.
However, they lag far behind high-precision stereo based methods in accuracy.
We argue that the main reason is due to the poor geometry-aware feature
representation in 3D space. To solve this problem, we propose an efficient
stereo geometry network (ESGN). The key in our ESGN is an efficient
geometry-aware feature generation (EGFG) module. Our EGFG module first uses a
stereo correlation and reprojection module to construct multi-scale stereo
volumes in camera frustum space, second employs a multi-scale BEV projection
and fusion module to generate multiple geometry-aware features. In these two
steps, we adopt deep multi-scale information fusion for discriminative
geometry-aware feature generation, without any complex aggregation networks. In
addition, we introduce a deep geometry-aware feature distillation scheme to
guide stereo feature learning with a LiDAR-based detector. The experiments are
performed on the classical KITTI dataset. On KITTI test set, our ESGN
outperforms the fast state-of-art-art detector YOLOStereo3D by 5.14\% on
mAP$_{3d}$ at 62$ms$. To the best of our knowledge, our ESGN achieves a best
trade-off between accuracy and speed. We hope that our efficient stereo
geometry network can provide more possible directions for fast 3D object
detection. Our source code will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CDLNet: Noise-Adaptive Convolutional Dictionary Learning Network for Blind Denoising and Demosaicing. (arXiv:2112.00913v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.00913">
<div class="article-summary-box-inner">
<span><p>Deep learning based methods hold state-of-the-art results in low-level image
processing tasks, but remain difficult to interpret due to their black-box
construction. Unrolled optimization networks present an interpretable
alternative to constructing deep neural networks by deriving their architecture
from classical iterative optimization methods without use of tricks from the
standard deep learning tool-box. So far, such methods have demonstrated
performance close to that of state-of-the-art models while using their
interpretable construction to achieve a comparably low learned parameter count.
In this work, we propose an unrolled convolutional dictionary learning network
(CDLNet) and demonstrate its competitive denoising and joint denoising and
demosaicing (JDD) performance both in low and high parameter count regimes.
Specifically, we show that the proposed model outperforms state-of-the-art
fully convolutional denoising and JDD models when scaled to a similar parameter
count. In addition, we leverage the model's interpretable construction to
propose a noise-adaptive parameterization of thresholds in the network that
enables state-of-the-art blind denoising performance, and near perfect
generalization on noise-levels unseen during training. Furthermore, we show
that such performance extends to the JDD task and unsupervised learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Modality-Aware Multiple Granularity Pre-Training for RGB-Infrared Person Re-Identification. (arXiv:2112.06147v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06147">
<div class="article-summary-box-inner">
<span><p>RGB-Infrared person re-identification (RGB-IR ReID) aims to associate people
across disjoint RGB and IR camera views. Currently, state-of-the-art
performance of RGB-IR ReID is not as impressive as that of conventional ReID.
Much of that is due to the notorious modality bias training issue brought by
the single-modality ImageNet pre-training, which might yield RGB-biased
representations that severely hinder the cross-modality image retrieval. This
paper makes first attempt to tackle the task from a pre-training perspective.
We propose a self-supervised pre-training solution, named Modality-Aware
Multiple Granularity Learning (MMGL), which directly trains models from scratch
only on multi-modal ReID datasets, but achieving competitive results against
ImageNet pre-training, without using any external data or sophisticated tuning
tricks. First, we develop a simple-but-effective 'permutation recovery' pretext
task that globally maps shuffled RGB-IR images into a shared latent permutation
space, providing modality-invariant global representations for downstream ReID
tasks. Second, we present a part-aware cycle-contrastive (PCC) learning
strategy that utilizes cross-modality cycle-consistency to maximize agreement
between semantically similar RGB-IR image patches. This enables contrastive
learning for the unpaired multi-modal scenarios, further improving the
discriminability of local features without laborious instance augmentation.
Based on these designs, MMGL effectively alleviates the modality bias training
problem. Extensive experiments demonstrate that it learns better
representations (+8.03% Rank-1 accuracy) with faster training speed (converge
only in few hours) and higher data efficiency (&lt;5% data size) than ImageNet
pre-training. The results also suggest it generalizes well to various existing
models, losses and has promising transferability across datasets. The code will
be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Paced Deep Regression Forests with Consideration on Ranking Fairness. (arXiv:2112.06455v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06455">
<div class="article-summary-box-inner">
<span><p>Deep discriminative models (DDMs), such as deep regression forests, deep
neural decision forests, have been extensively studied recently to solve
problems like facial age estimation, head pose estimation, gaze estimation and
so forth. Such problems are challenging in part because a large amount of
effective training data without noise and bias is often not available. While
some progress has been achieved through learning more discriminative features,
or reweighting samples, we argue what is more desirable is to learn gradually
to discriminate like human beings. Then, we resort to self-paced learning
(SPL). But a natural question arises: can self-paced regime lead DDMs to
achieve more robust and less biased solutions? A serious problem with SPL,
which is firstly discussed by this work, is it tends to aggravate the bias of
solutions, especially for obvious imbalanced data. To this end, this paper
proposes a new self-paced paradigm for deep discriminative model, which
distinguishes noisy and underrepresented examples according to the output
likelihood and entropy associated with each example, and tackle the fundamental
ranking problem in SPL from a new perspective: fairness. This paradigm is
fundamental, and could be easily combined with a variety of DDMs. Extensive
experiments on three computer vision tasks, such as facial age estimation, head
pose estimation and gaze estimation, demonstrate the efficacy of our paradigm.
To the best of our knowledge, our work is the first paper in the literature of
SPL that considers ranking fairness for self-paced regime construction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Community Detection in Medical Image Datasets: Using Wavelets and Spectral Methods. (arXiv:2112.12021v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12021">
<div class="article-summary-box-inner">
<span><p>Medical image datasets can have large number of images representing patients
with different health conditions and various disease severity. When dealing
with raw unlabeled image datasets, the large number of samples often makes it
hard for experts and non-experts to understand the variety of images present in
a dataset. Supervised learning methods rely on labeled images which requires a
considerable effort by medical experts to first understand the communities of
images present in the data and then labeling the images. Here, we propose an
algorithm to facilitate the automatic identification of communities in medical
image datasets. We further demonstrate that such analysis can be insightful in
a supervised setting when the images are already labeled. Such insights are
useful because, health and disease severity can be considered a continuous
spectrum, and within each class, there usually are finer communities worthy of
investigation, especially when they have similarities to communities in other
classes. In our approach, we use wavelet decomposition of images in tandem with
spectral methods. We show that the eigenvalues of a graph Laplacian can reveal
the number of notable communities in an image dataset. Moreover, analyzing the
similarities may be used to infer a spectrum representing the severity of the
disease. In our experiments, we use a dataset of images labeled with different
conditions for COVID patients. We detect 25 communities in the dataset and then
observe that only 6 of those communities contain patients with pneumonia. We
also investigate the contents of a colorectal cancer histology dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sketch2PQ: Freeform Planar Quadrilateral Mesh Design via a Single Sketch. (arXiv:2201.09367v4 [cs.GR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.09367">
<div class="article-summary-box-inner">
<span><p>The freeform architectural modeling process often involves two important
stages: concept design and digital modeling. In the first stage, architects
usually sketch the overall 3D shape and the panel layout on a physical or
digital paper briefly. In the second stage, a digital 3D model is created using
the sketch as a reference. The digital model needs to incorporate geometric
requirements for its components, such as the planarity of panels due to
consideration of construction costs, which can make the modeling process more
challenging. In this work, we present a novel sketch-based system to bridge the
concept design and digital modeling of freeform roof-like shapes represented as
planar quadrilateral (PQ) meshes. Our system allows the user to sketch the
surface boundary and contour lines under axonometric projection and supports
the sketching of occluded regions. In addition, the user can sketch feature
lines to provide directional guidance to the PQ mesh layout. Given the 2D
sketch input, we propose a deep neural network to infer in real-time the
underlying surface shape along with a dense conjugate direction field, both of
which are used to extract the final PQ mesh. To train and validate our network,
we generate a large synthetic dataset that mimics architect sketching of
freeform quadrilateral patches. The effectiveness and usability of our system
are demonstrated with quantitative and qualitative evaluation as well as user
studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Feature based Cross-slide Registration. (arXiv:2202.09971v5 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.09971">
<div class="article-summary-box-inner">
<span><p>Cross-slide image analysis provides additional information by analysing the
expression of different biomarkers as compared to a single slide analysis.
These biomarker stained slides are analysed side by side, revealing unknown
relations between them. During the slide preparation, a tissue section may be
placed at an arbitrary orientation as compared to other sections of the same
tissue block. The problem is compounded by the fact that tissue contents are
likely to change from one section to the next and there may be unique artefacts
on some of the slides. This makes registration of each section to a reference
section of the same tissue block an important pre-requisite task before any
cross-slide analysis. We propose a deep feature based registration (DFBR)
method which utilises data-driven features to estimate the rigid
transformation. We adopted a multi-stage strategy for improving the quality of
registration. We also developed a visualisation tool to view registered pairs
of WSIs at different magnifications. With the help of this tool, one can apply
a transformation on the fly without the need to generate transformed source WSI
in a pyramidal form. We compared the performance of data-driven features with
that of hand-crafted features on the COMET dataset. Our approach can align the
images with low registration errors. Generally, the success of non-rigid
registration is dependent on the quality of rigid registration. To evaluate the
efficacy of the DFBR method, the first two steps of the ANHIR winner's
framework are replaced with our DFBR to register challenge provided image
pairs. The modified framework produces comparable results to that of challenge
winning team.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning based Prediction of MSI using MMR Markers in Colorectal Cancer. (arXiv:2203.00449v3 [q-bio.QM] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.00449">
<div class="article-summary-box-inner">
<span><p>The accurate diagnosis and molecular profiling of colorectal cancers are
critical for planning the best treatment options for patients. Microsatellite
instability (MSI) or mismatch repair (MMR) status plays a vital role in
appropriate treatment selection, has prognostic implications and is used to
investigate the possibility of patients having underlying genetic disorders
(Lynch syndrome). NICE recommends that all CRC patients should be offered
MMR/MSI testing. Immunohistochemistry is commonly used to assess MMR status
with subsequent molecular testing performed as required. This incurs
significant extra costs and requires additional resources. The introduction of
automated methods that can predict MSI or MMR status from a target image could
substantially reduce the cost associated with MMR testing. Unlike previous
studies on MSI prediction involving training a CNN using coarse labels (MSI vs
Microsatellite Stable (MSS)), we have utilised fine-grain MMR labels for
training purposes. In this paper, we present our work on predicting MSI status
in a two-stage process using a single target slide either stained with CK8/18
or H&amp;E. First, we trained a multi-headed convolutional neural network model
where each head was responsible for predicting one of the MMR protein
expressions. To this end, we performed the registration of MMR stained slides
to the target slide as a pre-processing step. In the second stage, statistical
features computed from the MMR prediction maps were used for the final MSI
prediction. Our results demonstrated that MSI classification can be improved by
incorporating fine-grained MMR labels in comparison to the previous approaches
in which only coarse labels were utilised.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BPM-Net: non-contact blood pressure measuring network based on face videos. (arXiv:2203.03634v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.03634">
<div class="article-summary-box-inner">
<span><p>Blood pressure indicates cardiac function and peripheral vascular resistance
and is critical for disease diagnosis. Traditionally, blood pressure data are
mainly acquired through contact sensors, which require high maintenance and may
be inconvenient and unfriendly to some people (e.g., burn patients). In this
paper, we proposed an efficient non-contact blood pressure measurement network
based on face videos. First, an innovative oversampling training strategy is
proposed to handle the unbalanced data distribution. The input video sequences
are first normalized and converted to our proposed YUVT color space. Then the
spatio-temporal slicer encodes it into a multi-domain spatio-temporal mapping.
Finally, the feature extractor composed of a series backbone network and LSTM
fits the high-dimensional feature, which is fed into blood pressure classifier
to locates the blood pressure interval. The blood pressure calculator combines
the results of the feature extractor and the blood pressure classifier to
output the final blood pressure value. We tested BPM-Net on MMSE-HR dataset,
the MAE of systolic blood pressure reached 12.35 mmHg and that of diastolic
blood pressure reached 9.5 mmHg. Experimental results on MMSE-HR show that the
network outperforms existing state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tuning-free multi-coil compressed sensing MRI with Parallel Variable Density Approximate Message Passing (P-VDAMP). (arXiv:2203.04180v2 [math.NA] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.04180">
<div class="article-summary-box-inner">
<span><p>Magnetic Resonance Imaging (MRI) has excellent soft tissue contrast but is
hindered by an inherently slow data acquisition process. Compressed sensing,
which reconstructs sparse signals from incoherently sampled data, has been
widely applied to accelerate MRI acquisitions. Compressed sensing MRI requires
one or more model parameters to be tuned, which is usually done by hand, giving
sub-optimal tuning in general. To address this issue, we build on previous work
by the authors on the single-coil Variable Density Approximate Message Passing
(VDAMP) algorithm, extending the framework to multiple receiver coils to
propose the Parallel VDAMP (P-VDAMP) algorithm. For Bernoulli random variable
density sampling, P-VDAMP obeys a "state evolution", where the intermediate
per-iteration image estimate is distributed according to the ground truth
corrupted by a zero-mean Gaussian vector with approximately known covariance.
To our knowledge, P-VDAMP is the first algorithm for multi-coil MRI data that
obeys a state evolution with accurately tracked parameters. We leverage state
evolution to automatically tune sparse parameters on-the-fly with Stein's
Unbiased Risk Estimate (SURE). P-VDAMP is evaluated on brain, knee and
angiogram datasets and compared with four variants of the Fast Iterative
Shrinkage-Thresholding algorithm (FISTA), including two tuning-free variants
from the literature. The proposed method is found to have a similar
reconstruction quality and time to convergence as FISTA with an optimally tuned
sparse weighting and offers substantial robustness and reconstruction quality
improvements over competing tuning-free methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Global Tracking Transformers. (arXiv:2203.13250v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.13250">
<div class="article-summary-box-inner">
<span><p>We present a novel transformer-based architecture for global multi-object
tracking. Our network takes a short sequence of frames as input and produces
global trajectories for all objects. The core component is a global tracking
transformer that operates on objects from all frames in the sequence. The
transformer encodes object features from all frames, and uses trajectory
queries to group them into trajectories. The trajectory queries are object
features from a single frame and naturally produce unique trajectories. Our
global tracking transformer does not require intermediate pairwise grouping or
combinatorial association, and can be jointly trained with an object detector.
It achieves competitive performance on the popular MOT17 benchmark, with 75.3
MOTA and 59.1 HOTA. More importantly, our framework seamlessly integrates into
state-of-the-art large-vocabulary detectors to track any objects. Experiments
on the challenging TAO dataset show that our framework consistently improves
upon baselines that are based on pairwise association, outperforming published
works by a significant 7.7 tracking mAP. Code is available at
https://github.com/xingyizhou/GTR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recognition of polar lows in Sentinel-1 SAR images with deep learning. (arXiv:2203.16401v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.16401">
<div class="article-summary-box-inner">
<span><p>In this paper, we explore the possibility of detecting polar lows in C-band
SAR images by means of deep learning. Specifically, we introduce a novel
dataset consisting of Sentinel-1 images labeled as positive; representing a
maritime mesocyclone, or negative; representing a normal sea state. The dataset
is constructed using the ERA5 dataset as baseline and it consists of 2004
annotated images. To our knowledge, this is the first dataset of its kind to be
publicly released. The dataset is used to train a deep learning model to
classify the labeled images. Evaluated on an independent test set, the model
yields an F-1 score of 0.95, indicating that polar lows can be consistently
detected from SAR images. Interpretability techniques applied to the deep
learning model reveal that atmospheric fronts and cyclonic eyes are key
features in the classification. Moreover, experimental results show that the
model is accurate even if: (i) such features are significantly cropped due to
the limited swath width of the SAR, (ii) the features are partly covered by sea
ice and (iii) land is covering significant parts of the images. By evaluating
the model performance on multiple input image resolutions (pixel sizes of 500m,
1km and 2km), it is found that higher resolution yield the best performance.
This emphasises the potential of using high resolution sensors like SAR for
detecting polar lows, as compared to conventionally used sensors such as
scatterometers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inductive Biases for Object-Centric Representations in the Presence of Complex Textures. (arXiv:2204.08479v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.08479">
<div class="article-summary-box-inner">
<span><p>Understanding which inductive biases could be helpful for the unsupervised
learning of object-centric representations of natural scenes is challenging. We
use neural style transfer to generate datasets where objects have complex
textures while still retaining ground-truth annotations. We find that methods
that use a single module to reconstruct both the shape and visual appearance of
each object learn more useful representations and achieve better object
separation. In addition, we observe that adjusting the latent space size is not
sufficient to improve segmentation performance. Finally, the downstream
usefulness of the representations is significantly more strongly correlated
with segmentation quality than with reconstruction accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NAFSSR: Stereo Image Super-Resolution Using NAFNet. (arXiv:2204.08714v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.08714">
<div class="article-summary-box-inner">
<span><p>Stereo image super-resolution aims at enhancing the quality of
super-resolution results by utilizing the complementary information provided by
binocular systems. To obtain reasonable performance, most methods focus on
finely designing modules, loss functions, and etc. to exploit information from
another viewpoint. This has the side effect of increasing system complexity,
making it difficult for researchers to evaluate new ideas and compare methods.
This paper inherits a strong and simple image restoration model, NAFNet, for
single-view feature extraction and extends it by adding cross attention modules
to fuse features between views to adapt to binocular scenarios. The proposed
baseline for stereo image super-resolution is noted as NAFSSR. Furthermore,
training/testing strategies are proposed to fully exploit the performance of
NAFSSR. Extensive experiments demonstrate the effectiveness of our method. In
particular, NAFSSR outperforms the state-of-the-art methods on the KITTI 2012,
KITTI 2015, Middlebury, and Flickr1024 datasets. With NAFSSR, we won 1st place
in the NTIRE 2022 Stereo Image Super-resolution Challenge. Codes and models
will be released at https://github.com/megvii-research/NAFNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video Moment Retrieval from Text Queries via Single Frame Annotation. (arXiv:2204.09409v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.09409">
<div class="article-summary-box-inner">
<span><p>Video moment retrieval aims at finding the start and end timestamps of a
moment (part of a video) described by a given natural language query. Fully
supervised methods need complete temporal boundary annotations to achieve
promising results, which is costly since the annotator needs to watch the whole
moment. Weakly supervised methods only rely on the paired video and query, but
the performance is relatively poor. In this paper, we look closer into the
annotation process and propose a new paradigm called "glance annotation". This
paradigm requires the timestamp of only one single random frame, which we refer
to as a "glance", within the temporal boundary of the fully supervised
counterpart. We argue this is beneficial because comparing to weak supervision,
trivial cost is added yet more potential in performance is provided. Under the
glance annotation setting, we propose a method named as Video moment retrieval
via Glance Annotation (ViGA) based on contrastive learning. ViGA cuts the input
video into clips and contrasts between clips and queries, in which glance
guided Gaussian distributed weights are assigned to all clips. Our extensive
experiments indicate that ViGA achieves better results than the
state-of-the-art weakly supervised methods by a large margin, even comparable
to fully supervised methods in some cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multi-Person Video Dataset Annotation Method of Spatio-Temporally Actions. (arXiv:2204.10160v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.10160">
<div class="article-summary-box-inner">
<span><p>Spatio-temporal action detection is an important and challenging problem in
video understanding. However, the application of the existing large-scale
spatio-temporal action datasets in specific fields is limited, and there is
currently no public tool for making spatio-temporal action datasets, it takes a
lot of time and effort for researchers to customize the spatio-temporal action
datasets, so we propose a multi-Person video dataset Annotation Method of
spatio-temporally actions.First, we use ffmpeg to crop the videos and frame the
videos; then use yolov5 to detect human in the video frame, and then use deep
sort to detect the ID of the human in the video frame. By processing the
detection results of yolov5 and deep sort, we can get the annotation file of
the spatio-temporal action dataset to complete the work of customizing the
spatio-temporal action dataset.
https://github.com/Whiffe/Custom-ava-dataset_Custom-Spatio-Temporally-Action-Video-Dataset
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identity Preserving Loss for Learned Image Compression. (arXiv:2204.10869v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.10869">
<div class="article-summary-box-inner">
<span><p>Deep learning model inference on embedded devices is challenging due to the
limited availability of computation resources. A popular alternative is to
perform model inference on the cloud, which requires transmitting images from
the embedded device to the cloud. Image compression techniques are commonly
employed in such cloud-based architectures to reduce transmission latency over
low bandwidth networks. This work proposes an end-to-end image compression
framework that learns domain-specific features to achieve higher compression
ratios than standard HEVC/JPEG compression techniques while maintaining
accuracy on downstream tasks (e.g., recognition). Our framework does not
require fine-tuning of the downstream task, which allows us to drop-in any
off-the-shelf downstream task model without retraining. We choose faces as an
application domain due to the ready availability of datasets and off-the-shelf
recognition models as representative downstream tasks. We present a novel
Identity Preserving Reconstruction (IPR) loss function which achieves
Bits-Per-Pixel (BPP) values that are ~38% and ~42% of CRF-23 HEVC compression
for LFW (low-resolution) and CelebA-HQ (high-resolution) datasets,
respectively, while maintaining parity in recognition accuracy. The superior
compression ratio is achieved as the model learns to retain the domain-specific
features (e.g., facial features) while sacrificing details in the background.
Furthermore, images reconstructed by our proposed compression model are robust
to changes in downstream model architectures. We show at-par recognition
performance on the LFW dataset with an unseen recognition model while retaining
a lower BPP value of ~38% of CRF-23 HEVC compression.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multi-level Alignment Training Scheme for Video-and-Language Grounding. (arXiv:2204.10938v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.10938">
<div class="article-summary-box-inner">
<span><p>To solve video-and-language grounding tasks, the key is for the network to
understand the connection between the two modalities. For a pair of video and
language description, their semantic relation is reflected by their encodings'
similarity. A good multi-modality encoder should be able to well capture both
inputs' semantics and encode them in the shared feature space where embedding
distance gets properly translated into their semantic similarity. In this work,
we focused on this semantic connection between video and language, and
developed a multi-level alignment training scheme to directly shape the
encoding process. Global and segment levels of video-language alignment pairs
were designed, based on the information similarity ranging from high-level
context to fine-grained semantics. The contrastive loss was used to contrast
the encodings' similarities between the positive and negative alignment pairs,
and to ensure the network is trained in such a way that similar information is
encoded closely in the shared feature space while information of different
semantics is kept apart. Our multi-level alignment training can be applied to
various video-and-language grounding tasks. Together with the task-specific
training loss, our framework achieved comparable performance to previous
state-of-the-arts on multiple video QA and retrieval datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph-DETR3D: Rethinking Overlapping Regions for Multi-View 3D Object Detection. (arXiv:2204.11582v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11582">
<div class="article-summary-box-inner">
<span><p>3D object detection from multiple image views is a fundamental and
challenging task for visual scene understanding. Due to its low cost and high
efficiency, multi-view 3D object detection has demonstrated promising
application prospects. However, accurately detecting objects through
perspective views in the 3D space is extremely difficult due to the lack of
depth information. Recently, DETR3D introduces a novel 3D-2D query paradigm in
aggregating multi-view images for 3D object detection and achieves
state-of-the-art performance. In this paper, with intensive pilot experiments,
we quantify the objects located at different regions and find that the
"truncated instances" (i.e., at the border regions of each image) are the main
bottleneck hindering the performance of DETR3D. Although it merges multiple
features from two adjacent views in the overlapping regions, DETR3D still
suffers from insufficient feature aggregation, thus missing the chance to fully
boost the detection performance. In an effort to tackle the problem, we propose
Graph-DETR3D to automatically aggregate multi-view imagery information through
graph structure learning (GSL). It constructs a dynamic 3D graph between each
object query and 2D feature maps to enhance the object representations,
especially at the border regions. Besides, Graph-DETR3D benefits from a novel
depth-invariant multi-scale training strategy, which maintains the visual depth
consistency by simultaneously scaling the image size and the object depth.
Extensive experiments on the nuScenes dataset demonstrate the effectiveness and
efficiency of our Graph-DETR3D. Notably, our best model achieves 49.5 NDS on
the nuScenes test leaderboard, achieving new state-of-the-art in comparison
with various published image-view 3D object detectors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PVNAS: 3D Neural Architecture Search with Point-Voxel Convolution. (arXiv:2204.11797v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11797">
<div class="article-summary-box-inner">
<span><p>3D neural networks are widely used in real-world applications (e.g., AR/VR
headsets, self-driving cars). They are required to be fast and accurate;
however, limited hardware resources on edge devices make these requirements
rather challenging. Previous work processes 3D data using either voxel-based or
point-based neural networks, but both types of 3D models are not
hardware-efficient due to the large memory footprint and random memory access.
In this paper, we study 3D deep learning from the efficiency perspective. We
first systematically analyze the bottlenecks of previous 3D methods. We then
combine the best from point-based and voxel-based models together and propose a
novel hardware-efficient 3D primitive, Point-Voxel Convolution (PVConv). We
further enhance this primitive with the sparse convolution to make it more
effective in processing large (outdoor) scenes. Based on our designed 3D
primitive, we introduce 3D Neural Architecture Search (3D-NAS) to explore the
best 3D network architecture given a resource constraint. We evaluate our
proposed method on six representative benchmark datasets, achieving
state-of-the-art performance with 1.8-23.7x measured speedup. Furthermore, our
method has been deployed to the autonomous racing vehicle of MIT Driverless,
achieving larger detection range, higher accuracy and lower latency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Retrieval-Augmented Diffusion Models. (arXiv:2204.11824v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11824">
<div class="article-summary-box-inner">
<span><p>Generative image synthesis with diffusion models has recently achieved
excellent visual quality in several tasks such as text-based or
class-conditional image synthesis. Much of this success is due to a dramatic
increase in the computational capacity invested in training these models. This
work presents an alternative approach: inspired by its successful application
in natural language processing, we propose to complement the diffusion model
with a retrieval-based approach and to introduce an explicit memory in the form
of an external database. During training, our diffusion model is trained with
similar visual features retrieved via CLIP and from the neighborhood of each
training instance. By leveraging CLIP's joint image-text embedding space, our
model achieves highly competitive performance on tasks for which it has not
been explicitly trained, such as class-conditional or text-image synthesis, and
can be conditioned on both text and image embeddings. Moreover, we can apply
our approach to unconditional generation, where it achieves state-of-the-art
performance. Our approach incurs low computational and memory overheads and is
easy to implement. We discuss its relationship to concurrent work and will
publish code and pretrained models soon.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scaling Cross-Domain Content-Based Image Retrieval for E-commerce Snap and Search Application. (arXiv:2204.11593v1 [cs.IR] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11593">
<div class="article-summary-box-inner">
<span><p>In this industry talk at ECIR 2022, we illustrate how we approach the main
challenges from large scale cross-domain content-based image retrieval using a
cascade method and a combination of our visual search and classification
capabilities. Specifically, we present a system that is able to handle the
scale of the data for e-commerce usage and the cross-domain nature of the query
and gallery image pools. We showcase the approach applied in real-world
e-commerce snap and search use case and its impact on ranking and latency
performance.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-04-27 23:08:35.980695478 UTC">2022-04-27 23:08:35 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>