<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-08-27T01:30:00Z">08-27</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.AI updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Model-based Decision Making with Imagination for Autonomous Parking. (arXiv:2108.11420v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11420">
<div class="article-summary-box-inner">
<span><p>Autonomous parking technology is a key concept within autonomous driving
research. This paper will propose an imaginative autonomous parking algorithm
to solve issues concerned with parking. The proposed algorithm consists of
three parts: an imaginative model for anticipating results before parking, an
improved rapid-exploring random tree (RRT) for planning a feasible trajectory
from a given start point to a parking lot, and a path smoothing module for
optimizing the efficiency of parking tasks. Our algorithm is based on a real
kinematic vehicle model; which makes it more suitable for algorithm application
on real autonomous cars. Furthermore, due to the introduction of the
imagination mechanism, the processing speed of our algorithm is ten times
faster than that of traditional methods, permitting the realization of
real-time planning simultaneously. In order to evaluate the algorithm's
effectiveness, we have compared our algorithm with traditional RRT, within
three different parking scenarios. Ultimately, results show that our algorithm
is more stable than traditional RRT and performs better in terms of efficiency
and quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PIVODL: Privacy-preserving vertical federated learning over distributed labels. (arXiv:2108.11444v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11444">
<div class="article-summary-box-inner">
<span><p>Federated learning (FL) is an emerging privacy preserving machine learning
protocol that allows multiple devices to collaboratively train a shared global
model without revealing their private local data. Non-parametric models like
gradient boosting decision trees (GBDT) have been commonly used in FL for
vertically partitioned data. However, all these studies assume that all the
data labels are stored on only one client, which may be unrealistic for
real-world applications. Therefore, in this work, we propose a secure vertical
FL framework, named PIVODL, to train GBDT with data labels distributed on
multiple devices. Both homomorphic encryption and differential privacy are
adopted to prevent label information from being leaked through transmitted
gradients and leaf values. Our experimental results show that both information
leakage and model performance degradation of the proposed PIVODL are
negligible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Statistical Relational to Neural Symbolic Artificial Intelligence: a Survey. (arXiv:2108.11451v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11451">
<div class="article-summary-box-inner">
<span><p>Neural-symbolic and statistical relational artificial intelligence both
integrate frameworks for learning with logical reasoning. This survey
identifies several parallels across seven different dimensions between these
two fields. These cannot only be used to characterize and position
neural-symbolic artificial intelligence approaches but also to identify a
number of directions for further research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">With One Voice: Composing a Travel Voice Assistant from Re-purposed Models. (arXiv:2108.11463v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11463">
<div class="article-summary-box-inner">
<span><p>Voice assistants provide users a new way of interacting with digital
products, allowing them to retrieve information and complete tasks with an
increased sense of control and flexibility. Such products are comprised of
several machine learning models, like Speech-to-Text transcription, Named
Entity Recognition and Resolution, and Text Classification. Building a voice
assistant from scratch takes the prolonged efforts of several teams
constructing numerous models and orchestrating between components. Alternatives
such as using third-party vendors or re-purposing existing models may be
considered to shorten time-to-market and development costs. However, each
option has its benefits and drawbacks. We present key insights from building a
voice search assistant for Booking.com search and recommendation system. Our
paper compares the achieved performance and development efforts in dedicated
tailor-made solutions against existing re-purposed models. We share and discuss
our data-driven decisions about implementation trade-offs and their estimated
outcomes in hindsight, showing that a fully functional machine learning product
can be built from existing models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ETA Prediction with Graph Neural Networks in Google Maps. (arXiv:2108.11482v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11482">
<div class="article-summary-box-inner">
<span><p>Travel-time prediction constitutes a task of high importance in
transportation networks, with web mapping services like Google Maps regularly
serving vast quantities of travel time queries from users and enterprises
alike. Further, such a task requires accounting for complex spatiotemporal
interactions (modelling both the topological properties of the road network and
anticipating events -- such as rush hours -- that may occur in the future).
Hence, it is an ideal target for graph representation learning at scale. Here
we present a graph neural network estimator for estimated time of arrival (ETA)
which we have deployed in production at Google Maps. While our main
architecture consists of standard GNN building blocks, we further detail the
usage of training schedule methods such as MetaGradients in order to make our
model robust and production-ready. We also provide prescriptive studies:
ablating on various architectural decisions and training regimes, and
qualitative analyses on real-world situations where our model provides a
competitive edge. Our GNN proved powerful when deployed, significantly reducing
negative ETA outcomes in several regions compared to the previous production
baseline (40+% in cities like Sydney).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Maneuver Identification Challenge. (arXiv:2108.11503v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11503">
<div class="article-summary-box-inner">
<span><p>AI algorithms that identify maneuvers from trajectory data could play an
important role in improving flight safety and pilot training. AI challenges
allow diverse teams to work together to solve hard problems and are an
effective tool for developing AI solutions. AI challenges are also a key driver
of AI computational requirements. The Maneuver Identification Challenge hosted
at maneuver-id.mit.edu provides thousands of trajectories collected from pilots
practicing in flight simulators, descriptions of maneuvers, and examples of
these maneuvers performed by experienced pilots. Each trajectory consists of
positions, velocities, and aircraft orientations normalized to a common
coordinate system. Construction of the data set required significant data
architecture to transform flight simulator logs into AI ready data, which
included using a supercomputer for deduplication and data conditioning. There
are three proposed challenges. The first challenge is separating physically
plausible (good) trajectories from unfeasible (bad) trajectories. Human labeled
good and bad trajectories are provided to aid in this task. Subsequent
challenges are to label trajectories with their intended maneuvers and to
assess the quality of those maneuvers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Reinforcement Learning in Computer Vision: A Comprehensive Survey. (arXiv:2108.11510v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11510">
<div class="article-summary-box-inner">
<span><p>Deep reinforcement learning augments the reinforcement learning framework and
utilizes the powerful representation of deep neural networks. Recent works have
demonstrated the remarkable successes of deep reinforcement learning in various
domains including finance, medicine, healthcare, video games, robotics, and
computer vision. In this work, we provide a detailed review of recent and
state-of-the-art research advances of deep reinforcement learning in computer
vision. We start with comprehending the theories of deep learning,
reinforcement learning, and deep reinforcement learning. We then propose a
categorization of deep reinforcement learning methodologies and discuss their
advantages and limitations. In particular, we divide deep reinforcement
learning into seven main categories according to their applications in computer
vision, i.e. (i)landmark localization (ii) object detection; (iii) object
tracking; (iv) registration on both 2D image and 3D image volumetric data (v)
image segmentation; (vi) videos analysis; and (vii) other applications. Each of
these categories is further analyzed with reinforcement learning techniques,
network design, and performance. Moreover, we provide a comprehensive analysis
of the existing publicly available datasets and examine source code
availability. Finally, we present some open issues and discuss future research
directions on deep reinforcement learning in computer vision
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Effective and Efficient Embedding via an Adaptively-Masked Twins-based Layer. (arXiv:2108.11513v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11513">
<div class="article-summary-box-inner">
<span><p>Embedding learning for categorical features is crucial for the deep
learning-based recommendation models (DLRMs). Each feature value is mapped to
an embedding vector via an embedding learning process. Conventional methods
configure a fixed and uniform embedding size to all feature values from the
same feature field. However, such a configuration is not only sub-optimal for
embedding learning but also memory costly. Existing methods that attempt to
resolve these problems, either rule-based or neural architecture search
(NAS)-based, need extensive efforts on the human design or network training.
They are also not flexible in embedding size selection or in warm-start-based
applications. In this paper, we propose a novel and effective embedding size
selection scheme. Specifically, we design an Adaptively-Masked Twins-based
Layer (AMTL) behind the standard embedding layer. AMTL generates a mask vector
to mask the undesired dimensions for each embedding vector. The mask vector
brings flexibility in selecting the dimensions and the proposed layer can be
easily added to either untrained or trained DLRMs. Extensive experimental
evaluations show that the proposed scheme outperforms competitive baselines on
all the benchmark tasks, and is also memory-efficient, saving 60\% memory usage
without compromising any performance metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bilateral Denoising Diffusion Models. (arXiv:2108.11514v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11514">
<div class="article-summary-box-inner">
<span><p>Denoising diffusion probabilistic models (DDPMs) have emerged as competitive
generative models yet brought challenges to efficient sampling. In this paper,
we propose novel bilateral denoising diffusion models (BDDMs), which take
significantly fewer steps to generate high-quality samples. From a bilateral
modeling objective, BDDMs parameterize the forward and reverse processes with a
score network and a scheduling network, respectively. We show that a new lower
bound tighter than the standard evidence lower bound can be derived as a
surrogate objective for training the two networks. In particular, BDDMs are
efficient, simple-to-train, and capable of further improving any pre-trained
DDPM by optimizing the inference noise schedules. Our experiments demonstrated
that BDDMs can generate high-fidelity samples with as few as 3 sampling steps
and produce comparable or even higher quality samples than DDPMs using 1000
steps with only 16 sampling steps (a 62x speedup).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A New Interpolation Approach and Corresponding Instance-Based Learning. (arXiv:2108.11530v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11530">
<div class="article-summary-box-inner">
<span><p>Starting from finding approximate value of a function, introduces the measure
of approximation-degree between two numerical values, proposes the concepts of
"strict approximation" and "strict approximation region", then, derives the
corresponding one-dimensional interpolation methods and formulas, and then
presents a calculation model called "sum-times-difference formula" for
high-dimensional interpolation, thus develops a new interpolation approach,
that is, ADB interpolation. ADB interpolation is applied to the interpolation
of actual functions with satisfactory results. Viewed from principle and
effect, the interpolation approach is of novel idea, and has the advantages of
simple calculation, stable accuracy, facilitating parallel processing, very
suiting for high-dimensional interpolation, and easy to be extended to the
interpolation of vector valued functions. Applying the approach to
instance-based learning, a new instance-based learning method, learning using
ADB interpolation, is obtained. The learning method is of unique technique,
which has also the advantages of definite mathematical basis, implicit distance
weights, avoiding misclassification, high efficiency, and wide range of
applications, as well as being interpretable, etc. In principle, this method is
a kind of learning by analogy, which and the deep learning that belongs to
inductive learning can complement each other, and for some problems, the two
can even have an effect of "different approaches but equal results" in big data
and cloud computing environment. Thus, the learning using ADB interpolation can
also be regarded as a kind of "wide learning" that is dual to deep learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TPH-YOLOv5: Improved YOLOv5 Based on Transformer Prediction Head for Object Detection on Drone-captured Scenarios. (arXiv:2108.11539v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11539">
<div class="article-summary-box-inner">
<span><p>Object detection on drone-captured scenarios is a recent popular task. As
drones always navigate in different altitudes, the object scale varies
violently, which burdens the optimization of networks. Moreover, high-speed and
low-altitude flight bring in the motion blur on the densely packed objects,
which leads to great challenge of object distinction. To solve the two issues
mentioned above, we propose TPH-YOLOv5. Based on YOLOv5, we add one more
prediction head to detect different-scale objects. Then we replace the original
prediction heads with Transformer Prediction Heads (TPH) to explore the
prediction potential with self-attention mechanism. We also integrate
convolutional block attention model (CBAM) to find attention region on
scenarios with dense objects. To achieve more improvement of our proposed
TPH-YOLOv5, we provide bags of useful strategies such as data augmentation,
multiscale testing, multi-model integration and utilizing extra classifier.
Extensive experiments on dataset VisDrone2021 show that TPH-YOLOv5 have good
performance with impressive interpretability on drone-captured scenarios. On
DET-test-challenge dataset, the AP result of TPH-YOLOv5 are 39.18%, which is
better than previous SOTA method (DPNetV3) by 1.81%. On VisDrone Challenge
2021, TPHYOLOv5 wins 5th place and achieves well-matched results with 1st place
model (AP 39.43%). Compared to baseline model (YOLOv5), TPH-YOLOv5 improves
about 7%, which is encouraging and competitive.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Surprising Effectiveness of Visual Odometry Techniques for Embodied PointGoal Navigation. (arXiv:2108.11550v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11550">
<div class="article-summary-box-inner">
<span><p>It is fundamental for personal robots to reliably navigate to a specified
goal. To study this task, PointGoal navigation has been introduced in simulated
Embodied AI environments. Recent advances solve this PointGoal navigation task
with near-perfect accuracy (99.6% success) in photo-realistically simulated
environments, assuming noiseless egocentric vision, noiseless actuation, and
most importantly, perfect localization. However, under realistic noise models
for visual sensors and actuation, and without access to a "GPS and Compass
sensor," the 99.6%-success agents for PointGoal navigation only succeed with
0.3%. In this work, we demonstrate the surprising effectiveness of visual
odometry for the task of PointGoal navigation in this realistic setting, i.e.,
with realistic noise models for perception and actuation and without access to
GPS and Compass sensors. We show that integrating visual odometry techniques
into navigation policies improves the state-of-the-art on the popular Habitat
PointNav benchmark by a large margin, improving success from 64.5% to 71.7%
while executing 6.4 times faster.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">XCI-Sketch: Extraction of Color Information from Images for Generation of Colored Outlines and Sketches. (arXiv:2108.11554v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11554">
<div class="article-summary-box-inner">
<span><p>Sketches are a medium to convey a visual scene from an individual's creative
perspective. The addition of color substantially enhances the overall
expressivity of a sketch. This paper proposes two methods to mimic human-drawn
colored sketches by utilizing the Contour Drawing Dataset. Our first approach
renders colored outline sketches by applying image processing techniques aided
by k-means color clustering. The second method uses a generative adversarial
network to develop a model that can generate colored sketches from previously
unobserved images. We assess the results obtained through quantitative and
qualitative evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Attention in Machine Reading Comprehension. (arXiv:2108.11574v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11574">
<div class="article-summary-box-inner">
<span><p>Achieving human-level performance on some of Machine Reading Comprehension
(MRC) datasets is no longer challenging with the help of powerful Pre-trained
Language Models (PLMs). However, the internal mechanism of these artifacts
still remains unclear, placing an obstacle for further understanding these
models. This paper focuses on conducting a series of analytical experiments to
examine the relations between the multi-head self-attention and the final
performance, trying to analyze the potential explainability in PLM-based MRC
models. We perform quantitative analyses on SQuAD (English) and CMRC 2018
(Chinese), two span-extraction MRC datasets, on top of BERT, ALBERT, and
ELECTRA in various aspects. We discover that {\em passage-to-question} and {\em
passage understanding} attentions are the most important ones, showing strong
correlations to the final performance than other parts. Through visualizations
and case studies, we also observe several general findings on the attention
maps, which could be helpful to understand how these models solve the
questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identification of the Resting Position Based on EGG, ECG, Respiration Rate and SpO2 Using Stacked Ensemble Learning. (arXiv:2108.11604v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11604">
<div class="article-summary-box-inner">
<span><p>Rest is essential for a high-level physiological and psychological
performance. It is also necessary for the muscles to repair, rebuild, and
strengthen. There is a significant correlation between the quality of rest and
the resting posture. Therefore, identification of the resting position is of
paramount importance to maintain a healthy life. Resting postures can be
classified into four basic categories: Lying on the back (supine), facing of
the left / right sides and free-fall position. The later position is already
considered to be an unhealthy posture by researchers equivocally and hence can
be eliminated. In this paper, we analyzed the other three states of resting
position based on the data collected from the physiological parameters:
Electrogastrogram (EGG), Electrocardiogram (ECG), Respiration Rate, Heart Rate,
and Oxygen Saturation (SpO2). Based on these parameters, the resting position
is classified using a hybrid stacked ensemble machine learning model designed
using the Decision tree, Random Forest, and Xgboost algorithms. Our study
demonstrates a 100% accurate prediction of the resting position using the
hybrid model. The proposed method of identifying the resting position based on
physiological parameters has the potential to be integrated into wearable
devices. This is a low cost, highly accurate and autonomous technique to
monitor the body posture while maintaining the user privacy by eliminating the
use of RGB camera conventionally used to conduct the polysomnography (sleep
Monitoring) or resting position studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Dense Deformation Embedding Network for Template-Free Shape Correspondence. (arXiv:2108.11609v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11609">
<div class="article-summary-box-inner">
<span><p>Shape correspondence from 3D deformation learning has attracted appealing
academy interests recently. Nevertheless, current deep learning based methods
require the supervision of dense annotations to learn per-point translations,
which severely overparameterize the deformation process. Moreover, they fail to
capture local geometric details of original shape via global feature embedding.
To address these challenges, we develop a new Unsupervised Dense Deformation
Embedding Network (i.e., UD^2E-Net), which learns to predict deformations
between non-rigid shapes from dense local features. Since it is non-trivial to
match deformation-variant local features for deformation prediction, we develop
an Extrinsic-Intrinsic Autoencoder to frst encode extrinsic geometric features
from source into intrinsic coordinates in a shared canonical shape, with which
the decoder then synthesizes corresponding target features. Moreover, a bounded
maximum mean discrepancy loss is developed to mitigate the distribution
divergence between the synthesized and original features. To learn natural
deformation without dense supervision, we introduce a coarse parameterized
deformation graph, for which a novel trace and propagation algorithm is
proposed to improve both the quality and effciency of the deformation. Our
UD^2E-Net outperforms state-of-the-art unsupervised methods by 24% on Faust
Inter challenge and even supervised methods by 13% on Faust Intra challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-shot Visual Relationship Co-localization. (arXiv:2108.11618v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11618">
<div class="article-summary-box-inner">
<span><p>In this paper, given a small bag of images, each containing a common but
latent predicate, we are interested in localizing visual subject-object pairs
connected via the common predicate in each of the images. We refer to this
novel problem as visual relationship co-localization or VRC as an abbreviation.
VRC is a challenging task, even more so than the well-studied object
co-localization task. This becomes further challenging when using just a few
images, the model has to learn to co-localize visual subject-object pairs
connected via unseen predicates. To solve VRC, we propose an optimization
framework to select a common visual relationship in each image of the bag. The
goal of the optimization framework is to find the optimal solution by learning
visual relationship similarity across images in a few-shot setting. To obtain
robust visual relationship representation, we utilize a simple yet effective
technique that learns relationship embedding as a translation vector from
visual subject to visual object in a shared space. Further, to learn visual
relationship similarity, we utilize a proven meta-learning technique commonly
used for few-shot classification tasks. Finally, to tackle the combinatorial
complexity challenge arising from an exponential number of feasible solutions,
we use a greedy approximation inference algorithm that selects approximately
the best solution.
</p>
<p>We extensively evaluate our proposed framework on variations of bag sizes
obtained from two challenging public datasets, namely VrR-VG and VG-150, and
achieve impressive visual co-localization performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoMPM: Context Modeling with Speaker's Pre-trained Memory Tracking for Emotion Recognition in Conversation. (arXiv:2108.11626v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11626">
<div class="article-summary-box-inner">
<span><p>As the use of interactive machines grow, the task of Emotion Recognition in
Conversation (ERC) became more important. If the machine generated sentences
reflect emotion, more human-like sympathetic conversations are possible. Since
emotion recognition in conversation is inaccurate if the previous utterances
are not taken into account, many studies reflect the dialogue context to
improve the performances. We introduce CoMPM, a context embedding module (CoM)
combined with a pre-trained memory module (PM) that tracks memory of the
speaker's previous utterances within the context, and show that the pre-trained
memory significantly improves the final accuracy of emotion recognition. We
experimented on both the multi-party datasets (MELD, EmoryNLP) and the
dyadic-party datasets (IEMOCAP, DailyDialog), showing that our approach achieve
competitive performance on all datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MCML: A Novel Memory-based Contrastive Meta-Learning Method for Few Shot Slot Tagging. (arXiv:2108.11635v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11635">
<div class="article-summary-box-inner">
<span><p>Meta-learning is widely used for few-shot slot tagging in the task of
few-shot learning. The performance of existing methods is, however, seriously
affected by catastrophic forgetting. This phenomenon is common in deep learning
as the training and testing modules fail to take into account historical
information, i.e. previously trained episodes in the metric-based
meta-learning. To overcome this predicament, we propose the Memory-based
Contrastive Meta-learning (MCML) method. Specifically, we propose a
learn-from-memory mechanism that use explicit memory to keep track of the label
representations of previously trained episodes and propose a contrastive
learning method to compare the current label embedded in the few shot episode
with the historic ones stored in the memory, and an adaption-from memory
mechanism to determine the output label based on the contrast between the input
labels embedded in the test episode and the label clusters in the memory.
Experimental results show that MCML is scalable and outperforms metric-based
meta-learning and optimization-based meta-learning on all 1shot, 5-shot,
10-shot, and 20-shot scenarios of the SNIPS dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Model-based Reinforcement Learning for Autonomous Greenhouse Control. (arXiv:2108.11645v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11645">
<div class="article-summary-box-inner">
<span><p>Due to the high efficiency and less weather dependency, autonomous
greenhouses provide an ideal solution to meet the increasing demand for fresh
food. However, managers are faced with some challenges in finding appropriate
control strategies for crop growth, since the decision space of the greenhouse
control problem is an astronomical number. Therefore, an intelligent
closed-loop control framework is highly desired to generate an automatic
control policy. As a powerful tool for optimal control, reinforcement learning
(RL) algorithms can surpass human beings' decision-making and can also be
seamlessly integrated into the closed-loop control framework. However, in
complex real-world scenarios such as agricultural automation control, where the
interaction with the environment is time-consuming and expensive, the
application of RL algorithms encounters two main challenges, i.e., sample
efficiency and safety. Although model-based RL methods can greatly mitigate the
efficiency problem of greenhouse control, the safety problem has not got too
much attention. In this paper, we present a model-based robust RL framework for
autonomous greenhouse control to meet the sample efficiency and safety
challenges. Specifically, our framework introduces an ensemble of environment
models to work as a simulator and assist in policy optimization, thereby
addressing the low sample efficiency problem. As for the safety concern, we
propose a sample dropout module to focus more on worst-case samples, which can
help improve the adaptability of the greenhouse planting policy in extreme
cases. Experimental results demonstrate that our approach can learn a more
effective greenhouse planting policy with better robustness than existing
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Convolutional Neural Networks Demystified: A Matched Filtering Perspective Based Tutorial. (arXiv:2108.11663v1 [cs.IT])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11663">
<div class="article-summary-box-inner">
<span><p>Deep Neural Networks (DNN) and especially Convolutional Neural Networks (CNN)
are a de-facto standard for the analysis of large volumes of signals and
images. Yet, their development and underlying principles have been largely
performed in an ad-hoc and black box fashion. To help demystify CNNs, we
revisit their operation from first principles and a matched filtering
perspective. We establish that the convolution operation within CNNs, their
very backbone, represents a matched filter which examines the input
signal/image for the presence of pre-defined features. This perspective is
shown to be physically meaningful, and serves as a basis for a step-by-step
tutorial on the operation of CNNs, including pooling, zero padding, various
ways of dimensionality reduction. Starting from first principles, both the
feed-forward pass and the learning stage (via back-propagation) are illuminated
in detail, both through a worked-out numerical example and the corresponding
visualizations. It is our hope that this tutorial will help shed new light and
physical intuition into the understanding and further development of deep
neural networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Network Module Detection from Multi-Modal Node Features with a Greedy Decision Forest for Actionable Explainable AI. (arXiv:2108.11674v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11674">
<div class="article-summary-box-inner">
<span><p>Network-based algorithms are used in most domains of research and industry in
a wide variety of applications and are of great practical use. In this work, we
demonstrate subnetwork detection based on multi-modal node features using a new
Greedy Decision Forest for better interpretability. The latter will be a
crucial factor in retaining experts and gaining their trust in such algorithms
in the future. To demonstrate a concrete application example, we focus in this
paper on bioinformatics and systems biology with a special focus on
biomedicine. However, our methodological approach is applicable in many other
domains as well. Systems biology serves as a very good example of a field in
which statistical data-driven machine learning enables the analysis of large
amounts of multi-modal biomedical data. This is important to reach the future
goal of precision medicine, where the complexity of patients is modeled on a
system level to best tailor medical decisions, health practices and therapies
to the individual patient. Our glass-box approach could help to uncover
disease-causing network modules from multi-omics data to better understand
diseases such as cancer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disentangling ODE parameters from dynamics in VAEs. (arXiv:2108.11684v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11684">
<div class="article-summary-box-inner">
<span><p>Deep networks have become increasingly of interest in dynamical system
prediction, but generalization remains elusive. In this work, we consider the
physical parameters of ODEs as factors of variation of the data generating
process. By leveraging ideas from supervised disentanglement in VAEs, we aim to
separate the ODE parameters from the dynamics in the latent space. Experiments
show that supervised disentanglement allows VAEs to capture the variability in
the dynamics and extrapolate better to ODE parameter spaces that were not
present in the training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SLIM: Explicit Slot-Intent Mapping with BERT for Joint Multi-Intent Detection and Slot Filling. (arXiv:2108.11711v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11711">
<div class="article-summary-box-inner">
<span><p>Utterance-level intent detection and token-level slot filling are two key
tasks for natural language understanding (NLU) in task-oriented systems. Most
existing approaches assume that only a single intent exists in an utterance.
However, there are often multiple intents within an utterance in real-life
scenarios. In this paper, we propose a multi-intent NLU framework, called SLIM,
to jointly learn multi-intent detection and slot filling based on BERT. To
fully exploit the existing annotation data and capture the interactions between
slots and intents, SLIM introduces an explicit slot-intent classifier to learn
the many-to-one mapping between slots and intents. Empirical results on three
public multi-intent datasets demonstrate (1) the superior performance of SLIM
compared to the current state-of-the-art for NLU with multiple intents and (2)
the benefits obtained from the slot-intent classifier.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Photos Are All You Need for Reciprocal Recommendation in Online Dating. (arXiv:2108.11714v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11714">
<div class="article-summary-box-inner">
<span><p>Recommender Systems are algorithms that predict a user's preference for an
item. Reciprocal Recommenders are a subset of recommender systems, where the
items in question are people, and the objective is therefore to predict a
bidirectional preference relation. They are used in settings such as online
dating services and social networks. In particular, images provided by users
are a crucial part of user preference, and one that is not exploited much in
the literature. We present a novel method of interpreting user image preference
history and using this to make recommendations. We train a recurrent neural
network to learn a user's preferences and make predictions of reciprocal
preference relations that can be used to make recommendations that satisfy both
users. We show that our proposed system achieves an F1 score of 0.87 when using
only photographs to produce reciprocal recommendations on a large real world
online dating dataset. Our system significantly outperforms on the state of the
art in both content-based and collaborative filtering systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A survey on Bayesian inference for Gaussian mixture model. (arXiv:2108.11753v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11753">
<div class="article-summary-box-inner">
<span><p>Clustering has become a core technology in machine learning, largely due to
its application in the field of unsupervised learning, clustering,
classification, and density estimation. A frequentist approach exists to hand
clustering based on mixture model which is known as the EM algorithm where the
parameters of the mixture model are usually estimated into a maximum likelihood
estimation framework. Bayesian approach for finite and infinite Gaussian
mixture model generates point estimates for all variables as well as associated
uncertainty in the form of the whole estimates' posterior distribution.
</p>
<p>The sole aim of this survey is to give a self-contained introduction to
concepts and mathematical tools in Bayesian inference for finite and infinite
Gaussian mixture model in order to seamlessly introduce their applications in
subsequent sections. However, we clearly realize our inability to cover all the
useful and interesting results concerning this field and given the paucity of
scope to present this discussion, e.g., the separated analysis of the
generation of Dirichlet samples by stick-breaking and Polya's Urn approaches.
We refer the reader to literature in the field of the Dirichlet process mixture
model for a much detailed introduction to the related fields. Some excellent
examples include (Frigyik et al., 2010; Murphy, 2012; Gelman et al., 2014;
Hoff, 2009).
</p>
<p>This survey is primarily a summary of purpose, significance of important
background and techniques for Gaussian mixture model, e.g., Dirichlet prior,
Chinese restaurant process, and most importantly the origin and complexity of
the methods which shed light on their modern applications. The mathematical
prerequisite is a first course in probability. Other than this modest
background, the development is self-contained, with rigorous proofs provided
throughout.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disentangling What and Where for 3D Object-Centric Representations Through Active Inference. (arXiv:2108.11762v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11762">
<div class="article-summary-box-inner">
<span><p>Although modern object detection and classification models achieve high
accuracy, these are typically constrained in advance on a fixed train set and
are therefore not flexible to deal with novel, unseen object categories.
Moreover, these models most often operate on a single frame, which may yield
incorrect classifications in case of ambiguous viewpoints. In this paper, we
propose an active inference agent that actively gathers evidence for object
classifications, and can learn novel object categories over time. Drawing
inspiration from the human brain, we build object-centric generative models
composed of two information streams, a what- and a where-stream. The
what-stream predicts whether the observed object belongs to a specific
category, while the where-stream is responsible for representing the object in
its internal 3D reference frame. We show that our agent (i) is able to learn
representations for many object categories in an unsupervised way, (ii)
achieves state-of-the-art classification accuracies, actively resolving
ambiguity when required and (iii) identifies novel object categories.
Furthermore, we validate our system in an end-to-end fashion where the agent is
able to search for an object at a given pose from a pixel-based rendering. We
believe that this is a first step towards building modular, intelligent systems
that can be used for a wide range of tasks involving three dimensional objects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multiple Sclerosis Lesions Identification/Segmentation in Magnetic Resonance Imaging using Ensemble CNN and Uncertainty Classification. (arXiv:2108.11791v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11791">
<div class="article-summary-box-inner">
<span><p>To date, several automated strategies for identification/segmentation of
Multiple Sclerosis (MS) lesions by Magnetic Resonance Imaging (MRI) have been
presented which are either outperformed by human experts or, at least, whose
results are well distinguishable from humans. This is due to the ambiguity
originated by MRI instabilities, peculiar MS Heterogeneity and MRI unspecific
nature with respect to MS. Physicians partially treat the uncertainty generated
by ambiguity relying on personal radiological/clinical/anatomical background
and experience.
</p>
<p>We present an automated framework for MS lesions identification/segmentation
based on three pivotal concepts to better emulate human reasoning: the modeling
of uncertainty; the proposal of two, separately trained, CNN, one optimized
with respect to lesions themselves and the other to the environment surrounding
lesions, respectively repeated for axial, coronal and sagittal directions; the
ensemble of the CNN output.
</p>
<p>The proposed framework is trained, validated and tested on the 2016 MSSEG
benchmark public data set from a single imaging modality, FLuid-Attenuated
Inversion Recovery (FLAIR). The comparison, performed on the segmented lesions
by means of most of the metrics normally used with respect to the ground-truth
and the 7 human raters in MSSEG, prove that there is no significant difference
between the proposed framework and the other raters. Results are also shown for
the uncertainty, though a comparison with the other raters is impossible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Out-of-Distribution Detection Using Latent Space of $\beta$-VAE for Cyber-Physical Systems. (arXiv:2108.11800v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11800">
<div class="article-summary-box-inner">
<span><p>Deep Neural Networks are actively being used in the design of autonomous
Cyber-Physical Systems (CPSs). The advantage of these models is their ability
to handle high-dimensional state-space and learn compact surrogate
representations of the operational state spaces. However, the problem is that
the sampled observations used for training the model may never cover the entire
state space of the physical environment, and as a result, the system will
likely operate in conditions that do not belong to the training distribution.
These conditions that do not belong to training distribution are referred to as
Out-of-Distribution (OOD). Detecting OOD conditions at runtime is critical for
the safety of CPS. In addition, it is also desirable to identify the context or
the feature(s) that are the source of OOD to select an appropriate control
action to mitigate the consequences that may arise because of the OOD
condition. In this paper, we study this problem as a multi-labeled time series
OOD detection problem over images, where the OOD is defined both sequentially
across short time windows (change points) as well as across the training data
distribution. A common approach to solving this problem is the use of
multi-chained one-class classifiers. However, this approach is expensive for
CPSs that have limited computational resources and require short inference
times. Our contribution is an approach to design and train a single
$\beta$-Variational Autoencoder detector with a partially disentangled latent
space sensitive to variations in image features. We use the feature sensitive
latent variables in the latent space to detect OOD images and identify the most
likely feature(s) responsible for the OOD. We demonstrate our approach using an
Autonomous Vehicle in the CARLA simulator and a real-world automotive dataset
called nuImages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human readable network troubleshooting based on anomaly detection and feature scoring. (arXiv:2108.11807v1 [cs.NI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11807">
<div class="article-summary-box-inner">
<span><p>Network troubleshooting is still a heavily human-intensive process. To reduce
the time spent by human operators in the diagnosis process, we present a system
based on (i) unsupervised learning methods for detecting anomalies in the time
domain, (ii) an attention mechanism to rank features in the feature space and
finally (iii) an expert knowledge module able to seamlessly incorporate
previously collected domain-knowledge. In this paper, we thoroughly evaluate
the performance of the full system and of its individual building blocks:
particularly, we consider (i) 10 anomaly detection algorithms as well as (ii)
10 attention mechanisms, that comprehensively represent the current state of
the art in the respective fields. Leveraging a unique collection of
expert-labeled datasets worth several months of real router telemetry data, we
perform a thorough performance evaluation contrasting practical results in
constrained stream-mode settings, with the results achievable by an ideal
oracle in academic settings. Our experimental evaluation shows that (i) the
proposed system is effective in achieving high levels of agreement with the
expert, and (ii) that even a simple statistical approach is able to extract
useful information from expert knowledge gained in past cases, significantly
improving troubleshooting performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When should agents explore?. (arXiv:2108.11811v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11811">
<div class="article-summary-box-inner">
<span><p>Exploration remains a central challenge for reinforcement learning (RL).
Virtually all existing methods share the feature of a monolithic behaviour
policy that changes only gradually (at best). In contrast, the exploratory
behaviours of animals and humans exhibit a rich diversity, namely including
forms of switching between modes. This paper presents an initial study of
mode-switching, non-monolithic exploration for RL. We investigate different
modes to switch between, at what timescales it makes sense to switch, and what
signals make for good switching triggers. We also propose practical algorithmic
components that make the switching mechanism adaptive and robust, which enables
flexibility without an accompanying hyper-parameter-tuning burden. Finally, we
report a promising and detailed analysis on Atari, using two-mode exploration
and switching at sub-episodic time-scales.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Magnetic Field Sensing for Pedestrian and Robot Indoor Positioning. (arXiv:2108.11824v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11824">
<div class="article-summary-box-inner">
<span><p>In this paper we address the problem of indoor localization using magnetic
field data in two setups, when data is collected by (i) human-held mobile phone
and (ii) by localization robots that perturb magnetic data with their own
electromagnetic field. For the first setup, we revise the state of the art
approaches and propose a novel extended pipeline to benefit from the presence
of magnetic anomalies in indoor environment created by different ferromagnetic
objects. We capture changes of the Earth's magnetic field due to indoor
magnetic anomalies and transform them in multi-variate times series. We then
convert temporal patterns into visual ones. We use methods of Recurrence Plots,
Gramian Angular Fields and Markov Transition Fields to represent magnetic field
time series as image sequences. We regress the continuous values of user
position in a deep neural network that combines convolutional and recurrent
layers. For the second setup, we analyze how magnetic field data get perturbed
by robots' electromagnetic field. We add an alignment step to the main
pipeline, in order to compensate the mismatch between train and test sets
obtained by different robots. We test our methods on two public (MagPie and
IPIN'20) and one proprietary (Hyundai department store) datasets. We report
evaluation results and show that our methods outperform the state of the art
methods by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gene Transformer: Transformers for the Gene Expression-based Classification of Cancer Subtypes. (arXiv:2108.11833v1 [q-bio.QM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11833">
<div class="article-summary-box-inner">
<span><p>Adenocarcinoma and squamous cell carcinoma constitute approximately 40% and
30% of all lung cancer subtypes, respectively, and display broad heterogeneity
in terms of clinical and molecular responses to therapy. Molecular subtyping
has enabled precision medicine to overcome these challenges and provide
significant biological insights to predict prognosis and improve clinical
decision making. Over the past decade, conventional ML algorithms and DL-based
CNNs have been espoused for the classification of cancer subtypes from gene
expression datasets. However, these methods are potentially biased toward
identification of cancer biomarkers. Recently proposed transformer-based
architectures that leverage the self-attention mechanism encode high throughput
gene expressions and learn representations that are computationally complex and
parametrically expensive. However, compared to the datasets for natural
language processing applications, gene expression consists of several hundreds
of thousands of genes from a limited number of observations, making it
difficult to efficiently train transformers for bioinformatics applications.
Hence, we propose an end-to-end deep learning approach, Gene Transformer, which
addresses the complexity of high-dimensional gene expression with a multi-head
self-attention module by identifying relevant biomarkers across multiple cancer
subtypes without requiring feature selection as a prerequisite for the current
classification algorithms. The proposed architecture achieved an overall
improved performance for all evaluation metrics and had fewer misclassification
errors than the commonly used traditional classification algorithms. The
classification results show that Gene Transformer can be an efficient approach
for classifying cancer subtypes, indicating that any improvement in deep
learning models in computational biology can also be reflected well in this
domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Geometry Based Machining Feature Retrieval with Inductive Transfer Learning. (arXiv:2108.11838v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11838">
<div class="article-summary-box-inner">
<span><p>Manufacturing industries have widely adopted the reuse of machine parts as a
method to reduce costs and as a sustainable manufacturing practice.
Identification of reusable features from the design of the parts and finding
their similar features from the database is an important part of this process.
In this project, with the help of fully convolutional geometric features, we
are able to extract and learn the high level semantic features from CAD models
with inductive transfer learning. The extracted features are then compared with
that of other CAD models from the database using Frobenius norm and identical
features are retrieved. Later we passed the extracted features to a deep
convolutional neural network with a spatial pyramid pooling layer and the
performance of the feature retrieval increased significantly. It was evident
from the results that the model could effectively capture the geometrical
elements from machining features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI at work -- Mitigating safety and discriminatory risk with technical standards. (arXiv:2108.11844v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11844">
<div class="article-summary-box-inner">
<span><p>The use of artificial intelligence (AI) and AI methods in the workplace holds
both great opportunities as well as risks to occupational safety and
discrimination. In addition to legal regulation, technical standards will play
a key role in mitigating such risk by defining technical requirements for
development and testing of AI systems. This paper provides an overview and
assessment of existing international, European and German standards as well as
those currently under development. The paper is part of the research project
"ExamAI - Testing and Auditing of AI systems" and focusses on the use of AI in
an industrial production environment as well as in the realm of human resource
management (HR).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatio-Temporal Graph Contrastive Learning. (arXiv:2108.11873v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11873">
<div class="article-summary-box-inner">
<span><p>Deep learning models are modern tools for spatio-temporal graph (STG)
forecasting. Despite their effectiveness, they require large-scale datasets to
achieve better performance and are vulnerable to noise perturbation. To
alleviate these limitations, an intuitive idea is to use the popular data
augmentation and contrastive learning techniques. However, existing graph
contrastive learning methods cannot be directly applied to STG forecasting due
to three reasons. First, we empirically discover that the forecasting task is
unable to benefit from the pretrained representations derived from contrastive
learning. Second, data augmentations that are used for defeating noise are less
explored for STG data. Third, the semantic similarity of samples has been
overlooked. In this paper, we propose a Spatio-Temporal Graph Contrastive
Learning framework (STGCL) to tackle these issues. Specifically, we improve the
performance by integrating the forecasting loss with an auxiliary contrastive
loss rather than using a pretrained paradigm. We elaborate on four types of
data augmentations, which disturb data in terms of graph structure, time
domain, and frequency domain. We also extend the classic contrastive loss
through a rule-based strategy that filters out the most semantically similar
negatives. Our framework is evaluated across three real-world datasets and four
state-of-the-art models. The consistent improvements demonstrate that STGCL can
be used as an off-the-shelf plug-in for existing deep models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human operator cognitive availability aware Mixed-Initiative control. (arXiv:2108.11885v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11885">
<div class="article-summary-box-inner">
<span><p>This paper presents a Cognitive Availability Aware Mixed-Initiative
Controller for remotely operated mobile robots. The controller enables dynamic
switching between different levels of autonomy (LOA), initiated by either the
AI or the human operator. The controller leverages a state-of-the-art computer
vision method and an off-the-shelf web camera to infer the cognitive
availability of the operator and inform the AI-initiated LOA switching. This
constitutes a qualitative advancement over previous Mixed-Initiative (MI)
controllers. The controller is evaluated in a disaster response experiment, in
which human operators have to conduct an exploration task with a remote robot.
MI systems are shown to effectively assist the operators, as demonstrated by
quantitative and qualitative results in performance and workload. Additionally,
some insights into the experimental difficulties of evaluating complex MI
controllers are presented.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Federated Reinforcement Learning: Techniques, Applications, and Open Challenges. (arXiv:2108.11887v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11887">
<div class="article-summary-box-inner">
<span><p>This paper presents a comprehensive survey of Federated Reinforcement
Learning (FRL), an emerging and promising field in Reinforcement Learning (RL).
Starting with a tutorial of Federated Learning (FL) and RL, we then focus on
the introduction of FRL as a new method with great potential by leveraging the
basic idea of FL to improve the performance of RL while preserving
data-privacy. According to the distribution characteristics of the agents in
the framework, FRL algorithms can be divided into two categories, i.e.
Horizontal Federated Reinforcement Learning (HFRL) and Vertical Federated
Reinforcement Learning (VFRL). We provide the detailed definitions of each
category by formulas, investigate the evolution of FRL from a technical
perspective, and highlight its advantages over previous RL algorithms. In
addition, the existing works on FRL are summarized by application fields,
including edge computing, communication, control optimization, and attack
detection. Finally, we describe and discuss several key research directions
that are crucial to solving the open problems within FRL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Learning for Discovering Effective Interaction Kernels between Celestial Bodies from Ephemerides. (arXiv:2108.11894v1 [astro-ph.EP])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11894">
<div class="article-summary-box-inner">
<span><p>Building accurate and predictive models of the underlying mechanisms of
celestial motion has inspired fundamental developments in theoretical physics.
Candidate theories seek to explain observations and predict future positions of
planets, stars, and other astronomical bodies as faithfully as possible. We use
a data-driven learning approach, extending that developed in Lu et al. ($2019$)
and extended in Zhong et al. ($2020$), to a derive stable and accurate model
for the motion of celestial bodies in our Solar System. Our model is based on a
collective dynamics framework, and is learned from the NASA Jet Propulsion
Lab's development ephemerides. By modeling the major astronomical bodies in the
Solar System as pairwise interacting agents, our learned model generate
extremely accurate dynamics that preserve not only intrinsic geometric
properties of the orbits, but also highly sensitive features of the dynamics,
such as perihelion precession rates. Our learned model can provide a unified
explanation to the observation data, especially in terms of reproducing the
perihelion precession of Mars, Mercury, and the Moon. Moreover, Our model
outperforms Newton's Law of Universal Gravitation in all cases and performs
similarly to, and exceeds on the Moon, the Einstein-Infeld-Hoffman equations
derived from Einstein's theory of general relativity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sketches for Time-Dependent Machine Learning. (arXiv:2108.11923v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11923">
<div class="article-summary-box-inner">
<span><p>Time series data can be subject to changes in the underlying process that
generates them and, because of these changes, models built on old samples can
become obsolete or perform poorly. In this work, we present a way to
incorporate information about the current data distribution and its evolution
across time into machine learning algorithms. Our solution is based on
efficiently maintaining statistics, particularly the mean and the variance, of
data features at different time resolutions. These data summarisations can be
performed over the input attributes, in which case they can then be fed into
the model as additional input features, or over latent representations learned
by models, such as those of Recurrent Neural Networks. In classification tasks,
the proposed techniques can significantly outperform the prediction
capabilities of equivalent architectures with no feature / latent
summarisations. Furthermore, these modifications do not introduce notable
computational and memory overhead when properly adjusted.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weisfeiler-Leman in the BAMBOO: Novel AMR Graph Metrics and a Benchmark for AMR Graph Similarity. (arXiv:2108.11949v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11949">
<div class="article-summary-box-inner">
<span><p>Several metrics have been proposed for assessing the similarity of (abstract)
meaning representations (AMRs), but little is known about how they relate to
human similarity ratings. Moreover, the current metrics have complementary
strengths and weaknesses: some emphasize speed, while others make the alignment
of graph structures explicit, at the price of a costly alignment step.
</p>
<p>In this work we propose new Weisfeiler-Leman AMR similarity metrics that
unify the strengths of previous metrics, while mitigating their weaknesses.
Specifically, our new metrics are able to match contextualized substructures
and induce n:m alignments between their nodes. Furthermore, we introduce a
Benchmark for AMR Metrics based on Overt Objectives (BAMBOO), the first
benchmark to support empirical assessment of graph-based MR similarity metrics.
BAMBOO maximizes the interpretability of results by defining multiple overt
objectives that range from sentence similarity objectives to stress tests that
probe a metric's robustness against meaning-altering and meaning-preserving
graph transformations. We show the benefits of BAMBOO by profiling previous
metrics and our own metrics. Results indicate that our novel metrics may serve
as a strong baseline for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Intriguing Relation Between Counterfactual Explanations and Adversarial Examples. (arXiv:2009.05487v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05487">
<div class="article-summary-box-inner">
<span><p>The same method that creates adversarial examples (AEs) to fool
image-classifiers can be used to generate counterfactual explanations (CEs)
that explain algorithmic decisions. This observation has led researchers to
consider CEs as AEs by another name. We argue that the relationship to the true
label and the tolerance with respect to proximity are two properties that
formally distinguish CEs and AEs. Based on these arguments, we introduce CEs,
AEs, and related concepts mathematically in a common framework. Furthermore, we
show connections between current methods for generating CEs and AEs, and
estimate that the fields will merge more and more as the number of common
use-cases grows.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cascaded Refinement Network for Point Cloud Completion with Self-supervision. (arXiv:2010.08719v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08719">
<div class="article-summary-box-inner">
<span><p>Point clouds are often sparse and incomplete, which imposes difficulties for
real-world applications. Existing shape completion methods tend to generate
rough shapes without fine-grained details. Considering this, we introduce a
two-branch network for shape completion. The first branch is a cascaded shape
completion sub-network to synthesize complete objects, where we propose to use
the partial input together with the coarse output to preserve the object
details during the dense point reconstruction. The second branch is an
auto-encoder to reconstruct the original partial input. The two branches share
a same feature extractor to learn an accurate global feature for shape
completion. Furthermore, we propose two strategies to enable the training of
our network when ground truth data are not available. This is to mitigate the
dependence of existing approaches on large amounts of ground truth training
data that are often difficult to obtain in real-world applications.
Additionally, our proposed strategies are also able to improve the
reconstruction quality for fully supervised learning. We verify our approach in
self-supervised, semi-supervised and fully supervised settings with superior
performances. Quantitative and qualitative results on different datasets
demonstrate that our method achieves more realistic outputs than
state-of-the-art approaches on the point cloud completion task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Network iLQR: A Reinforcement Learning Architecture for Trajectory Optimization. (arXiv:2011.10737v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10737">
<div class="article-summary-box-inner">
<span><p>As a notable machine learning paradigm, the research efforts in the context
of reinforcement learning have certainly progressed leaps and bounds. When
compared with reinforcement learning methods with the given system model, the
methodology of the reinforcement learning architecture based on the unknown
model generally exhibits significantly broader universality and applicability.
In this work, a new reinforcement learning architecture based on iterative
linear quadratic regulator (iLQR) is developed and presented without the
requirement of any prior knowledge of the system model, which is termed as an
approach of a "neural network iterative linear quadratic regulator (NNiLQR)".
Depending solely on measurement data, this method yields a completely new
non-parametric routine for the establishment of the optimal policy (without the
necessity of system modeling) through iterative refinements of the neural
network system. Rather importantly, this approach significantly outperforms the
classical iLQR method in terms of the given objective function because of the
innovative utilization of further exploration in the methodology. As clearly
indicated from the results attained in two illustrative examples, these
significant merits of the NNiLQR method are demonstrated rather evidently.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multistage BiCross encoder for multilingual access to COVID-19 health information. (arXiv:2101.03013v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03013">
<div class="article-summary-box-inner">
<span><p>The Coronavirus (COVID-19) pandemic has led to a rapidly growing 'infodemic'
of health information online. This has motivated the need for accurate semantic
search and retrieval of reliable COVID-19 information across millions of
documents, in multiple languages. To address this challenge, this paper
proposes a novel high precision and high recall neural Multistage BiCross
encoder approach. It is a sequential three-stage ranking pipeline which uses
the Okapi BM25 retrieval algorithm and transformer-based bi-encoder and
cross-encoder to effectively rank the documents with respect to the given
query. We present experimental results from our participation in the
Multilingual Information Access (MLIA) shared task on COVID-19 multilingual
semantic search. The independently evaluated MLIA results validate our approach
and demonstrate that it outperforms other state-of-the-art approaches according
to nearly all evaluation metrics in cases of both monolingual and bilingual
runs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Temporal Knowledge Graph Forecasting with Neural ODE. (arXiv:2101.05151v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05151">
<div class="article-summary-box-inner">
<span><p>Learning node representation on dynamically-evolving, multi-relational graph
data has gained great research interest. However, most of the existing models
for temporal knowledge graph forecasting use Recurrent Neural Network (RNN)
with discrete depth to capture temporal information, while time is a continuous
variable. Inspired by Neural Ordinary Differential Equation (NODE), we extend
the idea of continuum-depth models to time-evolving multi-relational graph
data, and propose a novel Temporal Knowledge Graph Forecasting model with NODE.
Our model captures temporal information through NODE and structural information
through a Graph Neural Network (GNN). Thus, our graph ODE model achieves a
continuous model in time and efficiently learns node representation for future
prediction. We evaluate our model on six temporal knowledge graph datasets by
performing link forecasting. Experiment results show the superiority of our
model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptivity without Compromise: A Momentumized, Adaptive, Dual Averaged Gradient Method for Stochastic Optimization. (arXiv:2101.11075v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11075">
<div class="article-summary-box-inner">
<span><p>We introduce MADGRAD, a novel optimization method in the family of AdaGrad
adaptive gradient methods. MADGRAD shows excellent performance on deep learning
optimization problems from multiple fields, including classification and
image-to-image tasks in vision, and recurrent and bidirectionally-masked models
in natural language processing. For each of these tasks, MADGRAD matches or
outperforms both SGD and ADAM in test set performance, even on problems for
which adaptive methods normally perform poorly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Solving the DeepFake Problem : An Analysis on Improving DeepFake Detection using Dynamic Face Augmentation. (arXiv:2102.09603v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09603">
<div class="article-summary-box-inner">
<span><p>The creation of altered and manipulated faces has become more common due to
the improvement of DeepFake generation methods. Simultaneously, we have seen
detection models' development for differentiating between a manipulated and
original face from image or video content. In this paper, we focus on
identifying the limitations and shortcomings of existing deepfake detection
frameworks. We identified some key problems surrounding deepfake detection
through quantitative and qualitative analysis of existing methods and datasets.
We found that deepfake datasets are highly oversampled, causing models to
become easily overfitted. The datasets are created using a small set of real
faces to generate multiple fake samples. When trained on these datasets, models
tend to memorize the actors' faces and labels instead of learning fake
features. To mitigate this problem, we propose a simple data augmentation
method termed Face-Cutout. Our method dynamically cuts out regions of an image
using the face landmark information. It helps the model selectively attend to
only the relevant regions of the input. Our evaluation experiments show that
Face-Cutout can successfully improve the data variation and alleviate the
problem of overfitting. Our method achieves a reduction in LogLoss of 15.2% to
35.3% on different datasets, compared to other occlusion-based techniques.
Moreover, we also propose a general-purpose data pre-processing guideline to
train and evaluate existing architectures allowing us to improve the
generalizability of these models for deepfake detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cluster-based Input Weight Initialization for Echo State Networks. (arXiv:2103.04710v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04710">
<div class="article-summary-box-inner">
<span><p>Echo State Networks (ESNs) are a special type of recurrent neural networks
(RNNs), in which the input and recurrent connections are traditionally
generated randomly, and only the output weights are trained. Despite the recent
success of ESNs in various tasks of audio, image and radar recognition, we
postulate that a purely random initialization is not the ideal way of
initializing ESNs. The aim of this work is to propose an unsupervised
initialization of the input connections using the K-Means algorithm on the
training data. We show that for a large variety of datasets this initialization
performs equivalently or superior than a randomly initialized ESN whilst
needing significantly less reservoir neurons. Furthermore, we discuss that this
approach provides the opportunity to estimate a suitable size of the reservoir
based on prior knowledge about the data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections. (arXiv:2104.04670v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04670">
<div class="article-summary-box-inner">
<span><p>Large pre-trained language models (LMs) such as GPT-3 have acquired a
surprising ability to perform zero-shot learning. For example, to classify
sentiment without any training examples, we can "prompt" the LM with the review
and the label description "Does the user like this movie?", and ask whether the
next word is "yes" or "no". However, the next word prediction training
objective is still misaligned with the target zero-shot learning objective. To
address this weakness, we propose meta-tuning, which directly optimizes the
zero-shot learning objective by fine-tuning pre-trained language models on a
collection of datasets. We focus on classification tasks, and construct the
meta-dataset by aggregating 43 existing datasets and annotating 441 label
descriptions in a question-answering (QA) format. When evaluated on unseen
tasks, meta-tuned models outperform a same-sized QA model and the previous SOTA
zero-shot learning system based on natural language inference. Additionally,
increasing parameter count from 220M to 770M improves AUC-ROC scores by 6.3%,
and we forecast that even larger models would perform better. Therefore,
measuring zero-shot learning performance on language models out-of-the-box
might underestimate their true potential, and community-wide efforts on
aggregating datasets and unifying their formats can help build models that
answer prompts better.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tensor Processing Primitives: A Programming Abstraction for Efficiency and Portability in Deep Learning Workloads. (arXiv:2104.05755v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05755">
<div class="article-summary-box-inner">
<span><p>During the past decade, novel Deep Learning (DL) algorithms/workloads and
hardware have been developed to tackle a wide range of problems. Despite the
advances in workload/hardware ecosystems, the programming methodology of DL
systems is stagnant. DL workloads leverage either highly optimized, yet
platform-specific and inflexible kernels from DL libraries, or in the case of
novel operators, reference implementations are built via DL framework
primitives with underwhelming performance. This work introduces the Tensor
Processing Primitives (TPP), a programming abstraction striving for efficient,
portable implementation of DL workloads with high productivity. TPPs define a
compact, yet versatile set of 2D-tensor operators (or a virtual Tensor ISA),
which subsequently can be utilized as building blocks to construct complex
operators on high-dimensional tensors. The TPP specification is
platform-agnostic, thus code expressed via TPPs is portable, whereas the TPP
implementation is highly optimized and platform-specific. We demonstrate the
efficacy of our approach using standalone kernels and end-to-end DL workloads
expressed entirely via TPPs that outperform state-of-the-art implementations on
multiple platforms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition. (arXiv:2105.01883v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01883">
<div class="article-summary-box-inner">
<span><p>We propose RepMLP, a multi-layer-perceptron-style neural network building
block for image recognition, which is composed of a series of fully-connected
(FC) layers. Compared to convolutional layers, FC layers are more efficient,
better at modeling the long-range dependencies and positional patterns, but
worse at capturing the local structures, hence usually less favored for image
recognition. We propose a structural re-parameterization technique that adds
local prior into an FC to make it powerful for image recognition. Specifically,
we construct convolutional layers inside a RepMLP during training and merge
them into the FC for inference. On CIFAR, a simple pure-MLP model shows
performance very close to CNN. By inserting RepMLP in traditional CNN, we
improve ResNets by 1.8% accuracy on ImageNet, 2.9% for face recognition, and
2.3% mIoU on Cityscapes with lower FLOPs. Our intriguing findings highlight
that combining the global representational capacity and positional perception
of FC with the local prior of convolution can improve the performance of neural
network with faster speed on both the tasks with translation invariance (e.g.,
semantic segmentation) and those with aligned images and positional patterns
(e.g., face recognition). The code and models are available at
https://github.com/DingXiaoH/RepMLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Implementation and Evaluation of a Multivariate Abstraction-Based, Interval-Based Dynamic Time-Warping Method as a Similarity Measure for Longitudinal Medical Records. (arXiv:2105.08450v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08450">
<div class="article-summary-box-inner">
<span><p>We extended dynamic time warping (DTW) into interval-based dynamic time
warping (iDTW), including (A) interval-based representation (iRep): [1]
abstracting raw, time-stamped data into interval-based abstractions, [2]
comparison-period scoping, [3] partitioning abstract intervals into a given
temporal granularity; (B) interval-based matching (iMatch): matching
partitioned, abstract-concepts records, using a modified DTW. Using domain
knowledge, we abstracted the raw data of medical records, for up to three
concepts out of four or five relevant concepts, into two interval types: State
abstractions (e.g. LOW, HIGH) and Gradient abstractions (e.g. INCREASING,
DECREASING). We created all uni-dimensional (State or Gradient) or
multi-dimensional (State and Gradient) abstraction combinations. Tasks:
Classifying 161 oncology patients records as autologous or allogenic
bone-marrow transplantation; classifying 125 hepatitis patients records as B or
C hepatitis; predicting micro- or macro-albuminuria in the next year for 151
Type 2 diabetes patients. We used a k-Nearest-Neighbors majority, k = an odd
number from 1 to SQRT(N), N = set size. 75,936 10-fold cross-validation
experiments were performed: 33,600 (Oncology), 28,800 (Hepatitis), 13,536
(Diabetes). Measures: Area Under the Curve (AUC), optimal Youden's Index.
Paired t-tests compared result vectors for equivalent configurations other than
a tested variable, to determine a significant mean accuracy difference
(P&lt;0.05). Mean classification and prediction using abstractions was
significantly better than using only raw time-stamped data. In each domain, at
least one abstraction combination led to a significantly better mean
performance than raw data. Increasing feature number and using
Multi-dimensional abstractions enhanced performance. Unlike when using raw
data, optimal mean performance was often reached with k=5, using abstractions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FeSHI: Feature Map Based Stealthy Hardware Intrinsic Attack. (arXiv:2106.06895v3 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06895">
<div class="article-summary-box-inner">
<span><p>To reduce the time-to-market and access to state-of-the-art techniques, CNN
hardware mapping and deployment on embedded accelerators are often outsourced
to untrusted third parties, which is going to be more prevalent in futuristic
artificial intelligence of things (AIoT) systems. These AIoT systems anticipate
horizontal collaboration among different resource-constrained AIoT node
devices, where CNN layers are partitioned and these devices collaboratively
compute complex CNN tasks. This horizontal collaboration opens another attack
surface to the CNN-based application, like inserting the hardware Trojans (HT)
into the embedded accelerators designed for the CNN. Therefore, there is a dire
need to explore this attack surface for designing secure embedded hardware
accelerators for CNNs. Towards this goal, in this paper, we exploited this
attack surface to propose an HT-based attack called FeSHI. Since in horizontal
collaboration of RC AIoT devices different sections of CNN architectures are
outsourced to different untrusted third parties, the attacker may not know the
input image, but it has access to the layer-by-layer output feature maps
information for the assigned sections of the CNN architecture. This attack
exploits the statistical distribution, i.e., Gaussian distribution, of the
layer-by-layer feature maps of the CNN to design two triggers for stealthy HT
with a very low probability of triggering. Also, three different novel,
stealthy and effective trigger designs are proposed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Backpropagation Algorithm Implemented on Spiking Neuromorphic Hardware. (arXiv:2106.07030v2 [cs.NE] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07030">
<div class="article-summary-box-inner">
<span><p>The capabilities of natural neural systems have inspired new generations of
machine learning algorithms as well as neuromorphic very large-scale integrated
(VLSI) circuits capable of fast, low-power information processing. However, it
has been argued that most modern machine learning algorithms are not
neurophysiologically plausible. In particular, the workhorse of modern deep
learning, the backpropagation algorithm, has proven difficult to translate to
neuromorphic hardware. In this study, we present a neuromorphic, spiking
backpropagation algorithm based on synfire-gated dynamical information
coordination and processing, implemented on Intel's Loihi neuromorphic research
processor. We demonstrate a proof-of-principle three-layer circuit that learns
to classify digits from the MNIST dataset. To our knowledge, this is the first
work to show a Spiking Neural Network (SNN) implementation of the
backpropagation algorithm that is fully on-chip, without a computer in the
loop. It is competitive in accuracy with off-chip trained SNNs and achieves an
energy-delay product suitable for edge computing. This implementation shows a
path for using in-memory, massively parallel neuromorphic processors for
low-power, low-latency implementation of modern deep learning applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Smart and Defensive Human-Machine Approach to Code Analysis. (arXiv:2108.03294v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03294">
<div class="article-summary-box-inner">
<span><p>Static analysis remains one of the most popular approaches for detecting and
correcting poor or vulnerable program code. It involves the examination of code
listings, test results, or other documentation to identify errors, violations
of development standards, or other problems, with the ultimate goal of fixing
these errors so that systems and software are as secure as possible. There
exists a plethora of static analysis tools, which makes it challenging for
businesses and programmers to select a tool to analyze their program code. It
is imperative to find ways to improve code analysis so that it can be employed
by cyber defenders to mitigate security risks. In this research, we propose a
method that employs the use of virtual assistants to work with programmers to
ensure that software are as safe as possible in order to protect
safety-critical systems from data breaches and other attacks. The proposed
method employs a recommender system that uses various metrics to help
programmers select the most appropriate code analysis tool for their project
and guides them through the analysis process. The system further tracks the
user's behavior regarding the adoption of the recommended practices.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking of AlphaStar. (arXiv:2108.03452v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03452">
<div class="article-summary-box-inner">
<span><p>We present a different view for AlphaStar (AS), the program achieving
Grand-Master level in the game StarCraft II. It is considered big progress for
AI research. However, in this paper, we present problems with the AS, some of
which are the defects of it, and some of which are important details that are
neglected in its article. These problems arise two questions. One is that what
can we get from the built of AS? The other is that does the battle between it
with humans fair? After the discussion, we present the future research
directions for these problems. Our study is based on a reproduction code of the
AS, and the codes are available online.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TDLS: A Top-Down Layer Searching Algorithm for Generating Counterfactual Visual Explanation. (arXiv:2108.04238v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04238">
<div class="article-summary-box-inner">
<span><p>Explanation of AI, as well as fairness of algorithms' decisions and the
transparency of the decision model, are becoming more and more important. And
it is crucial to design effective and human-friendly techniques when opening
the black-box model. Counterfactual conforms to the human way of thinking and
provides a human-friendly explanation, and its corresponding explanation
algorithm refers to a strategic alternation of a given data point so that its
model output is "counter-facted", i.e. the prediction is reverted. In this
paper, we adapt counterfactual explanation over fine-grained image
classification problem. We demonstrated an adaptive method that could give a
counterfactual explanation by showing the composed counterfactual feature map
using top-down layer searching algorithm (TDLS). We have proved that our TDLS
algorithm could provide more flexible counterfactual visual explanation in an
efficient way using VGG-16 model on Caltech-UCSD Birds 200 dataset. At the end,
we discussed several applicable scenarios of counterfactual visual
explanations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Time-Optimal Planning for Quadrotor Waypoint Flight. (arXiv:2108.04537v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04537">
<div class="article-summary-box-inner">
<span><p>Quadrotors are among the most agile flying robots. However, planning
time-optimal trajectories at the actuation limit through multiple waypoints
remains an open problem. This is crucial for applications such as inspection,
delivery, search and rescue, and drone racing. Early works used polynomial
trajectory formulations, which do not exploit the full actuator potential
because of their inherent smoothness. Recent works resorted to numerical
optimization but require waypoints to be allocated as costs or constraints at
specific discrete times. However, this time allocation is a priori unknown and
renders previous works incapable of producing truly time-optimal trajectories.
To generate truly time-optimal trajectories, we propose a solution to the time
allocation problem while exploiting the full quadrotor's actuator potential. We
achieve this by introducing a formulation of progress along the trajectory,
which enables the simultaneous optimization of the time allocation and the
trajectory itself. We compare our method against related approaches and
validate it in real-world flights in one of the world's largest motion-capture
systems, where we outperform human expert drone pilots in a drone-racing task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">All You Need is Color: Image based Spatial Gene Expression Prediction using Neural Stain Learning. (arXiv:2108.10446v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10446">
<div class="article-summary-box-inner">
<span><p>"Is it possible to predict expression levels of different genes at a given
spatial location in the routine histology image of a tumor section by modeling
its stain absorption characteristics?" In this work, we propose a "stain-aware"
machine learning approach for prediction of spatial transcriptomic gene
expression profiles using digital pathology image of a routine Hematoxylin &amp;
Eosin (H&amp;E) histology section. Unlike recent deep learning methods which are
used for gene expression prediction, our proposed approach termed Neural Stain
Learning (NSL) explicitly models the association of stain absorption
characteristics of the tissue with gene expression patterns in spatial
transcriptomics by learning a problem-specific stain deconvolution matrix in an
end-to-end manner. The proposed method with only 11 trainable weight parameters
outperforms both classical regression models with cellular composition and
morphological features as well as deep learning methods. We have found that the
gene expression predictions from the proposed approach show higher correlations
with true expression values obtained through sequencing for a larger set of
genes in comparison to other approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Word is Mightier than the Label: Learning without Pointillistic Labels using Data Programming. (arXiv:2108.10921v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10921">
<div class="article-summary-box-inner">
<span><p>Most advanced supervised Machine Learning (ML) models rely on vast amounts of
point-by-point labelled training examples. Hand-labelling vast amounts of data
may be tedious, expensive, and error-prone. Recently, some studies have
explored the use of diverse sources of weak supervision to produce competitive
end model classifiers. In this paper, we survey recent work on weak
supervision, and in particular, we investigate the Data Programming (DP)
framework. Taking a set of potentially noisy heuristics as input, DP assigns
denoised probabilistic labels to each data point in a dataset using a
probabilistic graphical model of heuristics. We analyze the math fundamentals
behind DP and demonstrate the power of it by applying it on two real-world text
classification tasks. Furthermore, we compare DP with pointillistic active and
semi-supervised learning techniques traditionally applied in data-sparse
settings.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">With One Voice: Composing a Travel Voice Assistant from Re-purposed Models. (arXiv:2108.11463v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11463">
<div class="article-summary-box-inner">
<span><p>Voice assistants provide users a new way of interacting with digital
products, allowing them to retrieve information and complete tasks with an
increased sense of control and flexibility. Such products are comprised of
several machine learning models, like Speech-to-Text transcription, Named
Entity Recognition and Resolution, and Text Classification. Building a voice
assistant from scratch takes the prolonged efforts of several teams
constructing numerous models and orchestrating between components. Alternatives
such as using third-party vendors or re-purposing existing models may be
considered to shorten time-to-market and development costs. However, each
option has its benefits and drawbacks. We present key insights from building a
voice search assistant for Booking.com search and recommendation system. Our
paper compares the achieved performance and development efforts in dedicated
tailor-made solutions against existing re-purposed models. We share and discuss
our data-driven decisions about implementation trade-offs and their estimated
outcomes in hindsight, showing that a fully functional machine learning product
can be built from existing models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Attention in Machine Reading Comprehension. (arXiv:2108.11574v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11574">
<div class="article-summary-box-inner">
<span><p>Achieving human-level performance on some of Machine Reading Comprehension
(MRC) datasets is no longer challenging with the help of powerful Pre-trained
Language Models (PLMs). However, the internal mechanism of these artifacts
still remains unclear, placing an obstacle for further understanding these
models. This paper focuses on conducting a series of analytical experiments to
examine the relations between the multi-head self-attention and the final
performance, trying to analyze the potential explainability in PLM-based MRC
models. We perform quantitative analyses on SQuAD (English) and CMRC 2018
(Chinese), two span-extraction MRC datasets, on top of BERT, ALBERT, and
ELECTRA in various aspects. We discover that {\em passage-to-question} and {\em
passage understanding} attentions are the most important ones, showing strong
correlations to the final performance than other parts. Through visualizations
and case studies, we also observe several general findings on the attention
maps, which could be helpful to understand how these models solve the
questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AVATAR: A Parallel Corpus for Java-Python Program Translation. (arXiv:2108.11590v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11590">
<div class="article-summary-box-inner">
<span><p>Program translation refers to migrating source code from one programming
language to another. It has a tremendous practical value in software
development as porting software across different languages is time-consuming
and costly. Automating program translation is of paramount importance in
software migration, and recently researchers explored unsupervised approaches
due to the unavailability of parallel corpora. However, the availability of
pre-trained language models for programming languages enable supervised
fine-tuning with a small amount of labeled examples. In this work, we present a
corpus of 8,475 programming problems and their solutions written in two popular
languages, Java and Python. We collect the dataset from competitive programming
sites, online platforms, and open source repositories. We present several
baselines, including models trained from scratch or pre-trained on large-scale
source code collection and fine-tuned on our proposed dataset. Experiment
results show that while the models perform relatively well in terms of the
lexical match, they lack in generating code that is accurate in terms of syntax
and data-flow match.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LayoutReader: Pre-training of Text and Layout for Reading Order Detection. (arXiv:2108.11591v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11591">
<div class="article-summary-box-inner">
<span><p>Reading order detection is the cornerstone to understanding visually-rich
documents (e.g., receipts and forms). Unfortunately, no existing work took
advantage of advanced deep learning models because it is too laborious to
annotate a large enough dataset. We observe that the reading order of WORD
documents is embedded in their XML metadata; meanwhile, it is easy to convert
WORD documents to PDFs or images. Therefore, in an automated manner, we
construct ReadingBank, a benchmark dataset that contains reading order, text,
and layout information for 500,000 document images covering a wide spectrum of
document types. This first-ever large-scale dataset unleashes the power of deep
neural networks for reading order detection. Specifically, our proposed
LayoutReader captures the text and layout information for reading order
prediction using the seq2seq model. It performs almost perfectly in reading
order detection and significantly improves both open-source and commercial OCR
engines in ordering text lines in their results in our experiments. We will
release the dataset and model at \url{https://aka.ms/readingbank}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Retrieval Augmented Code Generation and Summarization. (arXiv:2108.11601v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11601">
<div class="article-summary-box-inner">
<span><p>Software developers write a lot of source code and documentation during
software development. Intrinsically, developers often recall parts of source
code or code summaries that they had written in the past while implementing
software or documenting them. To mimic developers' code or summary generation
behavior, we propose a retrieval augmented framework, \tool, that retrieves
relevant code or summaries from a retrieval database and provides them as a
supplement to code generation or summarization models. \tool has a couple of
uniqueness. First, it extends the state-of-the-art dense retrieval technique to
search for relevant code or summaries. Second, it can work with retrieval
databases that include unimodal (only code or natural language description) or
bimodal instances (code-description pairs). We conduct experiments and
extensive analysis on two benchmark datasets of code generation and
summarization in Java and Python, and the promising results endorse the
effectiveness of our proposed retrieval augmented framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Negative Sampling for Unlabeled Entity Problem in Named Entity Recognition. (arXiv:2108.11607v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11607">
<div class="article-summary-box-inner">
<span><p>In many situations (e.g., distant supervision), unlabeled entity problem
seriously degrades the performances of named entity recognition (NER) models.
Recently, this issue has been well addressed by a notable approach based on
negative sampling. In this work, we perform two studies along this direction.
Firstly, we analyze why negative sampling succeeds both theoretically and
empirically. Based on the observation that named entities are highly sparse in
datasets, we show a theoretical guarantee that, for a long sentence, the
probability of containing no unlabeled entities in sampled negatives is high.
Missampling tests on synthetic datasets have verified our guarantee in
practice. Secondly, to mine hard negatives and further reduce missampling
rates, we propose a weighted and adaptive sampling distribution for negative
sampling. Experiments on synthetic datasets and well-annotated datasets show
that our method significantly improves negative sampling in robustness and
effectiveness. We also have achieved new state-of-the-art results on real-world
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoMPM: Context Modeling with Speaker's Pre-trained Memory Tracking for Emotion Recognition in Conversation. (arXiv:2108.11626v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11626">
<div class="article-summary-box-inner">
<span><p>As the use of interactive machines grow, the task of Emotion Recognition in
Conversation (ERC) became more important. If the machine generated sentences
reflect emotion, more human-like sympathetic conversations are possible. Since
emotion recognition in conversation is inaccurate if the previous utterances
are not taken into account, many studies reflect the dialogue context to
improve the performances. We introduce CoMPM, a context embedding module (CoM)
combined with a pre-trained memory module (PM) that tracks memory of the
speaker's previous utterances within the context, and show that the pre-trained
memory significantly improves the final accuracy of emotion recognition. We
experimented on both the multi-party datasets (MELD, EmoryNLP) and the
dyadic-party datasets (IEMOCAP, DailyDialog), showing that our approach achieve
competitive performance on all datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scalable End-to-End Training of Knowledge Graph-Enhanced Aspect Embedding for Aspect Level Sentiment Analysis. (arXiv:2108.11656v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11656">
<div class="article-summary-box-inner">
<span><p>Aspect level sentiment classification (ALSC) is a difficult problem with
state-of-the-art models showing less than 80% macro-F1 score on benchmark
datasets. Existing models do not incorporate information on aspect-aspect
relations in knowledge graphs (KGs), e.g. DBpedia. Two main challenges stem
from inaccurate disambiguation of aspects to KG entities, and the inability to
learn aspect representations from the large KGs in joint training with ALSC
models.
</p>
<p>We propose a two-level global-local entity embedding scheme that allows
efficient joint training of KG-based aspect embeddings and ALSC models. A novel
incorrect disambiguation detection technique addresses the problem of
inaccuracy in aspect disambiguation. The proposed methods show a consistent
improvement of $2.5 - 4.1$ percentage points, over the recent BERT-based
baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Technological Approaches to Detecting Online Disinformation and Manipulation. (arXiv:2108.11669v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11669">
<div class="article-summary-box-inner">
<span><p>The move of propaganda and disinformation to the online environment is
possible thanks to the fact that within the last decade, digital information
channels radically increased in popularity as a news source. The main advantage
of such media lies in the speed of information creation and dissemination.
This, on the other hand, inevitably adds pressure, accelerating editorial work,
fact-checking, and the scrutiny of source credibility. In this chapter, an
overview of computer-supported approaches to detecting disinformation and
manipulative techniques based on several criteria is presented. We concentrate
on the technical aspects of automatic methods which support fact-checking,
topic identification, text style analysis, or message filtering on social media
channels. Most of the techniques employ artificial intelligence and machine
learning with feature extraction combining available information resources. The
following text firstly specifies the tasks related to computer detection of
manipulation and disinformation spreading. The second section presents concrete
methods of solving the tasks of the analysis, and the third sections enlists
current verification and benchmarking datasets published and used in this area
for evaluation and comparison.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Why Intermediate-Task Fine-Tuning Works. (arXiv:2108.11696v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11696">
<div class="article-summary-box-inner">
<span><p>Supplementary Training on Intermediate Labeled-data Tasks (STILTs) is a
widely applied technique, which first fine-tunes the pretrained language models
on an intermediate task before on the target task of interest. While STILTs is
able to further improve the performance of pretrained language models, it is
still unclear why and when it works. Previous research shows that those
intermediate tasks involving complex inference, such as commonsense reasoning,
work especially well for RoBERTa. In this paper, we discover that the
improvement from an intermediate task could be orthogonal to it containing
reasoning or other complex skills -- a simple real-fake discrimination task
synthesized by GPT2 can benefit diverse target tasks. We conduct extensive
experiments to study the impact of different factors on STILTs. These findings
suggest rethinking the role of intermediate fine-tuning in the STILTs pipeline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Augmentation for Low-Resource Named Entity Recognition Using Backtranslation. (arXiv:2108.11703v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11703">
<div class="article-summary-box-inner">
<span><p>The state of art natural language processing systems relies on sizable
training datasets to achieve high performance. Lack of such datasets in the
specialized low resource domains lead to suboptimal performance. In this work,
we adapt backtranslation to generate high quality and linguistically diverse
synthetic data for low-resource named entity recognition. We perform
experiments on two datasets from the materials science (MaSciP) and biomedical
domains (S800). The empirical results demonstrate the effectiveness of our
proposed augmentation strategy, particularly in the low-resource scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Statutory Article Retrieval Dataset in French. (arXiv:2108.11792v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11792">
<div class="article-summary-box-inner">
<span><p>Statutory article retrieval is the task of automatically retrieving law
articles relevant to a legal question. While recent advances in natural
language processing have sparked considerable interest in many legal tasks,
statutory article retrieval remains primarily untouched due to the scarcity of
large-scale and high-quality annotated datasets. To address this bottleneck, we
introduce the Belgian Statutory Article Retrieval Dataset (BSARD), which
consists of 1,100+ French native legal questions labeled by experienced jurists
with relevant articles from a corpus of 22,600+ Belgian law articles. Using
BSARD, we benchmark several unsupervised information retrieval methods based on
term weighting and pooled embeddings. Our best performing baseline achieves
50.8% R@100, which is promising for the feasibility of the task and indicates
that there is still substantial room for improvement. By the specificity of the
data domain and addressed task, BSARD presents a unique challenge problem for
future research on legal information retrieval.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-tuning Pretrained Language Models with Label Attention for Explainable Biomedical Text Classification. (arXiv:2108.11809v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11809">
<div class="article-summary-box-inner">
<span><p>The massive growth of digital biomedical data is making biomedical text
indexing and classification increasingly important. Accordingly, previous
research has devised numerous techniques ranging from rule-based systems to
deep neural networks, with most focusing on feedforward, convolutional or
recurrent neural architectures. More recently, fine-tuned transformers-based
pretrained models (PTMs) have demonstrated superior performance in many natural
language processing tasks. However, the direct use of PTMs in the biomedical
domain is only limited to the target documents, ignoring the rich semantic
information in the label descriptions. In this paper, we develop an improved
label attention-based architecture to inject semantic label description into
the fine-tuning process of PTMs. Results on two public medical datasets show
that the proposed fine-tuning scheme outperforms the conventionally fine-tuned
PTMs and prior state-of-the-art models. Furthermore, we show that fine-tuning
with the label attention mechanism is interpretable in the interpretability
study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Computational Approach to Measure Empathy and Theory-of-Mind from Written Texts. (arXiv:2108.11810v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11810">
<div class="article-summary-box-inner">
<span><p>Theory-of-mind (ToM), a human ability to infer the intentions and thoughts of
others, is an essential part of empathetic experiences. We provide here the
framework for using NLP models to measure ToM expressed in written texts. For
this purpose, we introduce ToM-Diary, a crowdsourced 18,238 diaries with 74,014
Korean sentences annotated with different ToM levels. Each diary was annotated
with ToM levels by trained psychology students and reviewed by selected
psychology experts. The annotators first divided the diaries based on whether
they mentioned other people: self-focused and other-focused. Examples of
self-focused sentences are "I am feeling good". The other-focused sentences
were further classified into different levels. These levels differ by whether
the writer 1) mentions the presence of others without inferring their mental
state(e.g., I saw a man walking down the street), 2) fails to take the
perspective of others (e.g., I don't understand why they refuse to wear masks),
or 3) successfully takes the perspective of others (It must have been hard for
them to continue working). We tested whether state-of-the-art transformer-based
models (e.g., BERT) could predict underlying ToM levels in sentences. We found
that BERT more successfully detected self-focused sentences than other-focused
ones. Sentences that successfully take the perspective of others (the highest
ToM level) were the most difficult to predict. Our study suggests a promising
direction for large-scale and computational approaches for identifying the
ability of authors to empathize and take the perspective of others. The dataset
is at [URL](https://github.com/humanfactorspsych/covid19-tom-empathy-diary)
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Just Say No: Analyzing the Stance of Neural Dialogue Generation in Offensive Contexts. (arXiv:2108.11830v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11830">
<div class="article-summary-box-inner">
<span><p>Dialogue models trained on human conversations inadvertently learn to
generate offensive responses. Moreover, models can insult anyone by agreeing
with an offensive context. To understand the dynamics of contextually offensive
language, we study the stance of dialogue model responses in offensive Reddit
conversations. Specifically, we crowd-annotate ToxiChat, a new dataset of 2,000
Reddit threads and model responses labeled with offensive language and stance.
Our analysis reveals that 42% of user responses agree with toxic comments; 3x
their agreement with safe comments (13%). Pre-trained transformer-based
classifiers fine-tuned on our dataset achieve 0.71 F1 for offensive labels and
0.53 Macro-F1 for stance labels. Finally, we analyze some existing controllable
text generation (CTG) methods to mitigate the contextual offensive behavior of
dialogue models. Compared to the baseline, our best CTG model obtains a 19%
reduction in agreement with offensive context and 29% fewer offensive
responses. This highlights the need for future work to characterize and analyze
more forms of inappropriate behavior in dialogue models to help make them
safer. Our code and corpus are available at
https://github.com/abaheti95/ToxiChat .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Alleviating Exposure Bias via Contrastive Learning for Abstractive Text Summarization. (arXiv:2108.11846v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11846">
<div class="article-summary-box-inner">
<span><p>Encoder-decoder models have achieved remarkable success in abstractive text
summarization, which aims to compress one or more documents into a shorter
version without the loss of the essential content. Unfortunately, these models
mostly suffer a discrepancy between training and inference, i.e., the exposure
bias problem. During the training stage, with teacher forcing these models are
optimized to maximize the likelihood of the gold summary given the gold summary
tokens as input to the decoder, while at inference the given tokens are
replaced by the generated tokens. Consequently, low-quality summaries are very
likely to be generated. To remedy this problem, we propose to leverage
contrastive learning to decrease the likelihood of these low-quality summaries,
and meanwhile increase the likelihood of the gold summary. Since our solution
expands the states that the model perceives during training, we expect that the
exposure bias problem can be alleviated. We experimentally demonstrate that our
method effectively improves the performance of the state-of-the-art model on
different datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Realistic Study of Auto-regressive Language Models for Named Entity Typing and Recognition. (arXiv:2108.11857v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11857">
<div class="article-summary-box-inner">
<span><p>Despite impressive results of language models for named entity recognition
(NER), their generalization to varied textual genres, a growing entity type
set, and new entities remains a challenge. Collecting thousands of annotations
in each new case for training or fine-tuning is expensive and time-consuming.
In contrast, humans can easily identify named entities given some simple
instructions. Inspired by this, we challenge the reliance on large datasets and
study pre-trained language models for NER in a meta-learning setup. First, we
test named entity typing (NET) in a zero-shot transfer scenario. Then, we
perform NER by giving few examples at inference. We propose a method to select
seen and rare / unseen names when having access only to the pre-trained model
and report results on these groups. The results show: auto-regressive language
models as meta-learners can perform NET and NER fairly well especially for
regular or seen names; name irregularity when often present for a certain
entity type can become an effective exploitable cue; names with words foreign
to the model have the most negative impact on results; the model seems to rely
more on name than context cues in few-shot NER.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Automated Fact-Checking. (arXiv:2108.11896v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11896">
<div class="article-summary-box-inner">
<span><p>Fact-checking has become increasingly important due to the speed with which
both information and misinformation can spread in the modern media ecosystem.
Therefore, researchers have been exploring how fact-checking can be automated,
using techniques based on natural language processing, machine learning,
knowledge representation, and databases to automatically predict the veracity
of claims. In this paper, we survey automated fact-checking stemming from
natural language processing, and discuss its connections to related tasks and
disciplines. In this process, we present an overview of existing datasets and
models, aiming to unify the various definitions given and identify common
concepts. Finally, we highlight challenges for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Similar Scenes arouse Similar Emotions: Parallel Data Augmentation for Stylized Image Captioning. (arXiv:2108.11912v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11912">
<div class="article-summary-box-inner">
<span><p>Stylized image captioning systems aim to generate a caption not only
semantically related to a given image but also consistent with a given style
description. One of the biggest challenges with this task is the lack of
sufficient paired stylized data. Many studies focus on unsupervised approaches,
without considering from the perspective of data augmentation. We begin with
the observation that people may recall similar emotions when they are in
similar scenes, and often express similar emotions with similar style phrases,
which underpins our data augmentation idea. In this paper, we propose a novel
Extract-Retrieve-Generate data augmentation framework to extract style phrases
from small-scale stylized sentences and graft them to large-scale factual
captions. First, we design the emotional signal extractor to extract style
phrases from small-scale stylized sentences. Second, we construct the plugable
multi-modal scene retriever to retrieve scenes represented with pairs of an
image and its stylized caption, which are similar to the query image or caption
in the large-scale factual data. In the end, based on the style phrases of
similar scenes and the factual description of the current scene, we build the
emotion-aware caption generator to generate fluent and diversified stylized
captions for the current scene. Extensive experimental results show that our
framework can alleviate the data scarcity problem effectively. It also
significantly boosts the performance of several existing image captioning
models in both supervised and unsupervised settings, which outperforms the
state-of-the-art stylized image captioning methods in terms of both sentence
relevance and stylishness by a substantial margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HAN: Higher-order Attention Network for Spoken Language Understanding. (arXiv:2108.11916v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11916">
<div class="article-summary-box-inner">
<span><p>Spoken Language Understanding (SLU), including intent detection and slot
filling, is a core component in human-computer interaction. The natural
attributes of the relationship among the two subtasks make higher requirements
on fine-grained feature interaction, i.e., the token-level intent features and
slot features. Previous works mainly focus on jointly modeling the relationship
between the two subtasks with attention-based models, while ignoring the
exploration of attention order. In this paper, we propose to replace the
conventional attention with our proposed Bilinear attention block and show that
the introduced Higher-order Attention Network (HAN) brings improvement for the
SLU task. Importantly, we conduct wide analysis to explore the effectiveness
brought from the higher-order attention.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Learning for Mediation in Armed Conflicts. (arXiv:2108.11942v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11942">
<div class="article-summary-box-inner">
<span><p>Today's conflicts are becoming increasingly complex, fluid and fragmented,
often involving a host of national and international actors with multiple and
often divergent interests. This development poses significant challenges for
conflict mediation, as mediators struggle to make sense of conflict dynamics,
such as the range of conflict parties and the evolution of their political
positions, the distinction between relevant and less relevant actors in peace
making, or the identification of key conflict issues and their interdependence.
International peace efforts appear increasingly ill-equipped to successfully
address these challenges. While technology is being increasingly used in a
range of conflict related fields, such as conflict predicting or information
gathering, less attention has been given to how technology can contribute to
conflict mediation. This case study is the first to apply state-of-the-art
machine learning technologies to data from an ongoing mediation process. Using
dialogue transcripts from peace negotiations in Yemen, this study shows how
machine-learning tools can effectively support international mediators by
managing knowledge and offering additional conflict analysis tools to assess
complex information. Apart from illustrating the potential of machine learning
tools in conflict mediation, the paper also emphasises the importance of
interdisciplinary and participatory research design for the development of
context-sensitive and targeted tools and to ensure meaningful and responsible
implementation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Position-Invariant Truecasing with a Word-and-Character Hierarchical Recurrent Neural Network. (arXiv:2108.11943v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11943">
<div class="article-summary-box-inner">
<span><p>Truecasing is the task of restoring the correct case (uppercase or lowercase)
of noisy text generated either by an automatic system for speech recognition or
machine translation or by humans. It improves the performance of downstream NLP
tasks such as named entity recognition and language modeling. We propose a
fast, accurate and compact two-level hierarchical word-and-character-based
recurrent neural network model, the first of its kind for this problem. Using
sequence distillation, we also address the problem of truecasing while ignoring
token positions in the sentence, i.e. in a position-invariant manner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SASRA: Semantically-aware Spatio-temporal Reasoning Agent for Vision-and-Language Navigation in Continuous Environments. (arXiv:2108.11945v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11945">
<div class="article-summary-box-inner">
<span><p>This paper presents a novel approach for the Vision-and-Language Navigation
(VLN) task in continuous 3D environments, which requires an autonomous agent to
follow natural language instructions in unseen environments. Existing
end-to-end learning-based VLN methods struggle at this task as they focus
mostly on utilizing raw visual observations and lack the semantic
spatio-temporal reasoning capabilities which is crucial in generalizing to new
environments. In this regard, we present a hybrid transformer-recurrence model
which focuses on combining classical semantic mapping techniques with a
learning-based method. Our method creates a temporal semantic memory by
building a top-down local ego-centric semantic map and performs cross-modal
grounding to align map and language modalities to enable effective learning of
VLN policy. Empirical results in a photo-realistic long-horizon simulation
environment show that the proposed approach outperforms a variety of
state-of-the-art methods and baselines with over 22% relative improvement in
SPL in prior unseen environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SAUCE: Truncated Sparse Document Signature Bit-Vectors for Fast Web-Scale Corpus Expansion. (arXiv:2108.11948v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11948">
<div class="article-summary-box-inner">
<span><p>Recent advances in text representation have shown that training on large
amounts of text is crucial for natural language understanding. However, models
trained without predefined notions of topical interest typically require
careful fine-tuning when transferred to specialized domains. When a sufficient
amount of within-domain text may not be available, expanding a seed corpus of
relevant documents from large-scale web data poses several challenges. First,
corpus expansion requires scoring and ranking each document in the collection,
an operation that can quickly become computationally expensive as the web
corpora size grows. Relying on dense vector spaces and pairwise similarity adds
to the computational expense. Secondly, as the domain concept becomes more
nuanced, capturing the long tail of domain-specific rare terms becomes
non-trivial, especially under limited seed corpora scenarios.
</p>
<p>In this paper, we consider the problem of fast approximate corpus expansion
given a small seed corpus with a few relevant documents as a query, with the
goal of capturing the long tail of a domain-specific set of concept terms. To
efficiently collect large-scale domain-specific corpora with limited relevance
feedback, we propose a novel truncated sparse document bit-vector
representation, termed Signature Assisted Unsupervised Corpus Expansion
(SAUCE). Experimental results show that SAUCE can reduce the computational
burden while ensuring high within-domain lexical coverage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weisfeiler-Leman in the BAMBOO: Novel AMR Graph Metrics and a Benchmark for AMR Graph Similarity. (arXiv:2108.11949v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11949">
<div class="article-summary-box-inner">
<span><p>Several metrics have been proposed for assessing the similarity of (abstract)
meaning representations (AMRs), but little is known about how they relate to
human similarity ratings. Moreover, the current metrics have complementary
strengths and weaknesses: some emphasize speed, while others make the alignment
of graph structures explicit, at the price of a costly alignment step.
</p>
<p>In this work we propose new Weisfeiler-Leman AMR similarity metrics that
unify the strengths of previous metrics, while mitigating their weaknesses.
Specifically, our new metrics are able to match contextualized substructures
and induce n:m alignments between their nodes. Furthermore, we introduce a
Benchmark for AMR Metrics based on Overt Objectives (BAMBOO), the first
benchmark to support empirical assessment of graph-based MR similarity metrics.
BAMBOO maximizes the interpretability of results by defining multiple overt
objectives that range from sentence similarity objectives to stress tests that
probe a metric's robustness against meaning-altering and meaning-preserving
graph transformations. We show the benefits of BAMBOO by profiling previous
metrics and our own metrics. Results indicate that our novel metrics may serve
as a strong baseline for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LocTex: Learning Data-Efficient Visual Representations from Localized Textual Supervision. (arXiv:2108.11950v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11950">
<div class="article-summary-box-inner">
<span><p>Computer vision tasks such as object detection and semantic/instance
segmentation rely on the painstaking annotation of large training datasets. In
this paper, we propose LocTex that takes advantage of the low-cost localized
textual annotations (i.e., captions and synchronized mouse-over gestures) to
reduce the annotation effort. We introduce a contrastive pre-training framework
between images and captions and propose to supervise the cross-modal attention
map with rendered mouse traces to provide coarse localization signals. Our
learned visual features capture rich semantics (from free-form captions) and
accurate localization (from mouse traces), which are very effective when
transferred to various downstream vision tasks. Compared with ImageNet
supervised pre-training, LocTex can reduce the size of the pre-training dataset
by 10x or the target dataset by 2x while achieving comparable or even improved
performance on COCO instance segmentation. When provided with the same amount
of annotations, LocTex achieves around 4% higher accuracy than the previous
state-of-the-art "vision+language" pre-training approach on the task of PASCAL
VOC image classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SUMBT+LaRL: Effective Multi-domain End-to-end Neural Task-oriented Dialog System. (arXiv:2009.10447v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.10447">
<div class="article-summary-box-inner">
<span><p>The recent advent of neural approaches for developing each dialog component
in task-oriented dialog systems has remarkably improved, yet optimizing the
overall system performance remains a challenge. Besides, previous research on
modeling complicated multi-domain goal-oriented dialogs in end-to-end fashion
has been limited. In this paper, we present an effective multi-domain
end-to-end trainable neural dialog system SUMBT+LaRL that incorporates two
previous strong models and facilitates them to be fully differentiable.
Specifically, the SUMBT+ estimates user-acts as well as dialog belief states,
and the LaRL models latent system action spaces and generates responses given
the estimated contexts. We emphasize that the training framework of three steps
significantly and stably increase dialog success rates: separately pretraining
the SUMBT+ and LaRL, fine-tuning the entire system, and then reinforcement
learning of dialog policy. We also introduce new reward criteria of
reinforcement learning for dialog policy training. Then, we discuss
experimental results depending on the reward criteria and different dialog
evaluation methods. Consequently, our model achieved the new state-of-the-art
success rate of 85.4% on corpus-based evaluation, and a comparable success rate
of 81.40% on simulator-based evaluation provided by the DSTC8 challenge. To our
best knowledge, our work is the first comprehensive study of a modularized E2E
multi-domain dialog system that learning from each component to the entire
dialog policy for task success.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Adversarial Learning for Cross-Lingual Word Embeddings. (arXiv:2010.08432v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08432">
<div class="article-summary-box-inner">
<span><p>Generative adversarial networks (GANs) have succeeded in inducing
cross-lingual word embeddings -- maps of matching words across languages --
without supervision. Despite these successes, GANs' performance for the
difficult case of distant languages is still not satisfactory. These
limitations have been explained by GANs' incorrect assumption that source and
target embedding spaces are related by a single linear mapping and are
approximately isomorphic. We assume instead that, especially across distant
languages, the mapping is only piece-wise linear, and propose a
multi-adversarial learning method. This novel method induces the seed
cross-lingual dictionary through multiple mappings, each induced to fit the
mapping for one subspace. Our experiments on unsupervised bilingual lexicon
induction show that this method improves performance over previous
single-mapping methods, especially for distant languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ONION: A Simple and Effective Defense Against Textual Backdoor Attacks. (arXiv:2011.10369v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10369">
<div class="article-summary-box-inner">
<span><p>Backdoor attacks are a kind of emergent training-time threat to deep neural
networks (DNNs). They can manipulate the output of DNNs and possess high
insidiousness. In the field of natural language processing, some attack methods
have been proposed and achieve very high attack success rates on multiple
popular models. Nevertheless, there are few studies on defending against
textual backdoor attacks. In this paper, we propose a simple and effective
textual backdoor defense named ONION, which is based on outlier word detection
and, to the best of our knowledge, is the first method that can handle all the
textual backdoor attack situations. Experiments demonstrate the effectiveness
of our model in defending BiLSTM and BERT against five different backdoor
attacks. All the code and data will be released to facilitate future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Progressive Transformer-Based Generation of Radiology Reports. (arXiv:2102.09777v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09777">
<div class="article-summary-box-inner">
<span><p>Inspired by Curriculum Learning, we propose a consecutive (i.e.
image-to-text-to-text) generation framework where we divide the problem of
radiology report generation into two steps. Contrary to generating the full
radiology report from the image at once, the model generates global concepts
from the image in the first step and then reforms them into finer and coherent
texts using transformer-based architecture. We follow the transformer-based
sequence-to-sequence paradigm at each step. We improve upon the
state-of-the-art on two benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Diversity of Neural Text Generation via Inverse Probability Weighting. (arXiv:2103.07649v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07649">
<div class="article-summary-box-inner">
<span><p>The neural text generation suffers from the text degeneration issue such as
repetition. Traditional stochastic sampling methods only focus on truncating
the unreliable "tail" of the distribution, and do not address the "head" part,
which we show might contain tedious or even repetitive candidates with high
probability that lead to repetition loops. They also do not consider the issue
that human text does not always favor high-probability words. Inspired by
these, in this work we propose a heuristic sampling method. We propose to use
interquartile range of the predicted distribution to determine the "head" part,
then permutate and rescale the "head" with inverse probability. This aims at
decreasing the probability for the tedious and possibly repetitive candidates
with higher probability, and increasing the probability for the rational but
more surprising candidates with lower probability. The proposed algorithm
provides a reasonable permutation on the predicted distribution which enhances
diversity without compromising rationality of the distribution. We use
pre-trained language model to compare our algorithm with traditional methods.
Results show that our algorithm can effectively increase the diversity of
generated samples while achieving close resemblance to human text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections. (arXiv:2104.04670v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04670">
<div class="article-summary-box-inner">
<span><p>Large pre-trained language models (LMs) such as GPT-3 have acquired a
surprising ability to perform zero-shot learning. For example, to classify
sentiment without any training examples, we can "prompt" the LM with the review
and the label description "Does the user like this movie?", and ask whether the
next word is "yes" or "no". However, the next word prediction training
objective is still misaligned with the target zero-shot learning objective. To
address this weakness, we propose meta-tuning, which directly optimizes the
zero-shot learning objective by fine-tuning pre-trained language models on a
collection of datasets. We focus on classification tasks, and construct the
meta-dataset by aggregating 43 existing datasets and annotating 441 label
descriptions in a question-answering (QA) format. When evaluated on unseen
tasks, meta-tuned models outperform a same-sized QA model and the previous SOTA
zero-shot learning system based on natural language inference. Additionally,
increasing parameter count from 220M to 770M improves AUC-ROC scores by 6.3%,
and we forecast that even larger models would perform better. Therefore,
measuring zero-shot learning performance on language models out-of-the-box
might underestimate their true potential, and community-wide efforts on
aggregating datasets and unifying their formats can help build models that
answer prompts better.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-QuestEval: A Referenceless Metric for Data-to-Text Semantic Evaluation. (arXiv:2104.07555v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07555">
<div class="article-summary-box-inner">
<span><p>QuestEval is a reference-less metric used in text-to-text tasks, that
compares the generated summaries directly to the source text, by automatically
asking and answering questions. Its adaptation to Data-to-Text tasks is not
straightforward, as it requires multimodal Question Generation and Answering
systems on the considered tasks, which are seldom available. To this purpose,
we propose a method to build synthetic multimodal corpora enabling to train
multimodal components for a data-QuestEval metric. The resulting metric is
reference-less and multimodal; it obtains state-of-the-art correlations with
human judgment on the WebNLG and WikiBio benchmarks. We make data-QuestEval's
code and models available for reproducibility purpose, as part of the QuestEval
project.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Power of Saturated Transformers: A View from Circuit Complexity. (arXiv:2106.16213v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16213">
<div class="article-summary-box-inner">
<span><p>Transformers have become a standard architecture for many NLP problems. This
has motivated theoretically analyzing their capabilities as models of language,
in order to understand what makes them successful, and what their potential
weaknesses might be. Recent work has shown that transformers with hard
attention are quite limited in capacity, and in fact can be simulated by
constant-depth circuits. However, hard attention is a restrictive assumption,
which may complicate the relevance of these results for practical transformers.
In this work, we analyze the circuit complexity of transformers with saturated
attention: a generalization of hard attention that more closely captures the
attention patterns learnable in practical transformers. We show that saturated
transformers transcend the limitations of hard-attention transformers. With
some minor assumptions, we prove that the number of bits needed to represent a
saturated transformer memory vector is $O(\log n)$, which implies saturated
transformers can be simulated by log-depth circuits. Thus, the jump from hard
to saturated attention can be understood as increasing the transformer's
effective circuit depth by a factor of $O(\log n)$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DRIFT: A Toolkit for Diachronic Analysis of Scientific Literature. (arXiv:2107.01198v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01198">
<div class="article-summary-box-inner">
<span><p>In this work, we present to the NLP community, and to the wider research
community as a whole, an application for the diachronic analysis of research
corpora. We open source an easy-to-use tool coined: DRIFT, which allows
researchers to track research trends and development over the years. The
analysis methods are collated from well-cited research works, with a few of our
own methods added for good measure. Succinctly put, some of the analysis
methods are: keyword extraction, word clouds, predicting
declining/stagnant/growing trends using Productivity, tracking bi-grams using
Acceleration plots, finding the Semantic Drift of words, tracking trends using
similarity, etc. To demonstrate the utility and efficacy of our tool, we
perform a case study on the cs.CL corpus of the arXiv repository and draw
inferences from the analysis methods. The toolkit and the associated code are
available here: https://github.com/rajaswa/DRIFT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text Models. (arXiv:2108.08877v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08877">
<div class="article-summary-box-inner">
<span><p>We provide the first exploration of text-to-text transformers (T5) sentence
embeddings. Sentence embeddings are broadly useful for language processing
tasks. While T5 achieves impressive performance on language tasks cast as
sequence-to-sequence mapping problems, it is unclear how to produce sentence
embeddings from encoder-decoder models. We investigate three methods for
extracting T5 sentence embeddings: two utilize only the T5 encoder and one uses
the full T5 encoder-decoder model. Our encoder-only models outperforms
BERT-based sentence embeddings on both transfer tasks and semantic textual
similarity (STS). Our encoder-decoder method achieves further improvement on
STS. Scaling up T5 from millions to billions of parameters is found to produce
consistent improvements on downstream tasks. Finally, we introduce a two-stage
contrastive learning approach that achieves a new state-of-art on STS using
sentence embeddings, outperforming both Sentence BERT and SimCSE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recurrent multiple shared layers in Depth for Neural Machine Translation. (arXiv:2108.10417v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10417">
<div class="article-summary-box-inner">
<span><p>Learning deeper models is usually a simple and effective approach to improve
model performance, but deeper models have larger model parameters and are more
difficult to train. To get a deeper model, simply stacking more layers of the
model seems to work well, but previous works have claimed that it cannot
benefit the model. We propose to train a deeper model with recurrent mechanism,
which loops the encoder and decoder blocks of Transformer in the depth
direction. To address the increasing of model parameters, we choose to share
parameters in different recursive moments. We conduct our experiments on WMT16
English-to-German and WMT14 English-to-France translation tasks, our model
outperforms the shallow Transformer-Base/Big baseline by 0.35, 1.45 BLEU
points, which is 27.23% of Transformer-Big model parameters. Compared to the
deep Transformer(20-layer encoder, 6-layer decoder), our model has similar
model performance and infer speed, but our model parameters are 54.72% of the
former.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">PGTRNet: Two-phase Weakly Supervised Object Detection with Pseudo Ground Truth Refining. (arXiv:2108.11439v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11439">
<div class="article-summary-box-inner">
<span><p>Weakly Supervised Object Detection (WSOD), aiming to train detectors with
only image-level annotations, has arisen increasing attention. Current
state-of-the-art approaches mainly follow a two-stage training strategy
whichintegrates a fully supervised detector (FSD) with a pure WSOD model. There
are two main problems hindering the performance of the two-phase WSOD
approaches, i.e., insufficient learning problem and strict reliance between the
FSD and the pseudo ground truth (PGT) generated by theWSOD model. This paper
proposes pseudo ground truth refinement network (PGTRNet), a simple yet
effective method without introducing any extra learnable parameters, to cope
with these problems. PGTRNet utilizes multiple bounding boxes to establish the
PGT, mitigating the insufficient learning problem. Besides, we propose a novel
online PGT refinement approach to steadily improve the quality of PGTby fully
taking advantage of the power of FSD during the second-phase training,
decoupling the first and second-phase models. Elaborate experiments are
conducted on the PASCAL VOC 2007 benchmark to verify the effectiveness of our
methods. Experimental results demonstrate that PGTRNet boosts the backbone
model by 2.074% mAP and achieves the state-of-the-art performance, showing the
significant potentials of the second-phase training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Design and Scaffolded Training of an Efficient DNN Operator for Computer Vision on the Edge. (arXiv:2108.11441v1 [cs.AR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11441">
<div class="article-summary-box-inner">
<span><p>Massively parallel systolic arrays and resource-efficient depthwise separable
convolutions are two promising techniques to accelerate DNN inference on the
edge. Interestingly, their combination is inefficient: Computational patterns
of depthwise separable convolutions do not exhibit a rhythmic systolic flow and
lack sufficient data reuse to saturate systolic arrays. We formally analyse
this inefficiency and propose an efficient operator, an optimal hardware
dataflow, and a superior training methodology towards alleviating this. The
efficient operator, called FuSeConv, is a drop-in replacement for depthwise
separable convolutions. FuSeConv factorizes convolution fully along their
spatial and depth dimensions. The resultant computation efficiently maps to
systolic arrays. The optimal dataflow, called Spatial-Tiled Output Stationary
(ST-OS), maximizes the efficiency of FuSeConv on systolic arrays. It maps
independent convolutions to rows of the array to maximize resource utilization
with negligible VLSI overheads. Neural Operator Scaffolding (NOS) scaffolds the
training of FuSeConv by distilling knowledge from the expensive depthwise
separable convolutions. This bridges the accuracy gap between FuSeConv networks
and baselines. Additionally, NOS can be combined with Neural Architecture
Search (NAS) to trade-off latency and accuracy. The HW/SW co-design of FuSeConv
with ST-OS achieves a significant speedup of 4.1-9.25X with state-of-the-art
efficient networks for ImageNet. The parameter efficiency of FuSeConv and its
significant out-performance over depthwise separable convolutions on systolic
arrays illustrates their promise as a strong solution on the edge. Training
FuSeConv networks with NOS achieves accuracy comparable to the baselines.
Further, by combining NOS with NAS, we design networks that define
state-of-the-art models improving on both accuracy and latency on systolic
arrays.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Riemannian Framework for Analysis of Human Body Surface. (arXiv:2108.11449v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11449">
<div class="article-summary-box-inner">
<span><p>We propose a novel framework for comparing 3D human shapes under the change
of shape and pose. This problem is challenging since 3D human shapes vary
significantly across subjects and body postures. We solve this problem by using
a Riemannian approach. Our core contribution is the mapping of the human body
surface to the space of metrics and normals. We equip this space with a family
of Riemannian metrics, called Ebin (or DeWitt) metrics. We treat a human body
surface as a point in a "shape space" equipped with a family of Riemmanian
metrics. The family of metrics is invariant under rigid motions and
reparametrizations; hence it induces a metric on the "shape space" of surfaces.
Using the alignment of human bodies with a given template, we show that this
family of metrics allows us to distinguish the changes in shape and pose. The
proposed framework has several advantages. First, we define family of metrics
with desired invariant properties for the comparison of human shape. Second, we
present an efficient framework to compute geodesic paths between human shape
given the chosen metric. Third, this framework provides some basic tools for
statistical shape analysis of human body surfaces. Finally, we demonstrate the
utility of the proposed framework in pose and shape retrieval of human body.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reducing Label Effort: Self-Supervised meets Active Learning. (arXiv:2108.11458v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11458">
<div class="article-summary-box-inner">
<span><p>Active learning is a paradigm aimed at reducing the annotation effort by
training the model on actively selected informative and/or representative
samples. Another paradigm to reduce the annotation effort is self-training that
learns from a large amount of unlabeled data in an unsupervised way and
fine-tunes on few labeled samples. Recent developments in self-training have
achieved very impressive results rivaling supervised learning on some datasets.
The current work focuses on whether the two paradigms can benefit from each
other. We studied object recognition datasets including CIFAR10, CIFAR100 and
Tiny ImageNet with several labeling budgets for the evaluations. Our
experiments reveal that self-training is remarkably more efficient than active
learning at reducing the labeling effort, that for a low labeling budget,
active learning offers no benefit to self-training, and finally that the
combination of active learning and self-training is fruitful when the labeling
budget is high. The performance gap between active learning trained either with
self-training or from scratch diminishes as we approach to the point where
almost half of the dataset is labeled.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Object Detection and Attribute Recognition by Feature Entanglement Reduction. (arXiv:2108.11501v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11501">
<div class="article-summary-box-inner">
<span><p>We explore object detection with two attributes: color and material. The task
aims to simultaneously detect objects and infer their color and material. A
straight-forward approach is to add attribute heads at the very end of a usual
object detection pipeline. However, we observe that the two goals are in
conflict: Object detection should be attribute-independent and attributes be
largely object-independent. Features computed by a standard detection network
entangle the category and attribute features; we disentangle them by the use of
a two-stream model where the category and attribute features are computed
independently but the classification heads share Regions of Interest (RoIs).
Compared with a traditional single-stream model, our model shows significant
improvements over VG-20, a subset of Visual Genome, on both supervised and
attribute transfer tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Maneuver Identification Challenge. (arXiv:2108.11503v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11503">
<div class="article-summary-box-inner">
<span><p>AI algorithms that identify maneuvers from trajectory data could play an
important role in improving flight safety and pilot training. AI challenges
allow diverse teams to work together to solve hard problems and are an
effective tool for developing AI solutions. AI challenges are also a key driver
of AI computational requirements. The Maneuver Identification Challenge hosted
at maneuver-id.mit.edu provides thousands of trajectories collected from pilots
practicing in flight simulators, descriptions of maneuvers, and examples of
these maneuvers performed by experienced pilots. Each trajectory consists of
positions, velocities, and aircraft orientations normalized to a common
coordinate system. Construction of the data set required significant data
architecture to transform flight simulator logs into AI ready data, which
included using a supercomputer for deduplication and data conditioning. There
are three proposed challenges. The first challenge is separating physically
plausible (good) trajectories from unfeasible (bad) trajectories. Human labeled
good and bad trajectories are provided to aid in this task. Subsequent
challenges are to label trajectories with their intended maneuvers and to
assess the quality of those maneuvers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalized Real-World Super-Resolution through Adversarial Robustness. (arXiv:2108.11505v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11505">
<div class="article-summary-box-inner">
<span><p>Real-world Super-Resolution (SR) has been traditionally tackled by first
learning a specific degradation model that resembles the noise and corruption
artifacts in low-resolution imagery. Thus, current methods lack generalization
and lose their accuracy when tested on unseen types of corruption. In contrast
to the traditional proposal, we present Robust Super-Resolution (RSR), a method
that leverages the generalization capability of adversarial attacks to tackle
real-world SR. Our novel framework poses a paradigm shift in the development of
real-world SR methods. Instead of learning a dataset-specific degradation, we
employ adversarial attacks to create difficult examples that target the model's
weaknesses. Afterward, we use these adversarial examples during training to
improve our model's capacity to process noisy inputs. We perform extensive
experimentation on synthetic and real-world images and empirically demonstrate
that our RSR method generalizes well across datasets without re-training for
specific noise priors. By using a single robust model, we outperform
state-of-the-art specialized methods on real-world benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Reinforcement Learning in Computer Vision: A Comprehensive Survey. (arXiv:2108.11510v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11510">
<div class="article-summary-box-inner">
<span><p>Deep reinforcement learning augments the reinforcement learning framework and
utilizes the powerful representation of deep neural networks. Recent works have
demonstrated the remarkable successes of deep reinforcement learning in various
domains including finance, medicine, healthcare, video games, robotics, and
computer vision. In this work, we provide a detailed review of recent and
state-of-the-art research advances of deep reinforcement learning in computer
vision. We start with comprehending the theories of deep learning,
reinforcement learning, and deep reinforcement learning. We then propose a
categorization of deep reinforcement learning methodologies and discuss their
advantages and limitations. In particular, we divide deep reinforcement
learning into seven main categories according to their applications in computer
vision, i.e. (i)landmark localization (ii) object detection; (iii) object
tracking; (iv) registration on both 2D image and 3D image volumetric data (v)
image segmentation; (vi) videos analysis; and (vii) other applications. Each of
these categories is further analyzed with reinforcement learning techniques,
network design, and performance. Moreover, we provide a comprehensive analysis
of the existing publicly available datasets and examine source code
availability. Finally, we present some open issues and discuss future research
directions on deep reinforcement learning in computer vision
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust High-Resolution Video Matting with Temporal Guidance. (arXiv:2108.11515v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11515">
<div class="article-summary-box-inner">
<span><p>We introduce a robust, real-time, high-resolution human video matting method
that achieves new state-of-the-art performance. Our method is much lighter than
previous approaches and can process 4K at 76 FPS and HD at 104 FPS on an Nvidia
GTX 1080Ti GPU. Unlike most existing methods that perform video matting
frame-by-frame as independent images, our method uses a recurrent architecture
to exploit temporal information in videos and achieves significant improvements
in temporal coherence and matting quality. Furthermore, we propose a novel
training strategy that enforces our network on both matting and segmentation
objectives. This significantly improves our model's robustness. Our method does
not require any auxiliary inputs such as a trimap or a pre-captured background
image, so it can be widely applied to existing human matting applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ChessMix: Spatial Context Data Augmentation for Remote Sensing Semantic Segmentation. (arXiv:2108.11535v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11535">
<div class="article-summary-box-inner">
<span><p>Labeling semantic segmentation datasets is a costly and laborious process if
compared with tasks like image classification and object detection. This is
especially true for remote sensing applications that not only work with
extremely high spatial resolution data but also commonly require the knowledge
of experts of the area to perform the manual labeling. Data augmentation
techniques help to improve deep learning models under the circumstance of few
and imbalanced labeled samples. In this work, we propose a novel data
augmentation method focused on exploring the spatial context of remote sensing
semantic segmentation. This method, ChessMix, creates new synthetic images from
the existing training set by mixing transformed mini-patches across the dataset
in a chessboard-like grid. ChessMix prioritizes patches with more examples of
the rarest classes to alleviate the imbalance problems. The results in three
diverse well-known remote sensing datasets show that this is a promising
approach that helps to improve the networks' performance, working especially
well in datasets with few available data. The results also show that ChessMix
is capable of improving the segmentation of objects with few labeled pixels
when compared to the most common data augmentation methods widely used.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TPH-YOLOv5: Improved YOLOv5 Based on Transformer Prediction Head for Object Detection on Drone-captured Scenarios. (arXiv:2108.11539v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11539">
<div class="article-summary-box-inner">
<span><p>Object detection on drone-captured scenarios is a recent popular task. As
drones always navigate in different altitudes, the object scale varies
violently, which burdens the optimization of networks. Moreover, high-speed and
low-altitude flight bring in the motion blur on the densely packed objects,
which leads to great challenge of object distinction. To solve the two issues
mentioned above, we propose TPH-YOLOv5. Based on YOLOv5, we add one more
prediction head to detect different-scale objects. Then we replace the original
prediction heads with Transformer Prediction Heads (TPH) to explore the
prediction potential with self-attention mechanism. We also integrate
convolutional block attention model (CBAM) to find attention region on
scenarios with dense objects. To achieve more improvement of our proposed
TPH-YOLOv5, we provide bags of useful strategies such as data augmentation,
multiscale testing, multi-model integration and utilizing extra classifier.
Extensive experiments on dataset VisDrone2021 show that TPH-YOLOv5 have good
performance with impressive interpretability on drone-captured scenarios. On
DET-test-challenge dataset, the AP result of TPH-YOLOv5 are 39.18%, which is
better than previous SOTA method (DPNetV3) by 1.81%. On VisDrone Challenge
2021, TPHYOLOv5 wins 5th place and achieves well-matched results with 1st place
model (AP 39.43%). Compared to baseline model (YOLOv5), TPH-YOLOv5 improves
about 7%, which is encouraging and competitive.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual-and-Language Navigation: A Survey and Taxonomy. (arXiv:2108.11544v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11544">
<div class="article-summary-box-inner">
<span><p>An agent that can understand natural-language instruction and carry out
corresponding actions in the visual world is one of the long-term challenges of
Artificial Intelligent (AI). Due to multifarious instructions from humans, it
requires the agent can link natural language to vision and action in
unstructured, previously unseen environments. If the instruction given by human
is a navigation task, this challenge is called Visual-and-Language Navigation
(VLN). It is a booming multi-disciplinary field of increasing importance and
with extraordinary practicality. Instead of focusing on the details of specific
methods, this paper provides a comprehensive survey on VLN tasks and makes a
classification carefully according the different characteristics of language
instructions in these tasks. According to when the instructions are given, the
tasks can be divided into single-turn and multi-turn. For single-turn tasks, we
further divided them into goal-orientation and route-orientation based on
whether the instructions contain a route. For multi-turn tasks, we divided them
into imperative task and interactive task based on whether the agent responses
to the instructions. This taxonomy enable researchers to better grasp the key
point of a specific task and identify directions for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Surprising Effectiveness of Visual Odometry Techniques for Embodied PointGoal Navigation. (arXiv:2108.11550v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11550">
<div class="article-summary-box-inner">
<span><p>It is fundamental for personal robots to reliably navigate to a specified
goal. To study this task, PointGoal navigation has been introduced in simulated
Embodied AI environments. Recent advances solve this PointGoal navigation task
with near-perfect accuracy (99.6% success) in photo-realistically simulated
environments, assuming noiseless egocentric vision, noiseless actuation, and
most importantly, perfect localization. However, under realistic noise models
for visual sensors and actuation, and without access to a "GPS and Compass
sensor," the 99.6%-success agents for PointGoal navigation only succeed with
0.3%. In this work, we demonstrate the surprising effectiveness of visual
odometry for the task of PointGoal navigation in this realistic setting, i.e.,
with realistic noise models for perception and actuation and without access to
GPS and Compass sensors. We show that integrating visual odometry techniques
into navigation policies improves the state-of-the-art on the popular Habitat
PointNav benchmark by a large margin, improving success from 64.5% to 71.7%
while executing 6.4 times faster.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">XCI-Sketch: Extraction of Color Information from Images for Generation of Colored Outlines and Sketches. (arXiv:2108.11554v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11554">
<div class="article-summary-box-inner">
<span><p>Sketches are a medium to convey a visual scene from an individual's creative
perspective. The addition of color substantially enhances the overall
expressivity of a sketch. This paper proposes two methods to mimic human-drawn
colored sketches by utilizing the Contour Drawing Dataset. Our first approach
renders colored outline sketches by applying image processing techniques aided
by k-means color clustering. The second method uses a generative adversarial
network to develop a model that can generate colored sketches from previously
unobserved images. We assess the results obtained through quantitative and
qualitative evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identity-aware Graph Memory Network for Action Detection. (arXiv:2108.11559v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11559">
<div class="article-summary-box-inner">
<span><p>Action detection plays an important role in high-level video understanding
and media interpretation. Many existing studies fulfill this spatio-temporal
localization by modeling the context, capturing the relationship of actors,
objects, and scenes conveyed in the video. However, they often universally
treat all the actors without considering the consistency and distinctness
between individuals, leaving much room for improvement. In this paper, we
explicitly highlight the identity information of the actors in terms of both
long-term and short-term context through a graph memory network, namely
identity-aware graph memory network (IGMN). Specifically, we propose the
hierarchical graph neural network (HGNN) to comprehensively conduct long-term
relation modeling within the same identity as well as between different ones.
Regarding short-term context, we develop a dual attention module (DAM) to
generate identity-aware constraint to reduce the influence of interference by
the actors of different identities. Extensive experiments on the challenging
AVA dataset demonstrate the effectiveness of our method, which achieves
state-of-the-art results on AVA v2.1 and v2.2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeighCNN: A CNN based SAR Speckle Reduction using Feature preserving Loss Function. (arXiv:2108.11573v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11573">
<div class="article-summary-box-inner">
<span><p>Coherent imaging systems like synthetic aperture radar are susceptible to
multiplicative noise that makes applications like automatic target recognition
challenging. In this paper, NeighCNN, a deep learning-based speckle reduction
algorithm that handles multiplicative noise with relatively simple
convolutional neural network architecture, is proposed. We have designed a loss
function which is an unique combination of weighted sum of Euclidean,
neighbourhood, and perceptual loss for training the deep network. Euclidean and
neighbourhood losses take pixel-level information into account, whereas
perceptual loss considers high-level semantic features between two images.
Various synthetic, as well as real SAR images, are used for testing the
NeighCNN architecture, and the results verify the noise removal and edge
preservation abilities of the proposed architecture. Performance metrics like
peak-signal-to-noise ratio, structural similarity index, and universal image
quality index are used for evaluating the efficiency of the proposed
architecture on synthetic images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shifted Chunk Transformer for Spatio-Temporal Representational Learning. (arXiv:2108.11575v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11575">
<div class="article-summary-box-inner">
<span><p>Spatio-temporal representational learning has been widely adopted in various
fields such as action recognition, video object segmentation, and action
anticipation. Previous spatio-temporal representational learning approaches
primarily employ ConvNets or sequential models,e.g., LSTM, to learn the
intra-frame and inter-frame features. Recently, Transformer models have
successfully dominated the study of natural language processing (NLP), image
classification, etc. However, the pure-Transformer based spatio-temporal
learning can be prohibitively costly on memory and computation to extract
fine-grained features from a tiny patch. To tackle the training difficulty and
enhance the spatio-temporal learning, we construct a shifted chunk Transformer
with pure self-attention blocks. Leveraging the recent efficient Transformer
design in NLP, this shifted chunk Transformer can learn hierarchical
spatio-temporal features from a local tiny patch to a global video clip. Our
shifted self-attention can also effectively model complicated inter-frame
variances. Furthermore, we build a clip encoder based on Transformer to model
long-term temporal dependencies. We conduct thorough ablation studies to
validate each component and hyper-parameters in our shifted chunk Transformer,
and it outperforms previous state-of-the-art approaches on Kinetics-400,
Kinetics-600, UCF101, and HMDB51. Code and trained models will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Dense Deformation Embedding Network for Template-Free Shape Correspondence. (arXiv:2108.11609v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11609">
<div class="article-summary-box-inner">
<span><p>Shape correspondence from 3D deformation learning has attracted appealing
academy interests recently. Nevertheless, current deep learning based methods
require the supervision of dense annotations to learn per-point translations,
which severely overparameterize the deformation process. Moreover, they fail to
capture local geometric details of original shape via global feature embedding.
To address these challenges, we develop a new Unsupervised Dense Deformation
Embedding Network (i.e., UD^2E-Net), which learns to predict deformations
between non-rigid shapes from dense local features. Since it is non-trivial to
match deformation-variant local features for deformation prediction, we develop
an Extrinsic-Intrinsic Autoencoder to frst encode extrinsic geometric features
from source into intrinsic coordinates in a shared canonical shape, with which
the decoder then synthesizes corresponding target features. Moreover, a bounded
maximum mean discrepancy loss is developed to mitigate the distribution
divergence between the synthesized and original features. To learn natural
deformation without dense supervision, we introduce a coarse parameterized
deformation graph, for which a novel trace and propagation algorithm is
proposed to improve both the quality and effciency of the deformation. Our
UD^2E-Net outperforms state-of-the-art unsupervised methods by 24% on Faust
Inter challenge and even supervised methods by 13% on Faust Intra challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-shot Visual Relationship Co-localization. (arXiv:2108.11618v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11618">
<div class="article-summary-box-inner">
<span><p>In this paper, given a small bag of images, each containing a common but
latent predicate, we are interested in localizing visual subject-object pairs
connected via the common predicate in each of the images. We refer to this
novel problem as visual relationship co-localization or VRC as an abbreviation.
VRC is a challenging task, even more so than the well-studied object
co-localization task. This becomes further challenging when using just a few
images, the model has to learn to co-localize visual subject-object pairs
connected via unseen predicates. To solve VRC, we propose an optimization
framework to select a common visual relationship in each image of the bag. The
goal of the optimization framework is to find the optimal solution by learning
visual relationship similarity across images in a few-shot setting. To obtain
robust visual relationship representation, we utilize a simple yet effective
technique that learns relationship embedding as a translation vector from
visual subject to visual object in a shared space. Further, to learn visual
relationship similarity, we utilize a proven meta-learning technique commonly
used for few-shot classification tasks. Finally, to tackle the combinatorial
complexity challenge arising from an exponential number of feasible solutions,
we use a greedy approximation inference algorithm that selects approximately
the best solution.
</p>
<p>We extensively evaluate our proposed framework on variations of bag sizes
obtained from two challenging public datasets, namely VrR-VG and VG-150, and
achieve impressive visual co-localization performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Web Image Context Extraction with Graph Neural Networks and Sentence Embeddings on the DOM tree. (arXiv:2108.11629v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11629">
<div class="article-summary-box-inner">
<span><p>Web Image Context Extraction (WICE) consists in obtaining the textual
information describing an image using the content of the surrounding webpage. A
common preprocessing step before performing WICE is to render the content of
the webpage. When done at a large scale (e.g., for search engine indexation),
it may become very computationally costly (up to several seconds per page). To
avoid this cost, we introduce a novel WICE approach that combines Graph Neural
Networks (GNNs) and Natural Language Processing models. Our method relies on a
graph model containing both node types and text as features. The model is fed
through several blocks of GNNs to extract the textual context. Since no labeled
WICE dataset with ground truth exists, we train and evaluate the GNNs on a
proxy task that consists in finding the semantically closest text to the image
caption. We then interpret importance weights to find the most relevant text
nodes and define them as the image context. Thanks to GNNs, our model is able
to encode both structural and semantic information from the webpage. We show
that our approach gives promising results to help address the large-scale WICE
problem using only HTML data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SketchLattice: Latticed Representation for Sketch Manipulation. (arXiv:2108.11636v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11636">
<div class="article-summary-box-inner">
<span><p>The key challenge in designing a sketch representation lies with handling the
abstract and iconic nature of sketches. Existing work predominantly utilizes
either, (i) a pixelative format that treats sketches as natural images
employing off-the-shelf CNN-based networks, or (ii) an elaborately designed
vector format that leverages the structural information of drawing orders using
sequential RNN-based methods. While the pixelative format lacks intuitive
exploitation of structural cues, sketches in vector format are absent in most
cases limiting their practical usage. Hence, in this paper, we propose a
lattice structured sketch representation that not only removes the bottleneck
of requiring vector data but also preserves the structural cues that vector
data provides. Essentially, sketch lattice is a set of points sampled from the
pixelative format of the sketch using a lattice graph. We show that our lattice
structure is particularly amenable to structural changes that largely benefits
sketch abstraction modeling for generation tasks. Our lattice representation
could be effectively encoded using a graph model, that uses significantly fewer
model parameters (13.5 times lesser) than existing state-of-the-art. Extensive
experiments demonstrate the effectiveness of sketch lattice for sketch
manipulation, including sketch healing and image-to-sketch synthesis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StackMix and Blot Augmentations for Handwritten Text Recognition. (arXiv:2108.11667v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11667">
<div class="article-summary-box-inner">
<span><p>This paper proposes a handwritten text recognition(HTR) system that
outperforms current state-of-the-artmethods. The comparison was carried out on
three of themost frequently used in HTR task datasets, namely Ben-tham, IAM,
and Saint Gall. In addition, the results on tworecently presented datasets,
Peter the Greats manuscriptsand HKR Dataset, are provided.The paper describes
the architecture of the neural net-work and two ways of increasing the volume
of train-ing data: augmentation that simulates strikethrough text(HandWritten
Blots) and a new text generation method(StackMix), which proved to be very
effective in HTR tasks.StackMix can also be applied to the standalone task of
gen-erating handwritten text based on printed text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Robust Loss for Point Cloud Registration. (arXiv:2108.11682v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11682">
<div class="article-summary-box-inner">
<span><p>The performance of surface registration relies heavily on the metric used for
the alignment error between the source and target shapes. Traditionally, such a
metric is based on the point-to-point or point-to-plane distance from the
points on the source surface to their closest points on the target surface,
which is susceptible to failure due to instability of the closest-point
correspondence. In this paper, we propose a novel metric based on the
intersection points between the two shapes and a random straight line, which
does not assume a specific correspondence. We verify the effectiveness of this
metric by extensive experiments, including its direct optimization for a single
registration problem as well as unsupervised learning for a set of registration
problems. The results demonstrate that the algorithms utilizing our proposed
metric outperforms the state-of-the-art optimization-based and unsupervised
learning-based methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving the Reliability of Semantic Segmentation of Medical Images by Uncertainty Modeling with Bayesian Deep Networks and Curriculum Learning. (arXiv:2108.11693v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11693">
<div class="article-summary-box-inner">
<span><p>In this paper we propose a novel method which leverages the uncertainty
measures provided by Bayesian deep networks through curriculum learning so that
the uncertainty estimates are fed back to the system to resample the training
data more densely in areas where uncertainty is high. We show in the concrete
setting of a semantic segmentation task (iPS cell colony segmentation) that the
proposed system is able to increase significantly the reliability of the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PoissonSeg: Semi-Supervised Few-Shot Medical Image Segmentation via Poisson Learning. (arXiv:2108.11694v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11694">
<div class="article-summary-box-inner">
<span><p>The application of deep learning to medical image segmentation has been
hampered due to the lack of abundant pixel-level annotated data. Few-shot
Semantic Segmentation (FSS) is a promising strategy for breaking the deadlock.
However, a high-performing FSS model still requires sufficient pixel-level
annotated classes for training to avoid overfitting, which leads to its
performance bottleneck in medical image segmentation due to the unmet need for
annotations. Thus, semi-supervised FSS for medical images is accordingly
proposed to utilize unlabeled data for further performance improvement.
Nevertheless, existing semi-supervised FSS methods has two obvious defects: (1)
neglecting the relationship between the labeled and unlabeled data; (2) using
unlabeled data directly for end-to-end training leads to degenerated
representation learning. To address these problems, we propose a novel
semi-supervised FSS framework for medical image segmentation. The proposed
framework employs Poisson learning for modeling data relationship and
propagating supervision signals, and Spatial Consistency Calibration for
encouraging the model to learn more coherent representations. In this process,
unlabeled samples do not involve in end-to-end training, but provide
supervisory information for query image segmentation through graph-based
learning. We conduct extensive experiments on three medical image segmentation
datasets (i.e. ISIC skin lesion segmentation, abdominal organs segmentation for
MRI and abdominal organs segmentation for CT) to demonstrate the
state-of-the-art performance and broad applicability of the proposed framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PAENet: A Progressive Attention-Enhanced Network for 3D to 2D Retinal Vessel Segmentation. (arXiv:2108.11695v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11695">
<div class="article-summary-box-inner">
<span><p>3D to 2D retinal vessel segmentation is a challenging problem in Optical
Coherence Tomography Angiography (OCTA) images. Accurate retinal vessel
segmentation is important for the diagnosis and prevention of ophthalmic
diseases. However, making full use of the 3D data of OCTA volumes is a vital
factor for obtaining satisfactory segmentation results. In this paper, we
propose a Progressive Attention-Enhanced Network (PAENet) based on attention
mechanisms to extract rich feature representation. Specifically, the framework
consists of two main parts, the three-dimensional feature learning path and the
two-dimensional segmentation path. In the three-dimensional feature learning
path, we design a novel Adaptive Pooling Module (APM) and propose a new
Quadruple Attention Module (QAM). The APM captures dependencies along the
projection direction of volumes and learns a series of pooling coefficients for
feature fusion, which efficiently reduces feature dimension. In addition, the
QAM reweights the features by capturing four-group cross-dimension
dependencies, which makes maximum use of 4D feature tensors. In the
two-dimensional segmentation path, to acquire more detailed information, we
propose a Feature Fusion Module (FFM) to inject 3D information into the 2D
path. Meanwhile, we adopt the Polarized Self-Attention (PSA) block to model the
semantic interdependencies in spatial and channel dimensions respectively.
Experimentally, our extensive experiments on the OCTA-500 dataset show that our
proposed algorithm achieves state-of-the-art performance compared with previous
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Glimpse-Attend-and-Explore: Self-Attention for Active Visual Exploration. (arXiv:2108.11717v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11717">
<div class="article-summary-box-inner">
<span><p>Active visual exploration aims to assist an agent with a limited field of
view to understand its environment based on partial observations made by
choosing the best viewing directions in the scene. Recent methods have tried to
address this problem either by using reinforcement learning, which is difficult
to train, or by uncertainty maps, which are task-specific and can only be
implemented for dense prediction tasks. In this paper, we propose the
Glimpse-Attend-and-Explore model which: (a) employs self-attention to guide the
visual exploration instead of task-specific uncertainty maps; (b) can be used
for both dense and sparse prediction tasks; and (c) uses a contrastive stream
to further improve the representations learned. Unlike previous works, we show
the application of our model on multiple tasks like reconstruction,
segmentation and classification. Our model provides encouraging results while
being less dependent on dataset bias in driving the exploration. We further
perform an ablation study to investigate the features and attention learned by
our model. Finally, we show that our self-attention module learns to attend
different regions of the scene by minimizing the loss on the downstream task.
Code: https://github.com/soroushseifi/glimpse-attend-explore.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmarking high-fidelity pedestrian tracking systems for research, real-time monitoring and crowd control. (arXiv:2108.11719v1 [physics.soc-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11719">
<div class="article-summary-box-inner">
<span><p>High-fidelity pedestrian tracking in real-life conditions has been an
important tool in fundamental crowd dynamics research allowing to quantify
statistics of relevant observables including walking velocities, mutual
distances and body orientations. As this technology advances, it is becoming
increasingly useful also in society. In fact, continued urbanization is
overwhelming existing pedestrian infrastructures such as transportation hubs
and stations, generating an urgent need for real-time highly-accurate usage
data, aiming both at flow monitoring and dynamics understanding. To
successfully employ pedestrian tracking techniques in research and technology,
it is crucial to validate and benchmark them for accuracy. This is not only
necessary to guarantee data quality, but also to identify systematic errors.
</p>
<p>In this contribution, we present and discuss a benchmark suite, towards an
open standard in the community, for privacy-respectful pedestrian tracking
techniques. The suite is technology-independent and is applicable to academic
and commercial pedestrian tracking systems, operating both in lab environments
and real-life conditions. The benchmark suite consists of 5 tests addressing
specific aspects of pedestrian tracking quality, including accurate crowd flux
estimation, density estimation, position detection and trajectory accuracy. The
output of the tests are quality factors expressed as single numbers. We provide
the benchmark results for two tracking systems, both operating in real-life,
one commercial, and the other based on overhead depth-maps developed at TU
Eindhoven. We discuss the results on the basis of the quality factors and
report on the typical sensor and algorithmic performance. This enables us to
highlight the current state-of-the-art, its limitations and provide
installation recommendations, with specific attention to multi-sensor setups
and data stitching.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Segmentation of Shoulder Muscle MRI Using a New Region and Edge based Deep Auto-Encoder. (arXiv:2108.11720v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11720">
<div class="article-summary-box-inner">
<span><p>Automatic segmentation of shoulder muscle MRI is challenging due to the high
variation in muscle size, shape, texture, and spatial position of tears. Manual
segmentation of tear and muscle portion is hard, time-consuming, and subjective
to pathological expertise. This work proposes a new Region and Edge-based Deep
Auto-Encoder (RE-DAE) for shoulder muscle MRI segmentation. The proposed RE-DAE
harmoniously employs average and max-pooling operation in the encoder and
decoder blocks of the Convolutional Neural Network (CNN). Region-based
segmentation incorporated in the Deep Auto-Encoder (DAE) encourages the network
to extract smooth and homogenous regions. In contrast, edge-based segmentation
tries to learn the boundary and anatomical information. These two concepts,
systematically combined in a DAE, generate a discriminative and sparse hybrid
feature space (exploiting both region homogeneity and boundaries). Moreover,
the concept of static attention is exploited in the proposed RE-DAE that helps
in effectively learning the tear region. The performances of the proposed MRI
segmentation based DAE architectures have been tested using a 3D MRI shoulder
muscle dataset using the hold-out cross-validation technique. The MRI data has
been collected from the Korea University Anam Hospital, Seoul, South Korea.
Experimental comparisons have been conducted by employing innovative
custom-made and existing pre-trained CNN architectures both using transfer
learning and fine-tuning. Objective evaluation on the muscle datasets using the
proposed SA-RE-DAE showed a dice similarity of 85.58% and 87.07%, an accuracy
of 81.57% and 95.58% for tear and muscle regions, respectively. The high visual
quality and the objective result suggest that the proposed SA-RE-DAE is able to
correctly segment tear and muscle regions in shoulder muscle MRI for better
clinical decisions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Diversify for Single Domain Generalization. (arXiv:2108.11726v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11726">
<div class="article-summary-box-inner">
<span><p>Domain generalization (DG) aims to generalize a model trained on multiple
source (i.e., training) domains to a distributionally different target (i.e.,
test) domain. In contrast to the conventional DG that strictly requires the
availability of multiple source domains, this paper considers a more realistic
yet challenging scenario, namely Single Domain Generalization (Single-DG),
where only one source domain is available for training. In this scenario, the
limited diversity may jeopardize the model generalization on unseen target
domains. To tackle this problem, we propose a style-complement module to
enhance the generalization power of the model by synthesizing images from
diverse distributions that are complementary to the source ones. More
specifically, we adopt a tractable upper bound of mutual information (MI)
between the generated and source samples and perform a two-step optimization
iteratively: (1) by minimizing the MI upper bound approximation for each sample
pair, the generated images are forced to be diversified from the source
samples; (2) subsequently, we maximize the MI between the samples from the same
semantic category, which assists the network to learn discriminative features
from diverse-styled images. Extensive experiments on three benchmark datasets
demonstrate the superiority of our approach, which surpasses the
state-of-the-art single-DG methods by up to 25.14%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Underwater Image Semantic Segmentation Method Focusing on Boundaries and a Real Underwater Scene Semantic Segmentation Dataset. (arXiv:2108.11727v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11727">
<div class="article-summary-box-inner">
<span><p>With the development of underwater object grabbing technology, underwater
object recognition and segmentation of high accuracy has become a challenge.
The existing underwater object detection technology can only give the general
position of an object, unable to give more detailed information such as the
outline of the object, which seriously affects the grabbing efficiency. To
address this problem, we label and establish the first underwater semantic
segmentation dataset of real scene(DUT-USEG:DUT Underwater Segmentation
Dataset). The DUT- USEG dataset includes 6617 images, 1487 of which have
semantic segmentation and instance segmentation annotations, and the remaining
5130 images have object detection box annotations. Based on this dataset, we
propose a semi-supervised underwater semantic segmentation network focusing on
the boundaries(US-Net: Underwater Segmentation Network). By designing a pseudo
label generator and a boundary detection subnetwork, this network realizes the
fine learning of boundaries between underwater objects and background, and
improves the segmentation effect of boundary areas. Experiments show that the
proposed method improves by 6.7% in three categories of holothurian, echinus,
starfish in DUT-USEG dataset, and achieves state-of-the-art results. The DUT-
USEG dataset will be released at https://github.com/baxiyi/DUT-USEG.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep learning based dictionary learning and tomographic image reconstruction. (arXiv:2108.11730v1 [stat.ML])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11730">
<div class="article-summary-box-inner">
<span><p>This work presents an approach for image reconstruction in clinical low-dose
tomography that combines principles from sparse signal processing with ideas
from deep learning. First, we describe sparse signal representation in terms of
dictionaries from a statistical perspective and interpret dictionary learning
as a process of aligning distribution that arises from a generative model with
empirical distribution of true signals. As a result we can see that sparse
coding with learned dictionaries resembles a specific variational autoencoder,
where the decoder is a linear function and the encoder is a sparse coding
algorithm. Next, we show that dictionary learning can also benefit from
computational advancements introduced in the context of deep learning, such as
parallelism and as stochastic optimization. Finally, we show that
regularization by dictionaries achieves competitive performance in computed
tomography (CT) reconstruction comparing to state-of-the-art model based and
data driven approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatio-Temporal Dynamic Inference Network for Group Activity Recognition. (arXiv:2108.11743v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11743">
<div class="article-summary-box-inner">
<span><p>Group activity recognition aims to understand the activity performed by a
group of people. In order to solve it, modeling complex spatio-temporal
interactions is the key. Previous methods are limited in reasoning on a
predefined graph, which ignores the inherent person-specific interaction
context. Moreover, they adopt inference schemes that are computationally
expensive and easily result in the over-smoothing problem. In this paper, we
manage to achieve spatio-temporal person-specific inferences by proposing
Dynamic Inference Network (DIN), which composes of Dynamic Relation (DR) module
and Dynamic Walk (DW) module. We firstly propose to initialize interaction
fields on a primary spatio-temporal graph. Within each interaction field, we
apply DR to predict the relation matrix and DW to predict the dynamic walk
offsets in a joint-processing manner, thus forming a person-specific
interaction graph. By updating features on the specific graph, a person can
possess a global-level interaction field with a local initialization.
Experiments indicate both modules' effectiveness. Moreover, DIN achieves
significant improvement compared to previous state-of-the-art methods on two
popular datasets under the same setting, while costing much less computation
overhead of the reasoning module.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training and Profiling a Pediatric Emotion Recognition Classifier on Mobile Devices. (arXiv:2108.11754v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11754">
<div class="article-summary-box-inner">
<span><p>Implementing automated emotion recognition on mobile devices could provide an
accessible diagnostic and therapeutic tool for those who struggle to recognize
emotion, including children with developmental behavioral conditions such as
autism. Although recent advances have been made in building more accurate
emotion classifiers, existing models are too computationally expensive to be
deployed on mobile devices. In this study, we optimized and profiled various
machine learning models designed for inference on edge devices and were able to
match previous state of the art results for emotion recognition on children.
Our best model, a MobileNet-V2 network pre-trained on ImageNet, achieved 65.11%
balanced accuracy and 64.19% F1-score on CAFE, while achieving a 45-millisecond
inference latency on a Motorola Moto G6 phone. This balanced accuracy is only
1.79% less than the current state of the art for CAFE, which used a model that
contains 26.62x more parameters and was unable to run on the Moto G6, even when
fully optimized. This work validates that with specialized design and
optimization techniques, machine learning models can become lightweight enough
for deployment on mobile devices and still achieve high accuracies on difficult
image classification tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inducing Semantic Grouping of Latent Concepts for Explanations: An Ante-Hoc Approach. (arXiv:2108.11761v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11761">
<div class="article-summary-box-inner">
<span><p>Self-explainable deep models are devised to represent the hidden concepts in
the dataset without requiring any posthoc explanation generation technique. We
worked with one of such models motivated by explicitly representing the
classifier function as a linear function and showed that by exploiting
probabilistic latent and properly modifying different parts of the model can
result better explanation as well as provide superior predictive performance.
Apart from standard visualization techniques, we proposed a new technique which
can strengthen human understanding towards hidden concepts. We also proposed a
technique of using two different self-supervision techniques to extract
meaningful concepts related to the type of self-supervision considered and
achieved significant performance boost. The most important aspect of our method
is that it works nicely in a low data regime and reaches the desired accuracy
in a few number of epochs. We reported exhaustive results with CIFAR10,
CIFAR100, and AWA2 datasets to show effect of our method with moderate and
relatively complex datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Physical Adversarial Attacks on an Aerial Imagery Object Detector. (arXiv:2108.11765v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11765">
<div class="article-summary-box-inner">
<span><p>Deep neural networks (DNNs) have become essential for processing the vast
amounts of aerial imagery collected using earth-observing satellite platforms.
However, DNNs are vulnerable towards adversarial examples, and it is expected
that this weakness also plagues DNNs for aerial imagery. In this work, we
demonstrate one of the first efforts on physical adversarial attacks on aerial
imagery, whereby adversarial patches were optimised, fabricated and installed
on or near target objects (cars) to significantly reduce the efficacy of an
object detector applied on overhead images. Physical adversarial attacks on
aerial images, particularly those captured from satellite platforms, are
challenged by atmospheric factors (lighting, weather, seasons) and the distance
between the observer and target. To investigate the effects of these
challenges, we devised novel experiments and metrics to evaluate the efficacy
of physical adversarial attacks against object detectors in aerial scenes. Our
results indicate the palpable threat posed by physical adversarial attacks
towards DNNs for processing satellite imagery.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comparison of Deep Saliency Map Generators on Multispectral Data in Object Detection. (arXiv:2108.11767v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11767">
<div class="article-summary-box-inner">
<span><p>Deep neural networks, especially convolutional deep neural networks, are
state-of-the-art methods to classify, segment or even generate images, movies,
or sounds. However, these methods lack of a good semantic understanding of what
happens internally. The question, why a COVID-19 detector has classified a
stack of lung-ct images as positive, is sometimes more interesting than the
overall specificity and sensitivity. Especially when human domain expert
knowledge disagrees with the given output. This way, human domain experts could
also be advised to reconsider their choice, regarding the information pointed
out by the system. In addition, the deep learning model can be controlled, and
a present dataset bias can be found. Currently, most explainable AI methods in
the computer vision domain are purely used on image classification, where the
images are ordinary images in the visible spectrum. As a result, there is no
comparison on how the methods behave with multimodal image data, as well as
most methods have not been investigated on how they behave when used for object
detection. This work tries to close the gaps. Firstly, investigating three
saliency map generator methods on how their maps differ across the different
spectra. This is achieved via accurate and systematic training. Secondly, we
examine how they behave when used for object detection. As a practical problem,
we chose object detection in the infrared and visual spectrum for autonomous
driving. The dataset used in this work is the Multispectral Object Detection
Dataset, where each scene is available in the FIR, MIR and NIR as well as
visual spectrum. The results show that there are differences between the
infrared and visual activation maps. Further, an advanced training with both,
the infrared and visual data not only improves the network's output, it also
leads to more focused spots in the saliency maps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-category Video Highlight Detection via Set-based Learning. (arXiv:2108.11770v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11770">
<div class="article-summary-box-inner">
<span><p>Autonomous highlight detection is crucial for enhancing the efficiency of
video browsing on social media platforms. To attain this goal in a data-driven
way, one may often face the situation where highlight annotations are not
available on the target video category used in practice, while the supervision
on another video category (named as source video category) is achievable. In
such a situation, one can derive an effective highlight detector on target
video category by transferring the highlight knowledge acquired from source
video category to the target one. We call this problem cross-category video
highlight detection, which has been rarely studied in previous works. For
tackling such practical problem, we propose a Dual-Learner-based Video
Highlight Detection (DL-VHD) framework. Under this framework, we first design a
Set-based Learning module (SL-module) to improve the conventional pair-based
learning by assessing the highlight extent of a video segment under a broader
context. Based on such learning manner, we introduce two different learners to
acquire the basic distinction of target category videos and the characteristics
of highlight moments on source video category, respectively. These two types of
highlight knowledge are further consolidated via knowledge distillation.
Extensive experiments on three benchmark datasets demonstrate the superiority
of the proposed SL-module, and the DL-VHD method outperforms five typical
Unsupervised Domain Adaptation (UDA) algorithms on various cross-category
highlight detection tasks. Our code is available at
https://github.com/ChrisAllenMing/Cross_Category_Video_Highlight .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ICM-3D: Instantiated Category Modeling for 3D Instance Segmentation. (arXiv:2108.11771v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11771">
<div class="article-summary-box-inner">
<span><p>Separating 3D point clouds into individual instances is an important task for
3D vision. It is challenging due to the unknown and varying number of instances
in a scene. Existing deep learning based works focus on a two-step pipeline:
first learn a feature embedding and then cluster the points. Such a two-step
pipeline leads to disconnected intermediate objectives. In this paper, we
propose an integrated reformulation of 3D instance segmentation as a per-point
classification problem. We propose ICM-3D, a single-step method to segment 3D
instances via instantiated categorization. The augmented category information
is automatically constructed from 3D spatial positions. We conduct extensive
experiments to verify the effectiveness of ICM-3D and show that it obtains
inspiring performance across multiple frameworks, backbones and benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Modulation Network for Audio-Visual Event Localization. (arXiv:2108.11773v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11773">
<div class="article-summary-box-inner">
<span><p>We study the problem of localizing audio-visual events that are both audible
and visible in a video. Existing works focus on encoding and aligning audio and
visual features at the segment level while neglecting informative correlation
between segments of the two modalities and between multi-scale event proposals.
We propose a novel MultiModulation Network (M2N) to learn the above correlation
and leverage it as semantic guidance to modulate the related auditory, visual,
and fused features. In particular, during feature encoding, we propose
cross-modal normalization and intra-modal normalization. The former modulates
the features of two modalities by establishing and exploiting the cross-modal
relationship. The latter modulates the features of a single modality with the
event-relevant semantic guidance of the same modality. In the fusion stage,we
propose a multi-scale proposal modulating module and a multi-alignment segment
modulating module to introduce multi-scale event proposals and enable dense
matching between cross-modal segments. With the auditory, visual, and fused
features modulated by the correlation information regarding audio-visual
events, M2N performs accurate event localization. Extensive experiments
conducted on the AVE dataset demonstrate that our proposed method outperforms
the state of the art in both supervised event localization and cross-modality
localization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quadratic mutual information regularization in real-time deep CNN models. (arXiv:2108.11774v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11774">
<div class="article-summary-box-inner">
<span><p>In this paper, regularized lightweight deep convolutional neural network
models, capable of effectively operating in real-time on devices with
restricted computational power for high-resolution video input are proposed.
Furthermore, a novel regularization method motivated by the Quadratic Mutual
Information, in order to improve the generalization ability of the utilized
models is proposed. Extensive experiments on various binary classification
problems involved in autonomous systems are performed, indicating the
effectiveness of the proposed models as well as of the proposed regularizer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Hierarchical Assessment of Adversarial Severity. (arXiv:2108.11785v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11785">
<div class="article-summary-box-inner">
<span><p>Adversarial Robustness is a growing field that evidences the brittleness of
neural networks. Although the literature on adversarial robustness is vast, a
dimension is missing in these studies: assessing how severe the mistakes are.
We call this notion "Adversarial Severity" since it quantifies the downstream
impact of adversarial corruptions by computing the semantic error between the
misclassification and the proper label. We propose to study the effects of
adversarial noise by measuring the Robustness and Severity into a large-scale
dataset: iNaturalist-H. Our contributions are: (i) we introduce novel
Hierarchical Attacks that harness the rich structured space of labels to create
adversarial examples. (ii) These attacks allow us to benchmark the Adversarial
Robustness and Severity of classification models. (iii) We enhance the
traditional adversarial training with a simple yet effective Hierarchical
Curriculum Training to learn these nodes gradually within the hierarchical
tree. We perform extensive experiments showing that hierarchical defenses allow
deep models to boost the adversarial Robustness by 1.85% and reduce the
severity of all attacks by 0.17, on average.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">State of the Art: Image Hashing. (arXiv:2108.11794v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11794">
<div class="article-summary-box-inner">
<span><p>Perceptual image hashing methods are often applied in various objectives,
such as image retrieval, finding duplicate or near-duplicate images, and
finding similar images from large-scale image content. The main challenge in
image hashing techniques is robust feature extraction, which generates the same
or similar hashes in images that are visually identical. In this article, we
present a short review of the state-of-the-art traditional perceptual hashing
and deep learning-based perceptual hashing methods, identifying the best
approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient training of lightweight neural networks using Online Self-Acquired Knowledge Distillation. (arXiv:2108.11798v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11798">
<div class="article-summary-box-inner">
<span><p>Knowledge Distillation has been established as a highly promising approach
for training compact and faster models by transferring knowledge from
heavyweight and powerful models. However, KD in its conventional version
constitutes an enduring, computationally and memory demanding process. In this
paper, Online Self-Acquired Knowledge Distillation (OSAKD) is proposed, aiming
to improve the performance of any deep neural model in an online manner. We
utilize k-nn non-parametric density estimation technique for estimating the
unknown probability distributions of the data samples in the output feature
space. This allows us for directly estimating the posterior class probabilities
of the data samples, and we use them as soft labels that encode explicit
information about the similarities of the data with the classes, negligibly
affecting the computational cost. The experimental evaluation on four datasets
validates the effectiveness of proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised domain adaptation for clinician pose estimation and instance segmentation in the OR. (arXiv:2108.11801v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11801">
<div class="article-summary-box-inner">
<span><p>The fine-grained localization of clinicians in the operating room (OR) is a
key component to design the new generation of OR support systems. Computer
vision models for person pixel-based segmentation and body-keypoints detection
are needed to better understand the clinical activities and the spatial layout
of the OR. This is challenging, not only because OR images are very different
from traditional vision datasets, but also because data and annotations are
hard to collect and generate in the OR due to privacy concerns. To address
these concerns, we first study how joint person pose estimation and instance
segmentation can be performed on low resolutions images from 1x to 12x. Second,
to address the domain shift and the lack of annotations, we propose a novel
unsupervised domain adaptation method, called \emph{AdaptOR}, to adapt a model
from an \emph{in-the-wild} labeled source domain to a statistically different
unlabeled target domain. We propose to exploit explicit geometric constraints
on the different augmentations of the unlabeled target domain image to generate
accurate pseudo labels, and using these pseudo labels to train the model on
high- and low-resolution OR images in a \emph{self-training} framework.
Furthermore, we propose \emph{disentangled feature normalization} to handle the
statistically different source and target domain data. Extensive experimental
results with detailed ablation studies on the two OR datasets \emph{MVOR+} and
\emph{TUM-OR-test} show the effectiveness of our approach against strongly
constructed baselines, especially on the low-resolution privacy-preserving OR
images. Finally, we show the generality of our method as a semi-supervised
learning (SSL) method on the large-scale \emph{COCO} dataset, where we achieve
comparable results with as few as \textbf{1\%} of labeled supervision against a
model trained with 100\% labeled supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mining Contextual Information Beyond Image for Semantic Segmentation. (arXiv:2108.11819v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11819">
<div class="article-summary-box-inner">
<span><p>This paper studies the context aggregation problem in semantic image
segmentation. The existing researches focus on improving the pixel
representations by aggregating the contextual information within individual
images. Though impressive, these methods neglect the significance of the
representations of the pixels of the corresponding class beyond the input
image. To address this, this paper proposes to mine the contextual information
beyond individual images to further augment the pixel representations. We first
set up a feature memory module, which is updated dynamically during training,
to store the dataset-level representations of various categories. Then, we
learn class probability distribution of each pixel representation under the
supervision of the ground-truth segmentation. At last, the representation of
each pixel is augmented by aggregating the dataset-level representations based
on the corresponding class probability distribution. Furthermore, by utilizing
the stored dataset-level representations, we also propose a representation
consistent learning strategy to make the classification head better address
intra-class compactness and inter-class dispersion. The proposed method could
be effortlessly incorporated into existing segmentation frameworks (e.g., FCN,
PSPNet, OCRNet and DeepLabV3) and brings consistent performance improvements.
Mining contextual information beyond image allows us to report state-of-the-art
performance on various benchmarks: ADE20K, LIP, Cityscapes and COCO-Stuff.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">State of the Art: Face Recognition. (arXiv:2108.11821v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11821">
<div class="article-summary-box-inner">
<span><p>Working with Child Sexual Exploitation Material (CSEM) in forensic
applications might be benefited from the progress in automatic face
recognition. However, discriminative parts of a face in CSEM, i.e., mostly the
eyes, could be often occluded to difficult the victim's identification. Most of
the face recognition approaches cannot deal with such kind of occlusions,
resulting in inaccurate face recognition results. This document presents a
short review face recognition methods for images with natural and eye occlude
faces. The purpose is to select the best baseline approach for solving
automatic face recognition of occluded faces.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast and Flexible Human Pose Estimation with HyperPose. (arXiv:2108.11826v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11826">
<div class="article-summary-box-inner">
<span><p>Estimating human pose is an important yet challenging task in multimedia
applications. Existing pose estimation libraries target reproducing standard
pose estimation algorithms. When it comes to customising these algorithms for
real-world applications, none of the existing libraries can offer both the
flexibility of developing custom pose estimation algorithms and the
high-performance of executing these algorithms on commodity devices. In this
paper, we introduce Hyperpose, a novel flexible and high-performance pose
estimation library. Hyperpose provides expressive Python APIs that enable
developers to easily customise pose estimation algorithms for their
applications. It further provides a model inference engine highly optimised for
real-time pose estimation. This engine can dynamically dispatch carefully
designed pose estimation tasks to CPUs and GPUs, thus automatically achieving
high utilisation of hardware resources irrespective of deployment environments.
Extensive evaluation results show that Hyperpose can achieve up to 3.1x~7.3x
higher pose estimation throughput compared to state-of-the-art pose estimation
libraries without compromising estimation accuracy. By 2021, Hyperpose has
received over 1000 stars on GitHub and attracted users from both industry and
academy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Geometry Based Machining Feature Retrieval with Inductive Transfer Learning. (arXiv:2108.11838v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11838">
<div class="article-summary-box-inner">
<span><p>Manufacturing industries have widely adopted the reuse of machine parts as a
method to reduce costs and as a sustainable manufacturing practice.
Identification of reusable features from the design of the parts and finding
their similar features from the database is an important part of this process.
In this project, with the help of fully convolutional geometric features, we
are able to extract and learn the high level semantic features from CAD models
with inductive transfer learning. The extracted features are then compared with
that of other CAD models from the database using Frobenius norm and identical
features are retrieved. Later we passed the extracted features to a deep
convolutional neural network with a spatial pyramid pooling layer and the
performance of the feature retrieval increased significantly. It was evident
from the results that the model could effectively capture the geometrical
elements from machining features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Consistent Relative Confidence and Label-Free Model Selection for Convolutional Neural Networks. (arXiv:2108.11845v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11845">
<div class="article-summary-box-inner">
<span><p>This paper is concerned with image classification based on deep convolutional
neural networks (CNNs). The focus is centered around the following question:
given a set of candidate CNN models, how to select the right one that has the
best generalization property for the current task? Present model selection
methods require access to a batch of labeled data for defining a performance
metric, such as the cross-entropy loss, the classification error rate, the
negative log-likelihood, and so on. In many practical cases, however, labeled
data are not available in time as labeling itself is a time-consuming and
expensive task. To this end, this paper presents an approach to CNN model
selection using only unlabeled data. This method is developed based on a
principle termed consistent relative confidence (CRC). The effectiveness and
efficiency of the presented method are demonstrated by extensive experimental
studies based on datasets MNIST and FasionMNIST.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Supervised Compression for Resource-constrained Edge Computing Systems. (arXiv:2108.11898v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11898">
<div class="article-summary-box-inner">
<span><p>There has been much interest in deploying deep learning algorithms on
low-powered devices, including smartphones, drones, and medical sensors.
However, full-scale deep neural networks are often too resource-intensive in
terms of energy and storage. As a result, the bulk part of the machine learning
operation is therefore often carried out on an edge server, where the data is
compressed and transmitted. However, compressing data (such as images) leads to
transmitting information irrelevant to the supervised task. Another popular
approach is to split the deep network between the device and the server while
compressing intermediate features. To date, however, such split computing
strategies have barely outperformed the aforementioned naive data compression
baselines due to their inefficient approaches to feature compression. This
paper adopts ideas from knowledge distillation and neural image compression to
compress intermediate feature representations more efficiently. Our supervised
compression approach uses a teacher model and a student model with a stochastic
bottleneck and learnable prior for entropy coding. We compare our approach to
various neural image and feature compression baselines in three vision tasks
and found that it achieves better supervised rate-distortion performance while
also maintaining smaller end-to-end latency. We furthermore show that the
learned feature representations can be tuned to serve multiple downstream
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Multi-scale Consistency for Weakly Supervised Segmentation Learning. (arXiv:2108.11900v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11900">
<div class="article-summary-box-inner">
<span><p>Collecting large-scale medical datasets with fine-grained annotations is
time-consuming and requires experts. For this reason, weakly supervised
learning aims at optimising machine learning models using weaker forms of
annotations, such as scribbles, which are easier and faster to collect.
Unfortunately, training with weak labels is challenging and needs
regularisation. Herein, we introduce a novel self-supervised multi-scale
consistency loss, which, coupled with an attention mechanism, encourages the
segmentor to learn multi-scale relationships between objects and improves
performance. We show state-of-the-art performance on several medical and
non-medical datasets. The code used for the experiments is available at
https://vios-s.github.io/multiscale-pyag.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Similar Scenes arouse Similar Emotions: Parallel Data Augmentation for Stylized Image Captioning. (arXiv:2108.11912v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11912">
<div class="article-summary-box-inner">
<span><p>Stylized image captioning systems aim to generate a caption not only
semantically related to a given image but also consistent with a given style
description. One of the biggest challenges with this task is the lack of
sufficient paired stylized data. Many studies focus on unsupervised approaches,
without considering from the perspective of data augmentation. We begin with
the observation that people may recall similar emotions when they are in
similar scenes, and often express similar emotions with similar style phrases,
which underpins our data augmentation idea. In this paper, we propose a novel
Extract-Retrieve-Generate data augmentation framework to extract style phrases
from small-scale stylized sentences and graft them to large-scale factual
captions. First, we design the emotional signal extractor to extract style
phrases from small-scale stylized sentences. Second, we construct the plugable
multi-modal scene retriever to retrieve scenes represented with pairs of an
image and its stylized caption, which are similar to the query image or caption
in the large-scale factual data. In the end, based on the style phrases of
similar scenes and the factual description of the current scene, we build the
emotion-aware caption generator to generate fluent and diversified stylized
captions for the current scene. Extensive experimental results show that our
framework can alleviate the data scarcity problem effectively. It also
significantly boosts the performance of several existing image captioning
models in both supervised and unsupervised settings, which outperforms the
state-of-the-art stylized image captioning methods in terms of both sentence
relevance and stylishness by a substantial margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">User-Centric Semi-Automated Infographics Authoring and Recommendation. (arXiv:2108.11914v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11914">
<div class="article-summary-box-inner">
<span><p>Designing infographics can be a tedious process for non-experts and
time-consuming even for professional designers. Based on the literature and a
formative study, we propose a flexible framework for automated and
semi-automated infographics design. This framework captures the main design
components in infographics and streamlines the generation workflow into three
steps, allowing users to control and optimize each aspect independently. Based
on the framework, we also propose an interactive tool, \name{}, for assisting
novice designers with creating high-quality infographics from an input in a
markdown format by offering recommendations of different design components of
infographics. Simultaneously, more experienced designers can provide custom
designs and layout ideas to the tool using a canvas to control the automated
generation process partially. As part of our work, we also contribute an
individual visual group (VG) and connection designs dataset (in SVG), along
with a 1k complete infographic image dataset with segmented VGs. This dataset
plays a crucial role in diversifying the infographic designs created by our
framework. We evaluate our approach with a comparison against similar tools, a
user study with novice and expert designers, and a case study. Results confirm
that our framework and \name{} excel in creating customized infographics and
exploring a large variety of designs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Re-using Adversarial Mask Discriminators for Test-time Training under Distribution Shifts. (arXiv:2108.11926v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11926">
<div class="article-summary-box-inner">
<span><p>Thanks to their ability to learn flexible data-driven losses, Generative
Adversarial Networks (GANs) are an integral part of many semi- and
weakly-supervised methods for medical image segmentation. GANs jointly optimise
a generator and an adversarial discriminator on a set of training data. After
training has completed, the discriminator is usually discarded and only the
generator is used for inference. But should we discard discriminators? In this
work, we argue that training stable discriminators produces expressive loss
functions that we can re-use at inference to detect and correct segmentation
mistakes. First, we identify key challenges and suggest possible solutions to
make discriminators re-usable at inference. Then, we show that we can combine
discriminators with image reconstruction costs (via decoders) to further
improve the model. Our method is simple and improves the test-time performance
of pre-trained GANs. Moreover, we show that it is compatible with standard
post-processing techniques and it has potentials to be used for Online
Continual Learning. With our work, we open new research avenues for re-using
adversarial discriminators at inference.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantically Coherent Out-of-Distribution Detection. (arXiv:2108.11941v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11941">
<div class="article-summary-box-inner">
<span><p>Current out-of-distribution (OOD) detection benchmarks are commonly built by
defining one dataset as in-distribution (ID) and all others as OOD. However,
these benchmarks unfortunately introduce some unwanted and impractical goals,
e.g., to perfectly distinguish CIFAR dogs from ImageNet dogs, even though they
have the same semantics and negligible covariate shifts. These unrealistic
goals will result in an extremely narrow range of model capabilities, greatly
limiting their use in real applications. To overcome these drawbacks, we
re-design the benchmarks and propose the semantically coherent
out-of-distribution detection (SC-OOD). On the SC-OOD benchmarks, existing
methods suffer from large performance degradation, suggesting that they are
extremely sensitive to low-level discrepancy between data sources while
ignoring their inherent semantics. To develop an effective SC-OOD detection
approach, we leverage an external unlabeled set and design a concise framework
featured by unsupervised dual grouping (UDG) for the joint modeling of ID and
OOD data. The proposed UDG can not only enrich the semantic knowledge of the
model by exploiting unlabeled data in an unsupervised manner, but also
distinguish ID/OOD samples to enhance ID classification and OOD detection tasks
simultaneously. Extensive experiments demonstrate that our approach achieves
state-of-the-art performance on SC-OOD benchmarks. Code and benchmarks are
provided on our project page: https://jingkang50.github.io/projects/scood.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Probabilistic Modeling for Human Mesh Recovery. (arXiv:2108.11944v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11944">
<div class="article-summary-box-inner">
<span><p>This paper focuses on the problem of 3D human reconstruction from 2D
evidence. Although this is an inherently ambiguous problem, the majority of
recent works avoid the uncertainty modeling and typically regress a single
estimate for a given input. In contrast to that, in this work, we propose to
embrace the reconstruction ambiguity and we recast the problem as learning a
mapping from the input to a distribution of plausible 3D poses. Our approach is
based on the normalizing flows model and offers a series of advantages. For
conventional applications, where a single 3D estimate is required, our
formulation allows for efficient mode computation. Using the mode leads to
performance that is comparable with the state of the art among deterministic
unimodal regression models. Simultaneously, since we have access to the
likelihood of each sample, we demonstrate that our model is useful in a series
of downstream tasks, where we leverage the probabilistic nature of the
prediction as a tool for more accurate estimation. These tasks include
reconstruction from multiple uncalibrated views, as well as human model
fitting, where our model acts as a powerful image-based prior for mesh
recovery. Our results validate the importance of probabilistic modeling, and
indicate state-of-the-art performance across a variety of settings. Code and
models are available at: https://www.seas.upenn.edu/~nkolot/projects/prohmr.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SASRA: Semantically-aware Spatio-temporal Reasoning Agent for Vision-and-Language Navigation in Continuous Environments. (arXiv:2108.11945v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11945">
<div class="article-summary-box-inner">
<span><p>This paper presents a novel approach for the Vision-and-Language Navigation
(VLN) task in continuous 3D environments, which requires an autonomous agent to
follow natural language instructions in unseen environments. Existing
end-to-end learning-based VLN methods struggle at this task as they focus
mostly on utilizing raw visual observations and lack the semantic
spatio-temporal reasoning capabilities which is crucial in generalizing to new
environments. In this regard, we present a hybrid transformer-recurrence model
which focuses on combining classical semantic mapping techniques with a
learning-based method. Our method creates a temporal semantic memory by
building a top-down local ego-centric semantic map and performs cross-modal
grounding to align map and language modalities to enable effective learning of
VLN policy. Empirical results in a photo-realistic long-horizon simulation
environment show that the proposed approach outperforms a variety of
state-of-the-art methods and baselines with over 22% relative improvement in
SPL in prior unseen environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LocTex: Learning Data-Efficient Visual Representations from Localized Textual Supervision. (arXiv:2108.11950v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11950">
<div class="article-summary-box-inner">
<span><p>Computer vision tasks such as object detection and semantic/instance
segmentation rely on the painstaking annotation of large training datasets. In
this paper, we propose LocTex that takes advantage of the low-cost localized
textual annotations (i.e., captions and synchronized mouse-over gestures) to
reduce the annotation effort. We introduce a contrastive pre-training framework
between images and captions and propose to supervise the cross-modal attention
map with rendered mouse traces to provide coarse localization signals. Our
learned visual features capture rich semantics (from free-form captions) and
accurate localization (from mouse traces), which are very effective when
transferred to various downstream vision tasks. Compared with ImageNet
supervised pre-training, LocTex can reduce the size of the pre-training dataset
by 10x or the target dataset by 2x while achieving comparable or even improved
performance on COCO instance segmentation. When provided with the same amount
of annotations, LocTex achieves around 4% higher accuracy than the previous
state-of-the-art "vision+language" pre-training approach on the task of PASCAL
VOC image classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unpriortized Autoencoder For Image Generation. (arXiv:1902.04294v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1902.04294">
<div class="article-summary-box-inner">
<span><p>In this paper, we treat the image generation task using an autoencoder, a
representative latent model. Unlike many studies regularizing the latent
variable's distribution by assuming a manually specified prior, we approach the
image generation task using an autoencoder by directly estimating the latent
distribution. To this end, we introduce 'latent density estimator' which
captures latent distribution explicitly and propose its structure. Through
experiments, we show that our generative model generates images with the
improved visual quality compared to previous autoencoder-based generative
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Augmenting Colonoscopy using Extended and Directional CycleGAN for Lossy Image Translation. (arXiv:2003.12473v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.12473">
<div class="article-summary-box-inner">
<span><p>Colorectal cancer screening modalities, such as optical colonoscopy (OC) and
virtual colonoscopy (VC), are critical for diagnosing and ultimately removing
polyps (precursors of colon cancer). The non-invasive VC is normally used to
inspect a 3D reconstructed colon (from CT scans) for polyps and if found, the
OC procedure is performed to physically traverse the colon via endoscope and
remove these polyps. In this paper, we present a deep learning framework,
Extended and Directional CycleGAN, for lossy unpaired image-to-image
translation between OC and VC to augment OC video sequences with
scale-consistent depth information from VC, and augment VC with
patient-specific textures, color and specular highlights from OC (e.g, for
realistic polyp synthesis). Both OC and VC contain structural information, but
it is obscured in OC by additional patient-specific texture and specular
highlights, hence making the translation from OC to VC lossy. The existing
CycleGAN approaches do not handle lossy transformations. To address this
shortcoming, we introduce an extended cycle consistency loss, which compares
the geometric structures from OC in the VC domain. This loss removes the need
for the CycleGAN to embed OC information in the VC domain. To handle a stronger
removal of the textures and lighting, a Directional Discriminator is introduced
to differentiate the direction of translation (by creating paired information
for the discriminator), as opposed to the standard CycleGAN which is
direction-agnostic. Combining the extended cycle consistency loss and the
Directional Discriminator, we show state-of-the-art results on scale-consistent
depth inference for phantom, textured VC and for real polyp and normal colon
video sequences. We also present results for realistic pendunculated and flat
polyp synthesis from bumps introduced in 3D VC models. Code/models:
https://github.com/nadeemlab/CEP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Sensory Substitution: Noninvasively Enabling Biological Neural Networks to Receive Input from Artificial Neural Networks. (arXiv:2005.13291v3 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.13291">
<div class="article-summary-box-inner">
<span><p>As is expressed in the adage "a picture is worth a thousand words", when
using spoken language to communicate visual information, brevity can be a
challenge. This work describes a novel technique for leveraging machine-learned
feature embeddings to sonify visual (and other types of) information into a
perceptual audio domain, allowing users to perceive this information using only
their aural faculty. The system uses a pretrained image embedding network to
extract visual features and embed them in a compact subset of Euclidean space
-- this converts the images into feature vectors whose $L^2$ distances can be
used as a meaningful measure of similarity. A generative adversarial network
(GAN) is then used to find a distance preserving map from this metric space of
feature vectors into the metric space defined by a target audio dataset
equipped with either the Euclidean metric or a mel-frequency cepstrum-based
psychoacoustic distance metric. We demonstrate this technique by sonifying
images of faces into human speech-like audio. For both target audio metrics,
the GAN successfully found a metric preserving mapping, and in human subject
tests, users were able to accurately classify audio sonifications of faces.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Adversarial Robustness: A Neural Architecture Search perspective. (arXiv:2007.08428v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08428">
<div class="article-summary-box-inner">
<span><p>Adversarial robustness of deep learning models has gained much traction in
the last few years. Various attacks and defenses are proposed to improve the
adversarial robustness of modern-day deep learning architectures. While all
these approaches help improve the robustness, one promising direction for
improving adversarial robustness is unexplored, i.e., the complex topology of
the neural network architecture. In this work, we address the following
question: Can the complex topology of a neural network give adversarial
robustness without any form of adversarial training?. We answer this
empirically by experimenting with different hand-crafted and NAS-based
architectures. Our findings show that, for small-scale attacks, NAS-based
architectures are more robust for small-scale datasets and simple tasks than
hand-crafted architectures. However, as the size of the dataset or the
complexity of task increases, hand-crafted architectures are more robust than
NAS-based architectures. Our work is the first large-scale study to understand
adversarial robustness purely from an architectural perspective. Our study
shows that random sampling in the search space of DARTS (a popular NAS method)
with simple ensembling can improve the robustness to PGD attack by nearly~12\%.
We show that NAS, which is popular for achieving SoTA accuracy, can provide
adversarial accuracy as a free add-on without any form of adversarial training.
Our results show that leveraging the search space of NAS methods with methods
like ensembles can be an excellent way to achieve adversarial robustness
without any form of adversarial training. We also introduce a metric that can
be used to calculate the trade-off between clean accuracy and adversarial
robustness. Code and pre-trained models will be made available at
\url{https://github.com/tdchaitanya/nas-robustness}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Claustrum Segmentation in Human Brain MRI Using Deep Learning. (arXiv:2008.03465v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.03465">
<div class="article-summary-box-inner">
<span><p>In the last two decades, neuroscience has produced intriguing evidence for a
central role of the claustrum in mammalian forebrain structure and function.
However, relatively few in vivo studies of the claustrum exist in humans. A
reason for this may be the delicate and sheet-like structure of the claustrum
lying between the insular cortex and the putamen, which makes it not amenable
to conventional segmentation methods. Recently, Deep Learning (DL) based
approaches have been successfully introduced for automated segmentation of
complex, subcortical brain structures. In the following, we present a
multi-view DL-based approach to segment the claustrum in T1-weighted MRI scans.
We trained and evaluated the proposed method in 181 individuals, using
bilateral manual claustrum annotations by an expert neuroradiologist as the
reference standard. Cross-validation experiments yielded median volumetric
similarity, robust Hausdorff distance, and Dice score of 93.3%, 1.41mm, and
71.8%, respectively, representing equal or superior segmentation performance
compared to human intra-rater reliability. The leave-one-scanner-out evaluation
showed good transferability of the algorithm to images from unseen scanners at
slightly inferior performance. Furthermore, we found that DL-based claustrum
segmentation benefits from multi-view information and requires a sample size of
around 75 MRI scans in the training set. We conclude that the developed
algorithm allows for robust automated claustrum segmentation and thus yields
considerable potential for facilitating MRI-based research of the human
claustrum. The software and models of our method are made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimized Deep Encoder-Decoder Methods for Crack Segmentation. (arXiv:2008.06266v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.06266">
<div class="article-summary-box-inner">
<span><p>Surface crack segmentation poses a challenging computer vision task as
background, shape, colour and size of cracks vary. In this work we propose
optimized deep encoder-decoder methods consisting of a combination of
techniques which yield an increase in crack segmentation performance.
Specifically we propose a decoder-part for an encoder-decoder based deep
learning architecture for semantic segmentation and study its components to
achieve increased performance. We also examine the use of different encoder
strategies and introduce a data augmentation policy to increase the amount of
available training data. The performance evaluation of our method is carried
out on four publicly available crack segmentation datasets. Additionally, we
introduce two techniques into the field of surface crack segmentation,
previously not used there: Generating results using test-time-augmentation and
performing a statistical result analysis over multiple training runs. The
former approach generally yields increased performance results, whereas the
latter allows for more reproducible and better representability of a methods
results. Using those aforementioned strategies with our proposed
encoder-decoder architecture we are able to achieve new state of the art
results in all datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Heatmap Regression via Randomized Rounding. (arXiv:2009.00225v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00225">
<div class="article-summary-box-inner">
<span><p>Heatmap regression has become the mainstream methodology for deep
learning-based semantic landmark localization, including in facial landmark
localization and human pose estimation. Though heatmap regression is robust to
large variations in pose, illumination, and occlusion in unconstrained
settings, it usually suffers from a sub-pixel localization problem.
Specifically, considering that the activation point indices in heatmaps are
always integers, quantization error thus appears when using heatmaps as the
representation of numerical coordinates. Previous methods to overcome the
sub-pixel localization problem usually rely on high-resolution heatmaps. As a
result, there is always a trade-off between achieving localization accuracy and
computational cost, where the computational complexity of heatmap regression
depends on the heatmap resolution in a quadratic manner. In this paper, we
formally analyze the quantization error of vanilla heatmap regression and
propose a simple yet effective quantization system to address the sub-pixel
localization problem. The proposed quantization system induced by the
randomized rounding operation 1) encodes the fractional part of numerical
coordinates into the ground truth heatmap using a probabilistic approach during
training; and 2) decodes the predicted numerical coordinates from a set of
activation points during testing. We prove that the proposed quantization
system for heatmap regression is unbiased and lossless. Experimental results on
popular facial landmark localization datasets (WFLW, 300W, COFW, and AFLW) and
human pose estimation datasets (MPII and COCO) demonstrate the effectiveness of
the proposed method for efficient and accurate semantic landmark localization.
Code is available at <a href="http://github.com/baoshengyu/H3R.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cascaded Refinement Network for Point Cloud Completion with Self-supervision. (arXiv:2010.08719v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08719">
<div class="article-summary-box-inner">
<span><p>Point clouds are often sparse and incomplete, which imposes difficulties for
real-world applications. Existing shape completion methods tend to generate
rough shapes without fine-grained details. Considering this, we introduce a
two-branch network for shape completion. The first branch is a cascaded shape
completion sub-network to synthesize complete objects, where we propose to use
the partial input together with the coarse output to preserve the object
details during the dense point reconstruction. The second branch is an
auto-encoder to reconstruct the original partial input. The two branches share
a same feature extractor to learn an accurate global feature for shape
completion. Furthermore, we propose two strategies to enable the training of
our network when ground truth data are not available. This is to mitigate the
dependence of existing approaches on large amounts of ground truth training
data that are often difficult to obtain in real-world applications.
Additionally, our proposed strategies are also able to improve the
reconstruction quality for fully supervised learning. We verify our approach in
self-supervised, semi-supervised and fully supervised settings with superior
performances. Quantitative and qualitative results on different datasets
demonstrate that our method achieves more realistic outputs than
state-of-the-art approaches on the point cloud completion task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Stereo Depth Estimation From a Sequence-to-Sequence Perspective with Transformers. (arXiv:2011.02910v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.02910">
<div class="article-summary-box-inner">
<span><p>Stereo depth estimation relies on optimal correspondence matching between
pixels on epipolar lines in the left and right images to infer depth. In this
work, we revisit the problem from a sequence-to-sequence correspondence
perspective to replace cost volume construction with dense pixel matching using
position information and attention. This approach, named STereo TRansformer
(STTR), has several advantages: It 1) relaxes the limitation of a fixed
disparity range, 2) identifies occluded regions and provides confidence
estimates, and 3) imposes uniqueness constraints during the matching process.
We report promising results on both synthetic and real-world datasets and
demonstrate that STTR generalizes across different domains, even without
fine-tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeRD: Neural Reflectance Decomposition from Image Collections. (arXiv:2012.03918v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03918">
<div class="article-summary-box-inner">
<span><p>Decomposing a scene into its shape, reflectance, and illumination is a
challenging but important problem in computer vision and graphics. This problem
is inherently more challenging when the illumination is not a single light
source under laboratory conditions but is instead an unconstrained
environmental illumination. Though recent work has shown that implicit
representations can be used to model the radiance field of an object, most of
these techniques only enable view synthesis and not relighting. Additionally,
evaluating these radiance fields is resource and time-intensive. We propose a
neural reflectance decomposition (NeRD) technique that uses physically-based
rendering to decompose the scene into spatially varying BRDF material
properties. In contrast to existing techniques, our input images can be
captured under different illumination conditions. In addition, we also propose
techniques to convert the learned reflectance volume into a relightable
textured mesh enabling fast real-time rendering with novel illuminations. We
demonstrate the potential of the proposed approach with experiments on both
synthetic and real datasets, where we are able to obtain high-quality
relightable 3D assets from image collections. The datasets and code is
available on the project page: https://markboss.me/publication/2021-nerd/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recent Developments in Detection of Central Serous Retinopathy through Imaging and Artificial Intelligence Techniques A Review. (arXiv:2012.10961v4 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.10961">
<div class="article-summary-box-inner">
<span><p>Central Serous Retinopathy (CSR) or Central Serous Chorioretinopathy (CSC) is
a significant disease that causes blindness and vision loss among millions of
people worldwide. It transpires as a result of accumulation of watery fluids
behind the retina. Therefore, detection of CSR at early stages allows
preventive measures to avert any impairment to the human eye. Traditionally,
several manual methods for detecting CSR have been developed in the past;
however, they have shown to be imprecise and unreliable. Consequently,
Artificial Intelligence (AI) services in the medical field, including automated
CSR detection, are now possible to detect and cure this disease. This review
assessed a variety of innovative technologies and researches that contribute to
the automatic detection of CSR. In this review, various CSR disease detection
techniques, broadly classified into two categories: a) CSR detection based on
classical imaging technologies, and b) CSR detection based on Machine/Deep
Learning methods, have been reviewed after an elaborated evaluation of 29
different relevant articles. Additionally, it also goes over the advantages,
drawbacks and limitations of a variety of traditional imaging techniques, such
as Optical Coherence Tomography Angiography (OCTA), Fundus Imaging and more
recent approaches that utilize Artificial Intelligence techniques. Finally, it
is concluded that the most recent Deep Learning (DL) classifiers deliver
accurate, fast, and reliable CSR detection. However, more research needs to be
conducted on publicly available datasets to improve computation complexity for
the reliable detection and diagnosis of CSR disease.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Solving the DeepFake Problem : An Analysis on Improving DeepFake Detection using Dynamic Face Augmentation. (arXiv:2102.09603v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09603">
<div class="article-summary-box-inner">
<span><p>The creation of altered and manipulated faces has become more common due to
the improvement of DeepFake generation methods. Simultaneously, we have seen
detection models' development for differentiating between a manipulated and
original face from image or video content. In this paper, we focus on
identifying the limitations and shortcomings of existing deepfake detection
frameworks. We identified some key problems surrounding deepfake detection
through quantitative and qualitative analysis of existing methods and datasets.
We found that deepfake datasets are highly oversampled, causing models to
become easily overfitted. The datasets are created using a small set of real
faces to generate multiple fake samples. When trained on these datasets, models
tend to memorize the actors' faces and labels instead of learning fake
features. To mitigate this problem, we propose a simple data augmentation
method termed Face-Cutout. Our method dynamically cuts out regions of an image
using the face landmark information. It helps the model selectively attend to
only the relevant regions of the input. Our evaluation experiments show that
Face-Cutout can successfully improve the data variation and alleviate the
problem of overfitting. Our method achieves a reduction in LogLoss of 15.2% to
35.3% on different datasets, compared to other occlusion-based techniques.
Moreover, we also propose a general-purpose data pre-processing guideline to
train and evaluate existing architectures allowing us to improve the
generalizability of these models for deepfake detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PredRNN: A Recurrent Neural Network for Spatiotemporal Predictive Learning. (arXiv:2103.09504v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09504">
<div class="article-summary-box-inner">
<span><p>The predictive learning of spatiotemporal sequences aims to generate future
images by learning from the historical context, where the visual dynamics are
believed to have modular structures that can be learned with compositional
subsystems. This paper models these structures by presenting PredRNN, a new
recurrent network, in which a pair of memory cells are explicitly decoupled,
operate in nearly independent transition manners, and finally form unified
representations of the complex environment. Concretely, besides the original
memory cell of LSTM, this network is featured by a zigzag memory flow that
propagates in both bottom-up and top-down directions across all layers,
enabling the learned visual dynamics at different levels of RNNs to
communicate. It also leverages a memory decoupling loss to keep the memory
cells from learning redundant features. We further propose a new curriculum
learning strategy to force PredRNN to learn long-term dynamics from context
frames, which can be generalized to most sequence-to-sequence models. We
provide detailed ablation studies to verify the effectiveness of each
component. Our approach is shown to obtain highly competitive results on five
datasets for both action-free and action-conditioned predictive learning
scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigate Indistinguishable Points in Semantic Segmentation of 3D Point Cloud. (arXiv:2103.10339v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10339">
<div class="article-summary-box-inner">
<span><p>This paper investigates the indistinguishable points (difficult to predict
label) in semantic segmentation for large-scale 3D point clouds. The
indistinguishable points consist of those located in complex boundary, points
with similar local textures but different categories, and points in isolate
small hard areas, which largely harm the performance of 3D semantic
segmentation. To address this challenge, we propose a novel Indistinguishable
Area Focalization Network (IAF-Net), which selects indistinguishable points
adaptively by utilizing the hierarchical semantic features and enhances
fine-grained features for points especially those indistinguishable points. We
also introduce multi-stage loss to improve the feature representation in a
progressive way. Moreover, in order to analyze the segmentation performances of
indistinguishable areas, we propose a new evaluation metric called
Indistinguishable Points Based Metric (IPBM). Our IAF-Net achieves the
comparable results with state-of-the-art performance on several popular 3D
point cloud datasets e.g. S3DIS and ScanNet, and clearly outperforms other
methods on IPBM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AttrLostGAN: Attribute Controlled Image Synthesis from Reconfigurable Layout and Style. (arXiv:2103.13722v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13722">
<div class="article-summary-box-inner">
<span><p>Conditional image synthesis from layout has recently attracted much interest.
Previous approaches condition the generator on object locations as well as
class labels but lack fine-grained control over the diverse appearance aspects
of individual objects. Gaining control over the image generation process is
fundamental to build practical applications with a user-friendly interface. In
this paper, we propose a method for attribute controlled image synthesis from
layout which allows to specify the appearance of individual objects without
affecting the rest of the image. We extend a state-of-the-art approach for
layout-to-image generation to additionally condition individual objects on
attributes. We create and experiment on a synthetic, as well as the challenging
Visual Genome dataset. Our qualitative and quantitative results show that our
method can successfully control the fine-grained details of individual objects
when modelling complex scenes with multiple objects. Source code, dataset and
pre-trained models are publicly available
(https://github.com/stanifrolov/AttrLostGAN).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MultiScene: A Large-scale Dataset and Benchmark for Multi-scene Recognition in Single Aerial Images. (arXiv:2104.02846v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02846">
<div class="article-summary-box-inner">
<span><p>Aerial scene recognition is a fundamental research problem in interpreting
high-resolution aerial imagery. Over the past few years, most studies focus on
classifying an image into one scene category, while in real-world scenarios, it
is more often that a single image contains multiple scenes. Therefore, in this
paper, we investigate a more practical yet underexplored task -- multi-scene
recognition in single images. To this end, we create a large-scale dataset,
called MultiScene, composed of 100,000 unconstrained high-resolution aerial
images. Considering that manually labeling such images is extremely arduous, we
resort to low-cost annotations from crowdsourcing platforms, e.g.,
OpenStreetMap (OSM). However, OSM data might suffer from incompleteness and
incorrectness, which introduce noise into image labels. To address this issue,
we visually inspect 14,000 images and correct their scene labels, yielding a
subset of cleanly-annotated images, named MultiScene-Clean. With it, we can
develop and evaluate deep networks for multi-scene recognition using clean
data. Moreover, we provide crowdsourced annotations of all images for the
purpose of studying network learning with noisy labels. We conduct experiments
with extensive baseline models on both MultiScene-Clean and MultiScene to offer
benchmarks for multi-scene recognition in single images and learning from noisy
labels for this task, respectively. To facilitate progress, we make our dataset
and trained models available on
https://github.com/Hua-YS/Multi-Scene-Recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Co-Scale Conv-Attentional Image Transformers. (arXiv:2104.06399v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06399">
<div class="article-summary-box-inner">
<span><p>In this paper, we present Co-scale conv-attentional image Transformers
(CoaT), a Transformer-based image classifier equipped with co-scale and
conv-attentional mechanisms. First, the co-scale mechanism maintains the
integrity of Transformers' encoder branches at individual scales, while
allowing representations learned at different scales to effectively communicate
with each other; we design a series of serial and parallel blocks to realize
the co-scale mechanism. Second, we devise a conv-attentional mechanism by
realizing a relative position embedding formulation in the factorized attention
module with an efficient convolution-like implementation. CoaT empowers image
Transformers with enriched multi-scale and contextual modeling capabilities. On
ImageNet, relatively small CoaT models attain superior classification results
compared with similar-sized convolutional neural networks and image/vision
Transformers. The effectiveness of CoaT's backbone is also illustrated on
object detection and instance segmentation, demonstrating its applicability to
downstream computer vision tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MemX: An Attention-Aware Smart Eyewear System for Personalized Moment Auto-capture. (arXiv:2105.00916v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00916">
<div class="article-summary-box-inner">
<span><p>This work presents MemX: a biologically-inspired attention-aware eyewear
system developed with the goal of pursuing the long-awaited vision of a
personalized visual Memex. MemX captures human visual attention on the fly,
analyzes the salient visual content, and records moments of personal interest
in the form of compact video snippets. Accurate attentive scene detection and
analysis on resource-constrained platforms is challenging because these tasks
are computation and energy intensive. We propose a new temporal visual
attention network that unifies human visual attention tracking and salient
visual content analysis. Attention tracking focuses computation-intensive video
analysis on salient regions, while video analysis makes human attention
detection and tracking more accurate. Using the YouTube-VIS dataset and 30
participants, we experimentally show that MemX significantly improves the
attention tracking accuracy over the eye-tracking-alone method, while
maintaining high system energy efficiency. We have also conducted 11 in-field
pilot studies across a range of daily usage scenarios, which demonstrate the
feasibility and potential benefits of MemX.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition. (arXiv:2105.01883v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01883">
<div class="article-summary-box-inner">
<span><p>We propose RepMLP, a multi-layer-perceptron-style neural network building
block for image recognition, which is composed of a series of fully-connected
(FC) layers. Compared to convolutional layers, FC layers are more efficient,
better at modeling the long-range dependencies and positional patterns, but
worse at capturing the local structures, hence usually less favored for image
recognition. We propose a structural re-parameterization technique that adds
local prior into an FC to make it powerful for image recognition. Specifically,
we construct convolutional layers inside a RepMLP during training and merge
them into the FC for inference. On CIFAR, a simple pure-MLP model shows
performance very close to CNN. By inserting RepMLP in traditional CNN, we
improve ResNets by 1.8% accuracy on ImageNet, 2.9% for face recognition, and
2.3% mIoU on Cityscapes with lower FLOPs. Our intriguing findings highlight
that combining the global representational capacity and positional perception
of FC with the local prior of convolution can improve the performance of neural
network with faster speed on both the tasks with translation invariance (e.g.,
semantic segmentation) and those with aligned images and positional patterns
(e.g., face recognition). The code and models are available at
https://github.com/DingXiaoH/RepMLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Move2Hear: Active Audio-Visual Source Separation. (arXiv:2105.07142v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07142">
<div class="article-summary-box-inner">
<span><p>We introduce the active audio-visual source separation problem, where an
agent must move intelligently in order to better isolate the sounds coming from
an object of interest in its environment. The agent hears multiple audio
sources simultaneously (e.g., a person speaking down the hall in a noisy
household) and it must use its eyes and ears to automatically separate out the
sounds originating from a target object within a limited time budget. Towards
this goal, we introduce a reinforcement learning approach that trains movement
policies controlling the agent's camera and microphone placement over time,
guided by the improvement in predicted audio separation quality. We demonstrate
our approach in scenarios motivated by both augmented reality (system is
already co-located with the target object) and mobile robotics (agent begins
arbitrarily far from the target object). Using state-of-the-art realistic
audio-visual simulations in 3D environments, we demonstrate our model's ability
to find minimal movement sequences with maximal payoff for audio source
separation. Project: <a href="http://vision.cs.utexas.edu/projects/move2hear.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Making EfficientNet More Efficient: Exploring Batch-Independent Normalization, Group Convolutions and Reduced Resolution Training. (arXiv:2106.03640v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03640">
<div class="article-summary-box-inner">
<span><p>Much recent research has been dedicated to improving the efficiency of
training and inference for image classification. This effort has commonly
focused on explicitly improving theoretical efficiency, often measured as
ImageNet validation accuracy per FLOP. These theoretical savings have, however,
proven challenging to achieve in practice, particularly on high-performance
training accelerators.
</p>
<p>In this work, we focus on improving the practical efficiency of the
state-of-the-art EfficientNet models on a new class of accelerator, the
Graphcore IPU. We do this by extending this family of models in the following
ways: (i) generalising depthwise convolutions to group convolutions; (ii)
adding proxy-normalized activations to match batch normalization performance
with batch-independent statistics; (iii) reducing compute by lowering the
training resolution and inexpensively fine-tuning at higher resolution. We find
that these three methods improve the practical efficiency for both training and
inference. Code available at
https://github.com/graphcore/graphcore-research/tree/main/Making_EfficientNet_More_Efficient .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fully Transformer Networks for Semantic Image Segmentation. (arXiv:2106.04108v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04108">
<div class="article-summary-box-inner">
<span><p>Transformers have shown impressive performance in various natural language
processing and computer vision tasks, due to the capability of modeling
long-range dependencies. Recent progress has demonstrated to combine such
transformers with CNN-based semantic image segmentation models is very
promising. However, it is not well studied yet on how well a pure transformer
based approach can achieve for image segmentation. In this work, we explore a
novel framework for semantic image segmentation, which is encoder-decoder based
Fully Transformer Networks (FTN). Specifically, we first propose a Pyramid
Group Transformer (PGT) as the encoder for progressively learning hierarchical
features, while reducing the computation complexity of the standard visual
transformer(ViT). Then, we propose a Feature Pyramid Transformer (FPT) to fuse
semantic-level and spatial-level information from multiple levels of the PGT
encoder for semantic image segmentation. Surprisingly, this simple baseline can
achieve new state-of-the-art results on multiple challenging semantic
segmentation benchmarks, including PASCAL Context, ADE20K and COCO-Stuff. The
source code will be released upon the publication of this work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FoldIt: Haustral Folds Detection and Segmentation in Colonoscopy Videos. (arXiv:2106.12522v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12522">
<div class="article-summary-box-inner">
<span><p>Haustral folds are colon wall protrusions implicated for high polyp miss rate
during optical colonoscopy procedures. If segmented accurately, haustral folds
can allow for better estimation of missed surface and can also serve as
valuable landmarks for registering pre-treatment virtual (CT) and optical
colonoscopies, to guide navigation towards the anomalies found in pre-treatment
scans. We present a novel generative adversarial network, FoldIt, for
feature-consistent image translation of optical colonoscopy videos to virtual
colonoscopy renderings with haustral fold overlays. A new transitive loss is
introduced in order to leverage ground truth information between haustral fold
annotations and virtual colonoscopy renderings. We demonstrate the
effectiveness of our model on real challenging optical colonoscopy videos as
well as on textured virtual colonoscopy videos with clinician-verified haustral
fold annotations. All code and scripts to reproduce the experiments of this
paper will be made available via our Computational Endoscopy Platform at
https://github.com/nadeemlab/CEP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sub-millisecond Video Synchronization of Multiple Android Smartphones. (arXiv:2107.00987v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00987">
<div class="article-summary-box-inner">
<span><p>This paper addresses the problem of building an affordable easy-to-setup
synchronized multi-view camera system, which is in demand for many Computer
Vision and Robotics applications in high-dynamic environments. In our work, we
propose a solution for this problem -- a publicly-available Android application
for synchronized video recording on multiple smartphones with sub-millisecond
accuracy. We present a generalized mathematical model of timestamping for
Android smartphones and prove its applicability on 47 different physical
devices. Also, we estimate the time drift parameter for those smartphones,
which is less than 1.2 msec per minute for most of the considered devices, that
makes smartphones' camera system a worthy analog for professional multi-view
systems. Finally, we demonstrate Android-app performance on the camera system
built from Android smartphones quantitatively on setup with lights and
qualitatively -- on panorama stitching task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FFR_FD: Effective and Fast Detection of DeepFakes Based on Feature Point Defects. (arXiv:2107.02016v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02016">
<div class="article-summary-box-inner">
<span><p>The internet is filled with fake face images and videos synthesized by deep
generative models. These realistic DeepFakes pose a challenge to determine the
authenticity of multimedia content. As countermeasures, artifact-based
detection methods suffer from insufficiently fine-grained features that lead to
limited detection performance. DNN-based detection methods are not efficient
enough, given that a DeepFake can be created easily by mobile apps and
DNN-based models require high computational resources. For the first time, we
show that DeepFake faces have fewer feature points than real ones, especially
in certain facial regions. Inspired by feature point detector-descriptors to
extract discriminative features at the pixel level, we propose the Fused Facial
Region_Feature Descriptor (FFR_FD) for effective and fast DeepFake detection.
FFR_FD is only a vector extracted from the face, and it can be constructed from
any feature point detector-descriptors. We train a random forest classifier
with FFR_FD and conduct extensive experiments on six large-scale DeepFake
datasets, whose results demonstrate that our method is superior to most state
of the art DNN-based models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TDLS: A Top-Down Layer Searching Algorithm for Generating Counterfactual Visual Explanation. (arXiv:2108.04238v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04238">
<div class="article-summary-box-inner">
<span><p>Explanation of AI, as well as fairness of algorithms' decisions and the
transparency of the decision model, are becoming more and more important. And
it is crucial to design effective and human-friendly techniques when opening
the black-box model. Counterfactual conforms to the human way of thinking and
provides a human-friendly explanation, and its corresponding explanation
algorithm refers to a strategic alternation of a given data point so that its
model output is "counter-facted", i.e. the prediction is reverted. In this
paper, we adapt counterfactual explanation over fine-grained image
classification problem. We demonstrated an adaptive method that could give a
counterfactual explanation by showing the composed counterfactual feature map
using top-down layer searching algorithm (TDLS). We have proved that our TDLS
algorithm could provide more flexible counterfactual visual explanation in an
efficient way using VGG-16 model on Caltech-UCSD Birds 200 dataset. At the end,
we discussed several applicable scenarios of counterfactual visual
explanations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Online Multi-Granularity Distillation for GAN Compression. (arXiv:2108.06908v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06908">
<div class="article-summary-box-inner">
<span><p>Generative Adversarial Networks (GANs) have witnessed prevailing success in
yielding outstanding images, however, they are burdensome to deploy on
resource-constrained devices due to ponderous computational costs and hulking
memory usage. Although recent efforts on compressing GANs have acquired
remarkable results, they still exist potential model redundancies and can be
further compressed. To solve this issue, we propose a novel online
multi-granularity distillation (OMGD) scheme to obtain lightweight GANs, which
contributes to generating high-fidelity images with low computational demands.
We offer the first attempt to popularize single-stage online distillation for
GAN-oriented compression, where the progressively promoted teacher generator
helps to refine the discriminator-free based student generator. Complementary
teacher generators and network layers provide comprehensive and
multi-granularity concepts to enhance visual fidelity from diverse dimensions.
Experimental results on four benchmark datasets demonstrate that OMGD successes
to compress 40x MACs and 82.5X parameters on Pix2Pix and CycleGAN, without loss
of image quality. It reveals that OMGD provides a feasible solution for the
deployment of real-time image translation on resource-constrained devices. Our
code and models are made public at: https://github.com/bytedance/OMGD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Thermal Image Processing via Physics-Inspired Deep Networks. (arXiv:2108.07973v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07973">
<div class="article-summary-box-inner">
<span><p>We introduce DeepIR, a new thermal image processing framework that combines
physically accurate sensor modeling with deep network-based image
representation. Our key enabling observations are that the images captured by
thermal sensors can be factored into slowly changing, scene-independent sensor
non-uniformities (that can be accurately modeled using physics) and a
scene-specific radiance flux (that is well-represented using a deep
network-based regularizer). DeepIR requires neither training data nor periodic
ground-truth calibration with a known black body target--making it well suited
for practical computer vision tasks. We demonstrate the power of going DeepIR
by developing new denoising and super-resolution algorithms that exploit
multiple images of the scene captured with camera jitter. Simulated and real
data experiments demonstrate that DeepIR can perform high-quality
non-uniformity correction with as few as three images, achieving a 10dB PSNR
improvement over competing approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Urban Driving by Imitating a Reinforcement Learning Coach. (arXiv:2108.08265v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08265">
<div class="article-summary-box-inner">
<span><p>End-to-end approaches to autonomous driving commonly rely on expert
demonstrations. Although humans are good drivers, they are not good coaches for
end-to-end algorithms that demand dense on-policy supervision. On the contrary,
automated experts that leverage privileged information can efficiently generate
large scale on-policy and off-policy demonstrations. However, existing
automated experts for urban driving make heavy use of hand-crafted rules and
perform suboptimally even on driving simulators, where ground-truth information
is available. To address these issues, we train a reinforcement learning expert
that maps bird's-eye view images to continuous low-level actions. While setting
a new performance upper-bound on CARLA, our expert is also a better coach that
provides informative supervision signals for imitation learning agents to learn
from. Supervised by our reinforcement learning coach, a baseline end-to-end
agent with monocular camera-input achieves expert-level performance. Our
end-to-end agent achieves a 78% success rate while generalizing to a new town
and new weather on the NoCrash-dense benchmark and state-of-the-art performance
on the more challenging CARLA LeaderBoard.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Segmentation of Lungs COVID Infected Regions by Attention Mechanism and Synthetic Data. (arXiv:2108.08895v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08895">
<div class="article-summary-box-inner">
<span><p>Coronavirus has caused hundreds of thousands of deaths. Fatalities could
decrease if every patient could get suitable treatment by the healthcare
system. Machine learning, especially computer vision methods based on deep
learning, can help healthcare professionals diagnose and treat COVID-19
infected cases more efficiently. Hence, infected patients can get better
service from the healthcare system and decrease the number of deaths caused by
the coronavirus. This research proposes a method for segmenting infected lung
regions in a CT image. For this purpose, a convolutional neural network with an
attention mechanism is used to detect infected areas with complex patterns.
Attention blocks improve the segmentation accuracy by focusing on informative
parts of the image. Furthermore, a generative adversarial network generates
synthetic images for data augmentation and expansion of small available
datasets. Experimental results show the superiority of the proposed method
compared to some existing procedures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Quality LFW: A Database for Analyzing Cross-Resolution Image Face Recognition in Unconstrained Environments. (arXiv:2108.10290v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10290">
<div class="article-summary-box-inner">
<span><p>Real-world face recognition applications often deal with suboptimal image
quality or resolution due to different capturing conditions such as various
subject-to-camera distances, poor camera settings, or motion blur. This
characteristic has an unignorable effect on performance. Recent
cross-resolution face recognition approaches used simple, arbitrary, and
unrealistic down- and up-scaling techniques to measure robustness against
real-world edge-cases in image quality. Thus, we propose a new standardized
benchmark dataset and evaluation protocol derived from the famous Labeled Faces
in the Wild (LFW). In contrast to previous derivatives, which focus on pose,
age, similarity, and adversarial attacks, our Cross-Quality Labeled Faces in
the Wild (XQLFW) maximizes the quality difference. It contains only more
realistic synthetically degraded images when necessary. Our proposed dataset is
then used to further investigate the influence of image quality on several
state-of-the-art approaches. With XQLFW, we show that these models perform
differently in cross-quality cases, and hence, the generalizing capability is
not accurately predicted by their performance on LFW. Additionally, we report
baseline accuracy with recent deep learning models explicitly trained for
cross-resolution applications and evaluate the susceptibility to image quality.
To encourage further research in cross-resolution face recognition and incite
the assessment of image quality robustness, we publish the database and code
for evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">All You Need is Color: Image based Spatial Gene Expression Prediction using Neural Stain Learning. (arXiv:2108.10446v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10446">
<div class="article-summary-box-inner">
<span><p>"Is it possible to predict expression levels of different genes at a given
spatial location in the routine histology image of a tumor section by modeling
its stain absorption characteristics?" In this work, we propose a "stain-aware"
machine learning approach for prediction of spatial transcriptomic gene
expression profiles using digital pathology image of a routine Hematoxylin &amp;
Eosin (H&amp;E) histology section. Unlike recent deep learning methods which are
used for gene expression prediction, our proposed approach termed Neural Stain
Learning (NSL) explicitly models the association of stain absorption
characteristics of the tissue with gene expression patterns in spatial
transcriptomics by learning a problem-specific stain deconvolution matrix in an
end-to-end manner. The proposed method with only 11 trainable weight parameters
outperforms both classical regression models with cellular composition and
morphological features as well as deep learning methods. We have found that the
gene expression predictions from the proposed approach show higher correlations
with true expression values obtained through sequencing for a larger set of
genes in comparison to other approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Object Detection by Label Assignment Distillation. (arXiv:2108.10520v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10520">
<div class="article-summary-box-inner">
<span><p>Label assignment in object detection aims to assign targets, foreground or
background, to sampled regions in an image. Unlike labeling for image
classification, this problem is not well defined due to the object's bounding
box. In this paper, we investigate the problem from a perspective of
distillation, hence we call Label Assignment Distillation (LAD). Our initial
motivation is very simple, we use a teacher network to generate labels for the
student. This can be achieved in two ways: either using the teacher's
prediction as the direct targets (soft label), or through the hard labels
dynamically assigned by the teacher (LAD). Our experiments reveal that: (i) LAD
is more effective than soft-label, but they are complementary. (ii) Using LAD,
a smaller teacher can also improve a larger student significantly, while
soft-label can't. We then introduce Co-learning LAD, in which two networks
simultaneously learn from scratch and the role of teacher and student are
dynamically interchanged. Using PAA-ResNet50 as a teacher, our LAD techniques
can improve detectors PAA-ResNet101 and PAA-ResNeXt101 to $46 \rm AP$ and
$47.5\rm AP$ on the COCO test-dev set. With a strong teacher PAA-SwinB, we
improve the PAA-ResNet50 to $43.9\rm AP$ with only \1x schedule training, and
PAA-ResNet101 to $47.9\rm AP$, significantly surpassing the current methods.
Our source code and checkpoints will be released at
https://github.com/cybercore-co-ltd/CoLAD_paper.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Unified Taxonomy and Multimodal Dataset for Events in Invasion Games. (arXiv:2108.11149v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11149">
<div class="article-summary-box-inner">
<span><p>The automatic detection of events in complex sports games like soccer and
handball using positional or video data is of large interest in research and
industry. One requirement is a fundamental understanding of underlying
concepts, i.e., events that occur on the pitch. Previous work often deals only
with so-called low-level events based on well-defined rules such as free kicks,
free throws, or goals. High-level events, such as passes, are less frequently
approached due to a lack of consistent definitions. This introduces a level of
ambiguity that necessities careful validation when regarding event annotations.
Yet, this validation step is usually neglected as the majority of studies adopt
annotations from commercial providers on private datasets of unknown quality
and focuses on soccer only. To address these issues, we present (1) a universal
taxonomy that covers a wide range of low and high-level events for invasion
games and is exemplarily refined to soccer and handball, and (2) release two
multi-modal datasets comprising video and positional data with gold-standard
annotations to foster research in fine-grained and ball-centered event
spotting. Experiments on human performance demonstrate the robustness of the
proposed taxonomy, and that disagreements and ambiguities in the annotation
increase with the complexity of the event. An I3D model for video
classification is adopted for event spotting and reveals the potential for
benchmarking. Datasets are available at: https://github.com/mm4spa/eigd
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">YOLOP: You Only Look Once for Panoptic Driving Perception. (arXiv:2108.11250v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11250">
<div class="article-summary-box-inner">
<span><p>A panoptic driving perception system is an essential part of autonomous
driving. A high-precision and real-time perception system can assist the
vehicle in making the reasonable decision while driving. We present a panoptic
driving perception network (YOLOP) to perform traffic object detection,
drivable area segmentation and lane detection simultaneously. It is composed of
one encoder for feature extraction and three decoders to handle the specific
tasks. Our model performs extremely well on the challenging BDD100K dataset,
achieving state-of-the-art on all three tasks in terms of accuracy and speed.
Besides, we verify the effectiveness of our multi-task learning model for joint
training via ablative studies. To our best knowledge, this is the first work
that can process these three visual perception tasks simultaneously in
real-time on an embedded device Jetson TX2(23 FPS) and maintain excellent
accuracy. To facilitate further research, the source codes and pre-trained
models will be released at https://github.com/hustvl/YOLOP.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-08-29 23:02:10.001430940 UTC">2021-08-29 23:02:10 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.1</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>