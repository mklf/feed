<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-06-27T01:30:00Z">06-27</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Trajectories Encode Verb Meaning?. (arXiv:2206.11953v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11953">
<div class="article-summary-box-inner">
<span><p>Distributional models learn representations of words from text, but are
criticized for their lack of grounding, or the linking of text to the
non-linguistic world. Grounded language models have had success in learning to
connect concrete categories like nouns and adjectives to the world via images
and videos, but can struggle to isolate the meaning of the verbs themselves
from the context in which they typically occur. In this paper, we investigate
the extent to which trajectories (i.e. the position and rotation of objects
over time) naturally encode verb semantics. We build a procedurally generated
agent-object-interaction dataset, obtain human annotations for the verbs that
occur in this data, and compare several methods for representation learning
given the trajectories. We find that trajectories correlate as-is with some
verbs (e.g., fall), and that additional abstraction via self-supervised
pretraining can further capture nuanced differences in verb meaning (e.g., roll
vs. slide).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Disability Lens towards Biases in GPT-3 Generated Open-Ended Languages. (arXiv:2206.11993v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11993">
<div class="article-summary-box-inner">
<span><p>Language models (LM) are becoming prevalent in many language-based
application spaces globally. Although these LMs are improving our day-to-day
interactions with digital products, concerns remain whether open-ended
languages or text generated from these models reveal any biases toward a
specific group of people, thereby risking the usability of a certain product.
There is a need to identify whether these models possess bias to improve the
fairness in these models. This gap motivates our ongoing work, where we
measured the two aspects of bias in GPT-3 generated text through a disability
lens.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A multi-model-based deep learning framework for short text multiclass classification with the imbalanced and extremely small data set. (arXiv:2206.12027v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12027">
<div class="article-summary-box-inner">
<span><p>Text classification plays an important role in many practical applications.
In the real world, there are extremely small datasets. Most existing methods
adopt pre-trained neural network models to handle this kind of dataset.
However, these methods are either difficult to deploy on mobile devices because
of their large output size or cannot fully extract the deep semantic
information between phrases and clauses. This paper proposes a multimodel-based
deep learning framework for short-text multiclass classification with an
imbalanced and extremely small data set. Our framework mainly includes five
layers: The encoder layer uses DISTILBERT to obtain context-sensitive dynamic
word vectors that are difficult to represent in traditional feature engineering
methods. Since the transformer part of this layer is distilled, our framework
is compressed. Then, we use the next two layers to extract deep semantic
information. The output of the encoder layer is sent to a bidirectional LSTM
network, and the feature matrix is extracted hierarchically through the LSTM at
the word and sentence level to obtain the fine-grained semantic representation.
After that, the max-pooling layer converts the feature matrix into a
lower-dimensional matrix, preserving only the obvious features. Finally, the
feature matrix is taken as the input of a fully connected softmax layer, which
contains a function that can convert the predicted linear vector into the
output value as the probability of the text in each classification. Extensive
experiments on two public benchmarks demonstrate the effectiveness of our
proposed approach on an extremely small data set. It retains the
state-of-the-art baseline performance in terms of precision, recall, accuracy,
and F1 score, and through the model size, training time, and convergence epoch,
we can conclude that our method can be deployed faster and lighter on mobile
devices.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DialogID: A Dialogic Instruction Dataset for Improving Teaching Effectiveness in Online Environments. (arXiv:2206.12034v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12034">
<div class="article-summary-box-inner">
<span><p>Online dialogic instructions are a set of pedagogical instructions used in
real-world online educational contexts to motivate students, help understand
learning materials, and build effective study habits. In spite of the
popularity and advantages of online learning, the education technology and
educational data mining communities still suffer from the lack of large-scale,
high-quality, and well-annotated teaching instruction datasets to study
computational approaches to automatically detect online dialogic instructions
and further improve the online teaching effectiveness. Therefore, in this
paper, we present a dataset of online dialogic instruction detection,
\textsc{DialogID}, which contains 30,431 effective dialogic instructions. These
teaching instructions are well annotated into 8 categories. Furthermore, we
utilize the prevalent pre-trained language models (PLMs) and propose a simple
yet effective adversarial training learning paradigm to improve the quality and
generalization of dialogic instruction detection. Extensive experiments
demonstrate that our approach outperforms a wide range of baseline methods. The
data and our code are available for research purposes from:
\url{https://github.com/ai4ed/DialogID}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SC-Ques: A Sentence Completion Question Dataset for English as a Second Language Learners. (arXiv:2206.12036v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12036">
<div class="article-summary-box-inner">
<span><p>Sentence completion (SC) questions present a sentence with one or more blanks
that need to be filled in, three to five possible words or phrases as options.
SC questions are widely used for students learning English as a Second Language
(ESL). In this paper, we present a large-scale SC dataset, \textsc{SC-Ques},
which is made up of 292,517 ESL SC questions from real-world standardized
English examinations. Furthermore, we build a comprehensive benchmark of
automatically solving the SC questions by training the large-scale pre-trained
language models on the proposed \textsc{SC-Ques} dataset. We conduct detailed
analysis of the baseline models performance, limitations and trade-offs. The
data and our code are available for research purposes from:
\url{https://github.com/ai4ed/SC-Ques}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Text-to-Speech Based on Latent Representation of Speaking Styles Using Spontaneous Dialogue. (arXiv:2206.12040v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12040">
<div class="article-summary-box-inner">
<span><p>The recent text-to-speech (TTS) has achieved quality comparable to that of
humans; however, its application in spoken dialogue has not been widely
studied. This study aims to realize a TTS that closely resembles human
dialogue. First, we record and transcribe actual spontaneous dialogues. Then,
the proposed dialogue TTS is trained in two stages: first stage, variational
autoencoder (VAE)-VITS or Gaussian mixture variational autoencoder (GMVAE)-VITS
is trained, which introduces an utterance-level latent variable into
variational inference with adversarial learning for end-to-end text-to-speech
(VITS), a recently proposed end-to-end TTS model. A style encoder that extracts
a latent speaking style representation from speech is trained jointly with TTS.
In the second stage, a style predictor is trained to predict the speaking style
to be synthesized from dialogue history. During inference, by passing the
speaking style representation predicted by the style predictor to
VAE/GMVAE-VITS, speech can be synthesized in a style appropriate to the context
of the dialogue. Subjective evaluation results demonstrate that the proposed
method outperforms the original VITS in terms of dialogue-level naturalness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classifying Unstructured Clinical Notes via Automatic Weak Supervision. (arXiv:2206.12088v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12088">
<div class="article-summary-box-inner">
<span><p>Healthcare providers usually record detailed notes of the clinical care
delivered to each patient for clinical, research, and billing purposes. Due to
the unstructured nature of these narratives, providers employ dedicated staff
to assign diagnostic codes to patients' diagnoses using the International
Classification of Diseases (ICD) coding system. This manual process is not only
time-consuming but also costly and error-prone. Prior work demonstrated
potential utility of Machine Learning (ML) methodology in automating this
process, but it has relied on large quantities of manually labeled data to
train the models. Additionally, diagnostic coding systems evolve with time,
which makes traditional supervised learning strategies unable to generalize
beyond local applications. In this work, we introduce a general
weakly-supervised text classification framework that learns from class-label
descriptions only, without the need to use any human-labeled documents. It
leverages the linguistic domain knowledge stored within pre-trained language
models and the data programming framework to assign code labels to individual
texts. We demonstrate the efficacy and flexibility of our method by comparing
it to state-of-the-art weak text classifiers across four real-world text
classification datasets, in addition to assigning ICD codes to medical notes in
the publicly available MIMIC-III database.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified BERT for Few-shot Natural Language Understanding. (arXiv:2206.12094v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12094">
<div class="article-summary-box-inner">
<span><p>Even as pre-trained language models share a semantic encoder, natural
language understanding suffers from a diversity of output schemas. In this
paper, we propose UBERT, a unified bidirectional language understanding model
based on BERT framework, which can universally model the training objects of
different NLU tasks through a biaffine network. Specifically, UBERT encodes
prior knowledge from various aspects, uniformly constructing learning
representations across multiple NLU tasks, which is conducive to enhancing the
ability to capture common semantic understanding. Using the biaffine to model
scores pair of the start and end position of the original text, various
classification and extraction structures can be converted into a universal,
span-decoding approach. Experiments show that UBERT achieves the
state-of-the-art performance on 7 NLU tasks, 14 datasets on few-shot and
zero-shot setting, and realizes the unification of extensive information
extraction and linguistic reasoning tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do You Know My Emotion? Emotion-Aware Strategy Recognition towards a Persuasive Dialogue System. (arXiv:2206.12101v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12101">
<div class="article-summary-box-inner">
<span><p>Persuasive strategy recognition task requires the system to recognize the
adopted strategy of the persuader according to the conversation. However,
previous methods mainly focus on the contextual information, little is known
about incorporating the psychological feedback, i.e. emotion of the persuadee,
to predict the strategy. In this paper, we propose a Cross-channel Feedback
memOry Network (CFO-Net) to leverage the emotional feedback to iteratively
measure the potential benefits of strategies and incorporate them into the
contextual-aware dialogue information. Specifically, CFO-Net designs a feedback
memory module, including strategy pool and feedback pool, to obtain
emotion-aware strategy representation. The strategy pool aims to store
historical strategies and the feedback pool is to obtain updated strategy
weight based on feedback emotional information. Furthermore, a cross-channel
fusion predictor is developed to make a mutual interaction between the
emotion-aware strategy representation and the contextual-aware dialogue
information for strategy recognition. Experimental results on
\textsc{PersuasionForGood} confirm that the proposed model CFO-Net is effective
to improve the performance on M-F1 from 61.74 to 65.41.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MVP: Multi-task Supervised Pre-training for Natural Language Generation. (arXiv:2206.12131v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12131">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PLMs) have achieved notable success in natural
language generation (NLG) tasks. Up to now, most of the PLMs are pre-trained in
an unsupervised manner using large-scale general corpus. In the meanwhile, an
increasing number of models pre-trained with less labeled data showcase
superior performance compared to unsupervised models. Motivated by the success
of supervised pre-training, we propose Multi-task superVised Pre-training (MVP)
for natural language generation. For pre-training the text generation model
MVP, we collect a labeled pre-training corpus from 45 datasets over seven
generation tasks. For each task, we further pre-train specific soft prompts to
stimulate the model capacity in performing a specific task. Extensive
experiments have demonstrated the effectiveness of our supervised pre-training
in a number of NLG tasks, and our general methods achieve state-of-the-art
performance on 12 of 17 datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Capture Salient Historical Information: A Fast and Accurate Non-Autoregressive Model for Multi-turn Spoken Language Understanding. (arXiv:2206.12209v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12209">
<div class="article-summary-box-inner">
<span><p>Spoken Language Understanding (SLU), a core component of the task-oriented
dialogue system, expects a shorter inference facing the impatience of human
users. Existing work increases inference speed by designing non-autoregressive
models for single-turn SLU tasks but fails to apply to multi-turn SLU in
confronting the dialogue history. The intuitive idea is to concatenate all
historical utterances and utilize the non-autoregressive models directly.
However, this approach seriously misses the salient historical information and
suffers from the uncoordinated-slot problems. To overcome those shortcomings,
we propose a novel model for multi-turn SLU named Salient History Attention
with Layer-Refined Transformer (SHA-LRT), which composes of an SHA module, a
Layer-Refined Mechanism (LRM), and a Slot Label Generation (SLG) task. SHA
captures salient historical information for the current dialogue from both
historical utterances and results via a well-designed history-attention
mechanism. LRM predicts preliminary SLU results from Transformer's middle
states and utilizes them to guide the final prediction, and SLG obtains the
sequential dependency information for the non-autoregressive encoder.
Experiments on public datasets indicate that our model significantly improves
multi-turn SLU performance (17.5% on Overall) with accelerating (nearly 15
times) the inference process over the state-of-the-art baseline as well as
effective on the single-turn SLU tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prosody Cloning in Zero-Shot Multispeaker Text-to-Speech. (arXiv:2206.12229v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12229">
<div class="article-summary-box-inner">
<span><p>The cloning of a speaker's voice using an untranscribed reference sample is
one of the great advances of modern neural text-to-speech (TTS) methods.
Approaches for mimicking the prosody of a transcribed reference audio have also
been proposed recently. In this work, we bring these two tasks together for the
first time through utterance level normalization in conjunction with an
utterance level speaker embedding. We further introduce a lightweight aligner
for extracting fine-grained prosodic features, that can be finetuned on
individual samples within seconds. We show that it is possible to clone the
voice of a speaker as well as the prosody of a spoken reference independently
without any degradation in quality and high similarity to both original voice
and prosody, as our objective evaluation and human study show. All of our code
and trained models are available, alongside static and interactive demos.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Label Noise-Resistant Mean Teaching for Weakly Supervised Fake News Detection. (arXiv:2206.12260v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12260">
<div class="article-summary-box-inner">
<span><p>Fake news spreads at an unprecedented speed, reaches global audiences and
poses huge risks to users and communities. Most existing fake news detection
algorithms focus on building supervised training models on a large amount of
manually labeled data, which is expensive to acquire or often unavailable. In
this work, we propose a novel label noise-resistant mean teaching approach
(LNMT) for weakly supervised fake news detection. LNMT leverages unlabeled news
and feedback comments of users to enlarge the amount of training data and
facilitates model training by generating refined labels as weak supervision.
Specifically, LNMT automatically assigns initial weak labels to unlabeled
samples based on semantic correlation and emotional association between news
content and the comments. Moreover, in order to suppress the noises in weak
labels, LNMT establishes a mean teacher framework equipped with label
propagation and label reliability estimation. The framework measures a weak
label similarity matrix between the teacher and student networks, and
propagates different valuable weak label information to refine the weak labels.
Meanwhile, it exploits the consistency between the output class likelihood
vectors of the two networks to evaluate the reliability of the weak labels and
incorporates the reliability into model optimization to alleviate the negative
effect of noisy weak labels. Extensive experiments show the superior
performance of LNMT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Sentence Simplification via Dependency Parsing. (arXiv:2206.12261v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12261">
<div class="article-summary-box-inner">
<span><p>Text simplification is the task of rewriting a text so that it is readable
and easily understood. In this paper, we propose a simple yet novel
unsupervised sentence simplification system that harnesses parsing structures
together with sentence embeddings to produce linguistically effective
simplifications. This means our model is capable of introducing substantial
modifications to simplify a sentence while maintaining its original semantics
and adequate fluency. We establish the unsupervised state-of-the-art at 39.13
SARI on TurkCorpus set and perform competitively against supervised baselines
on various quality metrics. Furthermore, we demonstrate our framework's
extensibility to other languages via a proof-of-concept on Vietnamese data.
Code for reproduction is published at \url{https://github.com/isVy08/USDP}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emoji-based Fine-grained Attention Network for Sentiment Analysis in the Microblog Comments. (arXiv:2206.12262v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12262">
<div class="article-summary-box-inner">
<span><p>Microblogs have become a social platform for people to express their emotions
in real-time, and it is a trend to analyze user emotional tendencies from the
information on Microblogs. The dynamic features of emojis can affect the
sentiment polarity of microblog texts. Since existing models seldom consider
the diversity of emoji sentiment polarity,the paper propose a microblog
sentiment classification model based on ALBERT-FAET. We obtain text embedding
via ALBERT pretraining model and learn the inter-emoji embedding with an
attention-based LSTM network. In addition, a fine-grained attention mechanism
is proposed to capture the word-level interactions between plain text and
emoji. Finally, we concatenate these features and feed them into a CNN
classifier to predict the sentiment labels of the microblogs. To verify the
effectiveness of the model and the fine-grained attention network, we conduct
comparison experiments and ablation experiments. The comparison experiments
show that the model outperforms previous methods in three evaluation indicators
(accuracy, precision, and recall) and the model can significantly improve
sentiment classification. The ablation experiments show that compared with
ALBERT-AET, the proposed model ALBERT-FAET is better in the metrics, indicating
that the fine-grained attention network can understand the diversified
information of emoticons.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robustness of Explanation Methods for NLP Models. (arXiv:2206.12284v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12284">
<div class="article-summary-box-inner">
<span><p>Explanation methods have emerged as an important tool to highlight the
features responsible for the predictions of neural networks. There is mounting
evidence that many explanation methods are rather unreliable and susceptible to
malicious manipulations. In this paper, we particularly aim to understand the
robustness of explanation methods in the context of text modality. We provide
initial insights and results towards devising a successful adversarial attack
against text explanations. To our knowledge, this is the first attempt to
evaluate the adversarial robustness of an explanation method. Our experiments
show the explanation method can be largely disturbed for up to 86% of the
tested samples with small changes in the input sentence and its semantics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text and author-level political inference using heterogeneous knowledge representations. (arXiv:2206.12293v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12293">
<div class="article-summary-box-inner">
<span><p>The inference of politically-charged information from text data is a popular
research topic in Natural Language Processing (NLP) at both text- and
author-level. In recent years, studies of this kind have been implemented with
the aid of representations from transformers such as BERT. Despite considerable
success, however, we may ask whether results may be improved even further by
combining transformed-based models with additional knowledge representations.
To shed light on this issue, the present work describes a series of experiments
to compare alternative model configurations for political inference from text
in both English and Portuguese languages. Results suggest that certain text
representations - in particular, the combined use of BERT pre-trained language
models with a syntactic dependency model - may outperform the alternatives
across multiple experimental settings, making a potentially strong case for
further research in the use of heterogeneous text representations in these and
possibly other NLP tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Rhetorical Structure Theory-based descriptions of observed behaviour. (arXiv:2206.12294v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12294">
<div class="article-summary-box-inner">
<span><p>In a previous paper, we have proposed a set of concepts, axiom schemata and
algorithms that can be used by agents to learn to describe their behaviour,
goals, capabilities, and environment. The current paper proposes a new set of
concepts, axiom schemata and algorithms that allow the agent to learn new
descriptions of an observed behaviour (e.g., perplexing actions), of its actor
(e.g., undesired propositions or actions), and of its environment (e.g.,
incompatible propositions). Each learned description (e.g., a certain action
prevents another action from being performed in the future) is represented by a
relationship between entities (either propositions or actions) and is learned
by the agent, just by observation, using domain-independent axiom schemata and
or learning algorithms. The relations used by agents to represent the
descriptions they learn were inspired on the Theory of Rhetorical Structure
(RST). The main contribution of the paper is the relation family Although,
inspired on the RST relation Concession. The accurate definition of the
relations of the family Although involves a set of deontic concepts whose
definition and corresponding algorithms are presented. The relations of the
family Although, once extracted from the agent's observations, express surprise
at the observed behaviour and, in certain circumstances, present a
justification for it.
</p>
<p>The paper shows results of the presented proposals in a demonstration
scenario, using implemented software.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using BERT Embeddings to Model Word Importance in Conversational Transcripts for Deaf and Hard of Hearing Users. (arXiv:2206.12368v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12368">
<div class="article-summary-box-inner">
<span><p>Deaf and hard of hearing individuals regularly rely on captioning while
watching live TV. Live TV captioning is evaluated by regulatory agencies using
various caption evaluation metrics. However, caption evaluation metrics are
often not informed by preferences of DHH users or how meaningful the captions
are. There is a need to construct caption evaluation metrics that take the
relative importance of words in a transcript into account. We conducted
correlation analysis between two types of word embeddings and human-annotated
labeled word-importance scores in existing corpus. We found that normalized
contextualized word embeddings generated using BERT correlated better with
manually annotated importance scores than word2vec-based word embeddings. We
make available a pairing of word embeddings and their human-annotated
importance scores. We also provide proof-of-concept utility by training word
importance models, achieving an F1-score of 0.57 in the 6-class word importance
classification task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QAGAN: Adversarial Approach To Learning Domain Invariant Language Features. (arXiv:2206.12388v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12388">
<div class="article-summary-box-inner">
<span><p>Training models that are robust to data domain shift has gained an increasing
interest both in academia and industry. Question-Answering language models,
being one of the typical problem in Natural Language Processing (NLP) research,
has received much success with the advent of large transformer models. However,
existing approaches mostly work under the assumption that data is drawn from
same distribution during training and testing which is unrealistic and
non-scalable in the wild.
</p>
<p>In this paper, we explore adversarial training approach towards learning
domain-invariant features so that language models can generalize well to
out-of-domain datasets. We also inspect various other ways to boost our model
performance including data augmentation by paraphrasing sentences, conditioning
end of answer span prediction on the start word, and carefully designed
annealing function. Our initial results show that in combination with these
methods, we are able to achieve $15.2\%$ improvement in EM score and $5.6\%$
boost in F1 score on out-of-domain validation dataset over the baseline. We
also dissect our model outputs and visualize the model hidden-states by
projecting them onto a lower-dimensional space, and discover that our specific
adversarial training approach indeed encourages the model to learn domain
invariant embedding and bring them closer in the multi-dimensional space.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Exploratory Study on Utilising the Web of Linked Data for Product Data Mining. (arXiv:2109.01411v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01411">
<div class="article-summary-box-inner">
<span><p>The Linked Open Data practice has led to a significant growth of structured
data on the Web in the last decade. Such structured data describe real-world
entities in a machine-readable way, and have created an unprecedented
opportunity for research in the field of Natural Language Processing. However,
there is a lack of studies on how such data can be used, for what kind of
tasks, and to what extent they can be useful for these tasks. This work focuses
on the e-commerce domain to explore methods of utilising such structured data
to create language resources that may be used for product classification and
linking. We process billions of structured data points in the form of RDF
n-quads, to create multi-million words of product-related corpora that are
later used in three different ways for creating of language resources: training
word embedding models, continued pre-training of BERT-like language models, and
training Machine Translation models that are used as a proxy to generate
product-related keywords. Our evaluation on an extensive set of benchmarks
shows word embeddings to be the most reliable and consistent method to improve
the accuracy on both tasks (with up to 6.9 percentage points in macro-average
F1 on some datasets). The other two methods however, are not as useful. Our
analysis shows that this could be due to a number of reasons, including the
biased domain representation in the structured data and lack of vocabulary
coverage. We share our datasets and discuss how our lessons learned could be
taken forward to inform future research in this direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Lexicon Reader: Reduce Pronunciation Errors in End-to-end TTS by Leveraging External Textual Knowledge. (arXiv:2110.09698v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.09698">
<div class="article-summary-box-inner">
<span><p>End-to-end TTS requires a large amount of speech/text paired data to cover
all necessary knowledge, particularly how to pronounce different words in
diverse contexts, so that a neural model may learn such knowledge accordingly.
But in real applications, such high demand of training data is hard to be
satisfied and additional knowledge often needs to be injected manually. For
example, to capture pronunciation knowledge on languages without regular
orthography, a complicated grapheme-to-phoneme pipeline needs to be built based
on a large structured pronunciation lexicon, leading to extra, sometimes high,
costs to extend neural TTS to such languages. In this paper, we propose a
framework to learn to automatically extract knowledge from unstructured
external resources using a novel Token2Knowledge attention module. The
framework is applied to build a TTS model named Neural Lexicon Reader that
extracts pronunciations from raw lexicon texts in an end-to-end manner.
Experiments show the proposed model significantly reduces pronunciation errors
in low-resource, end-to-end Chinese TTS, and the lexicon-reading capability can
be transferred to other languages with a smaller amount of data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Simplified Variant of G\"odel's Ontological Argument. (arXiv:2202.06264v2 [cs.LO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.06264">
<div class="article-summary-box-inner">
<span><p>A simplified variant of G\"odel's ontological argument is presented. The
simplified argument is valid already in basic modal logics K or KT, it does not
suffer from modal collapse, and it avoids the rather complex predicates of
essence (Ess.) and necessary existence (NE) as used by G\"odel. The variant
presented has been obtained as a side result of a series of theory
simplification experiments conducted in interaction with a modern proof
assistant system. The starting point for these experiments was the computer
encoding of G\"odel's argument, and then automated reasoning techniques were
systematically applied to arrive at the simplified variant presented. The
presented work thus exemplifies a fruitful human-computer interaction in
computational metaphysics. Whether the presented result increases or decreases
the attractiveness and persuasiveness of the ontological argument is a question
I would like to pass on to philosophy and theology.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BiFSMN: Binary Neural Network for Keyword Spotting. (arXiv:2202.06483v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.06483">
<div class="article-summary-box-inner">
<span><p>The deep neural networks, such as the Deep-FSMN, have been widely studied for
keyword spotting (KWS) applications. However, computational resources for these
networks are significantly constrained since they usually run on-call on edge
devices. In this paper, we present BiFSMN, an accurate and extreme-efficient
binary neural network for KWS. We first construct a High-frequency Enhancement
Distillation scheme for the binarization-aware training, which emphasizes the
high-frequency information from the full-precision network's representation
that is more crucial for the optimization of the binarized network. Then, to
allow the instant and adaptive accuracy-efficiency trade-offs at runtime, we
also propose a Thinnable Binarization Architecture to further liberate the
acceleration potential of the binarized network from the topology perspective.
Moreover, we implement a Fast Bitwise Computation Kernel for BiFSMN on ARMv8
devices which fully utilizes registers and increases instruction throughput to
push the limit of deployment efficiency. Extensive experiments show that BiFSMN
outperforms existing binarization methods by convincing margins on various
datasets and is even comparable with the full-precision counterpart (e.g., less
than 3% drop on Speech Commands V1-12). We highlight that benefiting from the
thinnable architecture and the optimized 1-bit implementation, BiFSMN can
achieve an impressive 22.3x speedup and 15.5x storage-saving on real-world edge
hardware.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Provably Confidential Language Modelling. (arXiv:2205.01863v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.01863">
<div class="article-summary-box-inner">
<span><p>Large language models are shown to memorize privacy information such as
social security numbers in training data. Given the sheer scale of the training
corpus, it is challenging to screen and filter these privacy data, either
manually or automatically. In this paper, we propose Confidentially Redacted
Training (CRT), a method to train language generation models while protecting
the confidential segments. We borrow ideas from differential privacy (which
solves a related but distinct problem) and show that our method is able to
provably prevent unintended memorization by randomizing parts of the training
process. Moreover, we show that redaction with an approximately correct
screening policy amplifies the confidentiality guarantee. We implement the
method for both LSTM and GPT language models. Our experimental results show
that the models trained by CRT obtain almost the same perplexity while
preserving strong confidentiality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Sentence Embedding Models Performance for Patent Analysis. (arXiv:2206.02690v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02690">
<div class="article-summary-box-inner">
<span><p>Patent data is an important source of knowledge for innovation research.
While the technological similarity between pairs of patents is a key enabling
indicator for patent analysis. Recently researchers have been using patent
vector space models based on different NLP embeddings models to calculate
technological similarity between pairs of patents to help better understand
innovations, patent landscaping, technology mapping, and patent quality
evaluation. To the best of our knowledge, there is not a comprehensive survey
that builds a big picture of embedding models' performance for calculating
patent similarity indicators. Therefore, in this study, we provide an overview
of the accuracy of these algorithms based on patent classification performance.
In a detailed discussion, we report the performance of the top 3 algorithms at
section, class, and subclass levels. The results based on the first claim of
patents show that PatentSBERTa, Bert-for-patents, and TF-IDF Weighted Word
Embeddings have the best accuracy for computing sentence embeddings at the
subclass level. According to the first results, the performance of the models
in different classes varies which shows researchers in patent analysis can
utilize the results of this study for choosing the best proper model based on
the specific section of patent data they used.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph-in-Graph Network for Automatic Gene Ontology Description Generation. (arXiv:2206.05311v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05311">
<div class="article-summary-box-inner">
<span><p>Gene Ontology (GO) is the primary gene function knowledge base that enables
computational tasks in biomedicine. The basic element of GO is a term, which
includes a set of genes with the same function. Existing research efforts of GO
mainly focus on predicting gene term associations. Other tasks, such as
generating descriptions of new terms, are rarely pursued. In this paper, we
propose a novel task: GO term description generation. This task aims to
automatically generate a sentence that describes the function of a GO term
belonging to one of the three categories, i.e., molecular function, biological
process, and cellular component. To address this task, we propose a
Graph-in-Graph network that can efficiently leverage the structural information
of GO. The proposed network introduces a two-layer graph: the first layer is a
graph of GO terms where each node is also a graph (gene graph). Such a
Graph-in-Graph network can derive the biological functions of GO terms and
generate proper descriptions. To validate the effectiveness of the proposed
network, we build three large-scale benchmark datasets. By incorporating the
proposed Graph-in-Graph network, the performances of seven different
sequence-to-sequence models can be substantially boosted across all evaluation
metrics, with up to 34.7%, 14.5%, and 39.1% relative improvements in BLEU,
ROUGE-L, and METEOR, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-LexSum: Real-World Summaries of Civil Rights Lawsuits at Multiple Granularities. (arXiv:2206.10883v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.10883">
<div class="article-summary-box-inner">
<span><p>With the advent of large language models, methods for abstractive
summarization have made great strides, creating potential for use in
applications to aid knowledge workers processing unwieldy document collections.
One such setting is the Civil Rights Litigation Clearinghouse (CRLC)
(https://clearinghouse.net),which posts information about large-scale civil
rights lawsuits, serving lawyers, scholars, and the general public. Today,
summarization in the CRLC requires extensive training of lawyers and law
students who spend hours per case understanding multiple relevant documents in
order to produce high-quality summaries of key events and outcomes. Motivated
by this ongoing real-world summarization effort, we introduce Multi-LexSum, a
collection of 9,280 expert-authored summaries drawn from ongoing CRLC writing.
Multi-LexSum presents a challenging multi-document summarization task given the
length of the source documents, often exceeding two hundred pages per case.
Furthermore, Multi-LexSum is distinct from other datasets in its multiple
target summaries, each at a different granularity (ranging from one-sentence
"extreme" summaries to multi-paragraph narrations of over five hundred words).
We present extensive analysis demonstrating that despite the high-quality
summaries in the training data (adhering to strict content and style
guidelines), state-of-the-art summarization models perform poorly on this task.
We release Multi-LexSum for further research in summarization methods as well
as to facilitate development of applications to assist in the CRLC's mission at
https://multilexsum.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GEMv2: Multilingual NLG Benchmarking in a Single Line of Code. (arXiv:2206.11249v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11249">
<div class="article-summary-box-inner">
<span><p>Evaluation in machine learning is usually informed by past choices, for
example which datasets or metrics to use. This standardization enables the
comparison on equal footing using leaderboards, but the evaluation choices
become sub-optimal as better alternatives arise. This problem is especially
pertinent in natural language generation which requires ever-improving suites
of datasets, metrics, and human evaluation to make definitive claims. To make
following best model evaluation practices easier, we introduce GEMv2. The new
version of the Generation, Evaluation, and Metrics Benchmark introduces a
modular infrastructure for dataset, model, and metric developers to benefit
from each others work. GEMv2 supports 40 documented datasets in 51 languages.
Models for all datasets can be evaluated online and our interactive data card
creation and rendering tools make it easier to add new datasets to the living
benchmark.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Agriculture-Vision Challenge 2022 -- The Runner-Up Solution for Agricultural Pattern Recognition via Transformer-based Models. (arXiv:2206.11920v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11920">
<div class="article-summary-box-inner">
<span><p>The Agriculture-Vision Challenge in CVPR is one of the most famous and
competitive challenges for global researchers to break the boundary between
computer vision and agriculture sectors, aiming at agricultural pattern
recognition from aerial images. In this paper, we propose our solution to the
third Agriculture-Vision Challenge in CVPR 2022. We leverage a data
pre-processing scheme and several Transformer-based models as well as data
augmentation techniques to achieve a mIoU of 0.582, accomplishing the 2nd place
in this challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Galaxy Foundation Models with Hybrid Contrastive Learning. (arXiv:2206.11927v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11927">
<div class="article-summary-box-inner">
<span><p>New astronomical tasks are often related to earlier tasks for which labels
have already been collected. We adapt the contrastive framework BYOL to
leverage those labels as a pretraining task while also enforcing augmentation
invariance. For large-scale pretraining, we introduce GZ-Evo v0.1, a set of
96.5M volunteer responses for 552k galaxy images plus a further 1.34M
comparable unlabelled galaxies. Most of the 206 GZ-Evo answers are unknown for
any given galaxy, and so our pretraining task uses a Dirichlet loss that
naturally handles unknown answers. GZ-Evo pretraining, with or without hybrid
learning, improves on direct training even with plentiful downstream labels
(+4% accuracy with 44k labels). Our hybrid pretraining/contrastive method
further improves downstream accuracy vs. pretraining or contrastive learning,
especially in the low-label transfer regime (+6% accuracy with 750 labels).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TIAger: Tumor-Infiltrating Lymphocyte Scoring in Breast Cancer for the TiGER Challenge. (arXiv:2206.11943v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11943">
<div class="article-summary-box-inner">
<span><p>The quantification of tumor-infiltrating lymphocytes (TILs) has been shown to
be an independent predictor for prognosis of breast cancer patients. Typically,
pathologists give an estimate of the proportion of the stromal region that
contains TILs to obtain a TILs score. The Tumor InfiltratinG lymphocytes in
breast cancER (TiGER) challenge, aims to assess the prognostic significance of
computer-generated TILs scores for predicting survival as part of a Cox
proportional hazards model. For this challenge, as the TIAger team, we have
developed an algorithm to first segment tumor vs. stroma, before localising the
tumor bulk region for TILs detection. Finally, we use these outputs to generate
a TILs score for each case. On preliminary testing, our approach achieved a
tumor-stroma weighted Dice score of 0.791 and a FROC score of 0.572 for
lymphocytic detection. For predicting survival, our model achieved a C-index of
0.719. These results achieved first place across the preliminary testing
leaderboards of the TiGER challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UNeRF: Time and Memory Conscious U-Shaped Network for Training Neural Radiance Fields. (arXiv:2206.11952v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11952">
<div class="article-summary-box-inner">
<span><p>Neural Radiance Fields (NeRFs) increase reconstruction detail for novel view
synthesis and scene reconstruction, with applications ranging from large static
scenes to dynamic human motion. However, the increased resolution and
model-free nature of such neural fields come at the cost of high training times
and excessive memory requirements. Recent advances improve the inference time
by using complementary data structures yet these methods are ill-suited for
dynamic scenes and often increase memory consumption. Little has been done to
reduce the resources required at training time. We propose a method to exploit
the redundancy of NeRF's sample-based computations by partially sharing
evaluations across neighboring sample points. Our UNeRF architecture is
inspired by the UNet, where spatial resolution is reduced in the middle of the
network and information is shared between adjacent samples. Although this
change violates the strict and conscious separation of view-dependent
appearance and view-independent density estimation in the NeRF method, we show
that it improves novel view synthesis. We also introduce an alternative
subsampling strategy which shares computation while minimizing any violation of
view invariance. UNeRF is a plug-in module for the original NeRF network. Our
major contributions include reduction of the memory footprint, improved
accuracy, and reduced amortized processing time both during training and
inference. With only weak assumptions on locality, we achieve improved resource
utilization on a variety of neural radiance fields tasks. We demonstrate
applications to the novel view synthesis of static scenes as well as dynamic
human shape and motion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Second Place Solution for The 4th Large-scale Video Object Segmentation Challenge--Track 3: Referring Video Object Segmentation. (arXiv:2206.12035v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12035">
<div class="article-summary-box-inner">
<span><p>The referring video object segmentation task (RVOS) aims to segment object
instances in a given video referred by a language expression in all video
frames. Due to the requirement of understanding cross-modal semantics within
individual instances, this task is more challenging than the traditional
semi-supervised video object segmentation where the ground truth object masks
in the first frame are given. With the great achievement of Transformer in
object detection and object segmentation, RVOS has been made remarkable
progress where ReferFormer achieved the state-of-the-art performance. In this
work, based on the strong baseline framework--ReferFormer, we propose several
tricks to boost further, including cyclical learning rates, semi-supervised
approach, and test-time augmentation inference. The improved ReferFormer ranks
2nd place on CVPR2022 Referring Youtube-VOS Challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Protecting President Zelenskyy against Deep Fakes. (arXiv:2206.12043v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12043">
<div class="article-summary-box-inner">
<span><p>The 2022 Russian invasion of Ukraine is being fought on two fronts: a brutal
ground war and a duplicitous disinformation campaign designed to conceal and
justify Russia's actions. This campaign includes at least one example of a
deep-fake video purportedly showing Ukrainian President Zelenskyy admitting
defeat and surrendering. In anticipation of future attacks of this form, we
describe a facial and gestural behavioral model that captures distinctive
characteristics of Zelenskyy's speaking style. Trained on over eight hours of
authentic video from four different settings, we show that this behavioral
model can distinguish Zelenskyy from deep-fake imposters.This model can play an
important role -- particularly during the fog of war -- in distinguishing the
real from the fake.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bilateral Network with Channel Splitting Network and Transformer for Thermal Image Super-Resolution. (arXiv:2206.12046v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12046">
<div class="article-summary-box-inner">
<span><p>In recent years, the Thermal Image Super-Resolution (TISR) problem has become
an attractive research topic. TISR would been used in a wide range of fields,
including military, medical, agricultural and animal ecology. Due to the
success of PBVS-2020 and PBVS-2021 workshop challenge, the result of TISR keeps
improving and attracts more researchers to sign up for PBVS-2022 challenge. In
this paper, we will introduce the technical details of our submission to
PBVS-2022 challenge designing a Bilateral Network with Channel Splitting
Network and Transformer(BN-CSNT) to tackle the TISR problem. Firstly, we
designed a context branch based on channel splitting network with transformer
to obtain sufficient context information. Secondly, we designed a spatial
branch with shallow transformer to extract low level features which can
preserve the spatial information. Finally, for the context branch in order to
fuse the features from channel splitting network and transformer, we proposed
an attention refinement module, and then features from context branch and
spatial branch are fused by proposed feature fusion module. The proposed method
can achieve PSNR=33.64, SSIM=0.9263 for x4 and PSNR=21.08, SSIM=0.7803 for x2
in the PBVS-2022 challenge test dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SDF-StyleGAN: Implicit SDF-Based StyleGAN for 3D Shape Generation. (arXiv:2206.12055v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12055">
<div class="article-summary-box-inner">
<span><p>We present a StyleGAN2-based deep learning approach for 3D shape generation,
called SDF-StyleGAN, with the aim of reducing visual and geometric
dissimilarity between generated shapes and a shape collection. We extend
StyleGAN2 to 3D generation and utilize the implicit signed distance function
(SDF) as the 3D shape representation, and introduce two novel global and local
shape discriminators that distinguish real and fake SDF values and gradients to
significantly improve shape geometry and visual quality. We further complement
the evaluation metrics of 3D generative models with the shading-image-based
Fr\'echet inception distance (FID) scores to better assess visual quality and
shape distribution of the generated shapes. Experiments on shape generation
demonstrate the superior performance of SDF-StyleGAN over the state-of-the-art.
We further demonstrate the efficacy of SDF-StyleGAN in various tasks based on
GAN inversion, including shape reconstruction, shape completion from partial
point clouds, single-view image-based shape generation, and shape style
editing. Extensive ablation studies justify the efficacy of our framework
design. Our code and trained models are available at
https://github.com/Zhengxinyang/SDF-StyleGAN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mutual Information-guided Knowledge Transfer for Novel Class Discovery. (arXiv:2206.12063v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12063">
<div class="article-summary-box-inner">
<span><p>We tackle the novel class discovery problem, aiming to discover novel classes
in unlabeled data based on labeled data from seen classes. The main challenge
is to transfer knowledge contained in the seen classes to unseen ones. Previous
methods mostly transfer knowledge through sharing representation space or joint
label space. However, they tend to neglect the class relation between seen and
unseen categories, and thus the learned representations are less effective for
clustering unseen classes. In this paper, we propose a principle and general
method to transfer semantic knowledge between seen and unseen classes. Our
insight is to utilize mutual information to measure the relation between seen
classes and unseen classes in a restricted label space and maximizing mutual
information promotes transferring semantic knowledge. To validate the
effectiveness and generalization of our method, we conduct extensive
experiments both on novel class discovery and general novel class discovery
settings. Our results show that the proposed method outperforms previous SOTA
by a significant margin on several benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Learning of Features between Images and LiDAR. (arXiv:2206.12071v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12071">
<div class="article-summary-box-inner">
<span><p>Image and Point Clouds provide different information for robots. Finding the
correspondences between data from different sensors is crucial for various
tasks such as localization, mapping, and navigation. Learning-based descriptors
have been developed for single sensors; there is little work on cross-modal
features. This work treats learning cross-modal features as a dense contrastive
learning problem. We propose a Tuple-Circle loss function for cross-modality
feature learning. Furthermore, to learn good features and not lose generality,
we developed a variant of widely used PointNet++ architecture for point cloud
and U-Net CNN architecture for images. Moreover, we conduct experiments on a
real-world dataset to show the effectiveness of our loss function and network
structure. We show that our models indeed learn information from both images as
well as LiDAR by visualizing the features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MaskRange: A Mask-classification Model for Range-view based LiDAR Segmentation. (arXiv:2206.12073v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12073">
<div class="article-summary-box-inner">
<span><p>Range-view based LiDAR segmentation methods are attractive for practical
applications due to their direct inheritance from efficient 2D CNN
architectures. In literature, most range-view based methods follow the
per-pixel classification paradigm. Recently, in the image segmentation domain,
another paradigm formulates segmentation as a mask-classification problem and
has achieved remarkable performance. This raises an interesting question: can
the mask-classification paradigm benefit the range-view based LiDAR
segmentation and achieve better performance than the counterpart per-pixel
paradigm? To answer this question, we propose a unified mask-classification
model, MaskRange, for the range-view based LiDAR semantic and panoptic
segmentation. Along with the new paradigm, we also propose a novel data
augmentation method to deal with overfitting, context-reliance, and
class-imbalance problems. Extensive experiments are conducted on the
SemanticKITTI benchmark. Among all published range-view based methods, our
MaskRange achieves state-of-the-art performance with $66.10$ mIoU on semantic
segmentation and promising results with $53.10$ PQ on panoptic segmentation
with high efficiency. Our code will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A novel approach for glaucoma classification by wavelet neural networks using graph-based, statisitcal features of qualitatively improved images. (arXiv:2206.12099v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12099">
<div class="article-summary-box-inner">
<span><p>In this paper, we have proposed a new glaucoma classification approach that
employs a wavelet neural network (WNN) on optimally enhanced retinal images
features. To avoid tedious and error prone manual analysis of retinal images by
ophthalmologists, computer aided diagnosis (CAD) substantially aids in robust
diagnosis. Our objective is to introduce a CAD system with a fresh approach.
Retinal image quality improvement is attempted in two phases. The retinal image
preprocessing phase improves the brightness and contrast of the image through
quantile based histogram modification. It is followed by the image enhancement
phase, which involves multi scale morphological operations using image specific
dynamic structuring elements for the retinal structure enrichment. Graph based
retinal image features in terms of Local Graph Structures (LGS) and Graph
Shortest Path (GSP) statistics are extracted from various directions along with
the statistical features from the enhanced retinal dataset. WNN is employed to
classify glaucoma retinal images with a suitable wavelet activation function.
The performance of the WNN classifier is compared with multilayer perceptron
neural networks with various datasets. The results show our approach is
superior to the existing approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dissecting U-net for Seismic Application: An In-Depth Study on Deep Learning Multiple Removal. (arXiv:2206.12112v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12112">
<div class="article-summary-box-inner">
<span><p>Seismic processing often requires suppressing multiples that appear when
collecting data. To tackle these artifacts, practitioners usually rely on Radon
transform-based algorithms as post-migration gather conditioning. However, such
traditional approaches are both time-consuming and parameter-dependent, making
them fairly complex. In this work, we present a deep learning-based alternative
that provides competitive results, while reducing its usage's complexity, and
hence democratizing its applicability. We observe an excellent performance of
our network when inferring complex field data, despite the fact of being solely
trained on synthetics. Furthermore, extensive experiments show that our
proposal can preserve the inherent characteristics of the data, avoiding
undesired over-smoothed results, while removing the multiples. Finally, we
conduct an in-depth analysis of the model, where we pinpoint the effects of the
main hyperparameters with physical events. To the best of our knowledge, this
study pioneers the unboxing of neural networks for the demultiple process,
helping the user to gain insights into the inside running of the network.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self Supervised Learning for Few Shot Hyperspectral Image Classification. (arXiv:2206.12117v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12117">
<div class="article-summary-box-inner">
<span><p>Deep learning has proven to be a very effective approach for Hyperspectral
Image (HSI) classification. However, deep neural networks require large
annotated datasets to generalize well. This limits the applicability of deep
learning for HSI classification, where manually labelling thousands of pixels
for every scene is impractical. In this paper, we propose to leverage Self
Supervised Learning (SSL) for HSI classification. We show that by pre-training
an encoder on unlabeled pixels using Barlow-Twins, a state-of-the-art SSL
algorithm, we can obtain accurate models with a handful of labels. Experimental
results demonstrate that this approach significantly outperforms vanilla
supervised learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Some theoretical results on discrete contour trees. (arXiv:2206.12123v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12123">
<div class="article-summary-box-inner">
<span><p>Contour trees have been developed to visualize or encode scalar data in
imaging technologies and scientific simulations. Contours are defined on a
continuous scalar field. For discrete data, a continuous function is first
interpolated, where contours are then defined. In this paper we define a
discrete contour tree, called the iso-tree, on a scalar graph, and discuss its
properties. We show that the iso-tree model works for data of all dimensions,
and develop an axiomatic system formalizing the discrete contour structures. We
also report an isomorphism between iso-trees and augmented contour trees,
showing that contour tree algorithms can be used to compute discrete contour
trees, and vice versa.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Temporal Attention Unit: Towards Efficient Spatiotemporal Predictive Learning. (arXiv:2206.12126v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12126">
<div class="article-summary-box-inner">
<span><p>Spatiotemporal predictive learning aims to generate future frames by learning
from historical frames. In this paper, we investigate existing methods and
present a general framework of spatiotemporal predictive learning, in which the
spatial encoder and decoder capture intra-frame features and the middle
temporal module catches inter-frame correlations. While the mainstream methods
employ recurrent units to capture long-term temporal dependencies, they suffer
from low computational efficiency due to their unparallelizable architectures.
To parallelize the temporal module, we propose the Temporal Attention Unit
(TAU), which decomposes the temporal attention into intra-frame statical
attention and inter-frame dynamical attention. Moreover, while the mean squared
error loss focuses on intra-frame errors, we introduce a novel differential
divergence regularization to take inter-frame variations into account.
Extensive experiments demonstrate that the proposed method enables the derived
model to achieve competitive performance on various spatiotemporal prediction
benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Excavating RoI Attention for Underwater Object Detection. (arXiv:2206.12128v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12128">
<div class="article-summary-box-inner">
<span><p>Self-attention is one of the most successful designs in deep learning, which
calculates the similarity of different tokens and reconstructs the feature
based on the attention matrix. Originally designed for NLP, self-attention is
also popular in computer vision, and can be categorized into pixel-level
attention and patch-level attention. In object detection, RoI features can be
seen as patches from base feature maps. This paper aims to apply the attention
module to RoI features to improve performance. Instead of employing an original
self-attention module, we choose the external attention module, a modified
self-attention with reduced parameters. With the proposed double head structure
and the Positional Encoding module, our method can achieve promising
performance in object detection. The comprehensive experiments show that it
achieves promising performance, especially in the underwater object detection
dataset. The code will be avaiable in:
https://github.com/zsyasd/Excavating-RoI-Attention-for-Underwater-Object-Detection
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feature Representation Learning for Robust Retinal Disease Detection from Optical Coherence Tomography Images. (arXiv:2206.12136v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12136">
<div class="article-summary-box-inner">
<span><p>Ophthalmic images may contain identical-looking pathologies that can cause
failure in automated techniques to distinguish different retinal degenerative
diseases. Additionally, reliance on large annotated datasets and lack of
knowledge distillation can restrict ML-based clinical support systems'
deployment in real-world environments. To improve the robustness and
transferability of knowledge, an enhanced feature-learning module is required
to extract meaningful spatial representations from the retinal subspace. Such a
module, if used effectively, can detect unique disease traits and differentiate
the severity of such retinal degenerative pathologies. In this work, we propose
a robust disease detection architecture with three learning heads, i) A
supervised encoder for retinal disease classification, ii) An unsupervised
decoder for the reconstruction of disease-specific spatial information, and
iii) A novel representation learning module for learning the similarity between
encoder-decoder feature and enhancing the accuracy of the model. Our
experimental results on two publicly available OCT datasets illustrate that the
proposed model outperforms existing state-of-the-art models in terms of
accuracy, interpretability, and robustness for out-of-distribution retinal
disease detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Augmented Reality-Empowered Network Planning Services for Private Networks. (arXiv:2206.12139v1 [cs.NI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12139">
<div class="article-summary-box-inner">
<span><p>To support Industry 4.0 applications with haptics and human-machine
interaction, the sixth generation (6G) requires a new framework that is fully
autonomous, visual, and interactive. In this paper, we propose a novel
framework for private network planning services, providing an end-to-end
solution that receives visual and sensory data from the user device,
reconstructs the 3D network environment and performs network planning on the
server, and visualizes the network performance with augmented reality (AR) on
the display of the user devices. The solution is empowered by three key
technical components: 1) vision- and sensor fusion-based 3D environment
reconstruction, 2) ray tracing-based radio map generation and network planning,
and 3) AR-empowered network visualization enabled by real-time camera
relocalization. We conducted the proof-of-concept in a Bosch plant in Germany
and showed good network coverage of the optimized antenna location, as well as
high accuracy in both environment reconstruction and camera relocalization. We
also achieved real-time AR-supported network monitoring with an end-to-end
latency of about 32 ms per frame.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient and Robust Training of Dense Object Nets for Multi-Object Robot Manipulation. (arXiv:2206.12145v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12145">
<div class="article-summary-box-inner">
<span><p>We propose a framework for robust and efficient training of Dense Object Nets
(DON) with a focus on multi-object robot manipulation scenarios. DON is a
popular approach to obtain dense, view-invariant object descriptors, which can
be used for a multitude of downstream tasks in robot manipulation, such as,
pose estimation, state representation for control, etc.. However, the original
work focused training on singulated objects, with limited results on
instance-specific, multi-object applications. Additionally, a complex data
collection pipeline, including 3D reconstruction and mask annotation of each
object, is required for training. In this paper, we further improve the
efficacy of DON with a simplified data collection and training regime, that
consistently yields higher precision and enables robust tracking of keypoints
with less data requirements. In particular, we focus on training with
multi-object data instead of singulated objects, combined with a well-chosen
augmentation scheme. We additionally propose an alternative loss formulation to
the original pixelwise formulation that offers better results and is less
sensitive to hyperparameters. Finally, we demonstrate the robustness and
accuracy of our proposed framework on a real-world robotic grasping task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimized Views Photogrammetry: Precision Analysis and A Large-scale Case Study in Qingdao. (arXiv:2206.12216v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12216">
<div class="article-summary-box-inner">
<span><p>UAVs have become one of the widely used remote sensing platforms and played a
critical role in the construction of smart cities. However, due to the complex
environment in urban scenes, secure and accurate data acquisition brings great
challenges to 3D modeling and scene updating. Optimal trajectory planning of
UAVs and accurate data collection of onboard cameras are non-trivial issues in
urban modeling. This study presents the principle of optimized views
photogrammetry and verifies its precision and potential in large-scale 3D
modeling. Different from oblique photogrammetry, optimized views photogrammetry
uses rough models to generate and optimize UAV trajectories, which is achieved
through the consideration of model point reconstructability and view point
redundancy. Based on the principle of optimized views photogrammetry, this
study first conducts a precision analysis of 3D models by using UAV images of
optimized views photogrammetry and then executes a large-scale case study in
the urban region of Qingdao city, China, to verify its engineering potential.
By using GCPs for image orientation precision analysis and TLS (terrestrial
laser scanning) point clouds for model quality analysis, experimental results
show that optimized views photogrammetry could construct stable image
connection networks and could achieve comparable image orientation accuracy.
Benefiting from the accurate image acquisition strategy, the quality of mesh
models significantly improves, especially for urban areas with serious
occlusions, in which 3 to 5 times of higher accuracy has been achieved.
Besides, the case study in Qingdao city verifies that optimized views
photogrammetry can be a reliable and powerful solution for the large-scale 3D
modeling in complex urban scenes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Zoom Lens: A Novel Physical-World Attack to DNNs. (arXiv:2206.12251v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12251">
<div class="article-summary-box-inner">
<span><p>Although deep neural networks (DNNs) are known to be fragile, no one has
studied the effects of zooming-in and zooming-out of images in the physical
world on DNNs performance. In this paper, we demonstrate a novel physical
adversarial attack technique called Adversarial Zoom Lens (AdvZL), which uses a
zoom lens to zoom in and out of pictures of the physical world, fooling DNNs
without changing the characteristics of the target object. The proposed method
is so far the only adversarial attack technique that does not add physical
adversarial perturbation attack DNNs. In a digital environment, we construct a
data set based on AdvZL to verify the antagonism of equal-scale enlarged images
to DNNs. In the physical environment, we manipulate the zoom lens to zoom in
and out of the target object, and generate adversarial samples. The
experimental results demonstrate the effectiveness of AdvZL in both digital and
physical environments. We further analyze the antagonism of the proposed data
set to the improved DNNs. On the other hand, we provide a guideline for defense
against AdvZL by means of adversarial training. Finally, we look into the
threat possibilities of the proposed approach to future autonomous driving and
variant attack ideas similar to the proposed attack.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InfoAT: Improving Adversarial Training Using the Information Bottleneck Principle. (arXiv:2206.12292v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12292">
<div class="article-summary-box-inner">
<span><p>Adversarial training (AT) has shown excellent high performance in defending
against adversarial examples. Recent studies demonstrate that examples are not
equally important to the final robustness of models during AT, that is, the
so-called hard examples that can be attacked easily exhibit more influence than
robust examples on the final robustness. Therefore, guaranteeing the robustness
of hard examples is crucial for improving the final robustness of the model.
However, defining effective heuristics to search for hard examples is still
difficult. In this article, inspired by the information bottleneck (IB)
principle, we uncover that an example with high mutual information of the input
and its associated latent representation is more likely to be attacked. Based
on this observation, we propose a novel and effective adversarial training
method (InfoAT). InfoAT is encouraged to find examples with high mutual
information and exploit them efficiently to improve the final robustness of
models. Experimental results show that InfoAT achieves the best robustness
among different datasets and models in comparison with several state-of-the-art
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic extraction of coronary arteries using deep learning in invasive coronary angiograms. (arXiv:2206.12300v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12300">
<div class="article-summary-box-inner">
<span><p>Accurate extraction of coronary arteries from invasive coronary angiography
(ICA) is important in clinical decision-making for the diagnosis and risk
stratification of coronary artery disease (CAD). In this study, we develop a
method using deep learning to automatically extract the coronary artery lumen.
Methods. A deep learning model U-Net 3+, which incorporates the full-scale skip
connections and deep supervisions, was proposed for automatic extraction of
coronary arteries from ICAs. Transfer learning and a hybrid loss function were
employed in this novel coronary artery extraction framework. Results. A data
set containing 616 ICAs obtained from 210 patients was used. In the technical
evaluation, the U-Net 3+ achieved a Dice score of 0.8942 and a sensitivity of
0.8735, which is higher than U-Net ++ (Dice score: 0.8814, the sensitivity of
0.8331) and U-net (Dice score: 0.8799, the sensitivity of 0.8305). Conclusion.
Our study demonstrates that the U-Net 3+ is superior to other segmentation
frameworks for the automatic extraction of the coronary arteries from ICAs.
This result suggests great promise for clinical use.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How to train accurate BNNs for embedded systems?. (arXiv:2206.12322v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12322">
<div class="article-summary-box-inner">
<span><p>A key enabler of deploying convolutional neural networks on
resource-constrained embedded systems is the binary neural network (BNN). BNNs
save on memory and simplify computation by binarizing both features and
weights. Unfortunately, binarization is inevitably accompanied by a severe
decrease in accuracy. To reduce the accuracy gap between binary and
full-precision networks, many repair methods have been proposed in the recent
past, which we have classified and put into a single overview in this chapter.
The repair methods are divided into two main branches, training techniques and
network topology changes, which can further be split into smaller categories.
The latter category introduces additional cost (energy consumption or
additional area) for an embedded system, while the former does not. From our
overview, we observe that progress has been made in reducing the accuracy gap,
but BNN papers are not aligned on what repair methods should be used to get
highly accurate BNNs. Therefore, this chapter contains an empirical review that
evaluates the benefits of many repair methods in isolation over the
ResNet-20\&amp;CIFAR10 and ResNet-18\&amp;CIFAR100 benchmarks. We found three repair
categories most beneficial: feature binarizer, feature normalization, and
double residual. Based on this review we discuss future directions and research
opportunities. We sketch the benefit and costs associated with BNNs on embedded
systems because it remains to be seen whether BNNs will be able to close the
accuracy gap while staying highly energy-efficient on resource-constrained
embedded systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Segmentation-free PVC for Cardiac SPECT using a Densely-connected Multi-dimensional Dynamic Network. (arXiv:2206.12344v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12344">
<div class="article-summary-box-inner">
<span><p>In nuclear imaging, limited resolution causes partial volume effects (PVEs)
that affect image sharpness and quantitative accuracy. Partial volume
correction (PVC) methods incorporating high-resolution anatomical information
from CT or MRI have been demonstrated to be effective. However, such
anatomical-guided methods typically require tedious image registration and
segmentation steps. Accurately segmented organ templates are also hard to
obtain, particularly in cardiac SPECT imaging, due to the lack of hybrid
SPECT/CT scanners with high-end CT and associated motion artifacts. Slight
mis-registration/mis-segmentation would result in severe degradation in image
quality after PVC. In this work, we develop a deep-learning-based method for
fast cardiac SPECT PVC without anatomical information and associated organ
segmentation. The proposed network involves a densely-connected
multi-dimensional dynamic mechanism, allowing the convolutional kernels to be
adapted based on the input images, even after the network is fully trained.
Intramyocardial blood volume (IMBV) is introduced as an additional
clinical-relevant loss function for network optimization. The proposed network
demonstrated promising performance on 28 canine studies acquired on a GE
Discovery NM/CT 570c dedicated cardiac SPECT scanner with a 64-slice CT using
Technetium-99m-labeled red blood cells. This work showed that the proposed
network with densely-connected dynamic mechanism produced superior results
compared with the same network without such mechanism. Results also showed that
the proposed network without anatomical information could produce images with
statistically comparable IMBV measurements to the images generated by
anatomical-guided PVC methods, which could be helpful in clinical translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Megapixel Image Generation with Step-Unrolled Denoising Autoencoders. (arXiv:2206.12351v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12351">
<div class="article-summary-box-inner">
<span><p>An ongoing trend in generative modelling research has been to push sample
resolutions higher whilst simultaneously reducing computational requirements
for training and sampling. We aim to push this trend further via the
combination of techniques - each component representing the current pinnacle of
efficiency in their respective areas. These include vector-quantized GAN
(VQ-GAN), a vector-quantization (VQ) model capable of high levels of lossy -
but perceptually insignificant - compression; hourglass transformers, a highly
scaleable self-attention model; and step-unrolled denoising autoencoders
(SUNDAE), a non-autoregressive (NAR) text generative model. Unexpectedly, our
method highlights weaknesses in the original formulation of hourglass
transformers when applied to multidimensional data. In light of this, we
propose modifications to the resampling mechanism, applicable in any task
applying hierarchical transformers to multidimensional data. Additionally, we
demonstrate the scalability of SUNDAE to long sequence lengths - four times
longer than prior work. Our proposed framework scales to high-resolutions
($1024 \times 1024$) and trains quickly (2-4 days). Crucially, the trained
model produces diverse and realistic megapixel samples in approximately 2
seconds on a consumer-grade GPU (GTX 1080Ti). In general, the framework is
flexible: supporting an arbitrary number of sampling steps, sample-wise
self-stopping, self-correction capabilities, conditional generation, and a NAR
formulation that allows for arbitrary inpainting masks. We obtain FID scores of
10.56 on FFHQ256 - close to the original VQ-GAN in less than half the sampling
steps - and 21.85 on FFHQ1024 in only 100 sampling steps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HM3D-ABO: A Photo-realistic Dataset for Object-centric Multi-view 3D Reconstruction. (arXiv:2206.12356v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12356">
<div class="article-summary-box-inner">
<span><p>Reconstructing 3D objects is an important computer vision task that has wide
application in AR/VR. Deep learning algorithm developed for this task usually
relies on an unrealistic synthetic dataset, such as ShapeNet and Things3D. On
the other hand, existing real-captured object-centric datasets usually do not
have enough annotation to enable supervised training or reliable evaluation. In
this technical report, we present a photo-realistic object-centric dataset
HM3D-ABO. It is constructed by composing realistic indoor scene and realistic
object. For each configuration, we provide multi-view RGB observations, a
water-tight mesh model for the object, ground truth depth map and object mask.
The proposed dataset could also be useful for tasks such as camera pose
estimation and novel-view synthesis. The dataset generation code is released at
https://github.com/zhenpeiyang/HM3D-ABO.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Online Distillation with Mixed Sample Augmentation. (arXiv:2206.12370v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12370">
<div class="article-summary-box-inner">
<span><p>Mixed Sample Regularization (MSR), such as MixUp or CutMix, is a powerful
data augmentation strategy to generalize convolutional neural networks.
Previous empirical analysis has illustrated an orthogonal performance gain
between MSR and the conventional offline Knowledge Distillation (KD). To be
more specific, student networks can be enhanced with the involvement of MSR in
the training stage of the sequential distillation. Yet, the interplay between
MSR and online knowledge distillation, a stronger distillation paradigm, where
an ensemble of peer students learn mutually from each other, remains
unexplored. To bridge the gap, we make the first attempt at incorporating
CutMix into online distillation, where we empirically observe a significant
improvement. Encouraged by this fact, we propose an even stronger MSR
specifically for online distillation, named as Cut^nMix. Furthermore, a novel
online distillation framework is designed upon Cut^nMix, to enhance the
distillation with feature level mutual learning and a self-ensemble teacher.
Comprehensive evaluations on CIFAR10 and CIFAR100 with six network
architectures show that our approach can consistently outperform
state-of-the-art distillation methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QReg: On Regularization Effects of Quantization. (arXiv:2206.12372v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12372">
<div class="article-summary-box-inner">
<span><p>In this paper we study the effects of quantization in DNN training. We
hypothesize that weight quantization is a form of regularization and the amount
of regularization is correlated with the quantization level (precision). We
confirm our hypothesis by providing analytical study and empirical results. By
modeling weight quantization as a form of additive noise to weights, we explore
how this noise propagates through the network at training time. We then show
that the magnitude of this noise is correlated with the level of quantization.
To confirm our analytical study, we performed an extensive list of experiments
summarized in this paper in which we show that the regularization effects of
quantization can be seen in various vision tasks and models, over various
datasets. Based on our study, we propose that 8-bit quantization provides a
reliable form of regularization in different vision tasks and models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Defending Backdoor Attacks on Vision Transformer via Patch Processing. (arXiv:2206.12381v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12381">
<div class="article-summary-box-inner">
<span><p>Vision Transformers (ViTs) have a radically different architecture with
significantly less inductive bias than Convolutional Neural Networks. Along
with the improvement in performance, security and robustness of ViTs are also
of great importance to study. In contrast to many recent works that exploit the
robustness of ViTs against adversarial examples, this paper investigates a
representative causative attack, i.e., backdoor. We first examine the
vulnerability of ViTs against various backdoor attacks and find that ViTs are
also quite vulnerable to existing attacks. However, we observe that the
clean-data accuracy and backdoor attack success rate of ViTs respond
distinctively to patch transformations before the positional encoding. Then,
based on this finding, we propose an effective method for ViTs to defend both
patch-based and blending-based trigger backdoor attacks via patch processing.
The performances are evaluated on several benchmark datasets, including
CIFAR10, GTSRB, and TinyImageNet, which show the proposed novel defense is very
successful in mitigating backdoor attacks for ViTs. To the best of our
knowledge, this paper presents the first defensive strategy that utilizes a
unique characteristic of ViTs against backdoor attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text-Driven Stylization of Video Objects. (arXiv:2206.12396v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12396">
<div class="article-summary-box-inner">
<span><p>We tackle the task of stylizing video objects in an intuitive and semantic
manner following a user-specified text prompt. This is a challenging task as
the resulting video must satisfy multiple properties: (1) it has to be
temporally consistent and avoid jittering or similar artifacts, (2) the
resulting stylization must preserve both the global semantics of the object and
its fine-grained details, and (3) it must adhere to the user-specified text
prompt. To this end, our method stylizes an object in a video according to a
global target text prompt that describes the global semantics and a local
target text prompt that describes the local semantics. To modify the style of
an object, we harness the representational power of CLIP to get a similarity
score between (1) the local target text and a set of local stylized views, and
(2) a global target text and a set of stylized global views. We use a
pretrained atlas decomposition network to propagate the edits in a temporally
consistent manner. We demonstrate that our method can generate consistent style
changes in time for a variety of objects and videos, that adhere to the
specification of the target texts. We also show how varying the specificity of
the target texts, and augmenting the texts with a set of prefixes results in
stylizations with different levels of detail. Full results are given on our
project webpage:
https://sloeschcke.github.io/Text-Driven-Stylization-of-Video-Objects/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ZSON: Zero-Shot Object-Goal Navigation using Multimodal Goal Embeddings. (arXiv:2206.12403v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12403">
<div class="article-summary-box-inner">
<span><p>We present a scalable approach for learning open-world object-goal navigation
(ObjectNav) -- the task of asking a virtual robot (agent) to find any instance
of an object in an unexplored environment (e.g., "find a sink"). Our approach
is entirely zero-shot -- i.e., it does not require ObjectNav rewards or
demonstrations of any kind. Instead, we train on the image-goal navigation
(ImageNav) task, in which agents find the location where a picture (i.e., goal
image) was captured. Specifically, we encode goal images into a multimodal,
semantic embedding space to enable training semantic-goal navigation
(SemanticNav) agents at scale in unannotated 3D environments (e.g., HM3D).
After training, SemanticNav agents can be instructed to find objects described
in free-form natural language (e.g., "sink", "bathroom sink", etc.) by
projecting language goals into the same multimodal, semantic embedding space.
As a result, our approach enables open-world ObjectNav. We extensively evaluate
our agents on three ObjectNav datasets (Gibson, HM3D, and MP3D) and observe
absolute improvements in success of 4.2% - 20.0% over existing zero-shot
methods. For reference, these gains are similar or better than the 5%
improvement in success between the Habitat 2020 and 2021 ObjectNav challenge
winners. In an open-world setting, we discover that our agents can generalize
to compound instructions with a room explicitly mentioned (e.g., "Find a
kitchen sink") and when the target room can be inferred (e.g., "Find a sink and
a stove").
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RARTS: An Efficient First-Order Relaxed Architecture Search Method. (arXiv:2008.03901v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.03901">
<div class="article-summary-box-inner">
<span><p>Differentiable architecture search (DARTS) is an effective method for
data-driven neural network design based on solving a bilevel optimization
problem. Despite its success in many architecture search tasks, there are still
some concerns about the accuracy of first-order DARTS and the efficiency of the
second-order DARTS. In this paper, we formulate a single level alternative and
a relaxed architecture search (RARTS) method that utilizes the whole dataset in
architecture learning via both data and network splitting, without involving
mixed second derivatives of the corresponding loss functions like DARTS. In our
formulation of network splitting, two networks with different but related
weights cooperate in search of a shared architecture. The advantage of RARTS
over DARTS is justified by a convergence theorem and an analytically solvable
model. Moreover, RARTS outperforms DARTS and its variants in accuracy and
search efficiency, as shown in adequate experimental results. For the task of
searching topological architecture, i.e., the edges and the operations, RARTS
obtains a higher accuracy and 60\% reduction of computational cost than
second-order DARTS on CIFAR-10. RARTS continues to out-perform DARTS upon
transfer to ImageNet and is on par with recent variants of DARTS even though
our innovation is purely on the training algorithm without modifying search
space. For the task of searching width, i.e., the number of channels in
convolutional layers, RARTS also outperforms the traditional network pruning
benchmarks. Further experiments on the public architecture search benchmark
like NATS-Bench also support the preeminence of RARTS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Exit Semantic Segmentation Networks. (arXiv:2106.03527v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03527">
<div class="article-summary-box-inner">
<span><p>Semantic segmentation arises as the backbone of many vision systems, spanning
from self-driving cars and robot navigation to augmented reality and
teleconferencing. Frequently operating under stringent latency constraints
within a limited resource envelope, optimising for efficient execution becomes
important. At the same time, the heterogeneous capabilities of the target
platforms and diverse constraints of different applications require the design
and training of multiple target-specific segmentation models, leading to
excessive maintenance costs. To this end, we propose a framework for converting
state-of-the-art segmentation CNNs to Multi-Exit Semantic Segmentation (MESS)
networks: specially trained models that employ parametrised early exits along
their depth to i) dynamically save computation during inference on easier
samples and ii) save training and maintenance cost by offering a post-training
customisable speed-accuracy trade-off. Designing and training such networks
naively can hurt performance. Thus, we propose novel two-staged training scheme
for multi-exit networks. Furthermore, the parametrisation of MESS enables
co-optimising the number, placement and architecture of the attached
segmentation heads along with the exit policy, upon deployment via exhaustive
search in &lt;1GPUh. This allows MESS to rapidly adapt to the device capabilities
and application requirements for each target use-case, offering a
train-once-deploy-everywhere solution. MESS variants achieve latency gains of
up to 2.83x with the same accuracy, or 5.33 pp higher accuracy for the same
computational budget, compared to the original backbone network. Lastly, MESS
delivers orders of magnitude faster architecture selection, compared to
state-of-the-art techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hard hat wearing detection based on head keypoint localization. (arXiv:2106.10944v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10944">
<div class="article-summary-box-inner">
<span><p>In recent years, a lot of attention is paid to deep learning methods in the
context of vision-based construction site safety systems, especially regarding
personal protective equipment. However, despite all this attention, there is
still no reliable way to establish the relationship between workers and their
hard hats. To answer this problem a combination of deep learning, object
detection and head keypoint localization, with simple rule-based reasoning is
proposed in this article. In tests, this solution surpassed the previous
methods based on the relative bounding box position of different instances, as
well as direct detection of hard hat wearers and non-wearers. The results show
that the conjunction of novel deep learning methods with humanly-interpretable
rule-based systems can result in a solution that is both reliable and can
successfully mimic manual, on-site supervision. This work is the next step in
the development of fully autonomous construction site safety systems and shows
that there is still room for improvement in this area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved-Mask R-CNN: Towards an Accurate Generic MSK MRI instance segmentation platform (Data from the Osteoarthritis Initiative). (arXiv:2107.12889v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12889">
<div class="article-summary-box-inner">
<span><p>Objective assessment of Magnetic Resonance Imaging (MRI) scans of
osteoarthritis (OA) can address the limitation of the current OA assessment.
Segmentation of bone, cartilage, and joint fluid is necessary for the OA
objective assessment. Most of the proposed segmentation methods are not
performing instance segmentation and suffer from class imbalance problems. This
study deployed Mask R-CNN instance segmentation and improved it (improved-Mask
R-CNN (iMaskRCNN)) to obtain a more accurate generalized segmentation for
OA-associated tissues. Training and validation of the method were performed
using 500 MRI knees from the Osteoarthritis Initiative (OAI) dataset and 97 MRI
scans of patients with symptomatic hip OA. Three modifications to Mask R-CNN
yielded the iMaskRCNN: adding a 2nd ROIAligned block, adding an extra decoder
layer to the mask-header, and connecting them by a skip connection. The results
were assessed using Hausdorff distance, dice score, and coefficients of
variation (CoV). The iMaskRCNN led to improved bone and cartilage segmentation
compared to Mask RCNN as indicated with the increase in dice score from 95% to
98% for the femur, 95% to 97% for tibia, 71% to 80% for femoral cartilage, and
81% to 82% for tibial cartilage. For the effusion detection, dice improved with
iMaskRCNN 72% versus MaskRCNN 71%. The CoV values for effusion detection
between Reader1 and Mask R-CNN (0.33), Reader1 and iMaskRCNN (0.34), Reader2
and Mask R-CNN (0.22), Reader2 and iMaskRCNN (0.29) are close to CoV between
two readers (0.21), indicating a high agreement between the human readers and
both Mask R-CNN and iMaskRCNN. Mask R-CNN and iMaskRCNN can reliably and
simultaneously extract different scale articular tissues involved in OA,
forming the foundation for automated assessment of OA. The iMaskRCNN results
show that the modification improved the network performance around the edges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Localized Shape Modelling with Global Coherence: An Inverse Spectral Approach. (arXiv:2108.02161v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02161">
<div class="article-summary-box-inner">
<span><p>Many natural shapes have most of their characterizing features concentrated
over a few regions in space. For example, humans and animals have distinctive
head shapes, while inorganic objects like chairs and airplanes are made of
well-localized functional parts with specific geometric features. Often, these
features are strongly correlated -- a modification of facial traits in a
quadruped should induce changes to the body structure. However, in shape
modelling applications, these types of edits are among the hardest ones; they
require high precision, but also a global awareness of the entire shape. Even
in the deep learning era, obtaining manipulable representations that satisfy
such requirements is an open problem posing significant constraints. In this
work, we address this problem by defining a data-driven model upon a family of
linear operators (variants of the mesh Laplacian), whose spectra capture global
and local geometric properties of the shape at hand. Modifications to these
spectra are translated to semantically valid deformations of the corresponding
surface. By explicitly decoupling the global from the local surface features,
our pipeline allows to perform local edits while simultaneously maintaining a
global stylistic coherence. We empirically demonstrate how our learning-based
model generalizes to shape representations not seen at training time, and we
systematically analyze different choices of local operators over diverse shape
categories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised domain adaptation for clinician pose estimation and instance segmentationin the operating room. (arXiv:2108.11801v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11801">
<div class="article-summary-box-inner">
<span><p>The fine-grained localization of clinicians in the operating room (OR) is a
key component to design the new generation of OR support systems. Computer
vision models for person pixel-based segmentation and body-keypoints detection
are needed to better understand the clinical activities and the spatial layout
of the OR. This is challenging, not only because OR images are very different
from traditional vision datasets, but also because data and annotations are
hard to collect and generate in the OR due to privacy concerns. To address
these concerns, we first study how joint person pose estimation and instance
segmentation can be performed on low resolutions images with downsampling
factors from 1x to 12x. Second, to address the domain shift and the lack of
annotations, we propose a novel unsupervised domain adaptation method, called
AdaptOR, to adapt a model from an in-the-wild labeled source domain to a
statistically different unlabeled target domain. We propose to exploit explicit
geometric constraints on the different augmentations of the unlabeled target
domain image to generate accurate pseudo labels and use these pseudo labels to
train the model on high- and low-resolution OR images in a self-training
framework. Furthermore, we propose disentangled feature normalization to handle
the statistically different source and target domain data. Extensive
experimental results with detailed ablation studies on the two OR datasets
MVOR+ and TUM-OR-test show the effectiveness of our approach against strongly
constructed baselines, especially on the low-resolution privacy-preserving OR
images. Finally, we show the generality of our method as a semi-supervised
learning (SSL) method on the large-scale COCO dataset, where we achieve
comparable results with as few as 1% of labeled supervision against a model
trained with 100% labeled supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">F3: Fair and Federated Face Attribute Classification with Heterogeneous Data. (arXiv:2109.02351v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02351">
<div class="article-summary-box-inner">
<span><p>Fairness across different demographic groups is an essential criterion for
face-related tasks, Face Attribute Classification (FAC) being a prominent
example. Apart from this trend, Federated Learning (FL) is increasingly gaining
traction as a scalable paradigm for distributed training. Existing FL
approaches require data homogeneity to ensure fairness. However, this
assumption is too restrictive in real-world settings. We propose F3, a novel FL
framework for fair FAC under data heterogeneity. F3 adopts multiple heuristics
to improve fairness across different demographic groups without requiring data
homogeneity assumption. We demonstrate the efficacy of F3 by reporting
empirically observed fairness measures and accuracy guarantees on popular face
datasets. Our results suggest that F3 strikes a practical balance between
accuracy and fairness for FAC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ABO: Dataset and Benchmarks for Real-World 3D Object Understanding. (arXiv:2110.06199v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06199">
<div class="article-summary-box-inner">
<span><p>We introduce Amazon Berkeley Objects (ABO), a new large-scale dataset
designed to help bridge the gap between real and virtual 3D worlds. ABO
contains product catalog images, metadata, and artist-created 3D models with
complex geometries and physically-based materials that correspond to real,
household objects. We derive challenging benchmarks that exploit the unique
properties of ABO and measure the current limits of the state-of-the-art on
three open problems for real-world 3D object understanding: single-view 3D
reconstruction, material estimation, and cross-domain multi-view object
retrieval.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Vertebrae localization, segmentation and identification using a graph optimization and an anatomic consistency cycle. (arXiv:2110.12177v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.12177">
<div class="article-summary-box-inner">
<span><p>Vertebrae localization, segmentation and identification in CT images is key
to numerous clinical applications. While deep learning strategies have brought
to this field significant improvements over recent years, transitional and
pathological vertebrae are still plaguing most existing approaches as a
consequence of their poor representation in training datasets. Alternatively,
proposed non-learning based methods take benefit of prior knowledge to handle
such particular cases. In this work we propose to combine both strategies. To
this purpose we introduce an iterative cycle in which individual vertebrae are
recursively localized, segmented and identified using deep-networks, while
anatomic consistency is enforced using statistical priors. In this strategy,
the transitional vertebrae identification is handled by encoding their
configurations in a graphical model that aggregates local deep-network
predictions into an anatomically consistent final result. Our approach achieves
state-of-the-art results on the VerSe20 challenge benchmark, and outperforms
all methods on transitional vertebrae as well as the generalization to the
VerSe19 challenge benchmark. Furthermore, our method can detect and report
inconsistent spine regions that do not satisfy the anatomic consistency priors.
Our code and model are openly available for research purposes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lymphoma segmentation from 3D PET-CT images using a deep evidential network. (arXiv:2201.13078v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.13078">
<div class="article-summary-box-inner">
<span><p>An automatic evidential segmentation method based on Dempster-Shafer theory
and deep learning is proposed to segment lymphomas from three-dimensional
Positron Emission Tomography (PET) and Computed Tomography (CT) images. The
architecture is composed of a deep feature-extraction module and an evidential
layer. The feature extraction module uses an encoder-decoder framework to
extract semantic feature vectors from 3D inputs. The evidential layer then uses
prototypes in the feature space to compute a belief function at each voxel
quantifying the uncertainty about the presence or absence of a lymphoma at this
location. Two evidential layers are compared, based on different ways of using
distances to prototypes for computing mass functions. The whole model is
trained end-to-end by minimizing the Dice loss function. The proposed
combination of deep feature extraction and evidential segmentation is shown to
outperform the baseline UNet model as well as three other state-of-the-art
models on a dataset of 173 patients.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spelunking the Deep: Guaranteed Queries on General Neural Implicit Surfaces via Range Analysis. (arXiv:2202.02444v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02444">
<div class="article-summary-box-inner">
<span><p>Neural implicit representations, which encode a surface as the level set of a
neural network applied to spatial coordinates, have proven to be remarkably
effective for optimizing, compressing, and generating 3D geometry. Although
these representations are easy to fit, it is not clear how to best evaluate
geometric queries on the shape, such as intersecting against a ray or finding a
closest point. The predominant approach is to encourage the network to have a
signed distance property. However, this property typically holds only
approximately, leading to robustness issues, and holds only at the conclusion
of training, inhibiting the use of queries in loss functions. Instead, this
work presents a new approach to perform queries directly on general neural
implicit functions for a wide range of existing architectures. Our key tool is
the application of range analysis to neural networks, using automatic
arithmetic rules to bound the output of a network over a region; we conduct a
study of range analysis on neural networks, and identify variants of affine
arithmetic which are highly effective. We use the resulting bounds to develop
geometric queries including ray casting, intersection testing, constructing
spatial hierarchies, fast mesh extraction, closest-point evaluation, evaluating
bulk properties, and more. Our queries can be efficiently evaluated on GPUs,
and offer concrete accuracy guarantees even on randomly-initialized networks,
enabling their use in training objectives and beyond. We also show a
preliminary application to inverse rendering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rebalanced Siamese Contrastive Mining for Long-Tailed Recognition. (arXiv:2203.11506v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.11506">
<div class="article-summary-box-inner">
<span><p>Deep neural networks perform poorly on heavily class-imbalanced datasets.
Given the promising performance of contrastive learning, we propose Rebalanced
Siamese Contrastive Mining (ResCom) to tackle imbalanced recognition. Based on
the mathematical analysis and simulation results, we claim that supervised
contrastive learning suffers a dual class-imbalance problem at both the
original batch and Siamese batch levels, which is more serious than long-tailed
classification learning. In this paper, at the original batch level, we
introduce a class-balanced supervised contrastive loss to assign adaptive
weights for different classes. At the Siamese batch level, we present a
class-balanced queue, which maintains the same number of keys for all classes.
Furthermore, we note that the imbalanced contrastive loss gradient with respect
to the contrastive logits can be decoupled into the positives and negatives,
and easy positives and easy negatives will make the contrastive gradient
vanish. We propose supervised hard positive and negative pairs mining to pick
up informative pairs for contrastive computation and improve representation
learning. Finally, to approximately maximize the mutual information between the
two views, we propose Siamese Balanced Softmax and joint it with the
contrastive loss for one-stage training. Extensive experiments demonstrate that
ResCom outperforms the previous methods by large margins on multiple
long-tailed recognition benchmarks. Our code and models are made publicly
available at: https://github.com/dvlab-research/ResCom.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep learning for laboratory earthquake prediction and autoregressive forecasting of fault zone stress. (arXiv:2203.13313v2 [physics.geo-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.13313">
<div class="article-summary-box-inner">
<span><p>Earthquake forecasting and prediction have long and in some cases sordid
histories but recent work has rekindled interest based on advances in early
warning, hazard assessment for induced seismicity and successful prediction of
laboratory earthquakes. In the lab, frictional stick-slip events provide an
analog for earthquakes and the seismic cycle. Labquakes are ideal targets for
machine learning (ML) because they can be produced in long sequences under
controlled conditions. Recent works show that ML can predict several aspects of
labquakes using fault zone acoustic emissions. Here, we generalize these
results and explore deep learning (DL) methods for labquake prediction and
autoregressive (AR) forecasting. DL improves existing ML methods of labquake
prediction. AR methods allow forecasting at future horizons via iterative
predictions. We demonstrate that DL models based on Long-Short Term Memory
(LSTM) and Convolution Neural Networks predict labquakes under several
conditions, and that fault zone stress can be predicted with fidelity,
confirming that acoustic energy is a fingerprint of fault zone stress. We
predict also time to start of failure (TTsF) and time to the end of Failure
(TTeF) for labquakes. Interestingly, TTeF is successfully predicted in all
seismic cycles, while the TTsF prediction varies with the amount of preseismic
fault creep. We report AR methods to forecast the evolution of fault stress
using three sequence modeling frameworks: LSTM, Temporal Convolution Network
and Transformer Network. AR forecasting is distinct from existing predictive
models, which predict only a target variable at a specific time. The results
for forecasting beyond a single seismic cycle are limited but encouraging. Our
ML/DL models outperform the state-of-the-art and our autoregressive model
represents a novel framework that could enhance current methods of earthquake
forecasting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Intra- and Inter-Video Relation for Surgical Semantic Scene Segmentation. (arXiv:2203.15251v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.15251">
<div class="article-summary-box-inner">
<span><p>Automatic surgical scene segmentation is fundamental for facilitating
cognitive intelligence in the modern operating theatre. Previous works rely on
conventional aggregation modules (e.g., dilated convolution, convolutional
LSTM), which only make use of the local context. In this paper, we propose a
novel framework STswinCL that explores the complementary intra- and inter-video
relations to boost segmentation performance, by progressively capturing the
global context. We firstly develop a hierarchy Transformer to capture
intra-video relation that includes richer spatial and temporal cues from
neighbor pixels and previous frames. A joint space-time window shift scheme is
proposed to efficiently aggregate these two cues into each pixel embedding.
Then, we explore inter-video relation via pixel-to-pixel contrastive learning,
which well structures the global embedding space. A multi-source contrast
training objective is developed to group the pixel embeddings across videos
with the ground-truth guidance, which is crucial for learning the global
property of the whole data. We extensively validate our approach on two public
surgical video benchmarks, including EndoVis18 Challenge and CaDIS dataset.
Experimental results demonstrate the promising performance of our method, which
consistently exceeds previous state-of-the-art approaches. Code is available at
https://github.com/YuemingJin/STswinCL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Domain Adaptation for Cardiac Segmentation: Towards Structure Mutual Information Maximization. (arXiv:2204.09334v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.09334">
<div class="article-summary-box-inner">
<span><p>Unsupervised domain adaptation approaches have recently succeeded in various
medical image segmentation tasks. The reported works often tackle the domain
shift problem by aligning the domain-invariant features and minimizing the
domain-specific discrepancies. That strategy works well when the difference
between a specific domain and between different domains is slight. However, the
generalization ability of these models on diverse imaging modalities remains a
significant challenge. This paper introduces UDA-VAE++, an unsupervised domain
adaptation framework for cardiac segmentation with a compact loss function
lower bound. To estimate this new lower bound, we develop a novel Structure
Mutual Information Estimation (SMIE) block with a global estimator, a local
estimator, and a prior information matching estimator to maximize the mutual
information between the reconstruction and segmentation tasks. Specifically, we
design a novel sequential reparameterization scheme that enables information
flow and variance correction from the low-resolution latent space to the
high-resolution latent space. Comprehensive experiments on benchmark cardiac
segmentation datasets demonstrate that our model outperforms previous
state-of-the-art qualitatively and quantitatively. The code is available at
https://github.com/LOUEY233/Toward-Mutual-Information}{https://github.com/LOUEY233/Toward-Mutual-Information
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Quality of Pose-varied Face Restoration with Local Weak Feature Sensing and GAN Prior. (arXiv:2205.14377v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.14377">
<div class="article-summary-box-inner">
<span><p>Facial semantic guidance (including facial landmarks, facial heatmaps, and
facial parsing maps) and facial generative adversarial networks (GAN) prior
have been widely used in blind face restoration (BFR) in recent years. Although
existing BFR methods have achieved good performance in ordinary cases, these
solutions have limited resilience when applied to face images with serious
degradation and pose-varied (e.g., looking right, looking left, laughing, etc.)
in real-world scenarios. In this work, we propose a well-designed blind face
restoration network with generative facial prior. The proposed network is
mainly comprised of an asymmetric codec and a StyleGAN2 prior network. In the
asymmetric codec, we adopt a mixed multi-path residual block (MMRB) to
gradually extract weak texture features of input images, which can better
preserve the original facial features and avoid excessive fantasy. The MMRB can
also be plug-and-play in other networks. Furthermore, thanks to the affluent
and diverse facial priors of the StyleGAN2 model, we adopt a fine-tuned
approach to flexibly restore natural and realistic facial details. Besides, a
novel self-supervised training strategy is specially designed for face
restoration tasks to fit the distribution closer to the target and maintain
training stability. Extensive experiments on both synthetic and real-world
datasets demonstrate that our model achieves superior performance to the prior
art for face restoration and face super-resolution tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RankSim: Ranking Similarity Regularization for Deep Imbalanced Regression. (arXiv:2205.15236v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.15236">
<div class="article-summary-box-inner">
<span><p>Data imbalance, in which a plurality of the data samples come from a small
proportion of labels, poses a challenge in training deep neural networks.
Unlike classification, in regression the labels are continuous, potentially
boundless, and form a natural ordering. These distinct features of regression
call for new techniques that leverage the additional information encoded in
label-space relationships. This paper presents the RankSim (ranking similarity)
regularizer for deep imbalanced regression, which encodes an inductive bias
that samples that are closer in label space should also be closer in feature
space. In contrast to recent distribution smoothing based approaches, RankSim
captures both nearby and distant relationships: for a given data sample,
RankSim encourages the sorted list of its neighbors in label space to match the
sorted list of its neighbors in feature space. RankSim is complementary to
conventional imbalanced learning techniques, including re-weighting, two-stage
training, and distribution smoothing, and lifts the state-of-the-art
performance on three imbalanced regression benchmarks: IMDB-WIKI-DIR,
AgeDB-DIR, and STS-B-DIR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">High-Definition Map Generation Technologies For Autonomous Driving. (arXiv:2206.05400v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.05400">
<div class="article-summary-box-inner">
<span><p>Autonomous driving has been among the most popular and challenging topics in
the past few years. On the road to achieving full autonomy, researchers have
utilized various sensors, such as LiDAR, camera, Inertial Measurement Unit
(IMU), and GPS, and developed intelligent algorithms for autonomous driving
applications such as object detection, object segmentation, obstacle avoidance,
and path planning. High-definition (HD) maps have drawn lots of attention in
recent years. Because of the high precision and informative level of HD maps in
localization, it has immediately become one of the critical components of
autonomous driving. From big organizations like Baidu Apollo, NVIDIA, and
TomTom to individual researchers, researchers have created HD maps for
different scenes and purposes for autonomous driving. It is necessary to review
the state-of-the-art methods for HD map generation. This paper reviews recent
HD map generation technologies that leverage both 2D and 3D map generation.
This review introduces the concept of HD maps and their usefulness in
autonomous driving and gives a detailed overview of HD map generation
techniques. We will also discuss the limitations of the current HD map
generation technologies to motivate future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open-Sampling: Exploring Out-of-Distribution data for Re-balancing Long-tailed datasets. (arXiv:2206.08802v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.08802">
<div class="article-summary-box-inner">
<span><p>Deep neural networks usually perform poorly when the training dataset suffers
from extreme class imbalance. Recent studies found that directly training with
out-of-distribution data (i.e., open-set samples) in a semi-supervised manner
would harm the generalization performance. In this work, we theoretically show
that out-of-distribution data can still be leveraged to augment the minority
classes from a Bayesian perspective. Based on this motivation, we propose a
novel method called Open-sampling, which utilizes open-set noisy labels to
re-balance the class priors of the training dataset. For each open-set
instance, the label is sampled from our pre-defined distribution that is
complementary to the distribution of original class priors. We empirically show
that Open-sampling not only re-balances the class priors but also encourages
the neural network to learn separable representations. Extensive experiments
demonstrate that our proposed method significantly outperforms existing data
re-balancing methods and can boost the performance of existing state-of-the-art
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Voxel-MAE: Masked Autoencoders for Pre-training Large-scale Point Clouds. (arXiv:2206.09900v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09900">
<div class="article-summary-box-inner">
<span><p>Mask-based pre-training has achieved great success for self-supervised
learning in image, video, and language, without manually annotated supervision.
However, it has not yet been studied about large-scale point clouds with
redundant spatial information in autonomous driving. As the number of
large-scale point clouds is huge, it is impossible to reconstruct the input
point clouds. In this paper, we propose a mask voxel classification network for
large-scale point clouds pre-training. Our key idea is to divide the point
clouds into voxel representations and classify whether the voxel contains point
clouds. This simple strategy makes the network to be voxel-aware of the object
shape, thus improving the performance of the downstream tasks, such as 3D
object detection. Our Voxel-MAE with even a 90% masking ratio can still learn
representative features for the high spatial redundancy of large-scale point
clouds. We also validate the effectiveness of Voxel-MAE in unsupervised domain
adaptative tasks, which proves the generalization ability of Voxel-MAE. Our
Voxel-MAE proves that it is feasible to pre-train large-scale point clouds
without data annotations to enhance the perception ability of the autonomous
vehicle. Extensive experiments show great effectiveness of our pre-trained
model with 3D object detectors (SECOND, CenterPoint, and PV-RCNN) on three
popular datasets (KITTI, Waymo, and nuScenes). Codes are publicly available at
https://github.com/chaytonmin/Voxel-MAE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Optimizing OCR for Accessibility. (arXiv:2206.10254v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.10254">
<div class="article-summary-box-inner">
<span><p>Visual cues such as structure, emphasis, and icons play an important role in
efficient information foraging by sighted individuals and make for a
pleasurable reading experience. Blind, low-vision and other print-disabled
individuals miss out on these cues since current OCR and text-to-speech
software ignore them, resulting in a tedious reading experience. We identify
four semantic goals for an enjoyable listening experience, and identify
syntactic visual cues that help make progress towards these goals. Empirically,
we find that preserving even one or two visual cues in aural form significantly
enhances the experience for listening to print content.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open Vocabulary Object Detection with Proposal Mining and Prediction Equalization. (arXiv:2206.11134v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11134">
<div class="article-summary-box-inner">
<span><p>Open-vocabulary object detection (OVD) aims to scale up vocabulary size to
detect objects of novel categories beyond the training vocabulary. Recent work
resorts to the rich knowledge in pre-trained vision-language models. However,
existing methods are ineffective in proposal-level vision-language alignment.
Meanwhile, the models usually suffer from confidence bias toward base
categories and perform worse on novel ones. To overcome the challenges, we
present MEDet, a novel and effective OVD framework with proposal mining and
prediction equalization. First, we design an online proposal mining to refine
the inherited vision-semantic knowledge from coarse to fine, allowing for
proposal-level detection-oriented feature alignment. Second, based on causal
inference theory, we introduce a class-wise backdoor adjustment to reinforce
the predictions on novel categories to improve the overall OVD performance.
Extensive experiments on COCO and LVIS benchmarks verify the superiority of
MEDet over the competing approaches in detecting objects of novel categories,
e.g., 32.6% AP50 on COCO and 22.4% mask mAP on LVIS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LidarMultiNet: Unifying LiDAR Semantic Segmentation, 3D Object Detection, and Panoptic Segmentation in a Single Multi-task Network. (arXiv:2206.11428v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11428">
<div class="article-summary-box-inner">
<span><p>This technical report presents the 1st place winning solution for the Waymo
Open Dataset 3D semantic segmentation challenge 2022. Our network, termed
LidarMultiNet, unifies the major LiDAR perception tasks such as 3D semantic
segmentation, object detection, and panoptic segmentation in a single
framework. At the core of LidarMultiNet is a strong 3D voxel-based
encoder-decoder network with a novel Global Context Pooling (GCP) module
extracting global contextual features from a LiDAR frame to complement its
local features. An optional second stage is proposed to refine the first-stage
segmentation or generate accurate panoptic segmentation results. Our solution
achieves a mIoU of 71.13 and is the best for most of the 22 classes on the
Waymo 3D semantic segmentation test set, outperforming all the other 3D
semantic segmentation methods on the official leaderboard. We demonstrate for
the first time that major LiDAR perception tasks can be unified in a single
strong network that can be trained end-to-end.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Entropy-driven Sampling and Training Scheme for Conditional Diffusion Generation. (arXiv:2206.11474v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11474">
<div class="article-summary-box-inner">
<span><p>Denoising Diffusion Probabilistic Model (DDPM) is able to make flexible
conditional image generation from prior noise to real data, by introducing an
independent noise-aware classifier to provide conditional gradient guidance at
each time step of denoising process. However, due to the ability of classifier
to easily discriminate an incompletely generated image only with high-level
structure, the gradient, which is a kind of class information guidance, tends
to vanish early, leading to the collapse from conditional generation process
into the unconditional process. To address this problem, we propose two simple
but effective approaches from two perspectives. For sampling procedure, we
introduce the entropy of predicted distribution as the measure of guidance
vanishing level and propose an entropy-aware scaling method to adaptively
recover the conditional semantic guidance. For training stage, we propose the
entropy-aware optimization objectives to alleviate the overconfident prediction
for noisy data.On ImageNet1000 256x256, with our proposed sampling scheme and
trained classifier, the pretrained conditional and unconditional DDPM model can
achieve 10.89% (4.59 to 4.09) and 43.5% (12 to 6.78) FID improvement
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Parallel Structure from Motion for UAV Images via Weighted Connected Dominating Set. (arXiv:2206.11499v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11499">
<div class="article-summary-box-inner">
<span><p>Incremental Structure from Motion (ISfM) has been widely used for UAV image
orientation. Its efficiency, however, decreases dramatically due to the
sequential constraint. Although the divide-and-conquer strategy has been
utilized for efficiency improvement, cluster merging becomes difficult or
depends on seriously designed overlap structures. This paper proposes an
algorithm to extract the global model for cluster merging and designs a
parallel SfM solution to achieve efficient and accurate UAV image orientation.
First, based on vocabulary tree retrieval, match pairs are selected to
construct an undirected weighted match graph, whose edge weights are calculated
by considering both the number and distribution of feature matches. Second, an
algorithm, termed weighted connected dominating set (WCDS), is designed to
achieve the simplification of the match graph and build the global model, which
incorporates the edge weight in the graph node selection and enables the
successful reconstruction of the global model. Third, the match graph is
simultaneously divided into compact and non-overlapped clusters. After the
parallel reconstruction, cluster merging is conducted with the aid of common 3D
points between the global and cluster models. Finally, by using three UAV
datasets that are captured by classical oblique and recent optimized views
photogrammetry, the validation of the proposed solution is verified through
comprehensive analysis and comparison. The experimental results demonstrate
that the proposed parallel SfM can achieve 17.4 times efficiency improvement
and comparative orientation accuracy. In absolute BA, the geo-referencing
accuracy is approximately 2.0 and 3.0 times the GSD (Ground Sampling Distance)
value in the horizontal and vertical directions, respectively. For parallel
SfM, the proposed solution is a more reliable alternative.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Short-range forecasts of global precipitation using deep learning-augmented numerical weather prediction. (arXiv:2206.11669v2 [physics.ao-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11669">
<div class="article-summary-box-inner">
<span><p>Precipitation governs Earth's hydroclimate, and its daily spatiotemporal
fluctuations have major socioeconomic effects. Advances in Numerical weather
prediction (NWP) have been measured by the improvement of forecasts for various
physical fields such as temperature and pressure; however, large biases exist
in precipitation prediction. We augment the output of the well-known NWP model
CFSv2 with deep learning to create a hybrid model that improves short-range
global precipitation at 1-, 2-, and 3-day lead times. To hybridise, we address
the sphericity of the global data by using modified DLWP-CS architecture which
transforms all the fields to cubed-sphere projection. Dynamical model
precipitation and surface temperature outputs are fed into a modified DLWP-CS
(UNET) to forecast ground truth precipitation. While CFSv2's average bias is +5
to +7 mm/day over land, the multivariate deep learning model decreases it to
within -1 to +1 mm/day. Hurricane Katrina in 2005, Hurricane Ivan in 2004,
China floods in 2010, India floods in 2005, and Myanmar storm Nargis in 2008
are used to confirm the substantial enhancement in the skill for the hybrid
dynamical-deep learning model. CFSv2 typically shows a moderate to large bias
in the spatial pattern and overestimates the precipitation at short-range time
scales. The proposed deep learning augmented NWP model can address these biases
and vastly improve the spatial pattern and magnitude of predicted
precipitation. Deep learning enhanced CFSv2 reduces mean bias by 8x over
important land regions for 1 day lead compared to CFSv2. The spatio-temporal
deep learning system opens pathways to further the precision and accuracy in
global short-range precipitation forecasts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward Clinically Assisted Colorectal Polyp Recognition via Structured Cross-modal Representation Consistency. (arXiv:2206.11826v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11826">
<div class="article-summary-box-inner">
<span><p>The colorectal polyps classification is a critical clinical examination. To
improve the classification accuracy, most computer-aided diagnosis algorithms
recognize colorectal polyps by adopting Narrow-Band Imaging (NBI). However, the
NBI usually suffers from missing utilization in real clinic scenarios since the
acquisition of this specific image requires manual switching of the light mode
when polyps have been detected by using White-Light (WL) images. To avoid the
above situation, we propose a novel method to directly achieve accurate
white-light colonoscopy image classification by conducting structured
cross-modal representation consistency. In practice, a pair of multi-modal
images, i.e. NBI and WL, are fed into a shared Transformer to extract
hierarchical feature representations. Then a novel designed Spatial Attention
Module (SAM) is adopted to calculate the similarities between the class token
and patch tokens %from multi-levels for a specific modality image. By aligning
the class tokens and spatial attention maps of paired NBI and WL images at
different levels, the Transformer achieves the ability to keep both global and
local representation consistency for the above two modalities. Extensive
experimental results illustrate the proposed method outperforms the recent
studies with a margin, realizing multi-modal prediction with a single
Transformer while greatly improving the classification accuracy when only with
WL images.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-06-27 23:08:02.543406639 UTC">2022-06-27 23:08:02 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>