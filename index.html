<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-01-06T01:30:00Z">01-06</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">ZeroBERTo -- Leveraging Zero-Shot Text Classification by Topic Modeling. (arXiv:2201.01337v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01337">
<div class="article-summary-box-inner">
<span><p>Traditional text classification approaches often require a good amount of
labeled data, which is difficult to obtain, especially in restricted domains or
less widespread languages. This lack of labeled data has led to the rise of
low-resource methods, that assume low data availability in natural language
processing. Among them, zero-shot learning stands out, which consists of
learning a classifier without any previously labeled data. The best results
reported with this approach use language models such as Transformers, but fall
into two problems: high execution time and inability to handle long texts as
input. This paper proposes a new model, ZeroBERTo, which leverages an
unsupervised clustering step to obtain a compressed data representation before
the classification task. We show that ZeroBERTo has better performance for long
inputs and shorter execution time, outperforming XLM-R by about 12% in the F1
score in the FolhaUOL dataset. Keywords: Low-Resource NLP, Unlabeled data,
Zero-Shot Learning, Topic Modeling, Transformers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Hierarchical Model for Spoken Language Recognition. (arXiv:2201.01364v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01364">
<div class="article-summary-box-inner">
<span><p>Spoken language recognition (SLR) refers to the automatic process used to
determine the language present in a speech sample. SLR is an important task in
its own right, for example, as a tool to analyze or categorize large amounts of
multi-lingual data. Further, it is also an essential tool for selecting
downstream applications in a work flow, for example, to chose appropriate
speech recognition or machine translation models. SLR systems are usually
composed of two stages, one where an embedding representing the audio sample is
extracted and a second one which computes the final scores for each language.
In this work, we approach the SLR task as a detection problem and implement the
second stage as a probabilistic linear discriminant analysis (PLDA) model. We
show that discriminative training of the PLDA parameters gives large gains with
respect to the usual generative training. Further, we propose a novel
hierarchical approach were two PLDA models are trained, one to generate scores
for clusters of highly related languages and a second one to generate scores
conditional to each cluster. The final language detection scores are computed
as a combination of these two sets of scores. The complete model is trained
discriminatively to optimize a cross-entropy objective. We show that this
hierarchical approach consistently outperforms the non-hierarchical one for
detection of highly related languages, in many cases by large margins. We train
our systems on a collection of datasets including 100 languages and test them
both on matched and mismatched conditions, showing that the gains are robust to
condition mismatch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mining Adverse Drug Reactions from Unstructured Mediums at Scale. (arXiv:2201.01405v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01405">
<div class="article-summary-box-inner">
<span><p>Adverse drug reactions / events (ADR/ADE) have a major impact on patient
health and health care costs. Detecting ADR's as early as possible and sharing
them with regulators, pharma companies, and healthcare providers can prevent
morbidity and save many lives. While most ADR's are not reported via formal
channels, they are often documented in a variety of unstructured conversations
such as social media posts by patients, customer support call transcripts, or
CRM notes of meetings between healthcare providers and pharma sales reps. In
this paper, we propose a natural language processing (NLP) solution that
detects ADR's in such unstructured free-text conversations, which improves on
previous work in three ways. First, a new Named Entity Recognition (NER) model
obtains new state-of-the-art accuracy for ADR and Drug entity extraction on the
ADE, CADEC, and SMM4H benchmark datasets (91.75%, 78.76%, and 83.41% F1 scores
respectively). Second, two new Relation Extraction (RE) models are introduced -
one based on BioBERT while the other utilizing crafted features over a Fully
Connected Neural Network (FCNN) - are shown to perform on par with existing
state-of-the-art models, and outperform them when trained with a supplementary
clinician-annotated RE dataset. Third, a new text classification model, for
deciding if a conversation includes an ADR, obtains new state-of-the-art
accuracy on the CADEC dataset (86.69% F1 score). The complete solution is
implemented as a unified NLP pipeline in a production-grade library built on
top of Apache Spark, making it natively scalable and able to process millions
of batch or streaming records on commodity clusters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hyperparameter-free Continuous Learning for Domain Classification in Natural Language Understanding. (arXiv:2201.01420v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01420">
<div class="article-summary-box-inner">
<span><p>Domain classification is the fundamental task in natural language
understanding (NLU), which often requires fast accommodation to new emerging
domains. This constraint makes it impossible to retrain all previous domains,
even if they are accessible to the new model. Most existing continual learning
approaches suffer from low accuracy and performance fluctuation, especially
when the distributions of old and new data are significantly different. In
fact, the key real-world problem is not the absence of old data, but the
inefficiency to retrain the model with the whole old dataset. Is it potential
to utilize some old data to yield high accuracy and maintain stable
performance, while at the same time, without introducing extra hyperparameters?
In this paper, we proposed a hyperparameter-free continual learning model for
text data that can stably produce high performance under various environments.
Specifically, we utilize Fisher information to select exemplars that can
"record" key information of the original model. Also, a novel scheme called
dynamical weight consolidation is proposed to enable hyperparameter-free
learning during the retrain process. Extensive experiments demonstrate that
baselines suffer from fluctuated performance and therefore useless in practice.
On the contrary, our proposed model CCFI significantly and consistently
outperforms the best state-of-the-art method by up to 20% in average accuracy,
and each component of CCFI contributes effectively to overall performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Debiased Learning from Naturally Imbalanced Pseudo-Labels for Zero-Shot and Semi-Supervised Learning. (arXiv:2201.01490v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01490">
<div class="article-summary-box-inner">
<span><p>This work studies the bias issue of pseudo-labeling, a natural phenomenon
that widely occurs but often overlooked by prior research. Pseudo-labels are
generated when a classifier trained on source data is transferred to unlabeled
target data. We observe heavy long-tailed pseudo-labels when a semi-supervised
learning model FixMatch predicts labels on the unlabeled set even though the
unlabeled data is curated to be balanced. Without intervention, the training
model inherits the bias from the pseudo-labels and end up being sub-optimal. To
eliminate the model bias, we propose a simple yet effective method DebiasMatch,
comprising of an adaptive debiasing module and an adaptive marginal loss. The
strength of debiasing and the size of margins can be automatically adjusted by
making use of an online updated queue. Benchmarked on ImageNet-1K, DebiasMatch
significantly outperforms previous state-of-the-arts by more than 26% and 8.7%
on semi-supervised learning (0.2% annotated data) and zero-shot learning tasks
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Monitoring Energy Trends through Automatic Information Extraction. (arXiv:2201.01559v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01559">
<div class="article-summary-box-inner">
<span><p>Energy research is of crucial public importance but the use of computer
science technologies like automatic text processing and data management for the
energy domain is still rare. Employing these technologies in the energy domain
will be a significant contribution to the interdisciplinary topic of ``energy
informatics", just like the related progress within the interdisciplinary area
of ``bioinformatics". In this paper, we present the architecture of a Web-based
semantic system called EneMonIE (Energy Monitoring through Information
Extraction) for monitoring up-to-date energy trends through the use of
automatic, continuous, and guided information extraction from diverse types of
media available on the Web. The types of media handled by the system will
include online news articles, social media texts, online news videos, and
open-access scholarly papers and technical reports as well as various numeric
energy data made publicly available by energy organizations. The system will
utilize and contribute to the energy-related ontologies and its ultimate form
will comprise components for (i) text categorization, (ii) named entity
recognition, (iii) temporal expression extraction, (iv) event extraction, (v)
social network construction, (vi) sentiment analysis, (vii) information fusion
and summarization, (viii) media interlinking, and (ix) Web-based information
retrieval and visualization. Wits its diverse data sources, automatic text
processing capabilities, and presentation facilities open for public use;
EneMonIE will be an important source of distilled and concise information for
decision-makers including energy generation, transmission, and distribution
system operators, energy research centres, related investors and entrepreneurs
as well as for academicians, students, other individuals interested in the pace
of energy events and technologies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">All You Need In Sign Language Production. (arXiv:2201.01609v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01609">
<div class="article-summary-box-inner">
<span><p>Sign Language is the dominant form of communication language used in the deaf
and hearing-impaired community. To make an easy and mutual communication
between the hearing-impaired and the hearing communities, building a robust
system capable of translating the spoken language into sign language and vice
versa is fundamental. To this end, sign language recognition and production are
two necessary parts for making such a two-way system. Sign language recognition
and production need to cope with some critical challenges. In this survey, we
review recent advances in Sign Language Production (SLP) and related areas
using deep learning. To have more realistic perspectives to sign language, we
present an introduction to the Deaf culture, Deaf centers, psychological
perspective of sign language, the main differences between spoken language and
sign language. Furthermore, we present the fundamental components of a
bi-directional sign language translation system, discussing the main challenges
in this area. Also, the backbone architectures and methods in SLP are briefly
introduced and the proposed taxonomy on SLP is presented. Finally, a general
framework for SLP and performance evaluation, and also a discussion on the
recent developments, advantages, and limitations in SLP, commenting on possible
lines for future research are presented.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SMDT: Selective Memory-Augmented Neural Document Translation. (arXiv:2201.01631v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01631">
<div class="article-summary-box-inner">
<span><p>Existing document-level neural machine translation (NMT) models have
sufficiently explored different context settings to provide guidance for target
generation. However, little attention is paid to inaugurate more diverse
context for abundant context information. In this paper, we propose a Selective
Memory-augmented Neural Document Translation model to deal with documents
containing large hypothesis space of the context. Specifically, we retrieve
similar bilingual sentence pairs from the training corpus to augment global
context and then extend the two-stream attention model with selective mechanism
to capture local context and diverse global contexts. This unified approach
allows our model to be trained elegantly on three publicly document-level
machine translation datasets and significantly outperforms previous
document-level NMT models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relationship extraction for knowledge graph creation from biomedical literature. (arXiv:2201.01647v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01647">
<div class="article-summary-box-inner">
<span><p>Biomedical research is growing in such an exponential pace that scientists,
researchers and practitioners are no more able to cope with the amount of
published literature in the domain. The knowledge presented in the literature
needs to be systematized in such a ways that claims and hypothesis can be
easily found, accessed and validated. Knowledge graphs can provide such
framework for semantic knowledge representation from literature. However, in
order to build knowledge graph, it is necessary to extract knowledge in form of
relationships between biomedical entities and normalize both entities and
relationship types. In this paper, we present and compare few rule-based and
machine learning-based (Naive Bayes, Random Forests as examples of traditional
machine learning methods and T5-based model as an example of modern deep
learning) methods for scalable relationship extraction from biomedical
literature for the integration into the knowledge graphs. We examine how
resilient are these various methods to unbalanced and fairly small datasets,
showing that T5 model handles well both small datasets, due to its pre-training
on large C4 dataset as well as unbalanced data. The best performing model was
T5 model fine-tuned on balanced data, with reported F1-score of 0.88.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Strategies of Effective Digitization of Commentaries and Sub-commentaries: Towards the Construction of Textual History. (arXiv:2201.01693v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01693">
<div class="article-summary-box-inner">
<span><p>This paper describes additional aspects of a digital tool called the 'Textual
History Tool'. We describe its various salient features with special reference
to those of its features that may help the philologist digitize commentaries
and sub-commentaries on a text. This tool captures the historical evolution of
a text through various temporal stages, and interrelated data culled from
various types of related texts. We use the text of the K\=a\'sik\=avrtti (KV)
as a sample text, and with the help of philologists, we digitize the
commentaries available to us. We digitize the Ny\=asa (Ny), the Padama\~njar\=i
(Pm) and sub commentaries on the KV text known as the Tantraprad\=ipa (Tp), and
the Makaranda (Mk). We divide each commentary and sub-commentary into
functional units and describe the methodology and motivation behind the
functional unit division. Our functional unit division helps generate more
accurate phylogenetic trees for the text, based on distance methods using the
data entered in the tool.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Some Strategies to Capture Karaka-Yogyata with Special Reference to apadana. (arXiv:2201.01700v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01700">
<div class="article-summary-box-inner">
<span><p>In today's digital world language technology has gained importance. Several
softwares, have been developed and are available in the field of computational
linguistics. Such tools play a crucial role in making classical language texts
easily accessible. Some Indian philosophical schools have contributed towards
various techniques of verbal cognition to analyze sentences correctly. These
theories can be used to build computational tools for word sense disambiguation
(WSD). In the absence of WSD, one cannot have proper verbal cognition. These
theories considered the concept of 'Yogyat\=a' (congruity or compatibility) as
the indispensable cause of verbal cognition. In this work, we come up with some
insights on the basis of these theories to create a tool that will capture
Yogyat\=a of words. We describe the problem of ambiguity in a text and present
a method to resolve it computationally with the help of Yogyat\=a. Here, only
two major schools i.e. Ny\=aya and Vy\=akarana are considered. Our paper
attempts to show the implication of the creation of our tool in this area.
Also, our tool involves the creation of an 'ontological tag-set' as well as
strategies to mark up the lexicon. The introductory description of ablation is
also covered in this paper. Such strategies and some case studies shall form
the core of our paper.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi Document Reading Comprehension. (arXiv:2201.01706v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01706">
<div class="article-summary-box-inner">
<span><p>Reading Comprehension (RC) is a task of answering a question from a given
passage or a set of passages. In the case of multiple passages, the task is to
find the best possible answer to the question. Recent trials and experiments in
the field of Natural Language Processing (NLP) have proved that machines can be
provided with the ability to not only process the text in the passage and
understand its meaning to answer the question from the passage, but also can
surpass the Human Performance on many datasets such as Standford's Question
Answering Dataset (SQuAD). This paper presents a study on Reading Comprehension
and its evolution in Natural Language Processing over the past few decades. We
shall also study how the task of Single Document Reading Comprehension acts as
a building block for our Multi-Document Reading Comprehension System. In the
latter half of the paper, we'll be studying about a recently proposed model for
Multi-Document Reading Comprehension - RE3QA that is comprised of a Reader,
Retriever, and a Re-ranker based network to fetch the best possible answer from
a given set of passages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Atomized Search Length: Beyond User Models. (arXiv:2201.01745v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01745">
<div class="article-summary-box-inner">
<span><p>We argue that current IR metrics, modeled on optimizing user experience,
measure too narrow a portion of the IR space. If IR systems are weak, these
metrics undersample or completely filter out the deeper documents that need
improvement. If IR systems are relatively strong, these metrics undersample
deeper relevant documents that could underpin even stronger IR systems, ones
that could present content from tens or hundreds of relevant documents in a
user-digestible hierarchy or text summary. We reanalyze over 70 TREC tracks
from the past 28 years, showing that roughly half undersample top ranked
documents and nearly all undersample tail documents. We show that in the 2020
Deep Learning tracks, neural systems were actually near-optimal at top-ranked
documents, compared to only modest gains over BM25 on tail documents. Our
analysis is based on a simple new systems-oriented metric, 'atomized search
length', which is capable of accurately and evenly measuring all relevant
documents at any depth.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-automatic WordNet Linking using Word Embeddings. (arXiv:2201.01747v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01747">
<div class="article-summary-box-inner">
<span><p>Wordnets are rich lexico-semantic resources. Linked wordnets are extensions
of wordnets, which link similar concepts in wordnets of different languages.
Such resources are extremely useful in many Natural Language Processing (NLP)
applications, primarily those based on knowledge-based approaches. In such
approaches, these resources are considered as gold standard/oracle. Thus, it is
crucial that these resources hold correct information. Thereby, they are
created by human experts. However, manual maintenance of such resources is a
tedious and costly affair. Thus techniques that can aid the experts are
desirable. In this paper, we propose an approach to link wordnets. Given a
synset of the source language, the approach returns a ranked list of potential
candidate synsets in the target language from which the human expert can choose
the correct one(s). Our technique is able to retrieve a winner synset in the
top 10 ranked list for 60% of all synsets and 70% of noun synsets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards a Multi-modal, Multi-task Learning based Pre-training Framework for Document Representation Learning. (arXiv:2009.14457v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.14457">
<div class="article-summary-box-inner">
<span><p>Recent approaches in literature have exploited the multi-modal information in
documents (text, layout, image) to serve specific downstream document tasks.
However, they are limited by their - (i) inability to learn cross-modal
representations across text, layout and image dimensions for documents and (ii)
inability to process multi-page documents. Pre-training techniques have been
shown in Natural Language Processing (NLP) domain to learn generic textual
representations from large unlabelled datasets, applicable to various
downstream NLP tasks. In this paper, we propose a multi-task learning-based
framework that utilizes a combination of self-supervised and supervised
pre-training tasks to learn a generic document representation applicable to
various downstream document tasks. Specifically, we introduce Document Topic
Modelling and Document Shuffle Prediction as novel pre-training tasks to learn
rich image representations along with the text and layout representations for
documents. We utilize the Longformer network architecture as the backbone to
encode the multi-modal information from multi-page documents in an end-to-end
fashion. We showcase the applicability of our pre-training framework on a
variety of different real-world document tasks such as document classification,
document information extraction, and document retrieval. We evaluate our
framework on different standard document datasets and conduct exhaustive
experiments to compare performance against various ablations of our framework
and state-of-the-art baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting of a Patient's Condition From Clinical Narratives Using Natural Language Representation. (arXiv:2104.03969v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03969">
<div class="article-summary-box-inner">
<span><p>The rapid progress in clinical data management systems and artificial
intelligence approaches enable the era of personalized medicine. Intensive care
units (ICUs) are the ideal clinical research environment for such development
because they collect many clinical data and are highly computerized
environments. We designed a retrospective clinical study on a prospective ICU
database using clinical natural language to help in the early diagnosis of
heart failure in critically ill children. The methodology consisted of
empirical experiments of a learning algorithm to learn the hidden
interpretation and presentation of the French clinical note data. This study
included 1386 patients' clinical notes with 5444 single lines of notes. There
were 1941 positive cases (36 % of total) and 3503 negative cases classified by
two independent physicians using a standardized approach. The multilayer
perceptron neural network outperforms other discriminative and generative
classifiers. Consequently, the proposed framework yields an overall
classification performance with 89 % accuracy, 88 % recall, and 89 % precision.
This study successfully applied learning representation and machine learning
algorithms to detect heart failure from clinical natural language in a single
French institution. Further work is needed to use the same methodology in other
institutions and other languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Query Interpretations from Entity-Linked Segmentations. (arXiv:2105.08581v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08581">
<div class="article-summary-box-inner">
<span><p>Web search queries can be ambiguous: is "source of the nile" meant to find
information on the actual river or on a board game of that name? We tackle this
problem by deriving entity-based query interpretations: given some query, the
task is to derive all reasonable ways of linking suitable parts of the query to
semantically compatible entities in a background knowledge base. Our suggested
approach focuses on effectiveness but also on efficiency since web search
response times should not exceed some hundreds of milliseconds. In our
approach, we use query segmentation as a pre-processing step that finds
promising segment-based "interpretation skeletons". The individual segments
from these skeletons are then linked to entities from a knowledge base and the
reasonable combinations are ranked in a final step. An experimental comparison
on a combined corpus of all existing query entity linking datasets shows our
approach to have a better interpretation accuracy at a better run time than the
previously most effective methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VILA: Improving Structured Content Extraction from Scientific PDFs Using Visual Layout Groups. (arXiv:2106.00676v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00676">
<div class="article-summary-box-inner">
<span><p>Accurately extracting structured content from PDFs is a critical first step
for NLP over scientific papers. Recent work has improved extraction accuracy by
incorporating elementary layout information, e.g., each token's 2D position on
the page, into language model pretraining. We introduce new methods that
explicitly model VIsual LAyout (VILA) groups, i.e., text lines or text blocks,
to further improve performance. In our I-VILA approach, we show that simply
inserting special tokens denoting layout group boundaries into model inputs can
lead to a 1.9% Macro F1 improvement in token classification. In the H-VILA
approach, we show that hierarchical encoding of layout-groups can result in
up-to 47% inference time reduction with less than 0.8% Macro F1 loss. Unlike
prior layout-aware approaches, our methods do not require expensive additional
pretraining, only fine-tuning, which we show can reduce training cost by up to
95%. Experiments are conducted on a newly curated evaluation suite, S2-VLUE,
that unifies existing automatically-labeled datasets and includes a new dataset
of manual annotations covering diverse papers from 19 scientific disciplines.
Pre-trained weights, benchmark datasets, and source code are available at
https://github.com/allenai/VILA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Does Knowledge Graph Embedding Extrapolate to Unseen Data: a Semantic Evidence View. (arXiv:2109.11800v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11800">
<div class="article-summary-box-inner">
<span><p>Knowledge Graph Embedding (KGE) aims to learn representations for entities
and relations. Most KGE models have gained great success, especially on
extrapolation scenarios. Specifically, given an unseen triple (h, r, t), a
trained model can still correctly predict t from (h, r, ?), or h from (?, r,
t), such extrapolation ability is impressive. However, most existing KGE works
focus on the design of delicate triple modeling function, which mainly tells us
how to measure the plausibility of observed triples, but offers limited
explanation of why the methods can extrapolate to unseen data, and what are the
important factors to help KGE extrapolate. Therefore in this work, we attempt
to study the KGE extrapolation of two problems: 1. How does KGE extrapolate to
unseen data? 2. How to design the KGE model with better extrapolation ability?
For the problem 1, we first discuss the impact factors for extrapolation and
from relation, entity and triple level respectively, propose three Semantic
Evidences (SEs), which can be observed from train set and provide important
semantic information for extrapolation. Then we verify the effectiveness of SEs
through extensive experiments on several typical KGE methods. For the problem
2, to make better use of the three levels of SE, we propose a novel GNN-based
KGE model, called Semantic Evidence aware Graph Neural Network (SE-GNN). In
SE-GNN, each level of SE is modeled explicitly by the corresponding neighbor
pattern, and merged sufficiently by the multi-layer aggregation, which
contributes to obtaining more extrapolative knowledge representation. Finally,
through extensive experiments on FB15k-237 and WN18RR datasets, we show that
SE-GNN achieves state-of-the-art performance on Knowledge Graph Completion task
and performs a better extrapolation ability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Simple but Effective Bidirectional Framework for Relational Triple Extraction. (arXiv:2112.04940v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.04940">
<div class="article-summary-box-inner">
<span><p>Tagging based relational triple extraction methods are attracting growing
research attention recently. However, most of these methods take a
unidirectional extraction framework that first extracts all subjects and then
extracts objects and relations simultaneously based on the subjects extracted.
This framework has an obvious deficiency that it is too sensitive to the
extraction results of subjects. To overcome this deficiency, we propose a
bidirectional extraction framework based method that extracts triples based on
the entity pairs extracted from two complementary directions. Concretely, we
first extract all possible subject-object pairs from two paralleled directions.
These two extraction directions are connected by a shared encoder component,
thus the extraction features from one direction can flow to another direction
and vice versa. By this way, the extractions of two directions can boost and
complement each other. Next, we assign all possible relations for each entity
pair by a biaffine model. During training, we observe that the share structure
will lead to a convergence rate inconsistency issue which is harmful to
performance. So we propose a share-aware learning mechanism to address it. We
evaluate the proposed model on multiple benchmark datasets. Extensive
experimental results show that the proposed model is very effective and it
achieves state-of-the-art results on all of these datasets. Moreover,
experiments show that both the proposed bidirectional extraction framework and
the share-aware learning mechanism have good adaptability and can be used to
improve the performance of other tagging based methods. The source code of our
work is available at: https://github.com/neukg/BiRTE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-supervised Stance Detection of Tweets Via Distant Network Supervision. (arXiv:2201.00614v2 [cs.SI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.00614">
<div class="article-summary-box-inner">
<span><p>Detecting and labeling stance in social media text is strongly motivated by
hate speech detection, poll prediction, engagement forecasting, and concerted
propaganda detection. Today's best neural stance detectors need large volumes
of training data, which is difficult to curate given the fast-changing
landscape of social media text and issues on which users opine. Homophily
properties over the social network provide strong signal of coarse-grained
user-level stance. But semi-supervised approaches for tweet-level stance
detection fail to properly leverage homophily. In light of this, We present
SANDS, a new semi-supervised stance detector. SANDS starts from very few
labeled tweets. It builds multiple deep feature views of tweets. It also uses a
distant supervision signal from the social network to provide a surrogate loss
signal to the component learners. We prepare two new tweet datasets comprising
over 236,000 politically tinted tweets from two demographics (US and India)
posted by over 87,000 users, their follower-followee graph, and over 8,000
tweets annotated by linguists. SANDS achieves a macro-F1 score of 0.55 (0.49)
on US (India)-based datasets, outperforming 17 baselines (including variants of
SANDS) substantially, particularly for minority stance labels and noisy text.
Numerous ablation experiments on SANDS disentangle the dynamics of textual and
network-propagated stance signals.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Linear Variational State Space Filtering. (arXiv:2201.01353v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01353">
<div class="article-summary-box-inner">
<span><p>We introduce Variational State-Space Filters (VSSF), a new method for
unsupervised learning, identification, and filtering of latent Markov state
space models from raw pixels. We present a theoretically sound framework for
latent state space inference under heterogeneous sensor configurations. The
resulting model can integrate an arbitrary subset of the sensor measurements
used during training, enabling the learning of semi-supervised state
representations, thus enforcing that certain components of the learned latent
state space to agree with interpretable measurements. From this framework we
derive L-VSSF, an explicit instantiation of this model with linear latent
dynamics and Gaussian distribution parameterizations. We experimentally
demonstrate L-VSSF's ability to filter in latent space beyond the sequence
length of the training dataset across several different test environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DenseTact: Optical Tactile Sensor for Dense Shape Reconstruction. (arXiv:2201.01367v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01367">
<div class="article-summary-box-inner">
<span><p>Increasing the performance of tactile sensing in robots enables versatile,
in-hand manipulation. Vision-based tactile sensors have been widely used as
rich tactile feedback has been shown to be correlated with increased
performance in manipulation tasks. Existing tactile sensor solutions with high
resolution have limitations that include low accuracy, expensive components, or
lack of scalability. In this paper, an inexpensive, scalable, and compact
tactile sensor with high-resolution surface deformation modeling for surface
reconstruction of the 3D sensor surface is proposed. By measuring the image
from the fisheye camera, it is shown that the sensor can successfully estimate
the surface deformation in real-time (1.8ms) by using deep convolutional neural
networks. This sensor in its design and sensing abilities represents a
significant step toward better object in-hand localization, classification, and
surface estimation all enabled by high-resolution shape reconstruction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Processing Methods for Coronal Hole Segmentation, Matching, and Map Classification. (arXiv:2201.01380v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01380">
<div class="article-summary-box-inner">
<span><p>The paper presents the results from a multi-year effort to develop and
validate image processing methods for selecting the best physical models based
on solar image observations. The approach consists of selecting the physical
models based on their agreement with coronal holes extracted from the images.
Ultimately, the goal is to use physical models to predict geomagnetic storms.
We decompose the problem into three subproblems: (i) coronal hole segmentation
based on physical constraints, (ii) matching clusters of coronal holes between
different maps, and (iii) physical map classification. For segmenting coronal
holes, we develop a multi-modal method that uses segmentation maps from three
different methods to initialize a level-set method that evolves the initial
coronal hole segmentation to the magnetic boundary. Then, we introduce a new
method based on Linear Programming for matching clusters of coronal holes. The
final matching is then performed using Random Forests. The methods were
carefully validated using consensus maps derived from multiple readers, manual
clustering, manual map classification, and method validation for 50 maps. The
proposed multi-modal segmentation method significantly outperformed SegNet,
U-net, Henney-Harvey, and FCN by providing accurate boundary detection.
Overall, the method gave a 95.5% map classification accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Approach to Addressing Zero-Shot Learning Problem. (arXiv:2201.01391v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01391">
<div class="article-summary-box-inner">
<span><p>In recent years, self-supervised learning has had significant success in
applications involving computer vision and natural language processing. The
type of pretext task is important to this boost in performance. One common
pretext task is the measure of similarity and dissimilarity between pairs of
images. In this scenario, the two images that make up the negative pair are
visibly different to humans. However, in entomology, species are nearly
indistinguishable and thus hard to differentiate. In this study, we explored
the performance of a Siamese neural network using contrastive loss by learning
to push apart embeddings of bumblebee species pair that are dissimilar, and
pull together similar embeddings. Our experimental results show a 61% F1-score
on zero-shot instances, a performance showing 11% improvement on samples of
classes that share intersections with the training set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Corrupting Data to Remove Deceptive Perturbation: Using Preprocessing Method to Improve System Robustness. (arXiv:2201.01399v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01399">
<div class="article-summary-box-inner">
<span><p>Although deep neural networks have achieved great performance on
classification tasks, recent studies showed that well trained networks can be
fooled by adding subtle noises. This paper introduces a new approach to improve
neural network robustness by applying the recovery process on top of the
naturally trained classifier. In this approach, images will be intentionally
corrupted by some significant operator and then be recovered before passing
through the classifiers. SARGAN -- an extension on Generative Adversarial
Networks (GAN) is capable of denoising radar signals. This paper will show that
SARGAN can also recover corrupted images by removing the adversarial effects.
Our results show that this approach does improve the performance of naturally
trained networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fusing Convolutional Neural Network and Geometric Constraint for Image-based Indoor Localization. (arXiv:2201.01408v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01408">
<div class="article-summary-box-inner">
<span><p>This paper proposes a new image-based localization framework that explicitly
localizes the camera/robot by fusing Convolutional Neural Network (CNN) and
sequential images' geometric constraints. The camera is localized using a
single or few observed images and training images with 6-degree-of-freedom pose
labels. A Siamese network structure is adopted to train an image descriptor
network, and the visually similar candidate image in the training set is
retrieved to localize the testing image geometrically. Meanwhile, a
probabilistic motion model predicts the pose based on a constant velocity
assumption. The two estimated poses are finally fused using their uncertainties
to yield an accurate pose prediction. This method leverages the geometric
uncertainty and is applicable in indoor scenarios predominated by diffuse
illumination. Experiments on simulation and real data sets demonstrate the
efficiency of our proposed method. The results further show that combining the
CNN-based framework with geometric constraint achieves better accuracy when
compared with CNN-only methods, especially when the training data size is
small.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Synthesizing Tensor Transformations for Visual Self-attention. (arXiv:2201.01410v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01410">
<div class="article-summary-box-inner">
<span><p>Self-attention shows outstanding competence in capturing long-range
relationships while enhancing performance on vision tasks, such as image
classification and image captioning. However, the self-attention module highly
relies on the dot product multiplication and dimension alignment among
query-key-value features, which cause two problems: (1) The dot product
multiplication results in exhaustive and redundant computation. (2) Due to the
visual feature map often appearing as a multi-dimensional tensor, reshaping the
scale of the tensor feature to adapt to the dimension alignment might destroy
the internal structure of the tensor feature map. To address these problems,
this paper proposes a self-attention plug-in module with its variants, namely,
Synthesizing Tensor Transformations (STT), for directly processing image tensor
features. Without computing the dot-product multiplication among
query-key-value, the basic STT is composed of the tensor transformation to
learn the synthetic attention weight from visual information. The effectiveness
of STT series is validated on the image classification and image caption.
Experiments show that the proposed STT achieves competitive performance while
keeping robustness compared to self-attention based above vision tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Problem-dependent attention and effort in neural networks with an application to image resolution. (arXiv:2201.01415v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01415">
<div class="article-summary-box-inner">
<span><p>This paper introduces a new neural network-based estimation approach that is
inspired by the biological phenomenon whereby humans and animals vary the
levels of attention and effort that they dedicate to a problem depending upon
its difficulty. The proposed approach leverages alternate models' internal
levels of confidence in their own projections. If the least costly model is
confident in its classification, then that is the classification used; if not,
the model with the next lowest cost of implementation is run, and so on. This
use of successively more complex models -- together with the models' internal
propensity scores to evaluate their likelihood of being correct -- makes it
possible to substantially reduce resource use while maintaining high standards
for classification accuracy. The approach is applied to the digit recognition
problem from Google's Street View House Numbers dataset, using Multilayer
Perceptron (MLP) neural networks trained on high- and low-resolution versions
of the digit images. The algorithm examines the low-resolution images first,
only moving to higher resolution images if the classification from the initial
low-resolution pass does not have a high degree of confidence. For the MLPs
considered here, this sequential approach enables a reduction in resource usage
of more than 50\% without any sacrifice in classification accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Latent Vector Expansion using Autoencoder for Anomaly Detection. (arXiv:2201.01416v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01416">
<div class="article-summary-box-inner">
<span><p>Deep learning methods can classify various unstructured data such as images,
language, and voice as input data. As the task of classifying anomalies becomes
more important in the real world, various methods exist for classifying using
deep learning with data collected in the real world. As the task of classifying
anomalies becomes more important in the real world, there are various methods
for classifying using deep learning with data collected in the real world.
Among the various methods, the representative approach is a method of
extracting and learning the main features based on a transition model from
pre-trained models, and a method of learning an autoencoderbased structure only
with normal data and classifying it as abnormal through a threshold value.
However, if the dataset is imbalanced, even the state-of-the-arts models do not
achieve good performance. This can be addressed by augmenting normal and
abnormal features in imbalanced data as features with strong distinction. We
use the features of the autoencoder to train latent vectors from low to high
dimensionality. We train normal and abnormal data as a feature that has a
strong distinction among the features of imbalanced data. We propose a latent
vector expansion autoencoder model that improves classification performance at
imbalanced data. The proposed method shows performance improvement compared to
the basic autoencoder using imbalanced anomaly dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Advancing 3D Medical Image Analysis with Variable Dimension Transform based Supervised 3D Pre-training. (arXiv:2201.01426v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01426">
<div class="article-summary-box-inner">
<span><p>The difficulties in both data acquisition and annotation substantially
restrict the sample sizes of training datasets for 3D medical imaging
applications. As a result, constructing high-performance 3D convolutional
neural networks from scratch remains a difficult task in the absence of a
sufficient pre-training parameter. Previous efforts on 3D pre-training have
frequently relied on self-supervised approaches, which use either predictive or
contrastive learning on unlabeled data to build invariant 3D representations.
However, because of the unavailability of large-scale supervision information,
obtaining semantically invariant and discriminative representations from these
learning frameworks remains problematic. In this paper, we revisit an
innovative yet simple fully-supervised 3D network pre-training framework to
take advantage of semantic supervisions from large-scale 2D natural image
datasets. With a redesigned 3D network architecture, reformulated natural
images are used to address the problem of data scarcity and develop powerful 3D
representations. Comprehensive experiments on four benchmark datasets
demonstrate that the proposed pre-trained models can effectively accelerate
convergence while also improving accuracy for a variety of 3D medical imaging
tasks such as classification, segmentation and detection. In addition, as
compared to training from scratch, it can save up to 60% of annotation efforts.
On the NIH DeepLesion dataset, it likewise achieves state-of-the-art detection
performance, outperforming earlier self-supervised and fully-supervised
pre-training approaches, as well as methods that do training from scratch. To
facilitate further development of 3D medical models, our code and pre-trained
model weights are publicly available at https://github.com/urmagicsmine/CSPR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention-based Dual Supervised Decoder for RGBD Semantic Segmentation. (arXiv:2201.01427v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01427">
<div class="article-summary-box-inner">
<span><p>Encoder-decoder models have been widely used in RGBD semantic segmentation,
and most of them are designed via a two-stream network. In general, jointly
reasoning the color and geometric information from RGBD is beneficial for
semantic segmentation. However, most existing approaches fail to
comprehensively utilize multimodal information in both the encoder and decoder.
In this paper, we propose a novel attention-based dual supervised decoder for
RGBD semantic segmentation. In the encoder, we design a simple yet effective
attention-based multimodal fusion module to extract and fuse deeply multi-level
paired complementary information. To learn more robust deep representations and
rich multi-modal information, we introduce a dual-branch decoder to effectively
leverage the correlations and complementary cues of different tasks. Extensive
experiments on NYUDv2 and SUN-RGBD datasets demonstrate that our method
achieves superior performance against the state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural KEM: A Kernel Method with Deep Coefficient Prior for PET Image Reconstruction. (arXiv:2201.01443v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01443">
<div class="article-summary-box-inner">
<span><p>Image reconstruction of low-count positron emission tomography (PET) data is
challenging. Kernel methods address the challenge by incorporating image prior
information in the forward model of iterative PET image reconstruction. The
kernelized expectation-maximization (KEM) algorithm has been developed and
demonstrated to be effective and easy to implement. A common approach for a
further improvement of the kernel method would be adding an explicit
regularization, which however leads to a complex optimization problem. In this
paper, we propose an implicit regularization for the kernel method by using a
deep coefficient prior, which represents the kernel coefficient image in the
PET forward model using a convolutional neural-network. To solve the
maximum-likelihood neural network-based reconstruction problem, we apply the
principle of optimization transfer to derive a neural KEM algorithm. Each
iteration of the algorithm consists of two separate steps: a KEM step for image
update from the projection data and a deep-learning step in the image domain
for updating the kernel coefficient image using the neural network. This
optimization algorithm is guaranteed to monotonically increase the data
likelihood. The results from computer simulations and real patient data have
demonstrated that the neural KEM can outperform existing KEM and deep image
prior methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning-Based Sparse Whole-Slide Image Analysis for the Diagnosis of Gastric Intestinal Metaplasia. (arXiv:2201.01449v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01449">
<div class="article-summary-box-inner">
<span><p>In recent years, deep learning has successfully been applied to automate a
wide variety of tasks in diagnostic histopathology. However, fast and reliable
localization of small-scale regions-of-interest (ROI) has remained a key
challenge, as discriminative morphologic features often occupy only a small
fraction of a gigapixel-scale whole-slide image (WSI). In this paper, we
propose a sparse WSI analysis method for the rapid identification of high-power
ROI for WSI-level classification. We develop an evaluation framework inspired
by the early classification literature, in order to quantify the tradeoff
between diagnostic performance and inference time for sparse analytic
approaches. We test our method on a common but time-consuming task in pathology
- that of diagnosing gastric intestinal metaplasia (GIM) on hematoxylin and
eosin (H&amp;E)-stained slides from endoscopic biopsy specimens. GIM is a
well-known precursor lesion along the pathway to development of gastric cancer.
We performed a thorough evaluation of the performance and inference time of our
approach on a test set of GIM-positive and GIM-negative WSI, finding that our
method successfully detects GIM in all positive WSI, with a WSI-level
classification area under the receiver operating characteristic curve (AUC) of
0.98 and an average precision (AP) of 0.95. Furthermore, we show that our
method can attain these metrics in under one minute on a standard CPU. Our
results are applicable toward the goal of developing neural networks that can
easily be deployed in clinical settings to support pathologists in quickly
localizing and diagnosing small-scale morphologic features in WSI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust photon-efficient imaging using a pixel-wise residual shrinkage network. (arXiv:2201.01453v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01453">
<div class="article-summary-box-inner">
<span><p>Single-photon light detection and ranging (LiDAR) has been widely applied to
3D imaging in challenging scenarios. However, limited signal photon counts and
high noises in the collected data have posed great challenges for predicting
the depth image precisely. In this paper, we propose a pixel-wise residual
shrinkage network for photon-efficient imaging from high-noise data, which
adaptively generates the optimal thresholds for each pixel and denoises the
intermediate features by soft thresholding. Besides, redefining the
optimization target as pixel-wise classification provides a sharp advantage in
producing confident and accurate depth estimation when compared with existing
research. Comprehensive experiments conducted on both simulated and real-world
datasets demonstrate that the proposed model outperforms the state-of-the-arts
and maintains robust imaging performance under different signal-to-noise ratios
including the extreme case of 1:100.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-SRN: Structure-Preserving Super-Resolution Network with Cross Convolution. (arXiv:2201.01458v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01458">
<div class="article-summary-box-inner">
<span><p>It is challenging to restore low-resolution (LR) images to super-resolution
(SR) images with correct and clear details. Existing deep learning works almost
neglect the inherent structural information of images, which acts as an
important role for visual perception of SR results. In this paper, we design a
hierarchical feature exploitation network to probe and preserve structural
information in a multi-scale feature fusion manner. First, we propose a cross
convolution upon traditional edge detectors to localize and represent edge
features. Then, cross convolution blocks (CCBs) are designed with feature
normalization and channel attention to consider the inherent correlations of
features. Finally, we leverage multi-scale feature fusion group (MFFG) to embed
the cross convolution blocks and develop the relations of structural features
in different scales hierarchically, invoking a lightweight structure-preserving
network named as Cross-SRN. Experimental results demonstrate the Cross-SRN
achieves competitive or superior restoration performances against the
state-of-the-art methods with accurate and clear structural details. Moreover,
we set a criterion to select images with rich structural textures. The proposed
Cross-SRN outperforms the state-of-the-art methods on the selected benchmark,
which demonstrates that our network has a significant advantage in preserving
edges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Challenges of Artificial Intelligence -- From Machine Learning and Computer Vision to Emotional Intelligence. (arXiv:2201.01466v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01466">
<div class="article-summary-box-inner">
<span><p>Artificial intelligence (AI) has become a part of everyday conversation and
our lives. It is considered as the new electricity that is revolutionizing the
world. AI is heavily invested in both industry and academy. However, there is
also a lot of hype in the current AI debate. AI based on so-called deep
learning has achieved impressive results in many problems, but its limits are
already visible. AI has been under research since the 1940s, and the industry
has seen many ups and downs due to over-expectations and related
disappointments that have followed.
</p>
<p>The purpose of this book is to give a realistic picture of AI, its history,
its potential and limitations. We believe that AI is a helper, not a ruler of
humans. We begin by describing what AI is and how it has evolved over the
decades. After fundamentals, we explain the importance of massive data for the
current mainstream of artificial intelligence. The most common representations
for AI, methods, and machine learning are covered. In addition, the main
application areas are introduced. Computer vision has been central to the
development of AI. The book provides a general introduction to computer vision,
and includes an exposure to the results and applications of our own research.
Emotions are central to human intelligence, but little use has been made in AI.
We present the basics of emotional intelligence and our own research on the
topic. We discuss super-intelligence that transcends human understanding,
explaining why such achievement seems impossible on the basis of present
knowledge,and how AI could be improved. Finally, a summary is made of the
current state of AI and what to do in the future. In the appendix, we look at
the development of AI education, especially from the perspective of contents at
our own university.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sign Language Recognition System using TensorFlow Object Detection API. (arXiv:2201.01486v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01486">
<div class="article-summary-box-inner">
<span><p>Communication is defined as the act of sharing or exchanging information,
ideas or feelings. To establish communication between two people, both of them
are required to have knowledge and understanding of a common language. But in
the case of deaf and dumb people, the means of communication are different.
Deaf is the inability to hear and dumb is the inability to speak. They
communicate using sign language among themselves and with normal people but
normal people do not take seriously the importance of sign language. Not
everyone possesses the knowledge and understanding of sign language which makes
communication difficult between a normal person and a deaf and dumb person. To
overcome this barrier, one can build a model based on machine learning. A model
can be trained to recognize different gestures of sign language and translate
them into English. This will help a lot of people in communicating and
conversing with deaf and dumb people. The existing Indian Sing Language
Recognition systems are designed using machine learning algorithms with single
and double-handed gestures but they are not real-time. In this paper, we
propose a method to create an Indian Sign Language dataset using a webcam and
then using transfer learning, train a TensorFlow model to create a real-time
Sign Language Recognition system. The system achieves a good level of accuracy
even with a limited size dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exemplar-free Class Incremental Learning via Discriminative and Comparable One-class Classifiers. (arXiv:2201.01488v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01488">
<div class="article-summary-box-inner">
<span><p>The exemplar-free class incremental learning requires classification models
to learn new class knowledge incrementally without retaining any old samples.
Recently, the framework based on parallel one-class classifiers (POC), which
trains a one-class classifier (OCC) independently for each category, has
attracted extensive attention, since it can naturally avoid catastrophic
forgetting. POC, however, suffers from weak discriminability and comparability
due to its independent training strategy for different OOCs. To meet this
challenge, we propose a new framework, named Discriminative and Comparable
One-class classifiers for Incremental Learning (DisCOIL). DisCOIL follows the
basic principle of POC, but it adopts variational auto-encoders (VAE) instead
of other well-established one-class classifiers (e.g. deep SVDD), because a
trained VAE can not only identify the probability of an input sample belonging
to a class but also generate pseudo samples of the class to assist in learning
new tasks. With this advantage, DisCOIL trains a new-class VAE in contrast with
the old-class VAEs, which forces the new-class VAE to reconstruct better for
new-class samples but worse for the old-class pseudo samples, thus enhancing
the comparability. Furthermore, DisCOIL introduces a hinge reconstruction loss
to ensure the discriminability. We evaluate our method extensively on MNIST,
CIFAR10, and Tiny-ImageNet. The experimental results show that DisCOIL achieves
state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Debiased Learning from Naturally Imbalanced Pseudo-Labels for Zero-Shot and Semi-Supervised Learning. (arXiv:2201.01490v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01490">
<div class="article-summary-box-inner">
<span><p>This work studies the bias issue of pseudo-labeling, a natural phenomenon
that widely occurs but often overlooked by prior research. Pseudo-labels are
generated when a classifier trained on source data is transferred to unlabeled
target data. We observe heavy long-tailed pseudo-labels when a semi-supervised
learning model FixMatch predicts labels on the unlabeled set even though the
unlabeled data is curated to be balanced. Without intervention, the training
model inherits the bias from the pseudo-labels and end up being sub-optimal. To
eliminate the model bias, we propose a simple yet effective method DebiasMatch,
comprising of an adaptive debiasing module and an adaptive marginal loss. The
strength of debiasing and the size of margins can be automatically adjusted by
making use of an online updated queue. Benchmarked on ImageNet-1K, DebiasMatch
significantly outperforms previous state-of-the-arts by more than 26% and 8.7%
on semi-supervised learning (0.2% annotated data) and zero-shot learning tasks
respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FAVER: Blind Quality Prediction of Variable Frame Rate Videos. (arXiv:2201.01492v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01492">
<div class="article-summary-box-inner">
<span><p>Video quality assessment (VQA) remains an important and challenging problem
that affects many applications at the widest scales. Recent advances in mobile
devices and cloud computing techniques have made it possible to capture,
process, and share high resolution, high frame rate (HFR) videos across the
Internet nearly instantaneously. Being able to monitor and control the quality
of these streamed videos can enable the delivery of more enjoyable content and
perceptually optimized rate control. Accordingly, there is a pressing need to
develop VQA models that can be deployed at enormous scales. While some recent
effects have been applied to full-reference (FR) analysis of variable frame
rate and HFR video quality, the development of no-reference (NR) VQA algorithms
targeting frame rate variations has been little studied. Here, we propose a
first-of-a-kind blind VQA model for evaluating HFR videos, which we dub the
Framerate-Aware Video Evaluator w/o Reference (FAVER). FAVER uses extended
models of spatial natural scene statistics that encompass space-time
wavelet-decomposed video signals, to conduct efficient frame rate sensitive
quality prediction. Our extensive experiments on several HFR video quality
datasets show that FAVER outperforms other blind VQA algorithms at a reasonable
computational cost. To facilitate reproducible research and public evaluation,
an implementation of FAVER is being made freely available online:
\url{https://github.com/uniqzheng/HFR-BVQA}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Object Detection, Multi-object Tracking, and Re-Identification for Disaster Response Drones. (arXiv:2201.01494v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01494">
<div class="article-summary-box-inner">
<span><p>We aim to detect and identify multiple objects using multiple cameras and
computer vision for disaster response drones. The major challenges are taming
detection errors, resolving ID switching and fragmentation, adapting to
multi-scale features and multiple views with global camera motion. Two simple
approaches are proposed to solve these issues. One is a fast multi-camera
system that added a tracklet association, and the other is incorporating a
high-performance detector and tracker to resolve restrictions. (...) The
accuracy of our first approach (85.71%) is slightly improved compared to our
baseline, FairMOT (85.44%) in the validation dataset. In the final results
calculated based on L2-norm error, the baseline was 48.1, while the proposed
model combination was 34.9, which is a great reduction of error by a margin of
27.4%. In the second approach, although DeepSORT only processes a quarter of
all frames due to hardware and time limitations, our model with DeepSORT
(42.9%) outperforms FairMOT (71.4%) in terms of recall. Both of our models
ranked second and third place in the `AI Grand Challenge' organized by the
Korean Ministry of Science and ICT in 2020 and 2021, respectively. The source
codes are publicly available at these URLs
(github.com/mlvlab/drone_ai_challenge, github.com/mlvlab/Drone_Task1,
github.com/mlvlab/Rony2_task3, github.com/mlvlab/Drone_task4).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Depth Estimation for Multi-View Stereo: A Unified Representation and Focal Loss. (arXiv:2201.01501v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01501">
<div class="article-summary-box-inner">
<span><p>Depth estimation is solved as a regression or classification problem in
existing learning-based multi-view stereo methods. Although these two
representations have recently demonstrated their excellent performance, they
still have apparent shortcomings, e.g., regression methods tend to overfit due
to the indirect learning cost volume, and classification methods cannot
directly infer the exact depth due to its discrete prediction. In this paper,
we propose a novel representation, termed Unification, to unify the advantages
of regression and classification. It can directly constrain the cost volume
like classification methods, but also realize the sub-pixel depth prediction
like regression methods. To excavate the potential of unification, we design a
new loss function named Unified Focal Loss, which is more uniform and
reasonable to combat the challenge of sample imbalance. Combining these two
unburdened modules, we present a coarse-to-fine framework, that we call
UniMVSNet. The results of ranking first on both DTU and Tanks and Temples
benchmarks verify that our model not only performs the best but also has the
best generalization ability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Uniform Point Distribution in Feature-preserving Point Cloud Filtering. (arXiv:2201.01503v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01503">
<div class="article-summary-box-inner">
<span><p>As a popular representation of 3D data, point cloud may contain noise and
need to be filtered before use. Existing point cloud filtering methods either
cannot preserve sharp features or result in uneven point distribution in the
filtered output. To address this problem, this paper introduces a point cloud
filtering method that considers both point distribution and feature
preservation during filtering. The key idea is to incorporate a repulsion term
with a data term in energy minimization. The repulsion term is responsible for
the point distribution, while the data term is to approximate the noisy
surfaces while preserving the geometric features. This method is capable of
handling models with fine-scale features and sharp features. Extensive
experiments show that our method yields better results with a more uniform
point distribution ($5.8\times10^{-5}$ Chamfer Distance on average) in seconds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Culture-to-Culture Image Translation with Generative Adversarial Networks. (arXiv:2201.01565v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01565">
<div class="article-summary-box-inner">
<span><p>This article introduces the concept of image "culturization", i.e., defined
as the process of altering the "brushstroke of cultural features" that make
objects perceived as belonging to a given culture while preserving their
functionalities. First, we propose a pipeline for translating objects' images
from a source to a target cultural domain based on Generative Adversarial
Networks (GAN). Then, we gather data through an online questionnaire to test
four hypotheses concerning the preferences of Italian participants towards
objects and environments belonging to different cultures. As expected, results
depend on individual tastes and preference: however, they are in line with our
conjecture that some people, during the interaction with a robot or another
intelligent system, might prefer to be shown images whose cultural domain has
been modified to match their cultural background.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning True Rate-Distortion-Optimization for End-To-End Image Compression. (arXiv:2201.01586v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01586">
<div class="article-summary-box-inner">
<span><p>Even though rate-distortion optimization is a crucial part of traditional
image and video compression, not many approaches exist which transfer this
concept to end-to-end-trained image compression. Most frameworks contain static
compression and decompression models which are fixed after training, so
efficient rate-distortion optimization is not possible. In a previous work, we
proposed RDONet, which enables an RDO approach comparable to adaptive block
partitioning in HEVC. In this paper, we enhance the training by introducing
low-complexity estimations of the RDO result into the training. Additionally,
we propose fast and very fast RDO inference modes. With our novel training
method, we achieve average rate savings of 19.6% in MS-SSIM over the previous
RDONet model, which equals rate savings of 27.3% over a comparable conventional
deep image coder.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Biphasic Face Photo-Sketch Synthesis via Semantic-Driven Generative Adversarial Network with Graph Representation Learning. (arXiv:2201.01592v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01592">
<div class="article-summary-box-inner">
<span><p>In recent years, significant progress has been achieved in biphasic face
photo-sketch synthesis with the development of Generative Adversarial Network
(GAN). Biphasic face photo-sketch synthesis could be applied in wide-ranging
fields such as digital entertainment and law enforcement. However, generating
realistic photos and distinct sketches suffers from great challenges due to the
low quality of sketches and complex photo variations in the real scenes. To
this end, we propose a novel Semantic-Driven Generative Adversarial Network to
address the above issues, cooperating with the Graph Representation Learning.
Specifically, we inject class-wise semantic layouts into the generator to
provide style-based spatial supervision for synthesized face photos and
sketches. In addition, to improve the fidelity of the generated results, we
leverage the semantic layouts to construct two types of Representational Graphs
which indicate the intra-class semantic features and inter-class structural
features of the synthesized images. Furthermore, we design two types of
constraints based on the proposed Representational Graphs which facilitate the
preservation of the details in generated face photos and sketches. Moreover, to
further enhance the perceptual quality of synthesized images, we propose a
novel biphasic training strategy which is dedicated to refine the generated
results through Iterative Cycle Training. Extensive experiments are conducted
on CUFS and CUFSF datasets to demonstrate the prominent ability of our proposed
method which achieves the state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Probabilistic Graph Matching. (arXiv:2201.01603v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01603">
<div class="article-summary-box-inner">
<span><p>Most previous learning-based graph matching algorithms solve the
\textit{quadratic assignment problem} (QAP) by dropping one or more of the
matching constraints and adopting a relaxed assignment solver to obtain
sub-optimal correspondences. Such relaxation may actually weaken the original
graph matching problem, and in turn hurt the matching performance. In this
paper we propose a deep learning-based graph matching framework that works for
the original QAP without compromising on the matching constraints. In
particular, we design an affinity-assignment prediction network to jointly
learn the pairwise affinity and estimate the node assignments, and we then
develop a differentiable solver inspired by the probabilistic perspective of
the pairwise affinities. Aiming to obtain better matching results, the
probabilistic solver refines the estimated assignments in an iterative manner
to impose both discrete and one-to-one matching constraints. The proposed
method is evaluated on three popularly tested benchmarks (Pascal VOC, Willow
Object and SPair-71k), and it outperforms all previous state-of-the-arts on all
benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">All You Need In Sign Language Production. (arXiv:2201.01609v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01609">
<div class="article-summary-box-inner">
<span><p>Sign Language is the dominant form of communication language used in the deaf
and hearing-impaired community. To make an easy and mutual communication
between the hearing-impaired and the hearing communities, building a robust
system capable of translating the spoken language into sign language and vice
versa is fundamental. To this end, sign language recognition and production are
two necessary parts for making such a two-way system. Sign language recognition
and production need to cope with some critical challenges. In this survey, we
review recent advances in Sign Language Production (SLP) and related areas
using deep learning. To have more realistic perspectives to sign language, we
present an introduction to the Deaf culture, Deaf centers, psychological
perspective of sign language, the main differences between spoken language and
sign language. Furthermore, we present the fundamental components of a
bi-directional sign language translation system, discussing the main challenges
in this area. Also, the backbone architectures and methods in SLP are briefly
introduced and the proposed taxonomy on SLP is presented. Finally, a general
framework for SLP and performance evaluation, and also a discussion on the
recent developments, advantages, and limitations in SLP, commenting on possible
lines for future research are presented.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Lawin Transformer: Improving Semantic Segmentation Transformer with Multi-Scale Representations via Large Window Attention. (arXiv:2201.01615v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01615">
<div class="article-summary-box-inner">
<span><p>Multi-scale representations are crucial for semantic segmentation. The
community has witnessed the flourish of semantic segmentation convolutional
neural networks (CNN) exploiting multi-scale contextual information. Motivated
by that the vision transformer (ViT) is powerful in image classification, some
semantic segmentation ViTs are recently proposed, most of them attaining
impressive results but at a cost of computational economy. In this paper, we
succeed in introducing multi-scale representations into semantic segmentation
ViT via window attention mechanism and further improves the performance and
efficiency. To this end, we introduce large window attention which allows the
local window to query a larger area of context window at only a little
computation overhead. By regulating the ratio of the context area to the query
area, we enable the large window attention to capture the contextual
information at multiple scales. Moreover, the framework of spatial pyramid
pooling is adopted to collaborate with the large window attention, which
presents a novel decoder named large window attention spatial pyramid pooling
(LawinASPP) for semantic segmentation ViT. Our resulting ViT, Lawin
Transformer, is composed of an efficient hierachical vision transformer (HVT)
as encoder and a LawinASPP as decoder. The empirical results demonstrate that
Lawin Transformer offers an improved efficiency compared to the existing
method. Lawin Transformer further sets new state-of-the-art performance on
Cityscapes (84.4\% mIoU), ADE20K (56.2\% mIoU) and COCO-Stuff datasets. The
code will be released at https://github.com/yan-hao-tian/lawin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tackling the Class Imbalance Problem of Deep Learning Based Head and Neck Organ Segmentation. (arXiv:2201.01636v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01636">
<div class="article-summary-box-inner">
<span><p>The segmentation of organs at risk (OAR) is a required precondition for the
cancer treatment with image guided radiation therapy. The automation of the
segmentation task is therefore of high clinical relevance. Deep Learning (DL)
based medical image segmentation is currently the most successful approach, but
suffers from the over-presence of the background class and the anatomically
given organ size difference, which is most severe in the head and neck (HAN)
area. To tackle the HAN area specific class imbalance problem we first optimize
the patch-size of the currently best performing general purpose segmentation
framework, the nnU-Net, based on the introduced class imbalance measurement,
and second, introduce the class adaptive Dice loss to further compensate for
the highly imbalanced setting. Both the patch-size and the loss function are
parameters with direct influence on the class imbalance and their optimization
leads to a 3\% increase of the Dice score and 22% reduction of the 95%
Hausdorff distance compared to the baseline, finally reaching $0.8\pm0.15$ and
$3.17\pm1.7$ mm for the segmentation of seven HAN organs using a single and
simple neural network. The patch-size optimization and the class adaptive Dice
loss are both simply integrable in current DL based segmentation approaches and
allow to increase the performance for class imbalanced segmentation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TableParser: Automatic Table Parsing with Weak Supervision from Spreadsheets. (arXiv:2201.01654v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01654">
<div class="article-summary-box-inner">
<span><p>Tables have been an ever-existing structure to store data. There exist now
different approaches to store tabular data physically. PDFs, images,
spreadsheets, and CSVs are leading examples. Being able to parse table
structures and extract content bounded by these structures is of high
importance in many applications. In this paper, we devise TableParser, a system
capable of parsing tables in both native PDFs and scanned images with high
precision. We have conducted extensive experiments to show the efficacy of
domain adaptation in developing such a tool. Moreover, we create TableAnnotator
and ExcelAnnotator, which constitute a spreadsheet-based weak supervision
mechanism and a pipeline to enable table parsing. We share these resources with
the research community to facilitate further research in this interesting
direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluation of Thermal Imaging on Embedded GPU Platforms for Application in Vehicular Assistance Systems. (arXiv:2201.01661v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01661">
<div class="article-summary-box-inner">
<span><p>This study is focused on evaluating the real-time performance of thermal
object detection for smart and safe vehicular systems by deploying the trained
networks on GPU &amp; single-board EDGE-GPU computing platforms for onboard
automotive sensor suite testing. A novel large-scale thermal dataset comprising
of &gt; 35,000 distinct frames is acquired, processed, and open-sourced in
challenging weather and environmental scenarios. The dataset is a recorded from
lost-cost yet effective uncooled LWIR thermal camera, mounted stand-alone and
on an electric vehicle to minimize mechanical vibrations. State-of-the-art
YOLO-V5 networks variants are trained using four different public datasets as
well newly acquired local dataset for optimal generalization of DNN by
employing SGD optimizer. The effectiveness of trained networks is validated on
extensive test data using various quantitative metrics which include precision,
recall curve, mean average precision, and frames per second. The smaller
network variant of YOLO is further optimized using TensorRT inference
accelerator to explicitly boost the frames per second rate. Optimized network
engine increases the frames per second rate by 3.5 times when testing on low
power edge devices thus achieving 11 fps on Nvidia Jetson Nano and 60 fps on
Nvidia Xavier NX development boards.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Surface-Aligned Neural Radiance Fields for Controllable 3D Human Synthesis. (arXiv:2201.01683v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01683">
<div class="article-summary-box-inner">
<span><p>We propose a new method for reconstructing controllable implicit 3D human
models from sparse multi-view RGB videos. Our method defines the neural scene
representation on the mesh surface points and signed distances from the surface
of a human body mesh. We identify an indistinguishability issue that arises
when a point in 3D space is mapped to its nearest surface point on a mesh for
learning surface-aligned neural scene representation. To address this issue, we
propose projecting a point onto a mesh surface using a barycentric
interpolation with modified vertex normals. Experiments with the ZJU-MoCap and
Human3.6M datasets show that our approach achieves a higher quality in a
novel-view and novel-pose synthesis than existing methods. We also demonstrate
that our method easily supports the control of body shape and clothes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Investigation Of Ben-ford's Law Divergence And Machine Learning Techniques For Separability Of Fingerprint Images. (arXiv:2201.01699v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01699">
<div class="article-summary-box-inner">
<span><p>Protecting a fingerprint database against attackers is very vital in order to
protect against false acceptance rate or false rejection rate. A key property
in distinguishing fingerprint images is by exploiting the characteristics of
these different types of fingerprint images. The aim of this paper is to
perform the classification of fingerprint images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Probing TryOnGAN. (arXiv:2201.01703v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01703">
<div class="article-summary-box-inner">
<span><p>TryOnGAN is a recent virtual try-on approach, which generates highly
realistic images and outperforms most previous approaches. In this article, we
reproduce the TryOnGAN implementation and probe it along diverse angles: impact
of transfer learning, variants of conditioning image generation with poses and
properties of latent space interpolation. Some of these facets have never been
explored in literature earlier. We find that transfer helps training initially
but gains are lost as models train longer and pose conditioning via
concatenation performs better. The latent space self-disentangles the pose and
the style features and enables style transfer across poses. Our code and models
are available in open source.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Effect of Model Compression on Fairness in Facial Expression Recognition. (arXiv:2201.01709v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01709">
<div class="article-summary-box-inner">
<span><p>Deep neural networks have proved hugely successful, achieving human-like
performance on a variety of tasks. However, they are also computationally
expensive, which has motivated the development of model compression techniques
which reduce the resource consumption associated with deep learning models.
Nevertheless, recent studies have suggested that model compression can have an
adverse effect on algorithmic fairness, amplifying existing biases in machine
learning models. With this project we aim to extend those studies to the
context of facial expression recognition. To do that, we set up a neural
network classifier to perform facial expression recognition and implement
several model compression techniques on top of it. We then run experiments on
two facial expression datasets, namely the Extended Cohn-Kanade Dataset (CK+DB)
and the Real-World Affective Faces Database (RAF-DB), to examine the individual
and combined effect that compression techniques have on the model size,
accuracy and fairness. Our experimental results show that: (i) Compression and
quantisation achieve significant reduction in model size with minimal impact on
overall accuracy for both CK+DB and RAF-DB; (ii) in terms of model accuracy,
the classifier trained and tested on RAF-DB seems more robust to compression
compared to the CK+ DB; (iii) for RAF-DB, the different compression strategies
do not seem to increase the gap in predictive performance across the sensitive
attributes of gender, race and age which is in contrast with the results on the
CK+DB, where compression seems to amplify existing biases for gender. We
analyse the results and discuss the potential reasons for our findings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Robot Collaborative Perception with Graph Neural Networks. (arXiv:2201.01760v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01760">
<div class="article-summary-box-inner">
<span><p>Multi-robot systems such as swarms of aerial robots are naturally suited to
offer additional flexibility, resilience, and robustness in several tasks
compared to a single robot by enabling cooperation among the agents. To enhance
the autonomous robot decision-making process and situational awareness,
multi-robot systems have to coordinate their perception capabilities to
collect, share, and fuse environment information among the agents in an
efficient and meaningful way such to accurately obtain context-appropriate
information or gain resilience to sensor noise or failures. In this paper, we
propose a general-purpose Graph Neural Network (GNN) with the main goal to
increase, in multi-robot perception tasks, single robots' inference perception
accuracy as well as resilience to sensor failures and disturbances. We show
that the proposed framework can address multi-view visual perception problems
such as monocular depth estimation and semantic segmentation. Several
experiments both using photo-realistic and real data gathered from multiple
aerial robots' viewpoints show the effectiveness of the proposed approach in
challenging inference conditions including images corrupted by heavy noise and
camera occlusions or failures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Self-Supervised Audio-Visual Speech Recognition. (arXiv:2201.01763v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01763">
<div class="article-summary-box-inner">
<span><p>Audio-based automatic speech recognition (ASR) degrades significantly in
noisy environments and is particularly vulnerable to interfering speech, as the
model cannot determine which speaker to transcribe. Audio-visual speech
recognition (AVSR) systems improve robustness by complementing the audio stream
with the visual information that is invariant to noise and helps the model
focus on the desired speaker. However, previous AVSR work focused solely on the
supervised learning setup; hence the progress was hindered by the amount of
labeled data available. In this work, we present a self-supervised AVSR
framework built upon Audio-Visual HuBERT (AV-HuBERT), a state-of-the-art
audio-visual speech representation learning model. On the largest available
AVSR benchmark dataset LRS3, our approach outperforms prior state-of-the-art by
~50% (28.0% vs. 14.1%) using less than 10% of labeled data (433hr vs. 30hr) in
the presence of babble noise, while reducing the WER of an audio-based model by
over 75% (25.8% vs. 5.8%) on average.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Semantic Multimodal Hashing Network for Scalable Image-Text and Video-Text Retrievals. (arXiv:1901.02662v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1901.02662">
<div class="article-summary-box-inner">
<span><p>Hashing has been widely applied to multimodal retrieval on large-scale
multimedia data due to its efficiency in computation and storage. In this
article, we propose a novel deep semantic multimodal hashing network (DSMHN)
for scalable image-text and video-text retrieval. The proposed deep hashing
framework leverages 2-D convolutional neural networks (CNN) as the backbone
network to capture the spatial information for image-text retrieval, while the
3-D CNN as the backbone network to capture the spatial and temporal information
for video-text retrieval. In the DSMHN, two sets of modality-specific hash
functions are jointly learned by explicitly preserving both intermodality
similarities and intramodality semantic labels. Specifically, with the
assumption that the learned hash codes should be optimal for the classification
task, two stream networks are jointly trained to learn the hash functions by
embedding the semantic labels on the resultant hash codes. Moreover, a unified
deep multimodal hashing framework is proposed to learn compact and high-quality
hash codes by exploiting the feature representation learning, intermodality
similarity-preserving learning, semantic label-preserving learning, and hash
function learning with different types of loss functions simultaneously. The
proposed DSMHN method is a generic and scalable deep hashing framework for both
image-text and video-text retrievals, which can be flexibly integrated with
different types of loss functions. We conduct extensive experiments for both
single modal- and cross-modal-retrieval tasks on four widely used
multimodal-retrieval data sets. Experimental results on both image-text- and
video-text-retrieval tasks demonstrate that the DSMHN significantly outperforms
the state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Iterative Network for Image Super-Resolution. (arXiv:2005.09964v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.09964">
<div class="article-summary-box-inner">
<span><p>Single image super-resolution (SISR), as a traditional ill-conditioned
inverse problem, has been greatly revitalized by the recent development of
convolutional neural networks (CNN). These CNN-based methods generally map a
low-resolution image to its corresponding high-resolution version with
sophisticated network structures and loss functions, showing impressive
performances. This paper provides a new insight on conventional SISR algorithm,
and proposes a substantially different approach relying on the iterative
optimization. A novel iterative super-resolution network (ISRN) is proposed on
top of the iterative optimization. We first analyze the observation model of
image SR problem, inspiring a feasible solution by mimicking and fusing each
iteration in a more general and efficient manner. Considering the drawbacks of
batch normalization, we propose a feature normalization (F-Norm, FN) method to
regulate the features in network. Furthermore, a novel block with FN is
developed to improve the network representation, termed as FNB.
Residual-in-residual structure is proposed to form a very deep network, which
groups FNBs with a long skip connection for better information delivery and
stabling the training phase. Extensive experimental results on testing
benchmarks with bicubic (BI) degradation show our ISRN can not only recover
more structural information, but also achieve competitive or better PSNR/SSIM
results with much fewer parameters compared to other works. Besides BI, we
simulate the real-world degradation with blur-downscale (BD) and
downscale-noise (DN). ISRN and its extension ISRN+ both achieve better
performance than others with BD and DN degradation models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Accurate Entropy Model with Global Reference for Image Compression. (arXiv:2010.08321v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08321">
<div class="article-summary-box-inner">
<span><p>In recent deep image compression neural networks, the entropy model plays a
critical role in estimating the prior distribution of deep image encodings.
Existing methods combine hyperprior with local context in the entropy
estimation function. This greatly limits their performance due to the absence
of a global vision. In this work, we propose a novel Global Reference Model for
image compression to effectively leverage both the local and the global context
information, leading to an enhanced compression rate. The proposed method scans
decoded latents and then finds the most relevant latent to assist the
distribution estimating of the current latent. A by-product of this work is the
innovation of a mean-shifting GDN module that further improves the performance.
Experimental results demonstrate that the proposed model outperforms the
rate-distortion performance of most of the state-of-the-art methods in the
industry.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Differentiable Channel Sparsity Search via Weight Sharing within Filters. (arXiv:2010.14714v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14714">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose the differentiable channel sparsity search (DCSS)
for convolutional neural networks. Unlike traditional channel pruning
algorithms which require users to manually set prune ratios for each
convolutional layer, DCSS automatically searches the optimal combination of
sparsities. Inspired by the differentiable architecture search (DARTS), we draw
lessons from the continuous relaxation and leverage the gradient information to
balance the computational cost and metrics. Since directly applying the scheme
of DARTS causes shape mismatching and excessive memory consumption, we
introduce a novel technique called weight sharing within filters. This
technique elegantly eliminates the problem of shape mismatching with negligible
additional resources. We conduct comprehensive experiments on not only image
classification but also find-grained tasks including semantic segmentation and
image super resolution to verify the effectiveness of DCSS. Compared with
previous network pruning approaches, DCSS achieves state-of-the-art results for
image classification. Experimental results of semantic segmentation and image
super resolution indicate that task-specific search achieves better performance
than transferring slim models, demonstrating the wide applicability and high
efficiency of DCSS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Suppression of Correlated Noise with Similarity-based Unsupervised Deep Learning. (arXiv:2011.03384v6 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.03384">
<div class="article-summary-box-inner">
<span><p>Image denoising is a prerequisite for downstream tasks in many fields.
Low-dose and photon-counting computed tomography (CT) denoising can optimize
diagnostic performance at minimized radiation dose. Supervised deep denoising
methods are popular but require paired clean or noisy samples that are often
unavailable in practice. Limited by the independent noise assumption, current
unsupervised denoising methods cannot process correlated noises as in CT
images. Here we propose the first-of-its-kind similarity-based unsupervised
deep denoising approach, referred to as Noise2Sim, that works in a nonlocal and
nonlinear fashion to suppress not only independent but also correlated noises.
Theoretically, Noise2Sim is asymptotically equivalent to supervised learning
methods under mild conditions. Experimentally, Nosie2Sim recovers intrinsic
features from noisy low-dose CT and photon-counting CT images as effectively as
or even better than supervised learning methods on practical datasets visually,
quantitatively and statistically. Noise2Sim is a general unsupervised denoising
approach and has great potential in diverse applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GMLight: Lighting Estimation via Geometric Distribution Approximation. (arXiv:2102.10244v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10244">
<div class="article-summary-box-inner">
<span><p>Inferring the scene illumination from a single image is an essential yet
challenging task in computer vision and computer graphics. Existing works
estimate lighting by regressing representative illumination parameters or
generating illumination maps directly. However, these methods often suffer from
poor accuracy and generalization. This paper presents Geometric Mover's Light
(GMLight), a lighting estimation framework that employs a regression network
and a generative projector for effective illumination estimation. We
parameterize illumination scenes in terms of the geometric light distribution,
light intensity, ambient term, and auxiliary depth, which can be estimated by a
regression network. Inspired by the earth mover's distance, we design a novel
geometric mover's loss to guide the accurate regression of light distribution
parameters. With the estimated light parameters, the generative projector
synthesizes panoramic illumination maps with realistic appearance and
high-frequency details. Extensive experiments show that GMLight achieves
accurate illumination estimation and superior fidelity in relighting for 3D
object insertion. The codes are available at
\href{https://github.com/fnzhan/Illumination-Estimation}{https://github.com/fnzhan/Illumination-Estimation}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Monocular 3D Vehicle Detection Using Uncalibrated Traffic Cameras through Homography. (arXiv:2103.15293v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15293">
<div class="article-summary-box-inner">
<span><p>This paper proposes a method to extract the position and pose of vehicles in
the 3D world from a single traffic camera. Most previous monocular 3D vehicle
detection algorithms focused on cameras on vehicles from the perspective of a
driver, and assumed known intrinsic and extrinsic calibration. On the contrary,
this paper focuses on the same task using uncalibrated monocular traffic
cameras. We observe that the homography between the road plane and the image
plane is essential to 3D vehicle detection and the data synthesis for this
task, and the homography can be estimated without the camera intrinsics and
extrinsics. We conduct 3D vehicle detection by estimating the rotated bounding
boxes (r-boxes) in the bird's eye view (BEV) images generated from inverse
perspective mapping. We propose a new regression target called tailed r-box and
a dual-view network architecture which boosts the detection accuracy on warped
BEV images. Experiments show that the proposed method can generalize to new
camera and environment setups despite not seeing imaged from them during
training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Two stages for visual object tracking. (arXiv:2104.13648v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13648">
<div class="article-summary-box-inner">
<span><p>Siamese-based trackers have achived promising performance on visual object
tracking tasks. Most existing Siamese-based trackers contain two separate
branches for tracking, including classification branch and bounding box
regression branch. In addition, image segmentation provides an alternative way
to obetain the more accurate target region. In this paper, we propose a novel
tracker with two-stages: detection and segmentation. The detection stage is
capable of locating the target by Siamese networks. Then more accurate tracking
results are obtained by segmentation module given the coarse state estimation
in the first stage. We conduct experiments on four benchmarks. Our approach
achieves state-of-the-art results, with the EAO of 52.6$\%$ on VOT2016,
51.3$\%$ on VOT2018, and 39.0$\%$ on VOT2019 datasets, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved Real-Time Monocular SLAM Using Semantic Segmentation on Selective Frames. (arXiv:2105.00114v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00114">
<div class="article-summary-box-inner">
<span><p>Monocular simultaneous localization and mapping (SLAM) is emerging in
advanced driver assistance systems and autonomous driving, because a single
camera is cheap and easy to install. Conventional monocular SLAM has two major
challenges leading inaccurate localization and mapping. First, it is
challenging to estimate scales in localization and mapping. Second,
conventional monocular SLAM uses inappropriate mapping factors such as dynamic
objects and low-parallax areas in mapping. This paper proposes an improved
real-time monocular SLAM that resolves the aforementioned challenges by
efficiently using deep learning-based semantic segmentation. To achieve the
real-time execution of the proposed method, we apply semantic segmentation only
to downsampled keyframes in parallel with mapping processes. In addition, the
proposed method corrects scales of camera poses and three-dimensional (3D)
points, using estimated ground plane from road-labeled 3D points and the real
camera height. The proposed method also removes inappropriate corner features
labeled as moving objects and low parallax areas. Experiments with eight video
sequences demonstrate that the proposed monocular SLAM system achieves
significantly improved and comparable trajectory tracking accuracy, compared to
existing state-of-the-art monocular and stereo SLAM systems, respectively. The
proposed system can achieve real-time tracking on a standard CPU potentially
with a standard GPU support, whereas existing segmentation-aided monocular SLAM
does not.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VILA: Improving Structured Content Extraction from Scientific PDFs Using Visual Layout Groups. (arXiv:2106.00676v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00676">
<div class="article-summary-box-inner">
<span><p>Accurately extracting structured content from PDFs is a critical first step
for NLP over scientific papers. Recent work has improved extraction accuracy by
incorporating elementary layout information, e.g., each token's 2D position on
the page, into language model pretraining. We introduce new methods that
explicitly model VIsual LAyout (VILA) groups, i.e., text lines or text blocks,
to further improve performance. In our I-VILA approach, we show that simply
inserting special tokens denoting layout group boundaries into model inputs can
lead to a 1.9% Macro F1 improvement in token classification. In the H-VILA
approach, we show that hierarchical encoding of layout-groups can result in
up-to 47% inference time reduction with less than 0.8% Macro F1 loss. Unlike
prior layout-aware approaches, our methods do not require expensive additional
pretraining, only fine-tuning, which we show can reduce training cost by up to
95%. Experiments are conducted on a newly curated evaluation suite, S2-VLUE,
that unifies existing automatically-labeled datasets and includes a new dataset
of manual annotations covering diverse papers from 19 scientific disciplines.
Pre-trained weights, benchmark datasets, and source code are available at
https://github.com/allenai/VILA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Convolutional Neural Networks for Onychomycosis Detection. (arXiv:2106.16139v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16139">
<div class="article-summary-box-inner">
<span><p>The diagnosis of superficial fungal infections in dermatology is still mostly
based on manual direct microscopic examination with Potassium Hydroxide (KOH)
solution. However, this method can be time consuming and its diagnostic
accuracy rates vary widely depending on the clinician's experience. With the
increase of neural network applications in the field of clinical microscopy, it
is now possible to automate such manual processes increasing both efficiency
and accuracy. This study presents a deep neural network structure that enables
the rapid solutions for these problems and can perform automatic fungi
detection in grayscale images without dyes. 160 microscopic field photographs
containing the fungal element, obtained from patients with onychomycosis, and
297 microscopic field photographs containing dissolved keratin obtained from
normal nails were collected. Smaller patches containing 4234 fungi and 4981
keratin were extracted from these images. In order to detect fungus and
keratin, VGG16 and InceptionV3 models were developed. The VGG16 model had
95.98% accuracy, and the area under the curve (AUC) value of 0.9930, while the
InceptionV3 model had 95.90% accuracy and the AUC value of 0.9917. However,
average accuracy and AUC value of clinicians is 72.8% and 0.87, respectively.
This deep learning model allows the development of an automated system that can
detect fungi within microscopic images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rectifying the Shortcut Learning of Background for Few-Shot Learning. (arXiv:2107.07746v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07746">
<div class="article-summary-box-inner">
<span><p>The category gap between training and evaluation has been characterised as
one of the main obstacles to the success of Few-Shot Learning (FSL). In this
paper, we for the first time empirically identify image background, common in
realistic images, as a shortcut knowledge helpful for in-class classification
but ungeneralizable beyond training categories in FSL. A novel framework,
COSOC, is designed to tackle this problem by extracting foreground objects in
images at both training and evaluation without any extra supervision. Extensive
experiments carried on inductive FSL tasks demonstrate the effectiveness of our
approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations. (arXiv:2108.01073v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01073">
<div class="article-summary-box-inner">
<span><p>Guided image synthesis enables everyday users to create and edit
photo-realistic images with minimum effort. The key challenge is balancing
faithfulness to the user input (e.g., hand-drawn colored strokes) and realism
of the synthesized image. Existing GAN-based methods attempt to achieve such
balance using either conditional GANs or GAN inversions, which are challenging
and often require additional training data or loss functions for individual
applications. To address these issues, we introduce a new image synthesis and
editing method, Stochastic Differential Editing (SDEdit), based on a diffusion
model generative prior, which synthesizes realistic images by iteratively
denoising through a stochastic differential equation (SDE). Given an input
image with user guide of any type, SDEdit first adds noise to the input, then
subsequently denoises the resulting image through the SDE prior to increase its
realism. SDEdit does not require task-specific training or inversions and can
naturally achieve the balance between realism and faithfulness. SDEdit
significantly outperforms state-of-the-art GAN-based methods by up to 98.09% on
realism and 91.72% on overall satisfaction scores, according to a human
perception study, on multiple tasks, including stroke-based image synthesis and
editing as well as image compositing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bi-Temporal Semantic Reasoning for the Semantic Change Detection in HR Remote Sensing Images. (arXiv:2108.06103v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06103">
<div class="article-summary-box-inner">
<span><p>Semantic change detection (SCD) extends the multi-class change detection
(MCD) task to provide not only the change locations but also the detailed
land-cover/land-use (LCLU) categories before and after the observation
intervals. This fine-grained semantic change information is very useful in many
applications. Recent studies indicate that the SCD can be modeled through a
triple-branch Convolutional Neural Network (CNN), which contains two temporal
branches and a change branch. However, in this architecture, the communications
between the temporal branches and the change branch are insufficient. To
overcome the limitations in existing methods, we propose a novel CNN
architecture for the SCD, where the semantic temporal features are merged in a
deep CD unit. Furthermore, we elaborate on this architecture to reason the
bi-temporal semantic correlations. The resulting Bi-temporal Semantic Reasoning
Network (Bi-SRNet) contains two types of semantic reasoning blocks to reason
both single-temporal and cross-temporal semantic correlations, as well as a
novel loss function to improve the semantic consistency of change detection
results. Experimental results on a benchmark dataset show that the proposed
architecture obtains significant accuracy improvements over the existing
approaches, while the added designs in the Bi-SRNet further improves the
segmentation of both semantic categories and the changed areas. The codes in
this paper are accessible at: github.com/ggsDing/Bi-SRNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">No-Reference Image Quality Assessment via Transformers, Relative Ranking, and Self-Consistency. (arXiv:2108.06858v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06858">
<div class="article-summary-box-inner">
<span><p>The goal of No-Reference Image Quality Assessment (NR-IQA) is to estimate the
perceptual image quality in accordance with subjective evaluations, it is a
complex and unsolved problem due to the absence of the pristine reference
image. In this paper, we propose a novel model to address the NR-IQA task by
leveraging a hybrid approach that benefits from Convolutional Neural Networks
(CNNs) and self-attention mechanism in Transformers to extract both local and
non-local features from the input image. We capture local structure information
of the image via CNNs, then to circumvent the locality bias among the extracted
CNNs features and obtain a non-local representation of the image, we utilize
Transformers on the extracted features where we model them as a sequential
input to the Transformer model. Furthermore, to improve the monotonicity
correlation between the subjective and objective scores, we utilize the
relative distance information among the images within each batch and enforce
the relative ranking among them. Last but not least, we observe that the
performance of NR-IQA models degrades when we apply equivariant transformations
(e.g. horizontal flipping) to the inputs. Therefore, we propose a method that
leverages self-consistency as a source of self-supervision to improve the
robustness of NRIQA models. Specifically, we enforce self-consistency between
the outputs of our quality assessment model for each image and its
transformation (horizontally flipped) to utilize the rich self-supervisory
information and reduce the uncertainty of the model. To demonstrate the
effectiveness of our work, we evaluate it on seven standard IQA datasets (both
synthetic and authentic) and show that our model achieves state-of-the-art
results on various datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Complementary Feature Enhanced Network with Vision Transformer for Image Dehazing. (arXiv:2109.07100v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07100">
<div class="article-summary-box-inner">
<span><p>Conventional CNNs-based dehazing models suffer from two essential issues: the
dehazing framework (limited in interpretability) and the convolution layers
(content-independent and ineffective to learn long-range dependency
information). In this paper, firstly, we propose a new complementary feature
enhanced framework, in which the complementary features are learned by several
complementary subtasks and then together serve to boost the performance of the
primary task. One of the prominent advantages of the new framework is that the
purposively chosen complementary tasks can focus on learning weakly dependent
complementary features, avoiding repetitive and ineffective learning of the
networks. We design a new dehazing network based on such a framework.
Specifically, we select the intrinsic image decomposition as the complementary
tasks, where the reflectance and shading prediction subtasks are used to
extract the color-wise and texture-wise complementary features. To effectively
aggregate these complementary features, we propose a complementary features
selection module (CFSM) to select the more useful features for image dehazing.
Furthermore, we introduce a new version of vision transformer block, named
Hybrid Local-Global Vision Transformer (HyLoG-ViT), and incorporate it within
our dehazing networks. The HyLoG-ViT block consists of the local and the global
vision transformer paths used to capture local and global dependencies. As a
result, the HyLoG-ViT introduces locality in the networks and captures the
global and long-range dependencies. Extensive experiments on homogeneous,
non-homogeneous, and nighttime dehazing tasks reveal that the proposed dehazing
network can achieve comparable or even better performance than CNNs-based
dehazing models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast Gradient Non-sign Methods. (arXiv:2110.12734v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.12734">
<div class="article-summary-box-inner">
<span><p>Adversarial attacks make their success in "fooling" DNNs and among them,
gradient-based algorithms become one of the mainstreams. Based on the linearity
hypothesis [12], under $\ell_\infty$ constraint, $sign$ operation applied to
the gradients is a good choice for generating perturbations. However, the
side-effect from such operation exists since it leads to the bias of direction
between the real gradients and the perturbations. In other words, current
methods contain a gap between real gradients and actual noises, which leads to
biased and inefficient attacks. Therefore in this paper, based on the Taylor
expansion, the bias is analyzed theoretically and the correction of $\sign$,
i.e., Fast Gradient Non-sign Method (FGNM), is further proposed. Notably, FGNM
is a general routine, which can seamlessly replace the conventional $sign$
operation in gradient-based attacks with negligible extra computational cost.
Extensive experiments demonstrate the effectiveness of our methods.
Specifically, ours outperform them by \textbf{27.5\%} at most and
\textbf{9.5\%} on average. Our anonymous code is publicly available:
\url{https://git.io/mm-fgnm}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Versatile Learned Video Compression. (arXiv:2111.03386v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.03386">
<div class="article-summary-box-inner">
<span><p>Learned video compression methods have demonstrated great promise in catching
up with traditional video codecs in their rate-distortion (R-D) performance.
However, existing learned video compression schemes are limited by the binding
of the prediction mode and the fixed network framework. They are unable to
support various inter prediction modes and thus inapplicable for various
scenarios. In this paper, to break this limitation, we propose a versatile
learned video compression (VLVC) framework that uses one model to support all
possible prediction modes. Specifically, to realize versatile compression, we
first build a motion compensation module that applies multiple 3D motion vector
fields (i.e., voxel flows) for weighted trilinear warping in spatial-temporal
space. The voxel flows convey the information of temporal reference position
that helps to decouple inter prediction modes away from framework designing.
Secondly, in case of multiple-reference-frame prediction, we apply a flow
prediction module to predict accurate motion trajectories with unified
polynomial functions. We show that the flow prediction module can largely
reduce the transmission cost of voxel flows. Experimental results demonstrate
that our proposed VLVC not only supports versatile compression in various
settings, but also is the first end-to-end learned video compression method
that outperforms the latest VVC/H.266 standard reference software in terms of
MS-SSIM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Learning Guided 3D Image Recognition for Carbonate Pore and Mineral Volumes Determination. (arXiv:2111.04612v2 [physics.geo-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.04612">
<div class="article-summary-box-inner">
<span><p>Automated image processing algorithms can improve the quality, efficiency,
and consistency of classifying the morphology of heterogeneous carbonate rock
and can deal with a massive amount of data and images seamlessly. Geoscientists
face difficulties in setting the direction of the optimum method for
determining petrophysical properties from rock images, Micro-Computed
Tomography (uCT), or Magnetic Resonance Imaging (MRI). Most of the successful
work is from the homogeneous rocks focusing on 2D images with less focus on 3D
and requiring numerical simulation. Currently, image analysis methods converge
to three approaches: image processing, artificial intelligence, and combined
image processing with artificial intelligence. In this work, we propose two
methods to determine the porosity from 3D uCT and MRI images: an image
processing method with Image Resolution Optimized Gaussian Algorithm (IROGA);
advanced image recognition method enabled by Machine Learning Difference of
Gaussian Random Forest (MLDGRF). We have built reference 3D micro models and
collected images for calibration of IROGA and MLDGRF methods. To evaluate the
predictive capability of these calibrated approaches, we ran them on 3D uCT and
MRI images of natural heterogeneous carbonate rock. We measured the porosity
and lithology of the carbonate rock using three and two industry-standard ways,
respectively, as reference values. Notably, IROGA and MLDGRF have produced
porosity results with an accuracy of 96.2% and 97.1% on the training set and
91.7% and 94.4% on blind test validation, respectively, in comparison with the
three experimental measurements. We measured limestone and pyrite reference
values using two methods, X-ray powder diffraction, and grain density
measurements. MLDGRF has produced lithology (limestone and Pyrite) volumes with
97.7% accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Two-stage Rule-induction Visual Reasoning on RPMs with an Application to Video Prediction. (arXiv:2111.12301v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.12301">
<div class="article-summary-box-inner">
<span><p>Raven's Progressive Matrices (RPMs) are frequently used in evaluating human's
visual reasoning ability. Researchers have made considerable efforts in
developing systems to automatically solve the RPM problem, often through a
black-box end-to-end convolutional neural network for both visual recognition
and logical reasoning tasks. Based on the two intrinsic natures of RPM problem,
visual recognition and logical reasoning, we propose a Two-stage Rule-Induction
Visual Reasoner (TRIVR), which consists of a perception module and a reasoning
module, to tackle the challenges of real-world visual recognition and
subsequent logical reasoning tasks, respectively. For the reasoning module, we
further propose a "2+1" formulation that models human's thinking in solving
RPMs and significantly reduces the model complexity. It derives a reasoning
rule from each RPM sample, which is not feasible for existing methods. As a
result, the proposed reasoning module is capable of yielding a set of reasoning
rules modeling human in solving the RPM problems. To validate the proposed
method on real-world applications, an RPM-like Video Prediction (RVP) dataset
is constructed, where visual reasoning is conducted on RPMs constructed using
real-world video frames. Experimental results on various RPM-like datasets
demonstrate that the proposed TRIVR achieves a significant and consistent
performance gain compared with the state-of-the-art models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Morphology Decoder: A Machine Learning Guided 3D Vision Quantifying Heterogenous Rock Permeability for Planetary Surveillance and Robotic Functions. (arXiv:2111.13460v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.13460">
<div class="article-summary-box-inner">
<span><p>Permeability has a dominant influence on the flow properties of a natural
fluid. Lattice Boltzmann simulator determines permeability from the nano and
micropore network. The simulator holds millions of flow dynamics calculations
with its accumulated errors and high consumption of computing power. To
efficiently and consistently predict permeability, we propose a morphology
decoder, a parallel and serial flow reconstruction of machine learning
segmented heterogeneous Cretaceous texture from 3D micro computerized
tomography and nuclear magnetic resonance images. For 3D vision, we introduce
controllable-measurable-volume as new supervised segmentation, in which a
unique set of voxel intensity corresponds to grain and pore throat sizes. The
morphology decoder demarks and aggregates the morphologies boundaries in a
novel way to produce permeability. Morphology decoder method consists of five
novel processes, which describes in this paper, these novel processes are: (1)
Geometrical 3D Permeability, (2) Machine Learning guided 3D Properties
Recognition of Rock Morphology, (3) 3D Image Properties Integration Model for
Permeability, (4) MRI Permeability Imager, and (5) Morphology Decoder (the
process that integrates the other four novel processes).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TCGL: Temporal Contrastive Graph for Self-supervised Video Representation Learning. (arXiv:2112.03587v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.03587">
<div class="article-summary-box-inner">
<span><p>Video self-supervised learning is a challenging task, which requires
significant expressive power from the model to leverage rich spatial-temporal
knowledge and generate effective supervisory signals from large amounts of
unlabeled videos. However, existing methods fail to increase the temporal
diversity of unlabeled videos and ignore elaborately modeling multi-scale
temporal dependencies in an explicit way. To overcome these limitations, we
take advantage of the multi-scale temporal dependencies within videos and
proposes a novel video self-supervised learning framework named Temporal
Contrastive Graph Learning (TCGL), which jointly models the inter-snippet and
intra-snippet temporal dependencies for temporal representation learning with a
hybrid graph contrastive learning strategy. Specifically, a Spatial-Temporal
Knowledge Discovering (STKD) module is first introduced to extract
motion-enhanced spatial-temporal representations from videos based on the
frequency domain analysis of discrete cosine transform. To explicitly model
multi-scale temporal dependencies of unlabeled videos, our TCGL integrates the
prior knowledge about the frame and snippet orders into graph structures, i.e.,
the intra-/inter- snippet Temporal Contrastive Graphs (TCG). Then, specific
contrastive learning modules are designed to maximize the agreement between
nodes in different graph views. To generate supervisory signals for unlabeled
videos, we introduce an Adaptive Snippet Order Prediction (ASOP) module which
leverages the relational knowledge among video snippets to learn the global
context representation and recalibrate the channel-wise features adaptively.
Experimental results demonstrate the superiority of our TCGL over the
state-of-the-art methods on large-scale action recognition and video retrieval
benchmarks.The code is publicly available at
https://github.com/YangLiu9208/TCGL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Digital Rock Typing DRT Algorithm Formulation with Optimal Supervised Semantic Segmentation. (arXiv:2112.15068v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.15068">
<div class="article-summary-box-inner">
<span><p>Each grid block in a 3D geological model requires a rock type that represents
all physical and chemical properties of that block. The properties that
classify rock types are lithology, permeability, and capillary pressure.
Scientists and engineers determined these properties using conventional
laboratory measurements, which embedded destructive methods to the sample or
altered some of its properties (i.e., wettability, permeability, and porosity)
because the measurements process includes sample crushing, fluid flow, or fluid
saturation. Lately, Digital Rock Physics (DRT) has emerged to quantify these
properties from micro-Computerized Tomography (uCT) and Magnetic Resonance
Imaging (MRI) images. However, the literature did not attempt rock typing in a
wholly digital context. We propose performing Digital Rock Typing (DRT) by: (1)
integrating the latest DRP advances in a novel process that honors digital rock
properties determination, while; (2) digitalizing the latest rock typing
approaches in carbonate, and (3) introducing a novel carbonate rock typing
process that utilizes computer vision capabilities to provide more insight
about the heterogeneous carbonate rock texture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">P2P-Loc: Point to Point Tiny Person Localization. (arXiv:2112.15344v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.15344">
<div class="article-summary-box-inner">
<span><p>Bounding-box annotation form has been the most frequently used method for
visual object localization tasks. However, bounding-box annotation relies on a
large amount of precisely annotating bounding boxes, and it is expensive and
laborious. It is impossible to be employed in practical scenarios and even
redundant for some applications (such as tiny person localization) that the
size would not matter. Therefore, we propose a novel point-based framework for
the person localization task by annotating each person as a coarse point
(CoarsePoint) instead of an accurate bounding box that can be any point within
the object extent. Then, the network predicts the person's location as a 2D
coordinate in the image. Although this greatly simplifies the data annotation
pipeline, the CoarsePoint annotation inevitably decreases label reliability
(label uncertainty) and causes network confusion during training. As a result,
we propose a point self-refinement approach that iteratively updates point
annotations in a self-paced way. The proposed refinement system alleviates the
label uncertainty and progressively improves localization performance.
Experimental results show that our approach has achieved comparable object
localization performance while saving up to 80$\%$ of annotation cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MoCoPnet: Exploring Local Motion and Contrast Priors for Infrared Small Target Super-Resolution. (arXiv:2201.01014v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.01014">
<div class="article-summary-box-inner">
<span><p>Infrared small target super-resolution (SR) aims to recover reliable and
detailed high-resolution image with highcontrast targets from its
low-resolution counterparts. Since the infrared small target lacks color and
fine structure information, it is significant to exploit the supplementary
information among sequence images to enhance the target. In this paper, we
propose the first infrared small target SR method named local motion and
contrast prior driven deep network (MoCoPnet) to integrate the domain knowledge
of infrared small target into deep network, which can mitigate the intrinsic
feature scarcity of infrared small targets. Specifically, motivated by the
local motion prior in the spatio-temporal dimension, we propose a local
spatiotemporal attention module to perform implicit frame alignment and
incorporate the local spatio-temporal information to enhance the local features
(especially for small targets). Motivated by the local contrast prior in the
spatial dimension, we propose a central difference residual group to
incorporate the central difference convolution into the feature extraction
backbone, which can achieve center-oriented gradient-aware feature extraction
to further improve the target contrast. Extensive experiments have demonstrated
that our method can recover accurate spatial dependency and improve the target
contrast. Comparative results show that MoCoPnet can outperform the
state-of-the-art video SR and single image SR methods in terms of both SR
performance and target enhancement. Based on the SR results, we further
investigate the influence of SR on infrared small target detection and the
experimental results demonstrate that MoCoPnet promotes the detection
performance. The code is available at https://github.com/XinyiYing/MoCoPnet.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-01-06 23:07:26.337236263 UTC">2022-01-06 23:07:26 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>