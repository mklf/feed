<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-09-15T01:30:00Z">09-15</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">The Emergence of the Shape Bias Results from Communicative Efficiency. (arXiv:2109.06232v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06232">
<div class="article-summary-box-inner">
<span><p>By the age of two, children tend to assume that new word categories are based
on objects' shape, rather than their color or texture; this assumption is
called the shape bias. They are thought to learn this bias by observing that
their caregiver's language is biased towards shape based categories. This
presents a chicken and egg problem: if the shape bias must be present in the
language in order for children to learn it, how did it arise in language in the
first place? In this paper, we propose that communicative efficiency explains
both how the shape bias emerged and why it persists across generations. We
model this process with neural emergent language agents that learn to
communicate about raw pixelated images. First, we show that the shape bias
emerges as a result of efficient communication strategies employed by agents.
Second, we show that pressure brought on by communicative need is also
necessary for it to persist across generations; simply having a shape bias in
an agent's input language is insufficient. These results suggest that, over and
above the operation of other learning strategies, the shape bias in human
learners may emerge and be sustained by communicative pressures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KroneckerBERT: Learning Kronecker Decomposition for Pre-trained Language Models via Knowledge Distillation. (arXiv:2109.06243v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06243">
<div class="article-summary-box-inner">
<span><p>The development of over-parameterized pre-trained language models has made a
significant contribution toward the success of natural language processing.
While over-parameterization of these models is the key to their generalization
power, it makes them unsuitable for deployment on low-capacity devices. We push
the limits of state-of-the-art Transformer-based pre-trained language model
compression using Kronecker decomposition. We use this decomposition for
compression of the embedding layer, all linear mappings in the multi-head
attention, and the feed-forward network modules in the Transformer layer. We
perform intermediate-layer knowledge distillation using the uncompressed model
as the teacher to improve the performance of the compressed model. We present
our KroneckerBERT, a compressed version of the BERT_BASE model obtained using
this framework. We evaluate the performance of KroneckerBERT on well-known NLP
benchmarks and show that for a high compression factor of 19 (5% of the size of
the BERT_BASE model), our KroneckerBERT outperforms state-of-the-art
compression methods on the GLUE. Our experiments indicate that the proposed
model has promising out-of-distribution robustness and is superior to the
state-of-the-art compression methods on SQuAD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Sentence Resampling: A Simple Approach to Alleviate Dataset Length Bias and Beam-Search Degradation. (arXiv:2109.06253v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06253">
<div class="article-summary-box-inner">
<span><p>Neural Machine Translation (NMT) is known to suffer from a beam-search
problem: after a certain point, increasing beam size causes an overall drop in
translation quality. This effect is especially pronounced for long sentences.
While much work was done analyzing this phenomenon, primarily for
autoregressive NMT models, there is still no consensus on its underlying cause.
In this work, we analyze errors that cause major quality degradation with large
beams in NMT and Automatic Speech Recognition (ASR). We show that a factor that
strongly contributes to the quality degradation with large beams is
\textit{dataset length-bias} - \textit{NMT datasets are strongly biased towards
short sentences}. To mitigate this issue, we propose a new data augmentation
technique -- \textit{Multi-Sentence Resampling (MSR)}. This technique extends
the training examples by concatenating several sentences from the original
dataset to make a long training example. We demonstrate that MSR significantly
reduces degradation with growing beam size and improves final translation
quality on the IWSTL$15$ En-Vi, IWSTL$17$ En-Fr, and WMT$14$ En-De datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Multiway Multilingual NMT in the Turkic Languages. (arXiv:2109.06262v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06262">
<div class="article-summary-box-inner">
<span><p>Despite the increasing number of large and comprehensive machine translation
(MT) systems, evaluation of these methods in various languages has been
restrained by the lack of high-quality parallel corpora as well as engagement
with the people that speak these languages. In this study, we present an
evaluation of state-of-the-art approaches to training and evaluating MT systems
in 22 languages from the Turkic language family, most of which being extremely
under-explored. First, we adopt the TIL Corpus with a few key improvements to
the training and the evaluation sets. Then, we train 26 bilingual baselines as
well as a multi-way neural MT (MNMT) model using the corpus and perform an
extensive analysis using automatic metrics as well as human evaluations. We
find that the MNMT model outperforms almost all bilingual baselines in the
out-of-domain test sets and finetuning the model on a downstream task of a
single pair also results in a huge performance boost in both low- and
high-resource scenarios. Our attentive analysis of evaluation criteria for MT
models in Turkic languages also points to the necessity for further research in
this direction. We release the corpus splits, test sets as well as models to
the public.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Post-OCR Document Correction with large Ensembles of Character Sequence Models. (arXiv:2109.06264v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06264">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel method based on character
sequence-to-sequence models to correct documents already processed with Optical
Character Recognition (OCR) systems. The main contribution of this paper is a
set of strategies to accurately process strings much longer than the ones used
to train the sequence model while being sample- and resource-efficient,
supported by thorough experimentation. The strategy with the best performance
involves splitting the input document in character n-grams and combining their
individual corrections into the final output using a voting scheme that is
equivalent to an ensemble of a large number of sequence models. We further
investigate how to weigh the contributions from each one of the members of this
ensemble. We test our method on nine languages of the ICDAR 2019 competition on
post-OCR text correction and achieve a new state-of-the-art performance in five
of them. Our code for post-OCR correction is shared at
https://github.com/jarobyte91/post_ocr_correction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">STraTA: Self-Training with Task Augmentation for Better Few-shot Learning. (arXiv:2109.06270v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06270">
<div class="article-summary-box-inner">
<span><p>Despite their recent successes in tackling many NLP tasks, large-scale
pre-trained language models do not perform as well in few-shot settings where
only a handful of training examples are available. To address this shortcoming,
we propose STraTA, which stands for Self-Training with Task Augmentation, an
approach that builds on two key ideas for effective leverage of unlabeled data.
First, STraTA uses task augmentation, a novel technique that synthesizes a
large amount of data for auxiliary-task fine-tuning from target-task unlabeled
texts. Second, STraTA performs self-training by further fine-tuning the strong
base model created by task augmentation on a broad distribution of
pseudo-labeled data. Our experiments demonstrate that STraTA can substantially
improve sample efficiency across 12 few-shot benchmarks. Remarkably, on the
SST-2 sentiment dataset, STraTA, with only 8 training examples per class,
achieves comparable results to standard fine-tuning with 67K training examples.
Our analyses reveal that task augmentation and self-training are both
complementary and independently effective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MindCraft: Theory of Mind Modeling for Situated Dialogue in Collaborative Tasks. (arXiv:2109.06275v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06275">
<div class="article-summary-box-inner">
<span><p>An ideal integration of autonomous agents in a human world implies that they
are able to collaborate on human terms. In particular, theory of mind plays an
important role in maintaining common ground during human collaboration and
communication. To enable theory of mind modeling in situated interactions, we
introduce a fine-grained dataset of collaborative tasks performed by pairs of
human subjects in the 3D virtual blocks world of Minecraft. It provides
information that captures partners' beliefs of the world and of each other as
an interaction unfolds, bringing abundant opportunities to study human
collaborative behaviors in situated language communication. As a first step
towards our goal of developing embodied AI agents able to infer belief states
of collaborative partners in situ, we build and present results on
computational models for several theory of mind tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph Algorithms for Multiparallel Word Alignment. (arXiv:2109.06283v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06283">
<div class="article-summary-box-inner">
<span><p>With the advent of end-to-end deep learning approaches in machine
translation, interest in word alignments initially decreased; however, they
have again become a focus of research more recently. Alignments are useful for
typological research, transferring formatting like markup to translated texts,
and can be used in the decoding of machine translation systems. At the same
time, massively multilingual processing is becoming an important NLP scenario,
and pretrained language and machine translation models that are truly
multilingual are proposed. However, most alignment algorithms rely on bitexts
only and do not leverage the fact that many parallel corpora are multiparallel.
In this work, we exploit the multiparallelity of corpora by representing an
initial set of bilingual alignments as a graph and then predicting additional
edges in the graph. We present two graph algorithms for edge prediction: one
inspired by recommender systems and one based on network link prediction. Our
experimental results show absolute improvements in $F_1$ of up to 28% over the
baseline bilingual word aligner in different datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Phrase-BERT: Improved Phrase Embeddings from BERT with an Application to Corpus Exploration. (arXiv:2109.06304v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06304">
<div class="article-summary-box-inner">
<span><p>Phrase representations derived from BERT often do not exhibit complex phrasal
compositionality, as the model relies instead on lexical similarity to
determine semantic relatedness. In this paper, we propose a contrastive
fine-tuning objective that enables BERT to produce more powerful phrase
embeddings. Our approach (Phrase-BERT) relies on a dataset of diverse phrasal
paraphrases, which is automatically generated using a paraphrase generation
model, as well as a large-scale dataset of phrases in context mined from the
Books3 corpus. Phrase-BERT outperforms baselines across a variety of
phrase-level similarity tasks, while also demonstrating increased lexical
diversity between nearest neighbors in the vector space. Finally, as a case
study, we show that Phrase-BERT embeddings can be easily integrated with a
simple autoencoder to build a phrase-based neural topic model that interprets
topics as mixtures of words and phrases by performing a nearest neighbor search
in the embedding space. Crowdsourced evaluations demonstrate that this
phrase-based topic model produces more coherent and meaningful topics than
baseline word and phrase-level topic models, further validating the utility of
Phrase-BERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mitigating Catastrophic Forgetting in Scheduled Sampling with Elastic Weight Consolidation in Neural Machine Translation. (arXiv:2109.06308v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06308">
<div class="article-summary-box-inner">
<span><p>Despite strong performance in many sequence-to-sequence tasks, autoregressive
models trained with maximum likelihood estimation suffer from exposure bias,
i.e. a discrepancy between the ground-truth prefixes used during training and
the model-generated prefixes used at inference time. Scheduled sampling is a
simple and often empirically successful approach which addresses this issue by
incorporating model-generated prefixes into the training process. However, it
has been argued that it is an inconsistent training objective leading to models
ignoring the prefixes altogether. In this paper, we conduct systematic
experiments and find that it ameliorates exposure bias by increasing model
reliance on the input sequence. We also observe that as a side-effect, it
worsens performance when the model-generated prefix is correct, a form of
catastrophic forgetting. We propose using Elastic Weight Consolidation as
trade-off between mitigating exposure bias and retaining output quality.
Experiments on two IWSLT'14 translation tasks demonstrate that our approach
alleviates catastrophic forgetting and significantly improves BLEU compared to
standard scheduled sampling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Constraints and Descriptive Segmentation for Subevent Detection. (arXiv:2109.06316v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06316">
<div class="article-summary-box-inner">
<span><p>Event mentions in text correspond to real-world events of varying degrees of
granularity. The task of subevent detection aims to resolve this granularity
issue, recognizing the membership of multi-granular events in event complexes.
Since knowing the span of descriptive contexts of event complexes helps infer
the membership of events, we propose the task of event-based text segmentation
(EventSeg) as an auxiliary task to improve the learning for subevent detection.
To bridge the two tasks together, we propose an approach to learning and
enforcing constraints that capture dependencies between subevent detection and
EventSeg prediction, as well as guiding the model to make globally consistent
inference. Specifically, we adopt Rectifier Networks for constraint learning
and then convert the learned constraints to a regularization term in the loss
function of the neural model. Experimental results show that the proposed
method outperforms baseline methods by 2.3% and 2.5% on benchmark datasets for
subevent detection, HiEve and IC, respectively, while achieving a decent
performance on EventSeg prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Massively Multilingual Analysis of Cross-linguality in Shared Embedding Space. (arXiv:2109.06324v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06324">
<div class="article-summary-box-inner">
<span><p>In cross-lingual language models, representations for many different
languages live in the same space. Here, we investigate the linguistic and
non-linguistic factors affecting sentence-level alignment in cross-lingual
pretrained language models for 101 languages and 5,050 language pairs. Using
BERT-based LaBSE and BiLSTM-based LASER as our models, and the Bible as our
corpus, we compute a task-based measure of cross-lingual alignment in the form
of bitext retrieval performance, as well as four intrinsic measures of vector
space alignment and isomorphism. We then examine a range of linguistic,
quasi-linguistic, and training-related features as potential predictors of
these alignment metrics. The results of our analyses show that word order
agreement and agreement in morphological complexity are two of the strongest
linguistic predictors of cross-linguality. We also note in-family training data
as a stronger predictor than language-specific training data across the board.
We verify some of our linguistic findings by looking at the effect of
morphological segmentation on English-Inuktitut alignment, in addition to
examining the effect of word order agreement on isomorphism for 66 zero-shot
language pairs from a different corpus. We make the data and code for our
experiments publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Transferability of BERT Models on Uralic Languages. (arXiv:2109.06327v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06327">
<div class="article-summary-box-inner">
<span><p>Transformer-based language models such as BERT have outperformed previous
models on a large number of English benchmarks, but their evaluation is often
limited to English or a small number of well-resourced languages. In this work,
we evaluate monolingual, multilingual, and randomly initialized language models
from the BERT family on a variety of Uralic languages including Estonian,
Finnish, Hungarian, Erzya, Moksha, Karelian, Livvi, Komi Permyak, Komi Zyrian,
Northern S\'ami, and Skolt S\'ami. When monolingual models are available
(currently only et, fi, hu), these perform better on their native language, but
in general they transfer worse than multilingual models or models of
genetically unrelated languages that share the same character set. Remarkably,
straightforward transfer of high-resource models, even without special efforts
toward hyperparameter optimization, yields what appear to be state of the art
POS and NER tools for the minority Uralic languages where there is sufficient
data for finetuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Old BERT, New Tricks: Artificial Language Learning for Pre-Trained Language Models. (arXiv:2109.06333v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06333">
<div class="article-summary-box-inner">
<span><p>We extend the artificial language learning experimental paradigm from
psycholinguistics and apply it to pre-trained language models -- specifically,
BERT (Devlin et al., 2019). We treat the model as a subject in an artificial
language learning experimental setting: in order to learn the relation between
two linguistic properties A and B, we introduce a set of new, non-existent,
linguistic items, give the model information about their variation along
property A, then measure to what extent the model learns property B for these
items as a result of training. We show this method at work for degree modifiers
(expressions like "slightly", "very", "rather", "extremely") and test the
hypothesis that the degree expressed by modifiers (low, medium or high degree)
is related to their sensitivity to sentence polarity (whether they show
preference for affirmative or negative sentences or neither). Our experimental
results are compatible with existing linguistic observations that relate degree
semantics to polarity-sensitivity, including the main one: low degree semantics
leads to positive polarity sensitivity (that is, to preference towards
affirmative contexts). The method can be used in linguistics to elaborate on
hypotheses and interpret experimental results, as well as for more insightful
evaluation of linguistic representations in language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Intent Detection via Contrastive Pre-Training and Fine-Tuning. (arXiv:2109.06349v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06349">
<div class="article-summary-box-inner">
<span><p>In this work, we focus on a more challenging few-shot intent detection
scenario where many intents are fine-grained and semantically similar. We
present a simple yet effective few-shot intent detection schema via contrastive
pre-training and fine-tuning. Specifically, we first conduct self-supervised
contrastive pre-training on collected intent datasets, which implicitly learns
to discriminate semantically similar utterances without using any labels. We
then perform few-shot intent detection together with supervised contrastive
learning, which explicitly pulls utterances from the same intent closer and
pushes utterances across different intents farther. Experimental results show
that our proposed method achieves state-of-the-art performance on three
challenging intent detection datasets under 5-shot and 10-shot settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty-Aware Machine Translation Evaluation. (arXiv:2109.06352v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06352">
<div class="article-summary-box-inner">
<span><p>Several neural-based metrics have been recently proposed to evaluate machine
translation quality. However, all of them resort to point estimates, which
provide limited information at segment level. This is made worse as they are
trained on noisy, biased and scarce human judgements, often resulting in
unreliable quality predictions. In this paper, we introduce uncertainty-aware
MT evaluation and analyze the trustworthiness of the predicted quality. We
combine the COMET framework with two uncertainty estimation methods, Monte
Carlo dropout and deep ensembles, to obtain quality scores along with
confidence intervals. We compare the performance of our uncertainty-aware MT
evaluation methods across multiple language pairs from the QT21 dataset and the
WMT20 metrics task, augmented with MQM annotations. We experiment with varying
numbers of references and further discuss the usefulness of uncertainty-aware
quality estimation (without references) to flag possibly critical translation
mistakes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hunspell for Sorani Kurdish Spell Checking and Morphological Analysis. (arXiv:2109.06374v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06374">
<div class="article-summary-box-inner">
<span><p>Spell checking and morphological analysis are two fundamental tasks in text
and natural language processing and are addressed in the early stages of the
development of language technology. Despite the previous efforts, there is no
progress in open-source to create such tools for Sorani Kurdish, also known as
Central Kurdish, as a less-resourced language. In this paper, we present our
efforts in annotating a lexicon with morphosyntactic tags and also, extracting
morphological rules of Sorani Kurdish to build a morphological analyzer, a
stemmer and a spell-checking system using Hunspell. This implementation can be
used for further developments in the field by researchers and also, be
integrated into text editors under a publicly available license.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Compression, Transduction, and Creation: A Unified Framework for Evaluating Natural Language Generation. (arXiv:2109.06379v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06379">
<div class="article-summary-box-inner">
<span><p>Natural language generation (NLG) spans a broad range of tasks, each of which
serves for specific objectives and desires different properties of generated
text. The complexity makes automatic evaluation of NLG particularly
challenging. Previous work has typically focused on a single task and developed
individual evaluation metrics based on specific intuitions. In this paper, we
propose a unifying perspective based on the nature of information change in NLG
tasks, including compression (e.g., summarization), transduction (e.g., text
rewriting), and creation (e.g., dialog). Information alignment between input,
context, and output text plays a common central role in characterizing the
generation. With automatic alignment prediction models, we develop a family of
interpretable metrics that are suitable for evaluating key aspects of different
NLG tasks, often without need of gold reference data. Experiments show the
uniformly designed metrics achieve stronger or comparable correlations with
human judgement compared to state-of-the-art metrics in each of diverse tasks,
including text summarization, style transfer, and knowledge-grounded dialog.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rationales for Sequential Predictions. (arXiv:2109.06387v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06387">
<div class="article-summary-box-inner">
<span><p>Sequence models are a critical component of modern NLP systems, but their
predictions are difficult to explain. We consider model explanations though
rationales, subsets of context that can explain individual model predictions.
We find sequential rationales by solving a combinatorial optimization: the best
rationale is the smallest subset of input tokens that would predict the same
output as the full sequence. Enumerating all subsets is intractable, so we
propose an efficient greedy algorithm to approximate this objective. The
algorithm, which is called greedy rationalization, applies to any model. For
this approach to be effective, the model should form compatible conditional
distributions when making predictions on incomplete subsets of the context.
This condition can be enforced with a short fine-tuning step. We study greedy
rationalization on language modeling and machine translation. Compared to
existing baselines, greedy rationalization is best at optimizing the
combinatorial objective and provides the most faithful rationales. On a new
dataset of annotated sequential rationales, greedy rationales are most similar
to human rationales.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Proposal Generation Network for Temporal Sentence Localization in Videos. (arXiv:2109.06398v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06398">
<div class="article-summary-box-inner">
<span><p>We address the problem of temporal sentence localization in videos (TSLV).
Traditional methods follow a top-down framework which localizes the target
segment with pre-defined segment proposals. Although they have achieved decent
performance, the proposals are handcrafted and redundant. Recently, bottom-up
framework attracts increasing attention due to its superior efficiency. It
directly predicts the probabilities for each frame as a boundary. However, the
performance of bottom-up model is inferior to the top-down counterpart as it
fails to exploit the segment-level interaction. In this paper, we propose an
Adaptive Proposal Generation Network (APGN) to maintain the segment-level
interaction while speeding up the efficiency. Specifically, we first perform a
foreground-background classification upon the video and regress on the
foreground frames to adaptively generate proposals. In this way, the
handcrafted proposal design is discarded and the redundant proposals are
decreased. Then, a proposal consolidation module is further developed to
enhance the semantic of the generated proposals. Finally, we locate the target
moments with these generated proposals following the top-down framework.
Extensive experiments on three challenging benchmarks show that our proposed
APGN significantly outperforms previous state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Progressively Guide to Attend: An Iterative Alignment Framework for Temporal Sentence Grounding. (arXiv:2109.06400v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06400">
<div class="article-summary-box-inner">
<span><p>A key solution to temporal sentence grounding (TSG) exists in how to learn
effective alignment between vision and language features extracted from an
untrimmed video and a sentence description. Existing methods mainly leverage
vanilla soft attention to perform the alignment in a single-step process.
However, such single-step attention is insufficient in practice, since
complicated relations between inter- and intra-modality are usually obtained
through multi-step reasoning. In this paper, we propose an Iterative Alignment
Network (IA-Net) for TSG task, which iteratively interacts inter- and
intra-modal features within multiple steps for more accurate grounding.
Specifically, during the iterative reasoning process, we pad multi-modal
features with learnable parameters to alleviate the nowhere-to-attend problem
of non-matched frame-word pairs, and enhance the basic co-attention mechanism
in a parallel manner. To further calibrate the misaligned attention caused by
each reasoning step, we also devise a calibration module following each
attention module to refine the alignment knowledge. With such iterative
alignment scheme, our IA-Net can robustly capture the fine-grained relations
between vision and language domains step-by-step for progressively reasoning
the temporal boundaries. Extensive experiments conducted on three challenging
benchmarks demonstrate that our proposed model performs better than the
state-of-the-arts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Personality and Online Social Engagement: An Investigation of MBTI Users on Twitter. (arXiv:2109.06402v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06402">
<div class="article-summary-box-inner">
<span><p>Text-based personality prediction by computational models is an emerging
field with the potential to significantly improve on key weaknesses of
survey-based personality assessment. We investigate 3848 profiles from Twitter
with self-labeled Myers-Briggs personality traits (MBTI) - a framework closely
related to the Five Factor Model of personality - to better understand how
text-based digital traces from social engagement online can be used to predict
user personality traits. We leverage BERT, a state-of-the-art NLP architecture
based on deep learning, to analyze various sources of text that hold most
predictive power for our task. We find that biographies, statuses, and liked
tweets contain significant predictive power for all dimensions of the MBTI
system. We discuss our findings and their implications for the validity of the
MBTI and the lexical hypothesis, a foundational theory underlying the Five
Factor Model that links language use and behavior. Our results hold optimistic
implications for personality psychologists, computational linguists, and other
social scientists aiming to predict personality from observational text data
and explore the links between language and core behavioral traits.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gradient Imitation Reinforcement Learning for Low Resource Relation Extraction. (arXiv:2109.06415v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06415">
<div class="article-summary-box-inner">
<span><p>Low-resource Relation Extraction (LRE) aims to extract relation facts from
limited labeled corpora when human annotation is scarce. Existing works either
utilize self-training scheme to generate pseudo labels that will cause the
gradual drift problem, or leverage meta-learning scheme which does not solicit
feedback explicitly. To alleviate selection bias due to the lack of feedback
loops in existing LRE learning paradigms, we developed a Gradient Imitation
Reinforcement Learning method to encourage pseudo label data to imitate the
gradient descent direction on labeled data and bootstrap its optimization
capability through trial and error. We also propose a framework called GradLRE,
which handles two major scenarios in low-resource relation extraction. Besides
the scenario where unlabeled data is sufficient, GradLRE handles the situation
where no unlabeled data is available, by exploiting a contextualized
augmentation method to generate data. Experimental results on two public
datasets demonstrate the effectiveness of GradLRE on low resource relation
extraction when comparing with baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-document Event Identity via Dense Annotation. (arXiv:2109.06417v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06417">
<div class="article-summary-box-inner">
<span><p>In this paper, we study the identity of textual events from different
documents. While the complex nature of event identity is previously studied
(Hovy et al., 2013), the case of events across documents is unclear. Prior work
on cross-document event coreference has two main drawbacks. First, they
restrict the annotations to a limited set of event types. Second, they
insufficiently tackle the concept of event identity. Such annotation setup
reduces the pool of event mentions and prevents one from considering the
possibility of quasi-identity relations. We propose a dense annotation approach
for cross-document event coreference, comprising a rich source of event
mentions and a dense annotation effort between related document pairs. To this
end, we design a new annotation workflow with careful quality control and an
easy-to-use annotation interface. In addition to the links, we further collect
overlapping event contexts, including time, location, and participants, to shed
some light on the relation between identity decisions and context. We present
an open-access dataset for cross-document event coreference, CDEC-WN, collected
from English Wikinews and open-source our annotation toolkit to encourage
further research on cross-document tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Commonsense-Focused Dialogues for Response Generation: An Empirical Study. (arXiv:2109.06427v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06427">
<div class="article-summary-box-inner">
<span><p>Smooth and effective communication requires the ability to perform latent or
explicit commonsense inference. Prior commonsense reasoning benchmarks (such as
SocialIQA and CommonsenseQA) mainly focus on the discriminative task of
choosing the right answer from a set of candidates, and do not involve
interactive language generation as in dialogue. Moreover, existing dialogue
datasets do not explicitly focus on exhibiting commonsense as a facet. In this
paper, we present an empirical study of commonsense in dialogue response
generation. We first auto-extract commonsensical dialogues from existing
dialogue datasets by leveraging ConceptNet, a commonsense knowledge graph.
Furthermore, building on social contexts/situations in SocialIQA, we collect a
new dialogue dataset with 25K dialogues aimed at exhibiting social commonsense
in an interactive setting. We evaluate response generation models trained using
these datasets and find that models trained on both extracted and our collected
data produce responses that consistently exhibit more commonsense than
baselines. Finally we propose an approach for automatic evaluation of
commonsense that relies on features derived from ConceptNet and pre-trained
language and dialog models, and show reasonable correlation with human
evaluation of responses' commonsense quality. We are releasing a subset of our
collected data, Commonsense-Dialogues, containing about 11K dialogs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">YES SIR!Optimizing Semantic Space of Negatives with Self-Involvement Ranker. (arXiv:2109.06436v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06436">
<div class="article-summary-box-inner">
<span><p>Pre-trained model such as BERT has been proved to be an effective tool for
dealing with Information Retrieval (IR) problems. Due to its inspiring
performance, it has been widely used to tackle with real-world IR problems such
as document ranking. Recently, researchers have found that selecting "hard"
rather than "random" negative samples would be beneficial for fine-tuning
pre-trained models on ranking tasks. However, it remains elusive how to
leverage hard negative samples in a principled way. To address the
aforementioned issues, we propose a fine-tuning strategy for document ranking,
namely Self-Involvement Ranker (SIR), to dynamically select hard negative
samples to construct high-quality semantic space for training a high-quality
ranking model. Specifically, SIR consists of sequential compressors implemented
with pre-trained models. Front compressor selects hard negative samples for
rear compressor. Moreover, SIR leverages supervisory signal to adaptively
adjust semantic space of negative samples. Finally, supervisory signal in rear
compressor is computed based on condition probability and thus can control
sample dynamic and further enhance the model performance. SIR is a lightweight
and general framework for pre-trained models, which simplifies the ranking
process in industry practice. We test our proposed solution on MS MARCO with
document ranking setting, and the results show that SIR can significantly
improve the ranking performance of various pre-trained models. Moreover, our
method became the new SOTA model anonymously on MS MARCO Document ranking
leaderboard in May 2021.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncovering Implicit Gender Bias in Narratives through Commonsense Inference. (arXiv:2109.06437v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06437">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models learn socially harmful biases from their training
corpora, and may repeat these biases when used for generation. We study gender
biases associated with the protagonist in model-generated stories. Such biases
may be expressed either explicitly ("women can't park") or implicitly (e.g. an
unsolicited male character guides her into a parking space). We focus on
implicit biases, and use a commonsense reasoning engine to uncover them.
Specifically, we infer and analyze the protagonist's motivations, attributes,
mental states, and implications on others. Our findings regarding implicit
biases are in line with prior work that studied explicit biases, for example
showing that female characters' portrayal is centered around appearance, while
male figures' focus on intellect.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task-adaptive Pre-training and Self-training are Complementary for Natural Language Understanding. (arXiv:2109.06466v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06466">
<div class="article-summary-box-inner">
<span><p>Task-adaptive pre-training (TAPT) and Self-training (ST) have emerged as the
major semi-supervised approaches to improve natural language understanding
(NLU) tasks with massive amount of unlabeled data. However, it's unclear
whether they learn similar representations or they can be effectively combined.
In this paper, we show that TAPT and ST can be complementary with simple TFS
protocol by following TAPT -&gt; Finetuning -&gt; Self-training (TFS) process.
Experimental results show that TFS protocol can effectively utilize unlabeled
data to achieve strong combined gains consistently across six datasets covering
sentiment classification, paraphrase identification, natural language
inference, named entity recognition and dialogue slot classification. We
investigate various semi-supervised settings and consistently show that gains
from TAPT and ST can be strongly additive by following TFS procedure. We hope
that TFS could serve as an important semi-supervised baseline for future NLP
studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identifying Untrustworthy Samples: Data Filtering for Open-domain Dialogues with Bayesian Optimization. (arXiv:2109.06471v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06471">
<div class="article-summary-box-inner">
<span><p>Being able to reply with a related, fluent, and informative response is an
indispensable requirement for building high-quality conversational agents. In
order to generate better responses, some approaches have been proposed, such as
feeding extra information by collecting large-scale datasets with human
annotations, designing neural conversational models (NCMs) with complex
architecture and loss functions, or filtering out untrustworthy samples based
on a dialogue attribute, e.g., Relatedness or Genericness. In this paper, we
follow the third research branch and present a data filtering method for
open-domain dialogues, which identifies untrustworthy samples from training
data with a quality measure that linearly combines seven dialogue attributes.
The attribute weights are obtained via Bayesian Optimization (BayesOpt) that
aims to optimize an objective function for dialogue generation iteratively on
the validation set. Then we score training samples with the quality measure,
sort them in descending order, and filter out those at the bottom. Furthermore,
to accelerate the "filter-train-evaluate" iterations involved in BayesOpt on
large-scale datasets, we propose a training framework that integrates maximum
likelihood estimation (MLE) and negative training method (NEG). The training
method updates parameters of a trained NCMs on two small sets with newly
maintained and removed samples, respectively. Specifically, MLE is applied to
maximize the log-likelihood of newly maintained samples, while NEG is used to
minimize the log-likelihood of newly removed ones. Experimental results on two
datasets show that our method can effectively identify untrustworthy samples,
and NCMs trained on the filtered datasets achieve better performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Logic-level Evidence Retrieval and Graph-based Verification Network for Table-based Fact Verification. (arXiv:2109.06480v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06480">
<div class="article-summary-box-inner">
<span><p>Table-based fact verification task aims to verify whether the given statement
is supported by the given semi-structured table. Symbolic reasoning with
logical operations plays a crucial role in this task. Existing methods leverage
programs that contain rich logical information to enhance the verification
process. However, due to the lack of fully supervised signals in the program
generation process, spurious programs can be derived and employed, which leads
to the inability of the model to catch helpful logical operations. To address
the aforementioned problems, in this work, we formulate the table-based fact
verification task as an evidence retrieval and reasoning framework, proposing
the Logic-level Evidence Retrieval and Graph-based Verification network
(LERGV). Specifically, we first retrieve logic-level program-like evidence from
the given table and statement as supplementary evidence for the table. After
that, we construct a logic-level graph to capture the logical relations between
entities and functions in the retrieved evidence, and design a graph-based
verification network to perform logic-level graph-based reasoning based on the
constructed graph to classify the final entailment relation. Experimental
results on the large-scale benchmark TABFACT show the effectiveness of the
proposed approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AligNART: Non-autoregressive Neural Machine Translation by Jointly Learning to Estimate Alignment and Translate. (arXiv:2109.06481v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06481">
<div class="article-summary-box-inner">
<span><p>Non-autoregressive neural machine translation (NART) models suffer from the
multi-modality problem which causes translation inconsistency such as token
repetition. Most recent approaches have attempted to solve this problem by
implicitly modeling dependencies between outputs. In this paper, we introduce
AligNART, which leverages full alignment information to explicitly reduce the
modality of the target distribution. AligNART divides the machine translation
task into $(i)$ alignment estimation and $(ii)$ translation with aligned
decoder inputs, guiding the decoder to focus on simplified one-to-one
translation. To alleviate the alignment estimation problem, we further propose
a novel alignment decomposition method. Our experiments show that AligNART
outperforms previous non-iterative NART models that focus on explicit modality
reduction on WMT14 En$\leftrightarrow$De and WMT16 Ro$\rightarrow$En.
Furthermore, AligNART achieves BLEU scores comparable to those of the
state-of-the-art connectionist temporal classification based models on WMT14
En$\leftrightarrow$De. We also observe that AligNART effectively addresses the
token repetition problem even without sequence-level knowledge distillation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilevel profiling of situation and dialogue-based deep networks for movie genre classification using movie trailers. (arXiv:2109.06488v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06488">
<div class="article-summary-box-inner">
<span><p>Automated movie genre classification has emerged as an active and essential
area of research and exploration. Short duration movie trailers provide useful
insights about the movie as video content consists of the cognitive and the
affective level features. Previous approaches were focused upon either
cognitive or affective content analysis. In this paper, we propose a novel
multi-modality: situation, dialogue, and metadata-based movie genre
classification framework that takes both cognition and affect-based features
into consideration. A pre-features fusion-based framework that takes into
account: situation-based features from a regular snapshot of a trailer that
includes nouns and verbs providing the useful affect-based mapping with the
corresponding genres, dialogue (speech) based feature from audio, metadata
which together provides the relevant information for cognitive and affect based
video analysis. We also develop the English movie trailer dataset (EMTD), which
contains 2000 Hollywood movie trailers belonging to five popular genres:
Action, Romance, Comedy, Horror, and Science Fiction, and perform
cross-validation on the standard LMTD-9 dataset for validating the proposed
framework. The results demonstrate that the proposed methodology for movie
genre classification has performed excellently as depicted by the F1 scores,
precision, recall, and area under the precision-recall curves.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">conSultantBERT: Fine-tuned Siamese Sentence-BERT for Matching Jobs and Job Seekers. (arXiv:2109.06501v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06501">
<div class="article-summary-box-inner">
<span><p>In this paper we focus on constructing useful embeddings of textual
information in vacancies and resumes, which we aim to incorporate as features
into job to job seeker matching models alongside other features. We explain our
task where noisy data from parsed resumes, heterogeneous nature of the
different sources of data, and crosslinguality and multilinguality present
domain-specific challenges.
</p>
<p>We address these challenges by fine-tuning a Siamese Sentence-BERT (SBERT)
model, which we call conSultantBERT, using a large-scale, real-world, and high
quality dataset of over 270,000 resume-vacancy pairs labeled by our staffing
consultants. We show how our fine-tuned model significantly outperforms
unsupervised and supervised baselines that rely on TF-IDF-weighted feature
vectors and BERT embeddings. In addition, we find our model successfully
matches cross-lingual and multilingual textual content.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tribrid: Stance Classification with Neural Inconsistency Detection. (arXiv:2109.06508v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06508">
<div class="article-summary-box-inner">
<span><p>We study the problem of performing automatic stance classification on social
media with neural architectures such as BERT. Although these architectures
deliver impressive results, their level is not yet comparable to the one of
humans and they might produce errors that have a significant impact on the
downstream task (e.g., fact-checking). To improve the performance, we present a
new neural architecture where the input also includes automatically generated
negated perspectives over a given claim. The model is jointly learned to make
simultaneously multiple predictions, which can be used either to improve the
classification of the original perspective or to filter out doubtful
predictions. In the first case, we propose a weakly supervised method for
combining the predictions into a final one. In the second case, we show that
using the confidence scores to remove doubtful predictions allows our method to
achieve human-like performance over the retained information, which is still a
sizable part of the original input.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Prompt-based Few-shot Learning for Grounded Dialog Generation. (arXiv:2109.06513v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06513">
<div class="article-summary-box-inner">
<span><p>Dialog grounding enables conversational models to make full use of external
information to establish multiple desired qualities, such as knowledgeable,
engaging and empathetic. However, naturally grounded dialog corpora are usually
not directly available, which puts forward requirements for the few-shot
learning ability of conversational models. Motivated by recent advances in
pre-trained language models and prompt-based learning, in this paper we explore
prompt-based few-shot learning for grounded dialog generation (GDG). We first
formulate the prompt construction for GDG tasks, based on which we then conduct
comprehensive empirical analysis on two common types of prompting methods:
template-based prompting and soft-prompting. We demonstrate the potential of
prompt-based methods in few-shot learning for GDG and provide directions of
improvement for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Netmarble AI Center's WMT21 Automatic Post-Editing Shared Task Submission. (arXiv:2109.06515v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06515">
<div class="article-summary-box-inner">
<span><p>This paper describes Netmarble's submission to WMT21 Automatic Post-Editing
(APE) Shared Task for the English-German language pair. First, we propose a
Curriculum Training Strategy in training stages. Facebook Fair's WMT19 news
translation model was chosen to engage the large and powerful pre-trained
neural networks. Then, we post-train the translation model with different
levels of data at each training stages. As the training stages go on, we make
the system learn to solve multiple tasks by adding extra information at
different training stages gradually. We also show a way to utilize the
additional data in large volume for APE tasks. For further improvement, we
apply Multi-Task Learning Strategy with the Dynamic Weight Average during the
fine-tuning stage. To fine-tune the APE corpus with limited data, we add some
related subtasks to learn a unified representation. Finally, for better
performance, we leverage external translations as augmented machine translation
(MT) during the post-training and fine-tuning. As experimental results show,
our APE system significantly improves the translations of provided MT results
by -2.848 and +3.74 on the development dataset in terms of TER and BLEU,
respectively. It also demonstrates its effectiveness on the test dataset with
higher quality than the development dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Sampling of Dependency Structures. (arXiv:2109.06521v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06521">
<div class="article-summary-box-inner">
<span><p>Probabilistic distributions over spanning trees in directed graphs are a
fundamental model of dependency structure in natural language processing,
syntactic dependency trees. In NLP, dependency trees often have an additional
root constraint: only one edge may emanate from the root. However, no sampling
algorithm has been presented in the literature to account for this additional
constraint. In this paper, we adapt two spanning tree sampling algorithms to
faithfully sample dependency trees from a graph subject to the root constraint.
Wilson (1996)'s sampling algorithm has a running time of $\mathcal{O}(H)$ where
$H$ is the mean hitting time of the graph. Colbourn (1996)'s sampling algorithm
has a running time of $\mathcal{O}(N^3)$, which is often greater than the mean
hitting time of a directed graph. Additionally, we build upon Colbourn's
algorithm and present a novel extension that can sample $K$ trees without
replacement in $\mathcal{O}(K N^3 + K^2 N)$ time. To the best of our knowledge,
no algorithm has been given for sampling spanning trees without replacement
from a directed graph.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Different Strokes for Different Folks: Investigating Appropriate Further Pre-training Approaches for Diverse Dialogue Tasks. (arXiv:2109.06524v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06524">
<div class="article-summary-box-inner">
<span><p>Loading models pre-trained on the large-scale corpus in the general domain
and fine-tuning them on specific downstream tasks is gradually becoming a
paradigm in Natural Language Processing. Previous investigations prove that
introducing a further pre-training phase between pre-training and fine-tuning
phases to adapt the model on the domain-specific unlabeled data can bring
positive effects. However, most of these further pre-training works just keep
running the conventional pre-training task, e.g., masked language model, which
can be regarded as the domain adaptation to bridge the data distribution gap.
After observing diverse downstream tasks, we suggest that different tasks may
also need a further pre-training phase with appropriate training tasks to
bridge the task formulation gap. To investigate this, we carry out a study for
improving multiple task-oriented dialogue downstream tasks through designing
various tasks at the further pre-training phase. The experiment shows that
different downstream tasks prefer different further pre-training tasks, which
have intrinsic correlation and most further pre-training tasks significantly
improve certain target tasks rather than all. Our investigation indicates that
it is of great importance and effectiveness to design appropriate further
pre-training tasks modeling specific information that benefit downstream tasks.
Besides, we present multiple constructive empirical conclusions for enhancing
task-oriented dialogues.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Bill Similarity with Annotated and Augmented Corpora of Bills. (arXiv:2109.06527v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06527">
<div class="article-summary-box-inner">
<span><p>Bill writing is a critical element of representative democracy. However, it
is often overlooked that most legislative bills are derived, or even directly
copied, from other bills. Despite the significance of bill-to-bill linkages for
understanding the legislative process, existing approaches fail to address
semantic similarities across bills, let alone reordering or paraphrasing which
are prevalent in legal document writing. In this paper, we overcome these
limitations by proposing a 5-class classification task that closely reflects
the nature of the bill generation process. In doing so, we construct a
human-labeled dataset of 4,721 bill-to-bill relationships at the
subsection-level and release this annotated dataset to the research community.
To augment the dataset, we generate synthetic data with varying degrees of
similarity, mimicking the complex bill writing process. We use BERT variants
and apply multi-stage training, sequentially fine-tuning our models with
synthetic and human-labeled datasets. We find that the predictive performance
significantly improves when training with both human-labeled and synthetic
data. Finally, we apply our trained model to infer section- and bill-level
similarities. Our analysis shows that the proposed methodology successfully
captures the similarities across legal documents at various levels of
aggregation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Gradient-based Adversarial Training for Text Classification by Contrastive Learning and Auto-Encoder. (arXiv:2109.06536v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06536">
<div class="article-summary-box-inner">
<span><p>Recent work has proposed several efficient approaches for generating
gradient-based adversarial perturbations on embeddings and proved that the
model's performance and robustness can be improved when they are trained with
these contaminated embeddings. While they paid little attention to how to help
the model to learn these adversarial samples more efficiently. In this work, we
focus on enhancing the model's ability to defend gradient-based adversarial
attack during the model's training process and propose two novel adversarial
training approaches: (1) CARL narrows the original sample and its adversarial
sample in the representation space while enlarging their distance from
different labeled samples. (2) RAR forces the model to reconstruct the original
sample from its adversarial representation. Experiments show that the proposed
two approaches outperform strong baselines on various text classification
datasets. Analysis experiments find that when using our approaches, the
semantic representation of the input sentence won't be significantly affected
by adversarial perturbations, and the model's performance drops less under
adversarial attack. That is to say, our approaches can effectively improve the
robustness of the model. Besides, RAR can also be used to generate text-form
adversarial samples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Challenging Instances are Worth Learning: Generating Valuable Negative Samples for Response Selection Training. (arXiv:2109.06538v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06538">
<div class="article-summary-box-inner">
<span><p>Retrieval-based chatbot selects the appropriate response from candidates
according to the context, which heavily depends on a response selection module.
A response selection module is generally a scoring model to evaluate candidates
and is usually trained on the annotated positive response and sampled negative
responses. Sampling negative responses lead to two risks: a). The sampled
negative instances, especially that from random sampling methods, are mostly
irrelevant to the dialogue context and too easy to be fitted at the training
stage while causing a weak model in the real scenario. b). The so-called
negative instances may be positive, which is known as the fake negative
problem. To address the above issue, we employ pre-trained language models,
such as the DialoGPT to construct more challenging negative instances to
enhance the model robustness. Specifically, we provide garbled context to the
pre-trained model to generate responses and filter the fake negative ones. In
this way, our negative instances are fluent, context-related, and more
challenging for the model to learn, while can not be positive. Extensive
experiments show that our method brings significant and stable improvements on
the dialogue response selection capacity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Talking Space: inference from spatial linguistic meanings. (arXiv:2109.06554v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06554">
<div class="article-summary-box-inner">
<span><p>This paper concerns the intersection of natural language and the physical
space around us in which we live, that we observe and/or imagine things within.
Many important features of language have spatial connotations, for example,
many prepositions (like in, next to, after, on, etc.) are fundamentally
spatial. Space is also a key factor of the meanings of many
words/phrases/sentences/text, and space is a, if not the key, context for
referencing (e.g. pointing) and embodiment.
</p>
<p>We propose a mechanism for how space and linguistic structure can be made to
interact in a matching compositional fashion. Examples include Cartesian space,
subway stations, chesspieces on a chess-board, and Penrose's staircase. The
starting point for our construction is the DisCoCat model of compositional
natural language meaning, which we relax to accommodate physical space. We
address the issue of having multiple agents/objects in a space, including the
case that each agent has different capabilities with respect to that space,
e.g., the specific moves each chesspiece can make, or the different velocities
one may be able to reach.
</p>
<p>Once our model is in place, we show how inferences drawing from the structure
of physical space can be made. We also how how linguistic model of space can
interact with other such models related to our senses and/or embodiment, such
as the conceptual spaces of colour, taste and smell, resulting in a rich
compositional model of meaning that is close to human experience and embodiment
in the world.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Just What do You Think You're Doing, Dave?' A Checklist for Responsible Data Use in NLP. (arXiv:2109.06598v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06598">
<div class="article-summary-box-inner">
<span><p>A key part of the NLP ethics movement is responsible use of data, but exactly
what that means or how it can be best achieved remain unclear. This position
paper discusses the core legal and ethical principles for collection and
sharing of textual data, and the tensions between them. We propose a potential
checklist for responsible data (re-)use that could both standardise the peer
review of conference submissions, as well as enable a more in-depth view of
published research across the community. Our proposal aims to contribute to the
development of a consistent standard for data (re-)use, embraced across NLP
conferences.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-Parametric Unsupervised Domain Adaptation for Neural Machine Translation. (arXiv:2109.06604v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06604">
<div class="article-summary-box-inner">
<span><p>Recently, $k$NN-MT has shown the promising capability of directly
incorporating the pre-trained neural machine translation (NMT) model with
domain-specific token-level $k$-nearest-neighbor ($k$NN) retrieval to achieve
domain adaptation without retraining. Despite being conceptually attractive, it
heavily relies on high-quality in-domain parallel corpora, limiting its
capability on unsupervised domain adaptation, where in-domain parallel corpora
are scarce or nonexistent. In this paper, we propose a novel framework that
directly uses in-domain monolingual sentences in the target language to
construct an effective datastore for $k$-nearest-neighbor retrieval. To this
end, we first introduce an autoencoder task based on the target language, and
then insert lightweight adapters into the original NMT model to map the
token-level representation of this task to the ideal representation of
translation task. Experiments on multi-domain datasets demonstrate that our
proposed approach significantly improves the translation accuracy with
target-side monolingual data, while achieving comparable performance with
back-translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MDAPT: Multilingual Domain Adaptive Pretraining in a Single Model. (arXiv:2109.06605v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06605">
<div class="article-summary-box-inner">
<span><p>Domain adaptive pretraining, i.e. the continued unsupervised pretraining of a
language model on domain-specific text, improves the modelling of text for
downstream tasks within the domain. Numerous real-world applications are based
on domain-specific text, e.g. working with financial or biomedical documents,
and these applications often need to support multiple languages. However,
large-scale domain-specific multilingual pretraining data for such scenarios
can be difficult to obtain, due to regulations, legislation, or simply a lack
of language- and domain-specific text. One solution is to train a single
multilingual model, taking advantage of the data available in as many languages
as possible. In this work, we explore the benefits of domain adaptive
pretraining with a focus on adapting to multiple languages within a specific
domain. We propose different techniques to compose pretraining corpora that
enable a language model to both become domain-specific and multilingual.
Evaluation on nine domain-specific datasets-for biomedical named entity
recognition and financial sentence classification-covering seven different
languages show that a single multilingual domain-specific model can outperform
the general multilingual model, and performs close to its monolingual
counterpart. This finding holds across two different pretraining methods,
adapter-based pretraining and full model pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scalable Font Reconstruction with Dual Latent Manifolds. (arXiv:2109.06627v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06627">
<div class="article-summary-box-inner">
<span><p>We propose a deep generative model that performs typography analysis and font
reconstruction by learning disentangled manifolds of both font style and
character shape. Our approach enables us to massively scale up the number of
character types we can effectively model compared to previous methods.
Specifically, we infer separate latent variables representing character and
font via a pair of inference networks which take as input sets of glyphs that
either all share a character type, or belong to the same font. This design
allows our model to generalize to characters that were not observed during
training time, an important task in light of the relative sparsity of most
fonts. We also put forward a new loss, adapted from prior work that measures
likelihood using an adaptive distribution in a projected space, resulting in
more natural images without requiring a discriminator. We evaluate on the task
of font reconstruction over various datasets representing character types of
many languages, and compare favorably to modern style transfer systems
according to both automatic and manually-evaluated metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An MRC Framework for Semantic Role Labeling. (arXiv:2109.06660v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06660">
<div class="article-summary-box-inner">
<span><p>Semantic Role Labeling (SRL) aims at recognizing the predicate-argument
structure of a sentence and can be decomposed into two subtasks: predicate
disambiguation and argument labeling. Prior work deals with these two tasks
independently, which ignores the semantic connection between the two tasks. In
this paper, we propose to use the machine reading comprehension (MRC) framework
to bridge this gap. We formalize predicate disambiguation as multiple-choice
machine reading comprehension, where the descriptions of candidate senses of a
given predicate are used as options to select the correct sense. The chosen
predicate sense is then used to determine the semantic roles for that
predicate, and these semantic roles are used to construct the query for another
MRC model for argument labeling. In this way, we are able to leverage both the
predicate semantics and the semantic role semantics for argument labeling. We
also propose to select a subset of all the possible semantic roles for
computational efficiency. Experiments show that the proposed framework achieves
state-of-the-art results on both span and dependency benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Expert Knowledge-Guided Length-Variant Hierarchical Label Generation for Proposal Classification. (arXiv:2109.06661v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06661">
<div class="article-summary-box-inner">
<span><p>To advance the development of science and technology, research proposals are
submitted to open-court competitive programs developed by government agencies
(e.g., NSF). Proposal classification is one of the most important tasks to
achieve effective and fair review assignments. Proposal classification aims to
classify a proposal into a length-variant sequence of labels. In this paper, we
formulate the proposal classification problem into a hierarchical multi-label
classification task. Although there are certain prior studies, proposal
classification exhibit unique features: 1) the classification result of a
proposal is in a hierarchical discipline structure with different levels of
granularity; 2) proposals contain multiple types of documents; 3) domain
experts can empirically provide partial labels that can be leveraged to improve
task performances. In this paper, we focus on developing a new deep proposal
classification framework to jointly model the three features. In particular, to
sequentially generate labels, we leverage previously-generated labels to
predict the label of next level; to integrate partial labels from experts, we
use the embedding of these empirical partial labels to initialize the state of
neural networks. Our model can automatically identify the best length of label
sequence to stop next label prediction. Finally, we present extensive results
to demonstrate that our method can jointly model partial labels, textual
information, and semantic dependencies in label sequences, and, thus, achieve
advanced performances.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Inference for Multilingual Neural Machine Translation. (arXiv:2109.06679v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06679">
<div class="article-summary-box-inner">
<span><p>Multilingual NMT has become an attractive solution for MT deployment in
production. But to match bilingual quality, it comes at the cost of larger and
slower models. In this work, we consider several ways to make multilingual NMT
faster at inference without degrading its quality. We experiment with several
"light decoder" architectures in two 20-language multi-parallel settings:
small-scale on TED Talks and large-scale on ParaCrawl. Our experiments
demonstrate that combining a shallow decoder with vocabulary filtering leads to
more than twice faster inference with no loss in translation quality. We
validate our findings with BLEU and chrF (on 380 language pairs), robustness
evaluation and human evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-autoregressive Transformer with Unified Bidirectional Decoder for Automatic Speech Recognition. (arXiv:2109.06684v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06684">
<div class="article-summary-box-inner">
<span><p>Non-autoregressive (NAR) transformer models have been studied intensively in
automatic speech recognition (ASR), and a substantial part of NAR transformer
models is to use the casual mask to limit token dependencies. However, the
casual mask is designed for the left-to-right decoding process of the
non-parallel autoregressive (AR) transformer, which is inappropriate for the
parallel NAR transformer since it ignores the right-to-left contexts. Some
models are proposed to utilize right-to-left contexts with an extra decoder,
but these methods increase the model complexity. To tackle the above problems,
we propose a new non-autoregressive transformer with a unified bidirectional
decoder (NAT-UBD), which can simultaneously utilize left-to-right and
right-to-left contexts. However, direct use of bidirectional contexts will
cause information leakage, which means the decoder output can be affected by
the character information from the input of the same position. To avoid
information leakage, we propose a novel attention mask and modify vanilla
queries, keys, and values matrices for NAT-UBD. Experimental results verify
that NAT-UBD can achieve character error rates (CERs) of 5.0%/5.5% on the
Aishell1 dev/test sets, outperforming all previous NAR transformer models.
Moreover, NAT-UBD can run 49.8x faster than the AR transformer baseline when
decoding in a single step.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A system for information extraction from scientific texts in Russian. (arXiv:2109.06703v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06703">
<div class="article-summary-box-inner">
<span><p>In this paper, we present a system for information extraction from scientific
texts in the Russian language. The system performs several tasks in an
end-to-end manner: term recognition, extraction of relations between terms, and
term linking with entities from the knowledge base. These tasks are extremely
important for information retrieval, recommendation systems, and
classification. The advantage of the implemented methods is that the system
does not require a large amount of labeled data, which saves time and effort
for data labeling and therefore can be applied in low- and mid-resource
settings. The source code is publicly available and can be used for different
research purposes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KFCNet: Knowledge Filtering and Contrastive Learning Network for Generative Commonsense Reasoning. (arXiv:2109.06704v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06704">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models have led to substantial gains over a broad range
of natural language processing (NLP) tasks, but have been shown to have
limitations for natural language generation tasks with high-quality
requirements on the output, such as commonsense generation and ad keyword
generation. In this work, we present a novel Knowledge Filtering and
Contrastive learning Network (KFCNet) which references external knowledge and
achieves better generation performance. Specifically, we propose a BERT-based
filter model to remove low-quality candidates, and apply contrastive learning
separately to each of the encoder and decoder, within a general
encoder--decoder architecture. The encoder contrastive module helps to capture
global target semantics during encoding, and the decoder contrastive module
enhances the utility of retrieved prototypes while learning general features.
Extensive experiments on the CommonGen benchmark show that our model
outperforms the previous state of the art by a large margin: +6.6 points (42.5
vs. 35.9) for BLEU-4, +3.7 points (33.3 vs. 29.6) for SPICE, and +1.3 points
(18.3 vs. 17.0) for CIDEr. We further verify the effectiveness of the proposed
contrastive module on ad keyword generation, and show that our model has
potential commercial value.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Global Feature-Oriented Relational Triple Extraction Model based on Table Filling. (arXiv:2109.06705v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06705">
<div class="article-summary-box-inner">
<span><p>Table filling based relational triple extraction methods are attracting
growing research interests due to their promising performance and their
abilities on extracting triples from complex sentences. However, this kind of
methods are far from their full potential because most of them only focus on
using local features but ignore the global associations of relations and of
token pairs, which increases the possibility of overlooking some important
information during triple extraction. To overcome this deficiency, we propose a
global feature-oriented triple extraction model that makes full use of the
mentioned two kinds of global associations. Specifically, we first generate a
table feature for each relation. Then two kinds of global associations are
mined from the generated table features. Next, the mined global associations
are integrated into the table feature of each relation. This
"generate-mine-integrate" process is performed multiple times so that the table
feature of each relation is refined step by step. Finally, each relation's
table is filled based on its refined table feature, and all triples linked to
this relation are extracted based on its filled table. We evaluate the proposed
model on three benchmark datasets. Experimental results show our model is
effective and it achieves state-of-the-art results on all of these datasets.
The source code of our work is available at: https://github.com/neukg/GRTE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Answer Type Prediction using BERT: IAI at the ISWC SMART Task 2020. (arXiv:2109.06714v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06714">
<div class="article-summary-box-inner">
<span><p>This paper summarizes our participation in the SMART Task of the ISWC 2020
Challenge. A particular question we are interested in answering is how well
neural methods, and specifically transformer models, such as BERT, perform on
the answer type prediction task compared to traditional approaches. Our main
finding is that coarse-grained answer types can be identified effectively with
standard text classification methods, with over 95% accuracy, and BERT can
bring only marginal improvements. For fine-grained type detection, on the other
hand, BERT clearly outperforms previous retrieval-based approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controllable Dialogue Generation with Disentangled Multi-grained Style Specification and Attribute Consistency Reward. (arXiv:2109.06717v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06717">
<div class="article-summary-box-inner">
<span><p>Controllable text generation is an appealing but challenging task, which
allows users to specify particular attributes of the generated outputs. In this
paper, we propose a controllable dialogue generation model to steer response
generation under multi-attribute constraints. Specifically, we define and
categorize the commonly used control attributes into global and local ones,
which possess different granularities of effects on response generation. Then,
we significantly extend the conventional seq2seq framework by introducing a
novel two-stage decoder, which first uses a multi-grained style specification
layer to impose the stylistic constraints and determine word-level control
states of responses based on the attributes, and then employs a response
generation layer to generate final responses maintaining both semantic
relevancy to the contexts and fidelity to the attributes. Furthermore, we train
our model with an attribute consistency reward to promote response control with
explicit supervision signals. Extensive experiments and in-depth analyses on
two datasets indicate that our model can significantly outperform competitive
baselines in terms of response quality, content diversity and controllability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse Fuzzy Attention for Structural Sentiment Analysis. (arXiv:2109.06719v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06719">
<div class="article-summary-box-inner">
<span><p>Attention scorers have achieved success in parsing tasks like semantic and
syntactic dependency parsing. However, in tasks modeled into parsing, like
structural sentiment analysis, "dependency edges" are very sparse which hinders
parser performance. Thus we propose a sparse and fuzzy attention scorer with
pooling layers which improves parser performance and sets the new
state-of-the-art on structural sentiment analysis. We further explore the
parsing modeling on structural sentiment analysis with second-order parsing and
introduce a novel sparse second-order edge building procedure that leads to
significant improvement in parsing performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sequential Modelling with Applications to Music Recommendation, Fact-Checking, and Speed Reading. (arXiv:2109.06736v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06736">
<div class="article-summary-box-inner">
<span><p>Sequential modelling entails making sense of sequential data, which naturally
occurs in a wide array of domains. One example is systems that interact with
users, log user actions and behaviour, and make recommendations of items of
potential interest to users on the basis of their previous interactions. In
such cases, the sequential order of user interactions is often indicative of
what the user is interested in next. Similarly, for systems that automatically
infer the semantics of text, capturing the sequential order of words in a
sentence is essential, as even a slight re-ordering could significantly alter
its original meaning. This thesis makes methodological contributions and new
investigations of sequential modelling for the specific application areas of
systems that recommend music tracks to listeners and systems that process text
semantics in order to automatically fact-check claims, or "speed read" text for
efficient further classification. (Rest of abstract omitted due to arXiv
abstract limit)
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Information Seeking for Open-Domain Question Answering. (arXiv:2109.06747v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06747">
<div class="article-summary-box-inner">
<span><p>Information seeking is an essential step for open-domain question answering
to efficiently gather evidence from a large corpus. Recently, iterative
approaches have been proven to be effective for complex questions, by
recursively retrieving new evidence at each step. However, almost all existing
iterative approaches use predefined strategies, either applying the same
retrieval function multiple times or fixing the order of different retrieval
functions, which cannot fulfill the diverse requirements of various questions.
In this paper, we propose a novel adaptive information-seeking strategy for
open-domain question answering, namely AISO. Specifically, the whole retrieval
and answer process is modeled as a partially observed Markov decision process,
where three types of retrieval operations (e.g., BM25, DPR, and hyperlink) and
one answer operation are defined as actions. According to the learned policy,
AISO could adaptively select a proper retrieval action to seek the missing
evidence at each step, based on the collected evidence and the reformulated
query, or directly output the answer when the evidence set is sufficient for
the question. Experiments on SQuAD Open and HotpotQA fullwiki, which serve as
single-hop and multi-hop open-domain QA benchmarks, show that AISO outperforms
all baseline methods with predefined strategies in terms of both retrieval and
answer evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Zero-shot Cross-lingual Transfer between Closely Related Languages by injecting Character-level Noise. (arXiv:2109.06772v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06772">
<div class="article-summary-box-inner">
<span><p>Cross-lingual transfer between a high-resource language and its dialects or
closely related language varieties should be facilitated by their similarity,
but current approaches that operate in the embedding space do not take surface
similarity into account. In this work, we present a simple yet effective
strategy to improve cross-lingual transfer between closely related varieties by
augmenting the data of the high-resource parent language with character-level
noise to make the model more robust towards spelling variations. Our strategy
shows consistent improvements over several languages and tasks: Zero-shot
transfer of POS tagging and topic identification between language varieties
from the Germanic, Uralic, and Romance language genera. Our work provides
evidence for the usefulness of simple surface-level noise in improving transfer
between language varieties.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Everything Is All It Takes: A Multipronged Strategy for Zero-Shot Cross-Lingual Information Extraction. (arXiv:2109.06798v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06798">
<div class="article-summary-box-inner">
<span><p>Zero-shot cross-lingual information extraction (IE) describes the
construction of an IE model for some target language, given existing
annotations exclusively in some other language, typically English. While the
advance of pretrained multilingual encoders suggests an easy optimism of "train
on English, run on any language", we find through a thorough exploration and
extension of techniques that a combination of approaches, both new and old,
leads to better performance than any one cross-lingual strategy in particular.
We explore techniques including data projection and self-training, and how
different pretrained encoders impact them. We use English-to-Arabic IE as our
initial example, demonstrating strong performance in this setting for event
extraction, named entity recognition, part-of-speech tagging, and dependency
parsing. We then apply data projection and self-training to three tasks across
eight target languages. Because no single set of techniques performs the best
across all tasks, we encourage practitioners to explore various configurations
of the techniques described in this work when seeking to improve on zero-shot
training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Temporal Variational Model for Story Generation. (arXiv:2109.06807v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06807">
<div class="article-summary-box-inner">
<span><p>Recent language models can generate interesting and grammatically correct
text in story generation but often lack plot development and long-term
coherence. This paper experiments with a latent vector planning approach based
on a TD-VAE (Temporal Difference Variational Autoencoder), using the model for
conditioning and reranking for text generation. The results demonstrate strong
performance in automatic cloze and swapping evaluations. The human judgments
show stories generated with TD-VAE reranking improve on a GPT-2 medium baseline
and show comparable performance to a hierarchical LSTM reranking model.
Conditioning on the latent vectors proves disappointing and deteriorates
performance in human evaluation because it reduces the diversity of generation,
and the models don't learn to progress the narrative. This highlights an
important difference between technical task performance (e.g. cloze) and
generating interesting stories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What are the attackers doing now? Automating cyber threat intelligence extraction from text on pace with the changing threat landscape: A survey. (arXiv:2109.06808v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06808">
<div class="article-summary-box-inner">
<span><p>Cybersecurity researchers have contributed to the automated extraction of CTI
from textual sources, such as threat reports and online articles, where
cyberattack strategies, procedures, and tools are described. The goal of this
article is to aid cybersecurity researchers understand the current techniques
used for cyberthreat intelligence extraction from text through a survey of
relevant studies in the literature. We systematically collect "CTI extraction
from text"-related studies from the literature and categorize the CTI
extraction purposes. We propose a CTI extraction pipeline abstracted from these
studies. We identify the data sources, techniques, and CTI sharing formats
utilized in the context of the proposed pipeline. Our work finds ten types of
extraction purposes, such as extraction indicators of compromise extraction,
TTPs (tactics, techniques, procedures of attack), and cybersecurity keywords.
We also identify seven types of textual sources for CTI extraction, and textual
data obtained from hacker forums, threat reports, social media posts, and
online news articles have been used by almost 90% of the studies. Natural
language processing along with both supervised and unsupervised machine
learning techniques such as named entity recognition, topic modelling,
dependency parsing, supervised classification, and clustering are used for CTI
extraction. We observe the technical challenges associated with these studies
related to obtaining available clean, labelled data which could assure
replication, validation, and further extension of the studies. As we find the
studies focusing on CTI information extraction from text, we advocate for
building upon the current CTI extraction work to help cybersecurity
practitioners with proactive decision making such as threat prioritization,
automated threat modelling to utilize knowledge from past cybersecurity
incidents.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LM-Critic: Language Models for Unsupervised Grammatical Error Correction. (arXiv:2109.06822v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06822">
<div class="article-summary-box-inner">
<span><p>Training a model for grammatical error correction (GEC) requires a set of
labeled ungrammatical / grammatical sentence pairs, but manually annotating
such pairs can be expensive. Recently, the Break-It-Fix-It (BIFI) framework has
demonstrated strong results on learning to repair a broken program without any
labeled examples, but this relies on a perfect critic (e.g., a compiler) that
returns whether an example is valid or not, which does not exist for the GEC
task. In this work, we show how to leverage a pretrained language model (LM) in
defining an LM-Critic, which judges a sentence to be grammatical if the LM
assigns it a higher probability than its local perturbations. We apply this
LM-Critic and BIFI along with a large set of unlabeled sentences to bootstrap
realistic ungrammatical / grammatical pairs for training a corrector. We
evaluate our approach on GEC datasets across multiple domains (CoNLL-2014,
BEA-2019, GMEG-wiki and GMEG-yahoo) and show that it outperforms existing
methods in both the unsupervised setting (+7.7 F0.5) and the supervised setting
(+0.5 F0.5).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Types of Out-of-Distribution Texts and How to Detect Them. (arXiv:2109.06827v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06827">
<div class="article-summary-box-inner">
<span><p>Despite agreement on the importance of detecting out-of-distribution (OOD)
examples, there is little consensus on the formal definition of OOD examples
and how to best detect them. We categorize these examples by whether they
exhibit a background shift or a semantic shift, and find that the two major
approaches to OOD detection, model calibration and density estimation (language
modeling for text), have distinct behavior on these types of OOD data. Across
14 pairs of in-distribution and OOD English natural language understanding
datasets, we find that density estimation methods consistently beat calibration
methods in background shift settings, while performing worse in semantic shift
settings. In addition, we find that both methods generally fail to detect
examples from challenge data, highlighting a weak spot for current methods.
Since no single method works well across all settings, our results call for an
explicit definition of OOD examples when evaluating different detection
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Perils of Using Mechanical Turk to Evaluate Open-Ended Text Generation. (arXiv:2109.06835v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06835">
<div class="article-summary-box-inner">
<span><p>Recent text generation research has increasingly focused on open-ended
domains such as story and poetry generation. Because models built for such
tasks are difficult to evaluate automatically, most researchers in the space
justify their modeling choices by collecting crowdsourced human judgments of
text quality (e.g., Likert scores of coherence or grammaticality) from Amazon
Mechanical Turk (AMT). In this paper, we first conduct a survey of 45
open-ended text generation papers and find that the vast majority of them fail
to report crucial details about their AMT tasks, hindering reproducibility. We
then run a series of story evaluation experiments with both AMT workers and
English teachers and discover that even with strict qualification filters, AMT
workers (unlike teachers) fail to distinguish between model-generated text and
human-generated references. We show that AMT worker judgments improve when they
are shown model-generated output alongside human-generated references, which
enables the workers to better calibrate their ratings. Finally, interviews with
the English teachers provide deeper insights into the challenges of the
evaluation process, particularly when rating model-generated text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ePiC: Employing Proverbs in Context as a Benchmark for Abstract Language Understanding. (arXiv:2109.06838v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06838">
<div class="article-summary-box-inner">
<span><p>While large language models have shown exciting progress on several NLP
benchmarks, evaluating their ability for complex analogical reasoning remains
under-explored. Here, we introduce a high-quality crowdsourced dataset of
narratives for employing proverbs in context as a benchmark for abstract
language understanding. The dataset provides fine-grained annotation of aligned
spans between proverbs and narratives, and contains minimal lexical overlaps
between narratives and proverbs, ensuring that models need to go beyond
surface-level reasoning to succeed. We explore three tasks: (1) proverb
recommendation and alignment prediction, (2) narrative generation for a given
proverb and topic, and (3) identifying narratives with similar motifs. Our
experiments show that neural language models struggle in our tasks compared to
humans, and the tasks pose multiple learning challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BenchIE: Open Information Extraction Evaluation Based on Facts, Not Tokens. (arXiv:2109.06850v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06850">
<div class="article-summary-box-inner">
<span><p>Intrinsic evaluations of OIE systems are carried out either manually -- with
human evaluators judging the correctness of extractions -- or automatically, on
standardized benchmarks. The latter, while much more cost-effective, is less
reliable, primarily because of the incompleteness of the existing OIE
benchmarks: the ground truth extractions do not include all acceptable variants
of the same fact, leading to unreliable assessment of models' performance.
Moreover, the existing OIE benchmarks are available for English only. In this
work, we introduce BenchIE: a benchmark and evaluation framework for
comprehensive evaluation of OIE systems for English, Chinese and German. In
contrast to existing OIE benchmarks, BenchIE takes into account informational
equivalence of extractions: our gold standard consists of fact synsets,
clusters in which we exhaustively list all surface forms of the same fact. We
benchmark several state-of-the-art OIE systems using BenchIE and demonstrate
that these systems are significantly less effective than indicated by existing
OIE benchmarks. We make BenchIE (data and evaluation code) publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Summarize-then-Answer: Generating Concise Explanations for Multi-hop Reading Comprehension. (arXiv:2109.06853v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06853">
<div class="article-summary-box-inner">
<span><p>How can we generate concise explanations for multi-hop Reading Comprehension
(RC)? The current strategies of identifying supporting sentences can be seen as
an extractive question-focused summarization of the input text. However, these
extractive explanations are not necessarily concise i.e. not minimally
sufficient for answering a question. Instead, we advocate for an abstractive
approach, where we propose to generate a question-focused, abstractive summary
of input paragraphs and then feed it to an RC system. Given a limited amount of
human-annotated abstractive explanations, we train the abstractive explainer in
a semi-supervised manner, where we start from the supervised model and then
train it further through trial and error maximizing a conciseness-promoted
reward function. Our experiments demonstrate that the proposed abstractive
explainer can generate more compact explanations than an extractive explainer
with limited supervision (only 2k instances) while maintaining sufficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Broaden the Vision: Geo-Diverse Visual Commonsense Reasoning. (arXiv:2109.06860v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06860">
<div class="article-summary-box-inner">
<span><p>Commonsense is defined as the knowledge that is shared by everyone. However,
certain types of commonsense knowledge are correlated with culture and
geographic locations and they are only shared locally. For example, the
scenarios of wedding ceremonies vary across regions due to different customs
influenced by historical and religious factors. Such regional characteristics,
however, are generally omitted in prior work. In this paper, we construct a
Geo-Diverse Visual Commonsense Reasoning dataset (GD-VCR) to test
vision-and-language models' ability to understand cultural and
geo-location-specific commonsense. In particular, we study two state-of-the-art
Vision-and-Language models, VisualBERT and ViLBERT trained on VCR, a standard
multimodal commonsense benchmark with images primarily from Western regions. We
then evaluate how well the trained models can generalize to answering the
questions in GD-VCR. We find that the performance of both models for
non-Western regions including East Asia, South Asia, and Africa is
significantly lower than that for Western region. We analyze the reasons behind
the performance disparity and find that the performance gap is larger on QA
pairs that: 1) are concerned with culture-related scenarios, e.g., weddings,
religious activities, and festivals; 2) require high-level geo-diverse
commonsense reasoning rather than low-order perception and recognition. Dataset
and code are released at https://github.com/WadeYin9712/GD-VCR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Legal Transformer Models May Not Always Help. (arXiv:2109.06862v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06862">
<div class="article-summary-box-inner">
<span><p>Deep learning-based Natural Language Processing methods, especially
transformers, have achieved impressive performance in the last few years.
Applying those state-of-the-art NLP methods to legal activities to automate or
simplify some simple work is of great value. This work investigates the value
of domain adaptive pre-training and language adapters in legal NLP tasks. By
comparing the performance of language models with domain adaptive pre-training
on different tasks and different dataset splits, we show that domain adaptive
pre-training is only helpful with low-resource downstream tasks, thus far from
being a panacea. We also benchmark the performance of adapters in a typical
legal NLP task and show that they can yield similar performance to full model
tuning with much smaller training costs. As an additional result, we release
LegalRoBERTa, a RoBERTa model further pre-trained on legal corpora.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition. (arXiv:2109.06870v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06870">
<div class="article-summary-box-inner">
<span><p>This paper is a study of performance-efficiency trade-offs in pre-trained
models for automatic speech recognition (ASR). We focus on wav2vec 2.0, and
formalize several architecture designs that influence both the model
performance and its efficiency. Putting together all our observations, we
introduce SEW (Squeezed and Efficient Wav2vec), a pre-trained model
architecture with significant improvements along both performance and
efficiency dimensions across a variety of training setups. For example, under
the 100h-960h semi-supervised setup on LibriSpeech, SEW achieves a 1.9x
inference speedup compared to wav2vec 2.0, with a 13.5% relative reduction in
word error rate. With a similar inference time, SEW reduces word error rate by
25-50% across different model sizes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Hyper-Parameter Optimization for Neural Machine Translation on GPU Architectures. (arXiv:1805.02094v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1805.02094">
<div class="article-summary-box-inner">
<span><p>Neural machine translation (NMT) has been accelerated by deep learning neural
networks over statistical-based approaches, due to the plethora and
programmability of commodity heterogeneous computing architectures such as
FPGAs and GPUs and the massive amount of training corpuses generated from news
outlets, government agencies and social media. Training a learning classifier
for neural networks entails tuning hyper-parameters that would yield the best
performance. Unfortunately, the number of parameters for machine translation
include discrete categories as well as continuous options, which makes for a
combinatorial explosive problem. This research explores optimizing
hyper-parameters when training deep learning neural networks for machine
translation. Specifically, our work investigates training a language model with
Marian NMT. Results compare NMT under various hyper-parameter settings across a
variety of modern GPU architecture generations in single node and multi-node
settings, revealing insights on which hyper-parameters matter most in terms of
performance, such as words processed per second, convergence rates, and
translation accuracy, and provides insights on how to best achieve
high-performing NMT systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fighting the COVID-19 Infodemic: Modeling the Perspective of Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the Society. (arXiv:2005.00033v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00033">
<div class="article-summary-box-inner">
<span><p>With the emergence of the COVID-19 pandemic, the political and the medical
aspects of disinformation merged as the problem got elevated to a whole new
level to become the first global infodemic. Fighting this infodemic has been
declared one of the most important focus areas of the World Health
Organization, with dangers ranging from promoting fake cures, rumors, and
conspiracy theories to spreading xenophobia and panic. Ad-dressing the issue
requires solving a number of challenging problems such as identifying messages
containing claims, determining their check-worthiness and factuality, and their
potential to do harm as well as the nature of that harm, to mention just a few.
To address this gap, we release a large dataset of 16K manually annotated
tweets for fine-grained disinformation analysis that (i) focuses on COVID-19,
(ii) combines the perspectives and the interests of journalists, fact-checkers,
social media platforms, policy makers, and society, and (iii) covers Arabic,
Bulgarian, Dutch, and English. Finally, we show strong evaluation results using
pretrained Transformers, thus con-firming the practical utility of the dataset
in monolingual vs. multilingual, and single task vs. multitask settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">L2R2: Leveraging Ranking for Abductive Reasoning. (arXiv:2005.11223v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.11223">
<div class="article-summary-box-inner">
<span><p>The abductive natural language inference task ($\alpha$NLI) is proposed to
evaluate the abductive reasoning ability of a learning system. In the
$\alpha$NLI task, two observations are given and the most plausible hypothesis
is asked to pick out from the candidates. Existing methods simply formulate it
as a classification problem, thus a cross-entropy log-loss objective is used
during training. However, discriminating true from false does not measure the
plausibility of a hypothesis, for all the hypotheses have a chance to happen,
only the probabilities are different. To fill this gap, we switch to a ranking
perspective that sorts the hypotheses in order of their plausibilities. With
this new perspective, a novel $L2R^2$ approach is proposed under the
learning-to-rank framework. Firstly, training samples are reorganized into a
ranking form, where two observations and their hypotheses are treated as the
query and a set of candidate documents respectively. Then, an ESIM model or
pre-trained language model, e.g. BERT or RoBERTa, is obtained as the scoring
function. Finally, the loss functions for the ranking task can be either
pair-wise or list-wise for training. The experimental results on the ART
dataset reach the state-of-the-art in the public leaderboard.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Document Graph for Neural Machine Translation. (arXiv:2012.03477v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03477">
<div class="article-summary-box-inner">
<span><p>Previous works have shown that contextual information can improve the
performance of neural machine translation (NMT). However, most existing
document-level NMT methods only consider a few number of previous sentences.
How to make use of the whole document as global contexts is still a challenge.
To address this issue, we hypothesize that a document can be represented as a
graph that connects relevant contexts regardless of their distances. We employ
several types of relations, including adjacency, syntactic dependency, lexical
consistency, and coreference, to construct the document graph. Then, we
incorporate both source and target graphs into the conventional Transformer
architecture with graph convolutional networks. Experiments on various NMT
benchmarks, including IWSLT English--French, Chinese-English, WMT
English--German and Opensubtitle English--Russian, demonstrate that using
document graphs can significantly improve the translation quality. Extensive
analysis verifies that the document graph is beneficial for capturing discourse
phenomena.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantum Mathematics in Artificial Intelligence. (arXiv:2101.04255v4 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.04255">
<div class="article-summary-box-inner">
<span><p>In the decade since 2010, successes in artificial intelligence have been at
the forefront of computer science and technology, and vector space models have
solidified a position at the forefront of artificial intelligence. At the same
time, quantum computers have become much more powerful, and announcements of
major advances are frequently in the news.
</p>
<p>The mathematical techniques underlying both these areas have more in common
than is sometimes realized. Vector spaces took a position at the axiomatic
heart of quantum mechanics in the 1930s, and this adoption was a key motivation
for the derivation of logic and probability from the linear geometry of vector
spaces. Quantum interactions between particles are modelled using the tensor
product, which is also used to express objects and operations in artificial
neural networks.
</p>
<p>This paper describes some of these common mathematical areas, including
examples of how they are used in artificial intelligence (AI), particularly in
automated reasoning and natural language processing (NLP). Techniques discussed
include vector spaces, scalar products, subspaces and implication, orthogonal
projection and negation, dual vectors, density matrices, positive operators,
and tensor products. Application areas include information retrieval,
categorization and implication, modelling word-senses and disambiguation,
inference in knowledge bases, and semantic composition.
</p>
<p>Some of these approaches can potentially be implemented on quantum hardware.
Many of the practical steps in this implementation are in early stages, and
some are already realized. Explaining some of the common mathematical tools can
help researchers in both AI and quantum computing further exploit these
overlaps, recognizing and exploring new directions along the way.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fused Acoustic and Text Encoding for Multimodal Bilingual Pretraining and Speech Translation. (arXiv:2102.05766v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05766">
<div class="article-summary-box-inner">
<span><p>Recently, representation learning for text and speech has successfully
improved many language related tasks. However, all existing methods suffer from
two limitations: (a) they only learn from one input modality, while a unified
representation for both speech and text is needed by tasks such as end-to-end
speech translation, and as a result,(b) they can not exploit various
large-scale text and speech data and their performance is limited by the
scarcity of parallel speech translation data.To address these problems, we
propose a Fused Acoustic and Text Masked Language Model (FAT-MLM) which jointly
learns a unified representation for both acoustic and text input from various
types of corpora including parallel data for speech recognition and machine
translation, and even pure speech and text data. Within this cross-modal
representation learning framework, we further present an end-to-end model for
Fused Acoustic and Text Speech Translation (FAT-ST). Experiments on three
translation directions show that by fine-tuning from FAT-MLM, our proposed
speech translation models substantially improve translation quality by up to
+5.9 BLEU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Explanations for Model Interpretability. (arXiv:2103.01378v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01378">
<div class="article-summary-box-inner">
<span><p>Contrastive explanations clarify why an event occurred in contrast to
another. They are more inherently intuitive to humans to both produce and
comprehend. We propose a methodology to produce contrastive explanations for
classification models by modifying the representation to disregard
non-contrastive information, and modifying model behavior to only be based on
contrastive reasoning. Our method is based on projecting model representation
to a latent space that captures only the features that are useful (to the
model) to differentiate two potential decisions. We demonstrate the value of
contrastive explanations by analyzing two different scenarios, using both
high-level abstract concept attribution and low-level input token/span
attribution, on two widely used text classification tasks. Specifically, we
produce explanations for answering: for which label, and against which
alternative label, is some aspect of the input useful? And which aspects of the
input are useful for and against particular decisions? Overall, our findings
shed light on the ability of label-contrastive explanations to provide a more
accurate and finer-grained interpretability of a model's decision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving and Simplifying Pattern Exploiting Training. (arXiv:2103.11955v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11955">
<div class="article-summary-box-inner">
<span><p>Recently, pre-trained language models (LMs) have achieved strong performance
when fine-tuned on difficult benchmarks like SuperGLUE. However, performance
can suffer when there are very few labeled examples available for fine-tuning.
Pattern Exploiting Training (PET) is a recent approach that leverages patterns
for few-shot learning. However, PET uses task-specific unlabeled data. In this
paper, we focus on few-shot learning without any unlabeled data and introduce
ADAPET, which modifies PET's objective to provide denser supervision during
fine-tuning. As a result, ADAPET outperforms PET on SuperGLUE without any
task-specific unlabeled data. Our code can be found at
https://github.com/rrmenon10/ADAPET.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging pre-trained representations to improve access to untranscribed speech from endangered languages. (arXiv:2103.14583v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14583">
<div class="article-summary-box-inner">
<span><p>Pre-trained speech representations like wav2vec 2.0 are a powerful tool for
automatic speech recognition (ASR). Yet many endangered languages lack
sufficient data for pre-training such models, or are predominantly oral
vernaculars without a standardised writing system, precluding fine-tuning.
Query-by-example spoken term detection (QbE-STD) offers an alternative for
iteratively indexing untranscribed speech corpora by locating spoken query
terms. Using data from 7 Australian Aboriginal languages and a regional variety
of Dutch, all of which are endangered or vulnerable, we show that QbE-STD can
be improved by leveraging representations developed for ASR (wav2vec 2.0: the
English monolingual model and XLSR53 multilingual model). Surprisingly, the
English model outperformed the multilingual model on 4 Australian language
datasets, raising questions around how to optimally leverage self-supervised
speech representations for QbE-STD. Nevertheless, we find that wav2vec 2.0
representations (either English or XLSR53) offer large improvements (56-86%
relative) over state-of-the-art approaches on our endangered language datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Connecting Attributions and QA Model Behavior on Realistic Counterfactuals. (arXiv:2104.04515v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04515">
<div class="article-summary-box-inner">
<span><p>When a model attribution technique highlights a particular part of the input,
a user might understand this highlight as making a statement about
counterfactuals (Miller, 2019): if that part of the input were to change, the
model's prediction might change as well. This paper investigates how well
different attribution techniques align with this assumption on realistic
counterfactuals in the case of reading comprehension (RC). RC is a particularly
challenging test case, as token-level attributions that have been extensively
studied in other NLP tasks such as sentiment analysis are less suitable to
represent the reasoning that RC models perform. We construct counterfactual
sets for three different RC settings, and through heuristics that can connect
attribution methods' outputs to high-level model behavior, we can evaluate how
useful different attribution methods and even different formats are for
understanding counterfactuals. We find that pairwise attributions are better
suited to RC than token-level attributions across these different RC settings,
with our best performance coming from a modification that we propose to an
existing pairwise attribution method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Zero-Shot Multifaceted Visually Grounded Word Embeddings via Multi-Task Training. (arXiv:2104.07500v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07500">
<div class="article-summary-box-inner">
<span><p>Language grounding aims at linking the symbolic representation of language
(e.g., words) into the rich perceptual knowledge of the outside world. The
general approach is to embed both textual and visual information into a common
space -the grounded space-confined by an explicit relationship between both
modalities. We argue that this approach sacrifices the abstract knowledge
obtained from linguistic co-occurrence statistics in the process of acquiring
perceptual information. The focus of this paper is to solve this issue by
implicitly grounding the word embeddings. Rather than learning two mappings
into a joint space, our approach integrates modalities by determining a
reversible grounded mapping between the textual and the grounded space by means
of multi-task learning. Evaluations on intrinsic and extrinsic tasks show that
our embeddings are highly beneficial for both abstract and concrete words. They
are strongly correlated with human judgments and outperform previous works on a
wide range of benchmarks. Our grounded embeddings are publicly available here.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Path Hunter: Reducing Hallucination in Dialogue Systems via Path Grounding. (arXiv:2104.08455v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08455">
<div class="article-summary-box-inner">
<span><p>Dialogue systems powered by large pre-trained language models (LM) exhibit an
innate ability to deliver fluent and natural-looking responses. Despite their
impressive generation performance, these models can often generate factually
incorrect statements impeding their widespread adoption. In this paper, we
focus on the task of improving the faithfulness -- and thus reduce
hallucination -- of Neural Dialogue Systems to known facts supplied by a
Knowledge Graph (KG). We propose Neural Path Hunter which follows a
generate-then-refine strategy whereby a generated response is amended using the
k-hop subgraph of a KG. Neural Path Hunter leverages a separate token-level
fact critic to identify plausible sources of hallucination followed by a
refinement stage consisting of a chain of two neural LM's that retrieves
correct entities by crafting a query signal that is propagated over the k-hop
subgraph. Our proposed model can easily be applied to any dialogue generated
responses without retraining the model. We empirically validate our proposed
approach on the OpenDialKG dataset against a suite of metrics and report a
relative improvement of faithfulness over dialogue responses by 20.35% based on
FeQA (Durmus et al., 2020).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Attention is All You Need: Adapting Pretrained Transformers for Machine Translation. (arXiv:2104.08771v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08771">
<div class="article-summary-box-inner">
<span><p>We study the power of cross-attention in the Transformer architecture within
the context of transfer learning for machine translation, and extend the
findings of studies into cross-attention when training from scratch. We conduct
a series of experiments through fine-tuning a translation model on data where
either the source or target language has changed. These experiments reveal that
fine-tuning only the cross-attention parameters is nearly as effective as
fine-tuning all parameters (i.e., the entire translation model). We provide
insights into why this is the case and observe that limiting fine-tuning in
this manner yields cross-lingually aligned embeddings. The implications of this
finding for researchers and practitioners include a mitigation of catastrophic
forgetting, the potential for zero-shot translation, and the ability to extend
machine translation models to several new language pairs with reduced parameter
storage overhead.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Low-Dimensional Linear Geometry of Contextualized Word Representations. (arXiv:2105.07109v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07109">
<div class="article-summary-box-inner">
<span><p>Black-box probing models can reliably extract linguistic features like tense,
number, and syntactic role from pretrained word representations. However, the
manner in which these features are encoded in representations remains poorly
understood. We present a systematic study of the linear geometry of
contextualized word representations in ELMO and BERT. We show that a variety of
linguistic features (including structured dependency relationships) are encoded
in low-dimensional subspaces. We then refine this geometric picture, showing
that there are hierarchical relations between the subspaces encoding general
linguistic categories and more specific ones, and that low-dimensional feature
encodings are distributed rather than aligned to individual neurons. Finally,
we demonstrate that these linear subspaces are causally related to model
behavior, and can be used to perform fine-grained manipulation of BERT's output
distribution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coreference-Aware Dialogue Summarization. (arXiv:2106.08556v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08556">
<div class="article-summary-box-inner">
<span><p>Summarizing conversations via neural approaches has been gaining research
traction lately, yet it is still challenging to obtain practical solutions.
Examples of such challenges include unstructured information exchange in
dialogues, informal interactions between speakers, and dynamic role changes of
speakers as the dialogue evolves. Many of such challenges result in complex
coreference links. Therefore, in this work, we investigate different approaches
to explicitly incorporate coreference information in neural abstractive
dialogue summarization models to tackle the aforementioned challenges.
Experimental results show that the proposed approaches achieve state-of-the-art
performance, implying it is useful to utilize coreference information in
dialogue summarization. Evaluation results on factual correctness suggest such
coreference-aware models are better at tracing the information flow among
interlocutors and associating accurate status/actions with the corresponding
interlocutors and person mentions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Natural Language Understanding Pipeline for Bangla Conversational Agents. (arXiv:2107.05541v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05541">
<div class="article-summary-box-inner">
<span><p>Chatbots are intelligent software built to be used as a replacement for human
interaction. However, existing studies typically do not provide enough support
for low-resource languages like Bangla. Moreover, due to the increasing
popularity of social media, we can also see the rise of interactions in Bangla
transliteration (mostly in English) among the native Bangla speakers. In this
paper, we propose a novel approach to build a Bangla chatbot aimed to be used
as a business assistant which can communicate in Bangla and Bangla
Transliteration in English with high confidence consistently. Since annotated
data was not available for this purpose, we had to work on the whole machine
learning life cycle (data preparation, machine learning modeling, and model
deployment) using Rasa Open Source Framework, fastText embeddings, Polyglot
embeddings, Flask, and other systems as building blocks. While working with the
skewed annotated dataset, we try out different setups and pipelines to evaluate
which works best and provide possible reasoning behind the observed results.
Finally, we present a pipeline for intent classification and entity extraction
which achieves reasonable performance (accuracy: 83.02%, precision: 80.82%,
recall: 83.02%, F1-score: 80%).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">To Ship or Not to Ship: An Extensive Evaluation of Automatic Metrics for Machine Translation. (arXiv:2107.10821v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10821">
<div class="article-summary-box-inner">
<span><p>Automatic metrics are commonly used as the exclusive tool for declaring the
superiority of one machine translation system's quality over another. The
community choice of automatic metric guides research directions and industrial
developments by deciding which models are deemed better. Evaluating metrics
correlations with sets of human judgements has been limited by the size of
these sets. In this paper, we corroborate how reliable metrics are in contrast
to human judgements on -- to the best of our knowledge -- the largest
collection of judgements reported in the literature. Arguably, pairwise
rankings of two systems are the most common evaluation tasks in research or
deployment scenarios. Taking human judgement as a gold standard, we investigate
which metrics have the highest accuracy in predicting translation quality
rankings for such system pairs. Furthermore, we evaluate the performance of
various metrics across different language pairs and domains. Lastly, we show
that the sole use of BLEU impeded the development of improved models leading to
bad deployment decisions. We release the collection of 2.3M sentence-level
human judgements for 4380 systems for further analysis and replication of our
work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UNIQORN: Unified Question Answering over RDF Knowledge Graphs and Natural Language Text. (arXiv:2108.08614v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08614">
<div class="article-summary-box-inner">
<span><p>Question answering over knowledge graphs and other RDF data has been greatly
advanced, with a number of good systems providing crisp answers for natural
language questions or telegraphic queries. Some of these systems incorporate
textual sources as additional evidence for the answering process, but cannot
compute answers that are present in text alone. Conversely, systems from the IR
and NLP communities have addressed QA over text, but barely utilize semantic
data and knowledge. This paper presents the first QA system that can seamlessly
operate over RDF datasets and text corpora, or both together, in a unified
framework. Our method, called UNIQORN, builds a context graph on the fly, by
retrieving question-relevant triples from the RDF data and/or the text corpus,
where the latter case is handled by automatic information extraction. The
resulting graph is typically rich but highly noisy. UNIQORN copes with this
input by advanced graph algorithms for Group Steiner Trees, that identify the
best answer candidates in the context graph. Experimental results on several
benchmarks of complex questions with multiple entities and relations, show that
UNIQORN, an unsupervised method with only five parameters, produces results
comparable to the state-of-the-art on KGs, text corpora, and heterogeneous
sources. The graph-based methodology provides user-interpretable evidence for
the complete answering process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DEGREE: A Data-Efficient Generative Event Extraction Model. (arXiv:2108.12724v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12724">
<div class="article-summary-box-inner">
<span><p>Event extraction (EE) aims to identify structured events, including event
triggers and their corresponding arguments, from unstructured text. Most of the
existing works rely on a large number of labeled instances to train models,
while the labeled data could be expensive to be obtained. In this work, we
present a data-efficient event extraction method by formulating event
extraction as a natural language generation problem. The formulation allows us
to inject knowledge of label semantics, event structure, and output
dependencies into the model. Given a passage and an event type, our model
learns to summarize this passage into a templated sentence in a predefined
structure. The template is event-type-specific, manually created, and contains
event trigger and argument information. Lastly, a rule-based algorithm is used
to derive the trigger and argument predictions from the generated sentence. Our
method inherently enjoys the following benefits: (1) The pretraining of the
generative language models help incorporate the semantics of the labels for
generative EE. (2) The autoregressive generation process and our end-to-end
design for extracting triggers and arguments force the model to capture the
dependencies among the output triggers and their arguments. (3) The predefined
templates form concrete yet flexible rules to hint the models about the valid
patterns for each event type, reducing the models' burden to learn structures
from the data. Empirical results show that our model achieves superior
performance over strong baselines on EE tasks in the low data regime and
achieves competitive results to the current state-of-the-art when more data
becomes available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Retrieval Augmented Generation for Zero-shot Slot Filling. (arXiv:2108.13934v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13934">
<div class="article-summary-box-inner">
<span><p>Automatically inducing high quality knowledge graphs from a given collection
of documents still remains a challenging problem in AI. One way to make headway
for this problem is through advancements in a related task known as slot
filling. In this task, given an entity query in form of [Entity, Slot, ?], a
system is asked to fill the slot by generating or extracting the missing value
exploiting evidence extracted from relevant passage(s) in the given document
collection. The recent works in the field try to solve this task in an
end-to-end fashion using retrieval-based language models. In this paper, we
present a novel approach to zero-shot slot filling that extends dense passage
retrieval with hard negatives and robust training procedures for retrieval
augmented generation models. Our model reports large improvements on both T-REx
and zsRE slot filling datasets, improving both passage retrieval and slot value
generation, and ranking at the top-1 position in the KILT leaderboard.
Moreover, we demonstrate the robustness of our system showing its domain
adaptation capability on a new variant of the TACRED dataset for slot filling,
through a combination of zero/few-shot learning. We release the source code and
pre-trained models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mixup Decoding for Diverse Machine Translation. (arXiv:2109.03402v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03402">
<div class="article-summary-box-inner">
<span><p>Diverse machine translation aims at generating various target language
translations for a given source language sentence. Leveraging the linear
relationship in the sentence latent space introduced by the mixup training, we
propose a novel method, MixDiversity, to generate different translations for
the input sentence by linearly interpolating it with different sentence pairs
sampled from the training corpus when decoding. To further improve the
faithfulness and diversity of the translations, we propose two simple but
effective approaches to select diverse sentence pairs in the training corpus
and adjust the interpolation weight for each pair correspondingly. Moreover, by
controlling the interpolation weight, our method can achieve the trade-off
between faithfulness and diversity without any additional training, which is
required in most of the previous methods. Experiments on WMT'16 en-ro, WMT'14
en-de, and WMT'17 zh-en are conducted to show that our method substantially
outperforms all previous diverse machine translation methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Memory and Knowledge Augmented Language Models for Inferring Salience in Long-Form Stories. (arXiv:2109.03754v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03754">
<div class="article-summary-box-inner">
<span><p>Measuring event salience is essential in the understanding of stories. This
paper takes a recent unsupervised method for salience detection derived from
Barthes Cardinal Functions and theories of surprise and applies it to longer
narrative forms. We improve the standard transformer language model by
incorporating an external knowledgebase (derived from Retrieval Augmented
Generation) and adding a memory mechanism to enhance performance on longer
works. We use a novel approach to derive salience annotation using
chapter-aligned summaries from the Shmoop corpus for classic literary works.
Our evaluation against this data demonstrates that our salience detection model
improves performance over and above a non-knowledgebase and memory augmented
language model, both of which are crucial to this improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PPT: Pre-trained Prompt Tuning for Few-shot Learning. (arXiv:2109.04332v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04332">
<div class="article-summary-box-inner">
<span><p>Prompts for pre-trained language models (PLMs) have shown remarkable
performance by bridging the gap between pre-training tasks and various
downstream tasks. Among these methods, prompt tuning, which freezes PLMs and
only tunes soft prompts, provides an efficient and effective solution for
adapting large-scale PLMs to downstream tasks. However, prompt tuning is yet to
be fully explored. In our pilot experiments, we find that prompt tuning
performs comparably with conventional full-model fine-tuning when downstream
data are sufficient, whereas it performs much worse under few-shot learning
settings, which may hinder the application of prompt tuning in practice. We
attribute this low performance to the manner of initializing soft prompts.
Therefore, in this work, we propose to pre-train prompts by adding soft prompts
into the pre-training stage to obtain a better initialization. We name this
Pre-trained Prompt Tuning framework "PPT". To ensure the generalization of PPT,
we formulate similar classification tasks into a unified task form and
pre-train soft prompts for this unified task. Extensive experiments show that
tuning pre-trained prompts for downstream tasks can reach or even outperform
full-model fine-tuning under both full-data and few-shot settings. Our approach
is effective and efficient for using large-scale PLMs in practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How May I Help You? Using Neural Text Simplification to Improve Downstream NLP Tasks. (arXiv:2109.04604v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04604">
<div class="article-summary-box-inner">
<span><p>The general goal of text simplification (TS) is to reduce text complexity for
human consumption. This paper investigates another potential use of neural TS:
assisting machines performing natural language processing (NLP) tasks. We
evaluate the use of neural TS in two ways: simplifying input texts at
prediction time and augmenting data to provide machines with additional
information during training. We demonstrate that the latter scenario provides
positive effects on machine performance on two separate datasets. In
particular, the latter use of TS improves the performances of LSTM (1.82-1.98%)
and SpanBERT (0.7-1.3%) extractors on TACRED, a complex, large-scale,
real-world relation extraction task. Further, the same setting yields
improvements of up to 0.65% matched and 0.62% mismatched accuracies for a BERT
text classifier on MNLI, a practical natural language inference dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CINS: Comprehensive Instruction for Few-shot Learning in Task-oriented Dialog Systems. (arXiv:2109.04645v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04645">
<div class="article-summary-box-inner">
<span><p>As labeling cost for different modules in task-oriented dialog (ToD) systems
is high, a major challenge in practice is to learn different tasks with the
least amount of labeled data. Recently, prompting methods over pre-trained
language models (PLMs) have shown promising results for few-shot learning in
ToD. To better utilize the power of PLMs, this paper proposes Comprehensive
Instruction (CINS) that exploits PLMs with extra task-specific instructions. We
design a schema (definition, constraint, prompt) of instructions and their
customized realizations for three important downstream tasks in ToD, i.e.
intent classification, dialog state tracking, and natural language generation.
A sequence-to-sequence model (T5) is adopted to solve these three tasks in a
unified framework. Extensive experiments are conducted on these ToD tasks in
realistic few-shot learning scenarios with small validation data. Empirical
results demonstrate that the proposed CINS approach consistently improves
techniques that finetune PLMs with raw input or short prompts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RoR: Read-over-Read for Long Document Machine Reading Comprehension. (arXiv:2109.04780v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04780">
<div class="article-summary-box-inner">
<span><p>Transformer-based pre-trained models, such as BERT, have achieved remarkable
results on machine reading comprehension. However, due to the constraint of
encoding length (e.g., 512 WordPiece tokens), a long document is usually split
into multiple chunks that are independently read. It results in the reading
field being limited to individual chunks without information collaboration for
long document machine reading comprehension. To address this problem, we
propose RoR, a read-over-read method, which expands the reading field from
chunk to document. Specifically, RoR includes a chunk reader and a document
reader. The former first predicts a set of regional answers for each chunk,
which are then compacted into a highly-condensed version of the original
document, guaranteeing to be encoded once. The latter further predicts the
global answers from this condensed document. Eventually, a voting strategy is
utilized to aggregate and rerank the regional and global answers for final
prediction. Extensive experiments on two benchmarks QuAC and TriviaQA
demonstrate the effectiveness of RoR for long document reading. Notably, RoR
ranks 1st place on the QuAC leaderboard (https://quac.ai/) at the time of
submission (May 17th, 2021).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Universal Simultaneous Machine Translation with Mixture-of-Experts Wait-k Policy. (arXiv:2109.05238v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05238">
<div class="article-summary-box-inner">
<span><p>Simultaneous machine translation (SiMT) generates translation before reading
the entire source sentence and hence it has to trade off between translation
quality and latency. To fulfill the requirements of different translation
quality and latency in practical applications, the previous methods usually
need to train multiple SiMT models for different latency levels, resulting in
large computational costs. In this paper, we propose a universal SiMT model
with Mixture-of-Experts Wait-k Policy to achieve the best translation quality
under arbitrary latency with only one trained model. Specifically, our method
employs multi-head attention to accomplish the mixture of experts where each
head is treated as a wait-k expert with its own waiting words number, and given
a test latency and source inputs, the weights of the experts are accordingly
adjusted to produce the best translation. Experiments on three datasets show
that our method outperforms all the strong baselines under different latency,
including the state-of-the-art adaptive policy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling Concentrated Cross-Attention for Neural Machine Translation with Gaussian Mixture Model. (arXiv:2109.05244v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05244">
<div class="article-summary-box-inner">
<span><p>Cross-attention is an important component of neural machine translation
(NMT), which is always realized by dot-product attention in previous methods.
However, dot-product attention only considers the pair-wise correlation between
words, resulting in dispersion when dealing with long sentences and neglect of
source neighboring relationships. Inspired by linguistics, the above issues are
caused by ignoring a type of cross-attention, called concentrated attention,
which focuses on several central words and then spreads around them. In this
work, we apply Gaussian Mixture Model (GMM) to model the concentrated attention
in cross-attention. Experiments and analyses we conducted on three datasets
show that the proposed method outperforms the baseline and has significant
improvement on alignment quality, N-gram accuracy, and long sentence
translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Guiding Topic Flows in the Generative Chatbot by Enhancing the ConceptNet with the Conversation Corpora. (arXiv:2109.05406v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05406">
<div class="article-summary-box-inner">
<span><p>Human conversations consist of reasonable and natural topic flows, which are
observed as the shifts of the mentioned concepts across utterances. Previous
chatbots that incorporate the external commonsense knowledge graph prove that
modeling the concept shifts can effectively alleviate the dull and
uninformative response dilemma. However, there still exists a gap between the
concept relations in the natural conversation and those in the external
commonsense knowledge graph, which is an issue to solve. Specifically, the
concept relations in the external commonsense knowledge graph are not
intuitively built from the conversational scenario but the world knowledge,
which makes them insufficient for the chatbot construction. To bridge the above
gap, we propose the method to supply more concept relations extracted from the
conversational corpora and reconstruct an enhanced concept graph for the
chatbot construction. In addition, we present a novel, powerful, and fast graph
encoding architecture named the Edge-Transformer to replace the traditional GNN
architecture. Experimental results on the Reddit conversation dataset indicate
our proposed method significantly outperforms strong baseline systems and
achieves new SOTA results. Further analysis individually proves the
effectiveness of the enhanced concept graph and the Edge-Transformer
architecture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mitigating Language-Dependent Ethnic Bias in BERT. (arXiv:2109.05704v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05704">
<div class="article-summary-box-inner">
<span><p>BERT and other large-scale language models (LMs) contain gender and racial
bias. They also exhibit other dimensions of social bias, most of which have not
been studied in depth, and some of which vary depending on the language. In
this paper, we study ethnic bias and how it varies across languages by
analyzing and mitigating ethnic bias in monolingual BERT for English, German,
Spanish, Korean, Turkish, and Chinese. To observe and quantify ethnic bias, we
develop a novel metric called Categorical Bias score. Then we propose two
methods for mitigation; first using a multilingual model, and second using
contextual word alignment of two monolingual models. We compare our proposed
methods with monolingual BERT and show that these methods effectively alleviate
the ethnic bias. Which of the two methods works better depends on the amount of
NLP resources available for that language. We additionally experiment with
Arabic and Greek to verify that our proposed methods work for a wider variety
of languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CPT: A Pre-Trained Unbalanced Transformer for Both Chinese Language Understanding and Generation. (arXiv:2109.05729v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05729">
<div class="article-summary-box-inner">
<span><p>In this paper, we take the advantage of previous pre-trained models (PTMs)
and propose a novel Chinese Pre-trained Unbalanced Transformer (CPT). Different
from previous Chinese PTMs, CPT is designed for both natural language
understanding (NLU) and natural language generation (NLG) tasks. CPT consists
of three parts: a shared encoder, an understanding decoder, and a generation
decoder. Two specific decoders with a shared encoder are pre-trained with
masked language modeling (MLM) and denoising auto-encoding (DAE) tasks,
respectively. With the partially shared architecture and multi-task
pre-training, CPT can (1) learn specific knowledge of both NLU or NLG tasks
with two decoders and (2) be fine-tuned flexibly that fully exploits the
potential of the model. Moreover, the unbalanced Transformer saves the
computational and storage cost, which makes CPT competitive and greatly
accelerates the inference of text generation. Experimental results on a wide
range of Chinese NLU and NLG tasks show the effectiveness of CPT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Categorical Semantics of Reversible Pattern-Matching. (arXiv:2109.05837v2 [cs.LO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05837">
<div class="article-summary-box-inner">
<span><p>This paper is concerned with categorical structures for reversible
computation. In particular, we focus on a typed, functional reversible language
based on Theseus. We discuss how join inverse rig categories do not in general
capture pattern-matching, the core construct Theseus uses to enforce
reversibility. We then derive a categorical structure to add to join inverse
rig categories in order to capture pattern-matching. We show how such a
structure makes an adequate model for reversible pattern-matching.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Question Answering over Electronic Devices: A New Benchmark Dataset and a Multi-Task Learning based QA Framework. (arXiv:2109.05897v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05897">
<div class="article-summary-box-inner">
<span><p>Answering questions asked from instructional corpora such as E-manuals,
recipe books, etc., has been far less studied than open-domain factoid
context-based question answering. This can be primarily attributed to the
absence of standard benchmark datasets. In this paper we meticulously create a
large amount of data connected with E-manuals and develop suitable algorithm to
exploit it. We collect E-Manual Corpus, a huge corpus of 307,957 E-manuals and
pretrain RoBERTa on this large corpus. We create various benchmark QA datasets
which include question answer pairs curated by experts based upon two
E-manuals, real user questions from Community Question Answering Forum
pertaining to E-manuals etc. We introduce EMQAP (E-Manual Question Answering
Pipeline) that answers questions pertaining to electronics devices. Built upon
the pretrained RoBERTa, it harbors a supervised multi-task learning framework
which efficiently performs the dual tasks of identifying the section in the
E-manual where the answer can be found and the exact answer span within that
section. For E-Manual annotated question-answer pairs, we show an improvement
of about 40% in ROUGE-L F1 scores over the most competitive baseline. We
perform a detailed ablation study and establish the versatility of EMQAP across
different circumstances. The code and datasets are shared at
https://github.com/abhi1nandy2/EMNLP-2021-Findings, and the corresponding
project website is https://sites.google.com/view/emanualqa/home.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Language Models Encode Perceptual Structure Without Grounding? A Case Study in Color. (arXiv:2109.06129v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06129">
<div class="article-summary-box-inner">
<span><p>Pretrained language models have been shown to encode relational information,
such as the relations between entities or concepts in knowledge-bases --
(Paris, Capital, France). However, simple relations of this type can often be
recovered heuristically and the extent to which models implicitly reflect
topological structure that is grounded in world, such as perceptual structure,
is unknown. To explore this question, we conduct a thorough case study on
color. Namely, we employ a dataset of monolexemic color terms and color chips
represented in CIELAB, a color space with a perceptually meaningful distance
metric.
</p>
<p>Using two methods of evaluating the structural alignment of colors in this
space with text-derived color term representations, we find significant
correspondence. Analyzing the differences in alignment across the color
spectrum, we find that warmer colors are, on average, better aligned to the
perceptual color space than cooler ones, suggesting an intriguing connection to
findings from recent work on efficient communication in color naming. Further
analysis suggests that differences in alignment are, in part, mediated by
collocationality and differences in syntactic usage, posing questions as to the
relationship between color perception and usage and context.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Generatively Augmented Neural Network Watchdog for Image Classification Networks. (arXiv:2109.06168v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06168">
<div class="article-summary-box-inner">
<span><p>The identification of out-of-distribution data is vital to the deployment of
classification networks. For example, a generic neural network that has been
trained to differentiate between images of dogs and cats can only classify an
input as either a dog or a cat. If a picture of a car or a kumquat were to be
supplied to this classifier, the result would still be either a dog or a cat.
In order to mitigate this, techniques such as the neural network watchdog have
been developed. The compression of the image input into the latent layer of the
autoencoder defines the region of in-distribution in the image space. This
in-distribution set of input data has a corresponding boundary in the image
space. The watchdog assesses whether inputs are in inside or outside this
boundary. This paper demonstrates how to sharpen this boundary using generative
network training data augmentation thereby bettering the discrimination and
overall performance of the watchdog.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incremental Abstraction in Distributed Probabilistic SLAM Graphs. (arXiv:2109.06241v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06241">
<div class="article-summary-box-inner">
<span><p>Scene graphs represent the key components of a scene in a compact and
semantically rich way, but are difficult to build during incremental SLAM
operation because of the challenges of robustly identifying abstract scene
elements and optimising continually changing, complex graphs. We present a
distributed, graph-based SLAM framework for incrementally building scene graphs
based on two novel components. First, we propose an incremental abstraction
framework in which a neural network proposes abstract scene elements that are
incorporated into the factor graph of a feature-based monocular SLAM system.
Scene elements are confirmed or rejected through optimisation and incrementally
replace the points yielding a more dense, semantic and compact representation.
Second, enabled by our novel routing procedure, we use Gaussian Belief
Propagation (GBP) for distributed inference on a graph processor. The time per
iteration of GBP is structure-agnostic and we demonstrate the speed advantages
over direct methods for inference of heterogeneous factor graphs. We run our
system on real indoor datasets using planar abstractions and recover the major
planes with significant compression.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Modality Domain Adaptation for Vestibular Schwannoma and Cochlea Segmentation. (arXiv:2109.06274v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06274">
<div class="article-summary-box-inner">
<span><p>Automatic methods to segment the vestibular schwannoma (VS) tumors and the
cochlea from magnetic resonance imaging (MRI) are critical to VS treatment
planning. Although supervised methods have achieved satisfactory performance in
VS segmentation, they require full annotations by experts, which is laborious
and time-consuming. In this work, we aim to tackle the VS and cochlea
segmentation problem in an unsupervised domain adaptation setting. Our proposed
method leverages both the image-level domain alignment to minimize the domain
divergence and semi-supervised training to further boost the performance.
Furthermore, we propose to fuse the labels predicted from multiple models via
noisy label correction. Our results on the challenge validation leaderboard
showed that our unsupervised method has achieved promising VS and cochlea
segmentation performance with mean dice score of 0.8261 $\pm$ 0.0416; The mean
dice value for the tumor is 0.8302 $\pm$ 0.0772. This is comparable to the
weakly-supervised based method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MindCraft: Theory of Mind Modeling for Situated Dialogue in Collaborative Tasks. (arXiv:2109.06275v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06275">
<div class="article-summary-box-inner">
<span><p>An ideal integration of autonomous agents in a human world implies that they
are able to collaborate on human terms. In particular, theory of mind plays an
important role in maintaining common ground during human collaboration and
communication. To enable theory of mind modeling in situated interactions, we
introduce a fine-grained dataset of collaborative tasks performed by pairs of
human subjects in the 3D virtual blocks world of Minecraft. It provides
information that captures partners' beliefs of the world and of each other as
an interaction unfolds, bringing abundant opportunities to study human
collaborative behaviors in situated language communication. As a first step
towards our goal of developing embodied AI agents able to infer belief states
of collaborative partners in situ, we build and present results on
computational models for several theory of mind tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Monocular Camera Localization for Automated Vehicles Using Image Retrieval. (arXiv:2109.06296v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06296">
<div class="article-summary-box-inner">
<span><p>We address the problem of finding the current position and heading angle of
an autonomous vehicle in real-time using a single camera. Compared to methods
which require LiDARs and high definition (HD) 3D maps in real-time, the
proposed approach is easily scalable and computationally efficient, at the
price of lower precision.
</p>
<p>The new method combines and adapts existing algorithms in three different
fields: image retrieval, mapping database, and particle filtering. The result
is a simple, real-time localization method using an image retrieval method
whose performance is comparable to other monocular camera localization methods
which use a map built with LiDARs.
</p>
<p>We evaluate the proposed method using the KITTI odometry dataset and via
closed-loop experiments with an indoor 1:10 autonomous vehicle. The tests
demonstrate real-time capability and a 10cm level accuracy. Also, experimental
results of the closed-loop indoor tests show the presence of a positive
feedback loop between the localization error and the control error. Such
phenomena is analysed in details at the end of the article.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Physics Driven Domain Specific Transporter Framework with Attention Mechanism for Ultrasound Imaging. (arXiv:2109.06346v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06346">
<div class="article-summary-box-inner">
<span><p>Most applications of deep learning techniques in medical imaging are
supervised and require a large number of labeled data which is expensive and
requires many hours of careful annotation by experts. In this paper, we propose
an unsupervised, physics driven domain specific transporter framework with an
attention mechanism to identify relevant key points with applications in
ultrasound imaging. The proposed framework identifies key points that provide a
concise geometric representation highlighting regions with high structural
variation in ultrasound videos. We incorporate physics driven domain specific
information as a feature probability map and use the radon transform to
highlight features in specific orientations. The proposed framework has been
trained on130 Lung ultrasound (LUS) videos and 113 Wrist ultrasound (WUS)
videos and validated on 100 Lung ultrasound (LUS) videos and 58 Wrist
ultrasound (WUS) videos acquired from multiple centers across the globe. Images
from both datasets were independently assessed by experts to identify
clinically relevant features such as A-lines, B-lines and pleura from LUS and
radial metaphysis, radial epiphysis and carpal bones from WUS videos. The key
points detected from both datasets showed high sensitivity (LUS = 99\% , WUS =
74\%) in detecting the image landmarks identified by experts. Also, on
employing for classification of the given lung image into normal and abnormal
classes, the proposed approach, even with no prior training, achieved an
average accuracy of 97\% and an average F1-score of 95\% respectively on the
task of co-classification with 3 fold cross-validation. With the purely
unsupervised nature of the proposed approach, we expect the key point detection
approach to increase the applicability of ultrasound in various examination
performed in emergency and point of care.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">POPCORN: Progressive Pseudo-labeling with Consistency Regularization and Neighboring. (arXiv:2109.06361v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06361">
<div class="article-summary-box-inner">
<span><p>Semi-supervised learning (SSL) uses unlabeled data to compensate for the
scarcity of annotated images and the lack of method generalization to unseen
domains, two usual problems in medical segmentation tasks. In this work, we
propose POPCORN, a novel method combining consistency regularization and
pseudo-labeling designed for image segmentation. The proposed framework uses
high-level regularization to constrain our segmentation model to use similar
latent features for images with similar segmentations. POPCORN estimates a
proximity graph to select data from easiest ones to more difficult ones, in
order to ensure accurate pseudo-labeling and to limit confirmation bias.
Applied to multiple sclerosis lesion segmentation, our method demonstrates
competitive results compared to other state-of-the-art SSL strategies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sensor Adversarial Traits: Analyzing Robustness of 3D Object Detection Sensor Fusion Models. (arXiv:2109.06363v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06363">
<div class="article-summary-box-inner">
<span><p>A critical aspect of autonomous vehicles (AVs) is the object detection stage,
which is increasingly being performed with sensor fusion models: multimodal 3D
object detection models which utilize both 2D RGB image data and 3D data from a
LIDAR sensor as inputs. In this work, we perform the first study to analyze the
robustness of a high-performance, open source sensor fusion model architecture
towards adversarial attacks and challenge the popular belief that the use of
additional sensors automatically mitigate the risk of adversarial attacks. We
find that despite the use of a LIDAR sensor, the model is vulnerable to our
purposefully crafted image-based adversarial attacks including disappearance,
universal patch, and spoofing. After identifying the underlying reason, we
explore some potential defenses and provide some recommendations for improved
sensor fusion models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Heatmaps to Structural Explanations of Image Classifiers. (arXiv:2109.06365v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06365">
<div class="article-summary-box-inner">
<span><p>This paper summarizes our endeavors in the past few years in terms of
explaining image classifiers, with the aim of including negative results and
insights we have gained. The paper starts with describing the explainable
neural network (XNN), which attempts to extract and visualize several
high-level concepts purely from the deep network, without relying on human
linguistic concepts. This helps users understand network classifications that
are less intuitive and substantially improves user performance on a difficult
fine-grained classification task of discriminating among different species of
seagulls.
</p>
<p>Realizing that an important missing piece is a reliable heatmap visualization
tool, we have developed I-GOS and iGOS++ utilizing integrated gradients to
avoid local optima in heatmap generation, which improved the performance across
all resolutions. During the development of those visualizations, we realized
that for a significant number of images, the classifier has multiple different
paths to reach a confident prediction. This has lead to our recent development
of structured attention graphs (SAGs), an approach that utilizes beam search to
locate multiple coarse heatmaps for a single image, and compactly visualizes a
set of heatmaps by capturing how different combinations of image regions impact
the confidence of a classifier.
</p>
<p>Through the research process, we have learned much about insights in building
deep network explanations, the existence and frequency of multiple
explanations, and various tricks of the trade that make explanations work. In
this paper, we attempt to share those insights and opinions with the readers
with the hope that some of them will be informative for future researchers on
explainable deep learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AdaPruner: Adaptive Channel Pruning and Effective Weights Inheritance. (arXiv:2109.06397v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06397">
<div class="article-summary-box-inner">
<span><p>Channel pruning is one of the major compression approaches for deep neural
networks. While previous pruning methods have mostly focused on identifying
unimportant channels, channel pruning is considered as a special case of neural
architecture search in recent years. However, existing methods are either
complicated or prone to sub-optimal pruning. In this paper, we propose a
pruning framework that adaptively determines the number of each layer's
channels as well as the wights inheritance criteria for sub-network. Firstly,
evaluate the importance of each block in the network based on the mean of the
scaling parameters of the BN layers. Secondly, use the bisection method to
quickly find the compact sub-network satisfying the budget. Finally, adaptively
and efficiently choose the weight inheritance criterion that fits the current
architecture and fine-tune the pruned network to recover performance. AdaPruner
allows to obtain pruned network quickly, accurately and efficiently, taking
into account both the structure and initialization weights. We prune the
currently popular CNN models (VGG, ResNet, MobileNetV2) on different image
classification datasets, and the experimental results demonstrate the
effectiveness of our proposed method. On ImageNet, we reduce 32.8% FLOPs of
MobileNetV2 with only 0.62% decrease for top-1 accuracy, which exceeds all
previous state-of-the-art channel pruning methods. The code will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Proposal Generation Network for Temporal Sentence Localization in Videos. (arXiv:2109.06398v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06398">
<div class="article-summary-box-inner">
<span><p>We address the problem of temporal sentence localization in videos (TSLV).
Traditional methods follow a top-down framework which localizes the target
segment with pre-defined segment proposals. Although they have achieved decent
performance, the proposals are handcrafted and redundant. Recently, bottom-up
framework attracts increasing attention due to its superior efficiency. It
directly predicts the probabilities for each frame as a boundary. However, the
performance of bottom-up model is inferior to the top-down counterpart as it
fails to exploit the segment-level interaction. In this paper, we propose an
Adaptive Proposal Generation Network (APGN) to maintain the segment-level
interaction while speeding up the efficiency. Specifically, we first perform a
foreground-background classification upon the video and regress on the
foreground frames to adaptively generate proposals. In this way, the
handcrafted proposal design is discarded and the redundant proposals are
decreased. Then, a proposal consolidation module is further developed to
enhance the semantic of the generated proposals. Finally, we locate the target
moments with these generated proposals following the top-down framework.
Extensive experiments on three challenging benchmarks show that our proposed
APGN significantly outperforms previous state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Progressively Guide to Attend: An Iterative Alignment Framework for Temporal Sentence Grounding. (arXiv:2109.06400v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06400">
<div class="article-summary-box-inner">
<span><p>A key solution to temporal sentence grounding (TSG) exists in how to learn
effective alignment between vision and language features extracted from an
untrimmed video and a sentence description. Existing methods mainly leverage
vanilla soft attention to perform the alignment in a single-step process.
However, such single-step attention is insufficient in practice, since
complicated relations between inter- and intra-modality are usually obtained
through multi-step reasoning. In this paper, we propose an Iterative Alignment
Network (IA-Net) for TSG task, which iteratively interacts inter- and
intra-modal features within multiple steps for more accurate grounding.
Specifically, during the iterative reasoning process, we pad multi-modal
features with learnable parameters to alleviate the nowhere-to-attend problem
of non-matched frame-word pairs, and enhance the basic co-attention mechanism
in a parallel manner. To further calibrate the misaligned attention caused by
each reasoning step, we also devise a calibration module following each
attention module to refine the alignment knowledge. With such iterative
alignment scheme, our IA-Net can robustly capture the fine-grained relations
between vision and language domains step-by-step for progressively reasoning
the temporal boundaries. Extensive experiments conducted on three challenging
benchmarks demonstrate that our proposed model performs better than the
state-of-the-arts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Camera-Tracklet-Aware Contrastive Learning for Unsupervised Vehicle Re-Identification. (arXiv:2109.06401v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06401">
<div class="article-summary-box-inner">
<span><p>Recently, vehicle re-identification methods based on deep learning constitute
remarkable achievement. However, this achievement requires large-scale and
well-annotated datasets. In constructing the dataset, assigning globally
available identities (Ids) to vehicles captured from a great number of cameras
is labour-intensive, because it needs to consider their subtle appearance
differences or viewpoint variations. In this paper, we propose
camera-tracklet-aware contrastive learning (CTACL) using the multi-camera
tracklet information without vehicle identity labels. The proposed CTACL
divides an unlabelled domain, i.e., entire vehicle images, into multiple
camera-level subdomains and conducts contrastive learning within and beyond the
subdomains. The positive and negative samples for contrastive learning are
defined using tracklet Ids of each camera. Additionally, the domain adaptation
across camera networks is introduced to improve the generalisation performance
of learnt representations and alleviate the performance degradation resulted
from the domain gap between the subdomains. We demonstrate the effectiveness of
our approach on video-based and image-based vehicle Re-ID datasets.
Experimental results show that the proposed method outperforms the recent
state-of-the-art unsupervised vehicle Re-ID methods. The source code for this
paper is publicly available on
`https://github.com/andreYoo/CTAM-CTACL-VVReID.git'.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COVID-Net MLSys: Designing COVID-Net for the Clinical Workflow. (arXiv:2109.06421v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06421">
<div class="article-summary-box-inner">
<span><p>As the COVID-19 pandemic continues to devastate globally, one promising field
of research is machine learning-driven computer vision to streamline various
parts of the COVID-19 clinical workflow. These machine learning methods are
typically stand-alone models designed without consideration for the integration
necessary for real-world application workflows. In this study, we take a
machine learning and systems (MLSys) perspective to design a system for
COVID-19 patient screening with the clinical workflow in mind. The COVID-Net
system is comprised of the continuously evolving COVIDx dataset, COVID-Net deep
neural network for COVID-19 patient detection, and COVID-Net S deep neural
networks for disease severity scoring for COVID-19 positive patient cases. The
deep neural networks within the COVID-Net system possess state-of-the-art
performance, and are designed to be integrated within a user interface (UI) for
clinical decision support with automatic report generation to assist clinicians
in their treatment decisions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Region Domain Adaptation for Class-level Alignment. (arXiv:2109.06422v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06422">
<div class="article-summary-box-inner">
<span><p>Semantic segmentation requires a lot of training data, which necessitates
costly annotation. There have been many studies on unsupervised domain
adaptation (UDA) from one domain to another, e.g., from computer graphics to
real images. However, there is still a gap in accuracy between UDA and
supervised training on native domain data. It is arguably attributable to
class-level misalignment between the source and target domain data. To cope
with this, we propose a method that applies adversarial training to align two
feature distributions in the target domain. It uses a self-training framework
to split the image into two regions (i.e., trusted and untrusted), which form
two distributions to align in the feature space. We term this approach
cross-region adaptation (CRA) to distinguish from the previous methods of
aligning different domain distributions, which we call cross-domain adaptation
(CDA). CRA can be applied after any CDA method. Experimental results show that
this always improves the accuracy of the combined CDA method, having updated
the state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved Few-shot Segmentation by Redifinition of the Roles of Multi-level CNN Features. (arXiv:2109.06432v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06432">
<div class="article-summary-box-inner">
<span><p>This study is concerned with few-shot segmentation, i.e., segmenting the
region of an unseen object class in a query image, given support image(s) of
its instances. The current methods rely on the pretrained CNN features of the
support and query images. The key to good performance depends on the proper
fusion of their mid-level and high-level features; the former contains
shape-oriented information, while the latter has class-oriented information.
Current state-of-the-art methods follow the approach of Tian et al., which
gives the mid-level features the primary role and the high-level features the
secondary role. In this paper, we reinterpret this widely employed approach by
redifining the roles of the multi-level features; we swap the primary and
secondary roles. Specifically, we regard that the current methods improve the
initial estimate generated from the high-level features using the mid-level
features. This reinterpretation suggests a new application of the current
methods: to apply the same network multiple times to iteratively update the
estimate of the object's region, starting from its initial estimate. Our
experiments show that this method is effective and has updated the previous
state-of-the-art on COCO-20$^i$ in the 1-shot and 5-shot settings and on
PASCAL-5$^i$ in the 1-shot setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tesla-Rapture: A Lightweight Gesture Recognition System from mmWave Radar Point Clouds. (arXiv:2109.06448v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06448">
<div class="article-summary-box-inner">
<span><p>We present Tesla-Rapture, a gesture recognition interface for point clouds
generated by mmWave Radars. State of the art gesture recognition models are
either too resource consuming or not sufficiently accurate for integration into
real-life scenarios using wearable or constrained equipment such as IoT devices
(e.g. Raspberry PI), XR hardware (e.g. HoloLens), or smart-phones. To tackle
this issue, we developed Tesla, a Message Passing Neural Network (MPNN) graph
convolution approach for mmWave radar point clouds. The model outperforms the
state of the art on two datasets in terms of accuracy while reducing the
computational complexity and, hence, the execution time. In particular, the
approach, is able to predict a gesture almost 8 times faster than the most
accurate competitor. Our performance evaluation in different scenarios
(environments, angles, distances) shows that Tesla generalizes well and
improves the accuracy up to 20% in challenging scenarios like a through-wall
setting and sensing at extreme angles. Utilizing Tesla, we develop
Tesla-Rapture, a real-time implementation using a mmWave Radar on a Raspberry
PI 4 and evaluate its accuracy and time-complexity. We also publish the source
code, the trained models, and the implementation of the model for embedded
devices.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spiking Neural Networks for Visual Place Recognition via Weighted Neuronal Assignments. (arXiv:2109.06452v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06452">
<div class="article-summary-box-inner">
<span><p>Spiking neural networks (SNNs) offer both compelling potential advantages,
including energy efficiency and low latencies, and challenges including the
non-differentiable nature of event spikes. Much of the initial research in this
area has converted deep neural networks to equivalent SNNs, but this conversion
approach potentially negates some of the potential advantages of SNN-based
approaches developed from scratch. One promising area for high performance SNNs
is template matching and image recognition. This research introduces the first
high performance SNN for the Visual Place Recognition (VPR) task: given a query
image, the SNN has to find the closest match out of a list of reference images.
At the core of this new system is a novel assignment scheme that implements a
form of ambiguity-informed salience, by up-weighting single-place-encoding
neurons and down-weighting "ambiguous" neurons that respond to multiple
different reference places. In a range of experiments on the challenging Oxford
RobotCar and Nordland datasets, we show that our SNN achieves comparable VPR
performance to state-of-the-art and classical techniques, and degrades
gracefully in performance with an increasing number of reference places. Our
results provide a significant milestone towards SNNs that can provide robust,
energy-efficient and low latency robot localization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dodging Attack Using Carefully Crafted Natural Makeup. (arXiv:2109.06467v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06467">
<div class="article-summary-box-inner">
<span><p>Deep learning face recognition models are used by state-of-the-art
surveillance systems to identify individuals passing through public areas
(e.g., airports). Previous studies have demonstrated the use of adversarial
machine learning (AML) attacks to successfully evade identification by such
systems, both in the digital and physical domains. Attacks in the physical
domain, however, require significant manipulation to the human participant's
face, which can raise suspicion by human observers (e.g. airport security
officers). In this study, we present a novel black-box AML attack which
carefully crafts natural makeup, which, when applied on a human participant,
prevents the participant from being identified by facial recognition models. We
evaluated our proposed attack against the ArcFace face recognition model, with
20 participants in a real-world setup that includes two cameras, different
shooting angles, and different lighting conditions. The evaluation results show
that in the digital domain, the face recognition system was unable to identify
all of the participants, while in the physical domain, the face recognition
system was able to identify the participants in only 1.22% of the frames
(compared to 47.57% without makeup and 33.73% with random natural makeup),
which is below a reasonable threshold of a realistic operational environment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Space Time Recurrent Memory Network. (arXiv:2109.06474v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06474">
<div class="article-summary-box-inner">
<span><p>We propose a novel visual memory network architecture for the learning and
inference problem in the spatial-temporal domain. Different from the popular
transformers, we maintain a fixed set of memory slots in our memory network and
explore designs to input new information into the memory, combine the
information in different memory slots and decide when to discard old memory
slots. Finally, this architecture is benchmarked on the video object
segmentation and video prediction problems. Through the experiments, we show
that our memory architecture can achieve competitive results with
state-of-the-art while maintaining constant memory capacity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image-Based Alignment of 3D Scans. (arXiv:2109.06526v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06526">
<div class="article-summary-box-inner">
<span><p>Full 3D scanning can efficiently be obtained using structured light scanning
combined with a rotation stage. In this setting it is, however, necessary to
reposition the object and scan it in different poses in order to cover the
entire object. In this case, correspondence between the scans is lost, since
the object was moved. In this paper, we propose a fully automatic method for
aligning the scans of an object in two different poses. This is done by
matching 2D features between images from two poses and utilizing correspondence
between the images and the scanned point clouds. To demonstrate the approach,
we present the results of scanning three dissimilar objects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3-Dimensional Deep Learning with Spatial Erasing for Unsupervised Anomaly Segmentation in Brain MRI. (arXiv:2109.06540v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06540">
<div class="article-summary-box-inner">
<span><p>Purpose. Brain Magnetic Resonance Images (MRIs) are essential for the
diagnosis of neurological diseases. Recently, deep learning methods for
unsupervised anomaly detection (UAD) have been proposed for the analysis of
brain MRI. These methods rely on healthy brain MRIs and eliminate the
requirement of pixel-wise annotated data compared to supervised deep learning.
While a wide range of methods for UAD have been proposed, these methods are
mostly 2D and only learn from MRI slices, disregarding that brain lesions are
inherently 3D and the spatial context of MRI volumes remains unexploited.
</p>
<p>Methods. We investigate whether using increased spatial context by using MRI
volumes combined with spatial erasing leads to improved unsupervised anomaly
segmentation performance compared to learning from slices. We evaluate and
compare 2D variational autoencoder (VAE) to their 3D counterpart, propose 3D
input erasing, and systemically study the impact of the data set size on the
performance.
</p>
<p>Results. Using two publicly available segmentation data sets for evaluation,
3D VAE outperform their 2D counterpart, highlighting the advantage of
volumetric context. Also, our 3D erasing methods allow for further performance
improvements. Our best performing 3D VAE with input erasing leads to an average
DICE score of 31.40% compared to 25.76% for the 2D VAE.
</p>
<p>Conclusions. We propose 3D deep learning methods for UAD in brain MRI
combined with 3D erasing and demonstrate that 3D methods clearly outperform
their 2D counterpart for anomaly segmentation. Also, our spatial erasing method
allows for further performance improvements and reduces the requirement for
large data sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Level Features Contrastive Networks for Unsupervised Domain Adaptation. (arXiv:2109.06543v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06543">
<div class="article-summary-box-inner">
<span><p>Unsupervised domain adaptation aims to train a model from the labeled source
domain to make predictions on the unlabeled target domain when the data
distribution of the two domains is different. As a result, it needs to reduce
the data distribution difference between the two domains to improve the model's
generalization ability. Existing methods tend to align the two domains directly
at the domain-level, or perform class-level domain alignment based on deep
feature. The former ignores the relationship between the various classes in the
two domains, which may cause serious negative transfer, the latter alleviates
it by introducing pseudo-labels of the target domain, but it does not consider
the importance of performing class-level alignment on shallow feature
representations. In this paper, we develop this work on the method of
class-level alignment. The proposed method reduces the difference between two
domains dramaticlly by aligning multi-level features. In the case that the two
domains share the label space, the class-level alignment is implemented by
introducing Multi-Level Feature Contrastive Networks (MLFCNet). In practice,
since the categories of samples in target domain are unavailable, we
iteratively use clustering algorithm to obtain the pseudo-labels, and then
minimize Multi-Level Contrastive Discrepancy (MLCD) loss to achieve more
accurate class-level alignment. Experiments on three real-world benchmarks
ImageCLEF-DA, Office-31 and Office-Home demonstrate that MLFCNet compares
favorably against the existing state-of-the-art domain adaptation methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Scale Input Strategies for Medulloblastoma Tumor Classification using Deep Transfer Learning. (arXiv:2109.06547v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06547">
<div class="article-summary-box-inner">
<span><p>Medulloblastoma (MB) is a primary central nervous system tumor and the most
common malignant brain cancer among children. Neuropathologists perform
microscopic inspection of histopathological tissue slides under a microscope to
assess the severity of the tumor. This is a time-consuming task and often
infused with observer variability. Recently, pre-trained convolutional neural
networks (CNN) have shown promising results for MB subtype classification.
Typically, high-resolution images are divided into smaller tiles for
classification, while the size of the tiles has not been systematically
evaluated. We study the impact of tile size and input strategy and classify the
two major histopathological subtypes-Classic and Demoplastic/Nodular. To this
end, we use recently proposed EfficientNets and evaluate tiles with increasing
size combined with various downsampling scales. Our results demonstrate using
large input tiles pixels followed by intermediate downsampling and patch
cropping significantly improves MB classification performance. Our
top-performing method achieves the AUC-ROC value of 90.90\% compared to 84.53\%
using the previous approach with smaller input tiles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dense Deep Unfolding Network with 3D-CNN Prior for Snapshot Compressive Imaging. (arXiv:2109.06548v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06548">
<div class="article-summary-box-inner">
<span><p>Snapshot compressive imaging (SCI) aims to record three-dimensional signals
via a two-dimensional camera. For the sake of building a fast and accurate SCI
recovery algorithm, we incorporate the interpretability of model-based methods
and the speed of learning-based ones and present a novel dense deep unfolding
network (DUN) with 3D-CNN prior for SCI, where each phase is unrolled from an
iteration of Half-Quadratic Splitting (HQS). To better exploit the
spatial-temporal correlation among frames and address the problem of
information loss between adjacent phases in existing DUNs, we propose to adopt
the 3D-CNN prior in our proximal mapping module and develop a novel dense
feature map (DFM) strategy, respectively. Besides, in order to promote network
robustness, we further propose a dense feature map adaption (DFMA) module to
allow inter-phase information to fuse adaptively. All the parameters are
learned in an end-to-end fashion. Extensive experiments on simulation data and
real data verify the superiority of our method. The source code is available at
https://github.com/jianzhangcs/SCI3D.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Anomaly Attribution of Multivariate Time Series using Counterfactual Reasoning. (arXiv:2109.06562v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06562">
<div class="article-summary-box-inner">
<span><p>There are numerous methods for detecting anomalies in time series, but that
is only the first step to understanding them. We strive to exceed this by
explaining those anomalies. Thus we develop a novel attribution scheme for
multivariate time series relying on counterfactual reasoning. We aim to answer
the counterfactual question of would the anomalous event have occurred if the
subset of the involved variables had been more similarly distributed to the
data outside of the anomalous interval. Specifically, we detect anomalous
intervals using the Maximally Divergent Interval (MDI) algorithm, replace a
subset of variables with their in-distribution values within the detected
interval and observe if the interval has become less anomalous, by re-scoring
it with MDI. We evaluate our method on multivariate temporal and
spatio-temporal data and confirm the accuracy of our anomaly attribution of
multiple well-understood extreme climate events such as heatwaves and
hurricanes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Semantic Indexing Structure for Image Retrieval. (arXiv:2109.06583v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06583">
<div class="article-summary-box-inner">
<span><p>In large-scale image retrieval, many indexing methods have been proposed to
narrow down the searching scope of retrieval. The features extracted from
images usually are of high dimensions or unfixed sizes due to the existence of
key points. Most of existing index structures suffer from the dimension curse,
the unfixed feature size and/or the loss of semantic similarity. In this paper
a new classification-based indexing structure, called Semantic Indexing
Structure (SIS), is proposed, in which we utilize the semantic categories
rather than clustering centers to create database partitions, such that the
proposed index SIS can be combined with feature extractors without the
restriction of dimensions. Besides, it is observed that the size of each
semantic partition is positively correlated with the semantic distribution of
database. Along this way, we found that when the partition number is normalized
to five, the proposed algorithm performed very well in all the tests. Compared
with state-of-the-art models, SIS achieves outstanding performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">High-Fidelity GAN Inversion for Image Attribute Editing. (arXiv:2109.06590v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06590">
<div class="article-summary-box-inner">
<span><p>We present a novel high-fidelity generative adversarial network (GAN)
inversion framework that enables attribute editing with image-specific details
well-preserved (e.g., background, appearance and illumination). We first
formulate GAN inversion as a lossy data compression problem and carefully
discuss the Rate-Distortion-Edit trade-off. Due to this trade-off, previous
works fail to achieve high-fidelity reconstruction while keeping compelling
editing ability with a low bit-rate latent code only. In this work, we propose
a distortion consultation approach that employs the distortion map as a
reference for reconstruction. In the distortion consultation inversion (DCI),
the distortion map is first projected to a high-rate latent map, which then
complements the basic low-rate latent code with (lost) details via consultation
fusion. To achieve high-fidelity editing, we propose an adaptive distortion
alignment (ADA) module with a self-supervised training scheme. Extensive
experiments in the face and car domains show a clear improvement in terms of
both inversion and editing quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sampling Network Guided Cross-Entropy Method for Unsupervised Point Cloud Registration. (arXiv:2109.06619v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06619">
<div class="article-summary-box-inner">
<span><p>In this paper, by modeling the point cloud registration task as a Markov
decision process, we propose an end-to-end deep model embedded with the
cross-entropy method (CEM) for unsupervised 3D registration. Our model consists
of a sampling network module and a differentiable CEM module. In our sampling
network module, given a pair of point clouds, the sampling network learns a
prior sampling distribution over the transformation space. The learned sampling
distribution can be used as a "good" initialization of the differentiable CEM
module. In our differentiable CEM module, we first propose a maximum consensus
criterion based alignment metric as the reward function for the point cloud
registration task. Based on the reward function, for each state, we then
construct a fused score function to evaluate the sampled transformations, where
we weight the current and future rewards of the transformations. Particularly,
the future rewards of the sampled transforms are obtained by performing the
iterative closest point (ICP) algorithm on the transformed state. By selecting
the top-k transformations with the highest scores, we iteratively update the
sampling distribution. Furthermore, in order to make the CEM differentiable, we
use the sparsemax function to replace the hard top-$k$ selection. Finally, we
formulate a Geman-McClure estimator based loss to train our end-to-end
registration model. Extensive experimental results demonstrate the good
registration performance of our method on benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Attentive Graph Learning for Image Restoration. (arXiv:2109.06620v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06620">
<div class="article-summary-box-inner">
<span><p>Non-local self-similarity in natural images has been verified to be an
effective prior for image restoration. However, most existing deep non-local
methods assign a fixed number of neighbors for each query item, neglecting the
dynamics of non-local correlations. Moreover, the non-local correlations are
usually based on pixels, prone to be biased due to image degradation. To
rectify these weaknesses, in this paper, we propose a dynamic attentive graph
learning model (DAGL) to explore the dynamic non-local property on patch level
for image restoration. Specifically, we propose an improved graph model to
perform patch-wise graph convolution with a dynamic and adaptive number of
neighbors for each node. In this way, image content can adaptively balance
over-smooth and over-sharp artifacts through the number of its connected
neighbors, and the patch-wise non-local correlations can enhance the message
passing process. Experimental results on various image restoration tasks:
synthetic image denoising, real image denoising, image demosaicing, and
compression artifact reduction show that our DAGL can produce state-of-the-art
results with superior accuracy and visual quality. The source code is available
at https://github.com/jianzhangcs/DAGL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scalable Font Reconstruction with Dual Latent Manifolds. (arXiv:2109.06627v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06627">
<div class="article-summary-box-inner">
<span><p>We propose a deep generative model that performs typography analysis and font
reconstruction by learning disentangled manifolds of both font style and
character shape. Our approach enables us to massively scale up the number of
character types we can effectively model compared to previous methods.
Specifically, we infer separate latent variables representing character and
font via a pair of inference networks which take as input sets of glyphs that
either all share a character type, or belong to the same font. This design
allows our model to generalize to characters that were not observed during
training time, an important task in light of the relative sparsity of most
fonts. We also put forward a new loss, adapted from prior work that measures
likelihood using an adaptive distribution in a projected space, resulting in
more natural images without requiring a discriminator. We evaluate on the task
of font reconstruction over various datasets representing character types of
many languages, and compare favorably to modern style transfer systems
according to both automatic and manually-evaluated metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open-World Active Learning with Stacking Ensemble for Self-Driving Cars. (arXiv:2109.06628v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06628">
<div class="article-summary-box-inner">
<span><p>The environments, in which autonomous cars act, are high-risky, dynamic, and
full of uncertainty, demanding a continuous update of their sensory information
and knowledge bases. The frequency of facing an unknown object is too high
making hard the usage of Artificial Intelligence (AI) classical classification
models that usually rely on the close-world assumption. This problem of
classifying objects in this domain is better faced with and open-world AI
approach. We propose an algorithm to identify not only all the known entities
that may appear in front of the car, but also to detect and learn the classes
of those unknown objects that may be rare to stand on an highway (e.g., a lost
box from a truck). Our approach relies on the DOC algorithm from Lei Shu et.
al. as well as on the Query-by-Committee algorithm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigation of condominium building collapse in Surfside, Florida: a video feature tracking approach. (arXiv:2109.06629v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06629">
<div class="article-summary-box-inner">
<span><p>On June 24, 2021, a 12-story condominium building (Champlain Towers South) in
Surfside, Florida partially collapsed, resulting in one of the deadliest
building collapses in United States history with 98 people are confirmed dead.
We analyze this collapse event using a video clip that is publicly available
from social media. We apply computer vision algorithms to corroborate new
information from the video clip that may not be readily interpreted by human
eyes. By comparing the differential features against different video frames,
our method can quantify the falling structural components by intuitively
showing the directions and magnitudes of their movements. We demonstrate the
potential of this video processing methodology in investigations of
catastrophic structural failures and hope our results would serve as the basis
for further investigations of this and other structure collapse events.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Convolutional Generative Modeling for Artificial Microstructure Development of Aluminum-Silicon Alloy. (arXiv:2109.06635v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06635">
<div class="article-summary-box-inner">
<span><p>Machine learning which is a sub-domain of an Artificial Intelligence which is
finding various applications in manufacturing and material science sectors. In
the present study, Deep Generative Modeling which a type of unsupervised
machine learning technique has been adapted for the constructing the artificial
microstructure of Aluminium-Silicon alloy. Deep Generative Adversarial Networks
has been used for developing the artificial microstructure of the given
microstructure image dataset. The results obtained showed that the developed
models had learnt to replicate the lining near the certain images of the
microstructures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-modal Representation Learning for Video Advertisement Content Structuring. (arXiv:2109.06637v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06637">
<div class="article-summary-box-inner">
<span><p>Video advertisement content structuring aims to segment a given video
advertisement and label each segment on various dimensions, such as
presentation form, scene, and style. Different from real-life videos, video
advertisements contain sufficient and useful multi-modal content like caption
and speech, which provides crucial video semantics and would enhance the
structuring process. In this paper, we propose a multi-modal encoder to learn
multi-modal representation from video advertisements by interacting between
video-audio and text. Based on multi-modal representation, we then apply
Boundary-Matching Network to generate temporal proposals. To make the proposals
more accurate, we refine generated proposals by scene-guided alignment and
re-ranking. Finally, we incorporate proposal located embeddings into the
introduced multi-modal encoder to capture temporal relationships between local
features of each proposal and global features of the whole video for
classification. Experimental results show that our method achieves
significantly improvement compared with several baselines and Rank 1 on the
task of Multi-modal Ads Video Understanding in ACM Multimedia 2021 Grand
Challenge. Ablation study further shows that leveraging multi-modal content
like caption and speech in video advertisements significantly improve the
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learnable Discrete Wavelet Pooling (LDW-Pooling) For Convolutional Networks. (arXiv:2109.06638v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06638">
<div class="article-summary-box-inner">
<span><p>Pooling is a simple but essential layer in modern deep CNN architectures for
feature aggregation and extraction. Typical CNN design focuses on the conv
layers and activation functions, while leaving the pooling layers with fewer
options. We introduce the Learning Discrete Wavelet Pooling (LDW-Pooling) that
can be applied universally to replace standard pooling operations to better
extract features with improved accuracy and efficiency. Motivated from the
wavelet theory, we adopt the low-pass (L) and high-pass (H) filters
horizontally and vertically for pooling on a 2D feature map. Feature signals
are decomposed into four (LL, LH, HL, HH) subbands to retain features better
and avoid information dropping. The wavelet transform ensures features after
pooling can be fully preserved and recovered. We next adopt an energy-based
attention learning to fine-select crucial and representative features.
LDW-Pooling is effective and efficient when compared with other
state-of-the-art pooling techniques such as WaveletPooling and LiftPooling.
Extensive experimental validation shows that LDW-Pooling can be applied to a
wide range of standard CNN architectures and consistently outperform standard
(max, mean, mixed, and stochastic) pooling operations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CropDefender: deep watermark which is more convenient to train and more robust against cropping. (arXiv:2109.06651v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06651">
<div class="article-summary-box-inner">
<span><p>Digital image watermarking, which is a technique for invisibly embedding
information into an image, is used in fields such as property rights
protection. In recent years, some research has proposed the use of neural
networks to add watermarks to natural images. We take StegaStamp as an example
for our research. Whether facing traditional image editing methods, such as
brightness, contrast, saturation adjustment, or style change like 1-bit
conversion, GAN, StegaStamp has robustness far beyond traditional watermarking
techniques, but it still has two drawbacks: it is vulnerable to cropping and is
hard to train. We found that the causes of vulnerability to cropping is not the
loss of information on the edge, but the movement of watermark position. By
explicitly introducing the perturbation of cropping into the training, the
cropping resistance is significantly improved. For the problem of difficult
training, we introduce instance normalization to solve the vanishing gradient,
set losses' weights as learnable parameters to reduce the number of
hyperparameters, and use sigmoid to restrict pixel values of the generated
image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Adaptation by Maximizing Population Correlation with Neural Architecture Search. (arXiv:2109.06652v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06652">
<div class="article-summary-box-inner">
<span><p>In Domain Adaptation (DA), where the feature distributions of the source and
target domains are different, various distance-based methods have been proposed
to minimize the discrepancy between the source and target domains to handle the
domain shift. In this paper, we propose a new similarity function, which is
called Population Correlation (PC), to measure the domain discrepancy for DA.
Base on the PC function, we propose a new method called Domain Adaptation by
Maximizing Population Correlation (DAMPC) to learn a domain-invariant feature
representation for DA. Moreover, most existing DA methods use hand-crafted
bottleneck networks, which may limit the capacity and flexibility of the
corresponding model. Therefore, we further propose a method called DAMPC with
Neural Architecture Search (DAMPC-NAS) to search the optimal network
architecture for DAMPC. Experiments on several benchmark datasets, including
Office-31, Office-Home, and VisDA-2017, show that the proposed DAMPC-NAS method
achieves better results than state-of-the-art DA methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identifying partial mouse brain microscopy images from Allen reference atlas using a contrastively learned semantic space. (arXiv:2109.06662v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06662">
<div class="article-summary-box-inner">
<span><p>Precise identification of mouse brain microscopy images is a crucial first
step when anatomical structures in the mouse brain are to be registered to a
reference atlas. Practitioners usually rely on manual comparison of images or
tools that assume the presence of complete images. This work explores Siamese
Networks as the method for finding corresponding 2D reference atlas plates for
given partial 2D mouse brain images. Siamese networks are a class of
convolutional neural networks (CNNs) that use weight-shared paths to obtain low
dimensional embeddings of pairs of input images. The correspondence between the
partial mouse brain image and reference atlas plate is determined based on the
distance between low dimensional embeddings of brain slices and atlas plates
that are obtained from Siamese networks using contrastive learning. Experiments
showed that Siamese CNNs can precisely identify brain slices using the Allen
mouse brain atlas when training and testing images come from the same source.
They achieved TOP-1 and TOP-5 accuracy of 25% and 100%, respectively, taking
only 7.2 seconds to identify 29 images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Insect-Inspired Randomly, Weighted Neural Network with Random Fourier Features For Neuro-Symbolic Relational Learning. (arXiv:2109.06663v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06663">
<div class="article-summary-box-inner">
<span><p>Insects, such as fruit flies and honey bees, can solve simple associative
learning tasks and learn abstract concepts such as "sameness" and "difference",
which is viewed as a higher-order cognitive function and typically thought to
depend on top-down neocortical processing. Empirical research with fruit flies
strongly supports that a randomized representational architecture is used in
olfactory processing in insect brains. Based on these results, we propose a
Randomly Weighted Feature Network (RWFN) that incorporates randomly drawn,
untrained weights in an encoder that uses an adapted linear model as a decoder.
The randomized projections between input neurons and higher-order processing
centers in the input brain is mimicked in RWFN by a single-hidden-layer neural
network that specially structures latent representations in the hidden layer
using random Fourier features that better represent complex relationships
between inputs using kernel approximation. Because of this special
representation, RWFNs can effectively learn the degree of relationship among
inputs by training only a linear decoder model. We compare the performance of
RWFNs to LTNs for Semantic Image Interpretation (SII) tasks that have been used
as a representative example of how LTNs utilize reasoning over first-order
logic to surpass the performance of solely data-driven methods. We demonstrate
that compared to LTNs, RWFNs can achieve better or similar performance for both
object classification and detection of the part-of relations between objects in
SII tasks while using much far fewer learnable parameters (1:62 ratio) and a
faster learning process (1:2 ratio of running speed). Furthermore, we show that
because the randomized weights do not depend on the data, several decoders can
share a single randomized encoder, giving RWFNs a unique economy of spatial
scale for simultaneous classification tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">High-Resolution Image Harmonization via Collaborative Dual Transformations. (arXiv:2109.06671v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06671">
<div class="article-summary-box-inner">
<span><p>Given a composite image, image harmonization aims to adjust the foreground to
make it compatible with the background. High-resolution image harmonization is
in high demand, but still remains unexplored. Conventional image harmonization
methods learn global RGB-to-RGB transformation which could effortlessly scale
to high resolution, but ignore diverse local context. Recent deep learning
methods learn the dense pixel-to-pixel transformation which could generate
harmonious outputs, but are highly constrained in low resolution. In this work,
we propose a high-resolution image harmonization network with Collaborative
Dual Transformation (CDTNet) to combine pixel-to-pixel transformation and
RGB-to-RGB transformation coherently in an end-to-end framework. Our CDTNet
consists of a low-resolution generator for pixel-to-pixel transformation, a
color mapping module for RGB-to-RGB transformation, and a refinement module to
take advantage of both. Extensive experiments on high-resolution image
harmonization dataset demonstrate that our CDTNet strikes a good balance
between efficiency and effectiveness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Luminance Attentive Networks for HDR Image and Panorama Reconstruction. (arXiv:2109.06688v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06688">
<div class="article-summary-box-inner">
<span><p>It is very challenging to reconstruct a high dynamic range (HDR) from a low
dynamic range (LDR) image as an ill-posed problem. This paper proposes a
luminance attentive network named LANet for HDR reconstruction from a single
LDR image. Our method is based on two fundamental observations: (1) HDR images
stored in relative luminance are scale-invariant, which means the HDR images
will hold the same information when multiplied by any positive real number.
Based on this observation, we propose a novel normalization method called " HDR
calibration " for HDR images stored in relative luminance, calibrating HDR
images into a similar luminance scale according to the LDR images. (2) The main
difference between HDR images and LDR images is in under-/over-exposed areas,
especially those highlighted. Following this observation, we propose a
luminance attention module with a two-stream structure for LANet to pay more
attention to the under-/over-exposed areas. In addition, we propose an extended
network called panoLANet for HDR panorama reconstruction from an LDR panorama
and build a dualnet structure for panoLANet to solve the distortion problem
caused by the equirectangular panorama. Extensive experiments show that our
proposed approach LANet can reconstruct visually convincing HDR images and
demonstrate its superiority over state-of-the-art approaches in terms of all
metrics in inverse tone mapping. The image-based lighting application with our
proposed panoLANet also demonstrates that our method can simulate natural scene
lighting using only LDR panorama. Our source code is available at
https://github.com/LWT3437/LANet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LRWR: Large-Scale Benchmark for Lip Reading in Russian language. (arXiv:2109.06692v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06692">
<div class="article-summary-box-inner">
<span><p>Lipreading, also known as visual speech recognition, aims to identify the
speech content from videos by analyzing the visual deformations of lips and
nearby areas. One of the significant obstacles for research in this field is
the lack of proper datasets for a wide variety of languages: so far, these
methods have been focused only on English or Chinese. In this paper, we
introduce a naturally distributed large-scale benchmark for lipreading in
Russian language, named LRWR, which contains 235 classes and 135 speakers. We
provide a detailed description of the dataset collection pipeline and dataset
statistics. We also present a comprehensive comparison of the current popular
lipreading methods on LRWR and conduct a detailed analysis of their
performance. The results demonstrate the differences between the benchmarked
languages and provide several promising directions for lipreading models
finetuning. Thanks to our findings, we also achieved new state-of-the-art
results on the LRW benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ImUnity: a generalizable VAE-GAN solution for multicenter MR image harmonization. (arXiv:2109.06756v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06756">
<div class="article-summary-box-inner">
<span><p>ImUnity is an original deep-learning model designed for efficient and
flexible MR image harmonization. A VAE-GAN network, coupled with a confusion
module and an optional biological preservation module, uses multiple 2D-slices
taken from different anatomical locations in each subject of the training
database, as well as image contrast transformations for its self-supervised
training. It eventually generates 'corrected' MR images that can be used for
various multi-center population studies. Using 3 open source databases (ABIDE,
OASIS and SRPBS), which contain MR images from multiple acquisition scanner
types or vendors and a large range of subjects ages, we show that ImUnity: (1)
outperforms state-of-the-art methods in terms of quality of images generated
using traveling subjects; (2) removes sites or scanner biases while improving
patients classification; (3) harmonizes data coming from new sites or scanners
without the need for an additional fine-tuning and (4) allows the selection of
multiple MR reconstructed images according to the desired applications. Tested
here on T1-weighted images, ImUnity could be used to harmonize other types of
medical images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MotionHint: Self-Supervised Monocular Visual Odometrywith Motion Constraints. (arXiv:2109.06768v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06768">
<div class="article-summary-box-inner">
<span><p>We present a novel self-supervised algorithmnamedMotionHintfor monocular
visual odometry (VO) that takes motion constraints into account. A key aspect
of ourapproach is to use an appropriate motion model that can help existing
self-supervised monocular VO (SSM-VO) algorithms to overcome issues related to
the local minima within their self-supervised loss functions. The motion model
is expressed with a neural network named PPnet. It is trained to coarsely
predict the next pose of the camera and the uncertainty of this prediction. Our
self-supervised approach combines the original loss and the motion loss, which
is the weighted difference between the prediction and the generated ego-motion.
Taking two existing SSM-VO systems as our baseline, we evaluate our MotionHint
algorithm on the standard KITTI and EuRoC benchmark. Experimental results show
that our MotionHint algorithm can be easily applied to existing open-source
state-of-the-art SSM-VO systems to greatly improve the performance on KITTI
dataset by reducing the resulting ATE by up to 28.73%. For EuRoc dataset, our
method can extract the motion model.But due to the poor performance of the
baseline methods, MotionHint cannot significantly improve their results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Deep Learning Approach for Masking Fetal Gender in Ultrasound Images. (arXiv:2109.06790v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06790">
<div class="article-summary-box-inner">
<span><p>Ultrasound (US) imaging is highly effective with regards to both cost and
versatility in real-time diagnosis; however, determination of fetal gender by
US scan in the early stages of pregnancy is also a cause of sex-selective
abortion. This work proposes a deep learning object detection approach to
accurately mask fetal gender in US images in order to increase the
accessibility of the technology. We demonstrate how the YOLOv5L architecture
exhibits superior performance relative to other object detection models on this
task. Our model achieves 45.8% AP[0.5:0.95], 92% F1-score and 0.006 False
Positive Per Image rate on our test set. Furthermore, we introduce a bounding
box delay rule based on frame-to-frame structural similarity to reduce the
false negative rate by 85%, further improving masking reliability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic hippocampal surface generation via 3D U-net and active shape modeling with hybrid particle swarm optimization. (arXiv:2109.06817v1 [cs.NE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06817">
<div class="article-summary-box-inner">
<span><p>In this paper, we proposed and validated a fully automatic pipeline for
hippocampal surface generation via 3D U-net coupled with active shape modeling
(ASM). Principally, the proposed pipeline consisted of three steps. In the
beginning, for each magnetic resonance image, a 3D U-net was employed to obtain
the automatic hippocampus segmentation at each hemisphere. Secondly, ASM was
performed on a group of pre-obtained template surfaces to generate mean shape
and shape variation parameters through principal component analysis.
Ultimately, hybrid particle swarm optimization was utilized to search for the
optimal shape variation parameters that best match the segmentation. The
hippocampal surface was then generated from the mean shape and the shape
variation parameters. The proposed pipeline was observed to provide hippocampal
surfaces at both hemispheres with high accuracy, correct anatomical topology,
and sufficient smoothness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One-Class Meta-Learning: Towards Generalizable Few-Shot Open-Set Classification. (arXiv:2109.06859v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06859">
<div class="article-summary-box-inner">
<span><p>Real-world classification tasks are frequently required to work in an
open-set setting. This is especially challenging for few-shot learning problems
due to the small sample size for each known category, which prevents existing
open-set methods from working effectively; however, most multiclass few-shot
methods are limited to closed-set scenarios. In this work, we address the
problem of few-shot open-set classification by first proposing methods for
few-shot one-class classification and then extending them to few-shot
multiclass open-set classification. We introduce two independent few-shot
one-class classification methods: Meta Binary Cross-Entropy (Meta-BCE), which
learns a separate feature representation for one-class classification, and
One-Class Meta-Learning (OCML), which learns to generate one-class classifiers
given standard multiclass feature representation. Both methods can augment any
existing few-shot learning method without requiring retraining to work in a
few-shot multiclass open-set setting without degrading its closed-set
performance. We demonstrate the benefits and drawbacks of both methods in
different problem settings and evaluate them on three standard benchmark
datasets, miniImageNet, tieredImageNet, and Caltech-UCSD-Birds-200-2011, where
they surpass the state-of-the-art methods in the few-shot multiclass open-set
and few-shot one-class tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Broaden the Vision: Geo-Diverse Visual Commonsense Reasoning. (arXiv:2109.06860v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06860">
<div class="article-summary-box-inner">
<span><p>Commonsense is defined as the knowledge that is shared by everyone. However,
certain types of commonsense knowledge are correlated with culture and
geographic locations and they are only shared locally. For example, the
scenarios of wedding ceremonies vary across regions due to different customs
influenced by historical and religious factors. Such regional characteristics,
however, are generally omitted in prior work. In this paper, we construct a
Geo-Diverse Visual Commonsense Reasoning dataset (GD-VCR) to test
vision-and-language models' ability to understand cultural and
geo-location-specific commonsense. In particular, we study two state-of-the-art
Vision-and-Language models, VisualBERT and ViLBERT trained on VCR, a standard
multimodal commonsense benchmark with images primarily from Western regions. We
then evaluate how well the trained models can generalize to answering the
questions in GD-VCR. We find that the performance of both models for
non-Western regions including East Asia, South Asia, and Africa is
significantly lower than that for Western region. We analyze the reasons behind
the performance disparity and find that the performance gap is larger on QA
pairs that: 1) are concerned with culture-related scenarios, e.g., weddings,
religious activities, and festivals; 2) require high-level geo-diverse
commonsense reasoning rather than low-order perception and recognition. Dataset
and code are released at https://github.com/WadeYin9712/GD-VCR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recognizing License Plates in Real-Time. (arXiv:1906.04376v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.04376">
<div class="article-summary-box-inner">
<span><p>License plate detection and recognition (LPDR) is of growing importance for
enabling intelligent transportation and ensuring the security and safety of the
cities. However, LPDR faces a big challenge in a practical environment. The
license plates can have extremely diverse sizes, fonts and colors, and the
plate images are usually of poor quality caused by skewed capturing angles,
uneven lighting, occlusion, and blurring. In applications such as surveillance,
it often requires fast processing. To enable real-time and accurate license
plate recognition, in this work, we propose a set of techniques: 1) a contour
reconstruction method along with edge-detection to quickly detect the candidate
plates; 2) a simple zero-one-alternation scheme to effectively remove the fake
top and bottom borders around plates to facilitate more accurate segmentation
of characters on plates; 3) a set of techniques to augment the training data,
incorporate SIFT features into the CNN network, and exploit transfer learning
to obtain the initial parameters for more effective training; and 4) a
two-phase verification procedure to determine the correct plate at low cost, a
statistical filtering in the plate detection stage to quickly remove unwanted
candidates, and the accurate CR results after the CR process to perform further
plate verification without additional processing. We implement a complete LPDR
system based on our algorithms. The experimental results demonstrate that our
system can accurately recognize license plate in real-time. Additionally, it
works robustly under various levels of illumination and noise, and in the
presence of car movement. Compared to peer schemes, our system is not only
among the most accurate ones but is also the fastest, and can be easily applied
to other scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Universal Graph Transformer Self-Attention Networks. (arXiv:1909.11855v11 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.11855">
<div class="article-summary-box-inner">
<span><p>The transformer has been extensively used in research domains such as
computer vision, image processing, and natural language processing. The
transformer, however, has not been actively used in graph neural networks. To
this end, we introduce a transformer-based advanced GNN model, named UGformer,
to learn graph representations. In particular, given an input graph, we present
two UGformer variants. The first variant is to leverage the transformer on a
set of sampled neighbors for each node, while the second is to leverage the
transformer directly on the input graph. Experimental results demonstrate that
our UGformer achieves state-of-the-art accuracies on well-known benchmark
datasets for graph classification and inductive text classification. The code
is available on Github:
\url{https://github.com/daiquocnguyen/Graph-Transformer}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Binary-Ternary Quantization. (arXiv:1909.12205v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.12205">
<div class="article-summary-box-inner">
<span><p>Neural network models are resource hungry. It is difficult to deploy such
deep networks on devices with limited resources, like smart wearables,
cellphones, drones, and autonomous vehicles. Low bit quantization such as
binary and ternary quantization is a common approach to alleviate this resource
requirements. Ternary quantization provides a more flexible model and
outperforms binary quantization in terms of accuracy, however doubles the
memory footprint and increases the computational cost. Contrary to these
approaches, mixed quantized models allow a trade-off between accuracy and
memory footprint. In such models, quantization depth is often chosen manually,
or is tuned using a separate optimization routine. The latter requires training
a quantized network multiple times. Here, we propose an adaptive combination of
binary and ternary quantization, namely Smart Quantization (SQ), in which the
quantization depth is modified directly via a regularization function, so that
the model is trained only once. Our experimental results show that the proposed
method adapts quantization depth successfully while keeping the model accuracy
high on MNIST and CIFAR10 benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accelerated Zeroth-Order and First-Order Momentum Methods from Mini to Minimax Optimization. (arXiv:2008.08170v4 [math.OC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.08170">
<div class="article-summary-box-inner">
<span><p>In the paper, we propose a class of accelerated zeroth-order and first-order
momentum methods for both nonconvex mini-optimization and minimax-optimization.
Specifically, we propose a new accelerated zeroth-order momentum (Acc-ZOM)
method to solve stochastic mini-optimization problems. We prove that the
Acc-ZOM method achieves a lower query complexity of
$\tilde{O}(d^{3/4}\epsilon^{-3})$ for finding an $\epsilon$-stationary point,
which improves the best known result by a factor of $O(d^{1/4})$ where $d$
denotes the parameter dimension. In particular, the Acc-ZOM does not need large
batches that are required in the existing zeroth-order stochastic algorithms.
At the same time, we propose an accelerated zeroth-order momentum descent
ascent (Acc-ZOMDA) method for black-box minimax-optimization. We prove that the
Acc-ZOMDA method reaches the best known query complexity of
$\tilde{O}((d_1+d_2)\kappa_y^{3}\epsilon^{-3})$ without large batches for
finding an $\epsilon$-stationary point, where $d_1$ and $d_2$ denote dimensions
of optimization parameters and $\kappa_y$ is condition number. Moreover, we
propose an accelerated first-order momentum descent ascent (Acc-MDA) method for
solving white-box minimax problems, and prove that it achieves a lower gradient
complexity of $\tilde{O}(\kappa_y^{2.5}\epsilon^{-3})$ given batch size
$b=\kappa_y^{4}$ for finding an $\epsilon$-stationary point, which improves the
best known result by a factor of $O(\kappa_y^{1/2})$. Extensive experimental
results on the black-box adversarial attack to deep neural networks (DNNs) and
poisoning attack demonstrate the efficiency of our algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual News: Benchmark and Challenges in News Image Captioning. (arXiv:2010.03743v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03743">
<div class="article-summary-box-inner">
<span><p>We propose Visual News Captioner, an entity-aware model for the task of news
image captioning. We also introduce Visual News, a large-scale benchmark
consisting of more than one million news images along with associated news
articles, image captions, author information, and other metadata. Unlike the
standard image captioning task, news images depict situations where people,
locations, and events are of paramount importance. Our proposed method can
effectively combine visual and textual features to generate captions with
richer information such as events and entities. More specifically, built upon
the Transformer architecture, our model is further equipped with novel
multi-modal feature fusion techniques and attention mechanisms, which are
designed to generate named entities more accurately. Our method utilizes much
fewer parameters while achieving slightly better prediction results than
competing methods. Our larger and more diverse Visual News dataset further
highlights the remaining challenges in captioning news images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IMU-Assisted Learning of Single-View Rolling Shutter Correction. (arXiv:2011.03106v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.03106">
<div class="article-summary-box-inner">
<span><p>Rolling shutter distortion is highly undesirable for photography and computer
vision algorithms (e.g., visual SLAM) because pixels can be potentially
captured at different times and poses. In this paper, we propose a deep neural
network to predict depth and row-wise pose from a single image for rolling
shutter correction. Our contribution in this work is to incorporate inertial
measurement unit (IMU) data into the pose refinement process, which, compared
to the state-of-the-art, greatly enhances the pose prediction. The improved
accuracy and robustness make it possible for numerous vision algorithms to use
imagery captured by rolling shutter cameras and produce highly accurate
results. We also extend a dataset to have real rolling shutter images, IMU
data, depth maps, camera poses, and corresponding global shutter images for
rolling shutter correction training. We demonstrate the efficacy of the
proposed method by evaluating the performance of Direct Sparse Odometry (DSO)
algorithm on rolling shutter imagery corrected using the proposed approach.
Results show marked improvements of the DSO algorithm over using uncorrected
imagery, validating the proposed approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scale-covariant and scale-invariant Gaussian derivative networks. (arXiv:2011.14759v9 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14759">
<div class="article-summary-box-inner">
<span><p>This paper presents a hybrid approach between scale-space theory and deep
learning, where a deep learning architecture is constructed by coupling
parameterized scale-space operations in cascade. By sharing the learnt
parameters between multiple scale channels, and by using the transformation
properties of the scale-space primitives under scaling transformations, the
resulting network becomes provably scale covariant. By in addition performing
max pooling over the multiple scale channels, a resulting network architecture
for image classification also becomes provably scale invariant. We investigate
the performance of such networks on the MNISTLargeScale dataset, which contains
rescaled images from original MNIST over a factor of 4 concerning training data
and over a factor of 16 concerning testing data. It is demonstrated that the
resulting approach allows for scale generalization, enabling good performance
for classifying patterns at scales not present in the training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Infinite Nature: Perpetual View Generation of Natural Scenes from a Single Image. (arXiv:2012.09855v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09855">
<div class="article-summary-box-inner">
<span><p>We introduce the problem of perpetual view generation - long-range generation
of novel views corresponding to an arbitrarily long camera trajectory given a
single image. This is a challenging problem that goes far beyond the
capabilities of current view synthesis methods, which quickly degenerate when
presented with large camera motions. Methods for video generation also have
limited ability to produce long sequences and are often agnostic to scene
geometry. We take a hybrid approach that integrates both geometry and image
synthesis in an iterative `\emph{render}, \emph{refine} and \emph{repeat}'
framework, allowing for long-range generation that cover large distances after
hundreds of frames. Our approach can be trained from a set of monocular video
sequences. We propose a dataset of aerial footage of coastal scenes, and
compare our method with recent view synthesis and conditional video generation
baselines, showing that it can generate plausible scenes for much longer time
horizons over large camera trajectories compared to existing methods. Project
page at https://infinite-nature.github.io/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-line-of-Sight Imaging via Neural Transient Fields. (arXiv:2101.00373v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00373">
<div class="article-summary-box-inner">
<span><p>We present a neural modeling framework for Non-Line-of-Sight (NLOS) imaging.
Previous solutions have sought to explicitly recover the 3D geometry (e.g., as
point clouds) or voxel density (e.g., within a pre-defined volume) of the
hidden scene. In contrast, inspired by the recent Neural Radiance Field (NeRF)
approach, we use a multi-layer perceptron (MLP) to represent the neural
transient field or NeTF. However, NeTF measures the transient over spherical
wavefronts rather than the radiance along lines. We therefore formulate a
spherical volume NeTF reconstruction pipeline, applicable to both confocal and
non-confocal setups. Compared with NeRF, NeTF samples a much sparser set of
viewpoints (scanning spots) and the sampling is highly uneven. We thus
introduce a Monte Carlo technique to improve the robustness in the
reconstruction. Comprehensive experiments on synthetic and real datasets
demonstrate NeTF provides higher quality reconstruction and preserves fine
details largely missing in the state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Study and Analysis on Open-Set Semi-Supervised Learning. (arXiv:2101.08237v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08237">
<div class="article-summary-box-inner">
<span><p>Pseudo-labeling (PL) and Data Augmentation-based Consistency Training (DACT)
are two approaches widely used in Semi-Supervised Learning (SSL) methods. These
methods exhibit great power in many machine learning tasks by utilizing
unlabeled data for efficient training. But in a more realistic setting (termed
as open-set SSL), where unlabeled dataset contains out-of-distribution (OOD)
samples, the traditional SSL methods suffer severe performance degradation.
Recent approaches mitigate the negative influence of OOD samples by filtering
them out from the unlabeled data. However, it is not clear whether directly
removing the OOD samples is the best choice. Furthermore, why PL and DACT could
perform differently in open-set SSL remains a mystery. In this paper, we
thoroughly analyze various SSL methods (PL and DACT) on open-set SSL and
discuss pros and cons of these two approaches separately. Based on our
analysis, we propose Style Disturbance to improve traditional SSL methods on
open-set SSL and experimentally show our approach can achieve state-of-the-art
results on various datasets by utilizing OOD samples properly. We believe our
study can bring new insights for SSL research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transductive Zero-Shot Learning by Decoupled Feature Generation. (arXiv:2102.03266v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03266">
<div class="article-summary-box-inner">
<span><p>In this paper, we address zero-shot learning (ZSL), the problem of
recognizing categories for which no labeled visual data are available during
training. We focus on the transductive setting, in which unlabelled visual data
from unseen classes is available. State-of-the-art paradigms in ZSL typically
exploit generative adversarial networks to synthesize visual features from
semantic attributes. We posit that the main limitation of these approaches is
to adopt a single model to face two problems: 1) generating realistic visual
features, and 2) translating semantic attributes into visual cues. Differently,
we propose to decouple such tasks, solving them separately. In particular, we
train an unconditional generator to solely capture the complexity of the
distribution of visual data and we subsequently pair it with a conditional
generator devoted to enrich the prior knowledge of the data distribution with
the semantic content of the class embeddings. We present a detailed ablation
study to dissect the effect of our proposed decoupling approach, while
demonstrating its superiority over the related state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Point-set Distances for Learning Representations of 3D Point Clouds. (arXiv:2102.04014v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04014">
<div class="article-summary-box-inner">
<span><p>Learning an effective representation of 3D point clouds requires a good
metric to measure the discrepancy between two 3D point sets, which is
non-trivial due to their irregularity. Most of the previous works resort to
using the Chamfer discrepancy or Earth Mover's distance, but those metrics are
either ineffective in measuring the differences between point clouds or
computationally expensive. In this paper, we conduct a systematic study with
extensive experiments on distance metrics for 3D point clouds. From this study,
we propose to use sliced Wasserstein distance and its variants for learning
representations of 3D point clouds. In addition, we introduce a new algorithm
to estimate sliced Wasserstein distance that guarantees that the estimated
value is close enough to the true one. Experiments show that the sliced
Wasserstein distance and its variants allow the neural network to learn a more
efficient representation compared to the Chamfer discrepancy. We demonstrate
the efficiency of the sliced Wasserstein metric and its variants on several
tasks in 3D computer vision including training a point cloud autoencoder,
generative modeling, transfer learning, and point cloud registration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Deep-Learning Approach For Direct Whole-Heart Mesh Reconstruction. (arXiv:2102.07899v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07899">
<div class="article-summary-box-inner">
<span><p>Automated construction of surface geometries of cardiac structures from
volumetric medical images is important for a number of clinical applications.
While deep-learning-based approaches have demonstrated promising reconstruction
precision, these approaches have mostly focused on voxel-wise segmentation
followed by surface reconstruction and post-processing techniques. However,
such approaches suffer from a number of limitations including disconnected
regions or incorrect surface topology due to erroneous segmentation and
stair-case artifacts due to limited segmentation resolution. We propose a novel
deep-learning-based approach that directly predicts whole heart surface meshes
from volumetric CT and MR image data. Our approach leverages a graph
convolutional neural network to predict deformation on mesh vertices from a
pre-defined mesh template to reconstruct multiple anatomical structures in a 3D
image volume. Our method demonstrated promising performance of generating whole
heart reconstructions with as good or better accuracy than prior
deep-learning-based methods on both CT and MR data. Furthermore, by deforming a
template mesh, our method can generate whole heart geometries with better
anatomical consistency and produce high-resolution geometries from lower
resolution input image data. Our method was also able to produce temporally
consistent surface mesh predictions for heart motion from CT or MR cine
sequences, and therefore can potentially be applied for efficiently
constructing 4D whole heart dynamics. Our code and pre-trained networks are
available at https://github.com/fkong7/MeshDeformNet
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scalable Scene Flow from Point Clouds in the Real World. (arXiv:2103.01306v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01306">
<div class="article-summary-box-inner">
<span><p>Autonomous vehicles operate in highly dynamic environments necessitating an
accurate assessment of which aspects of a scene are moving and where they are
moving to. A popular approach to 3D motion estimation, termed scene flow, is to
employ 3D point cloud data from consecutive LiDAR scans, although such
approaches have been limited by the small size of real-world, annotated LiDAR
data. In this work, we introduce a new large-scale dataset for scene flow
estimation derived from corresponding tracked 3D objects, which is
$\sim$1,000$\times$ larger than previous real-world datasets in terms of the
number of annotated frames. We demonstrate how previous works were bounded
based on the amount of real LiDAR data available, suggesting that larger
datasets are required to achieve state-of-the-art predictive performance.
Furthermore, we show how previous heuristics for operating on point clouds such
as down-sampling heavily degrade performance, motivating a new class of models
that are tractable on the full point cloud. To address this issue, we introduce
the FastFlow3D architecture which provides real time inference on the full
point cloud. Additionally, we design human-interpretable metrics that better
capture real world aspects by accounting for ego-motion and providing
breakdowns per object type. We hope that this dataset may provide new
opportunities for developing real world scene flow systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Recent Advances in Deep Learning for Audio-Visual Emotion Recognition. (arXiv:2103.09154v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09154">
<div class="article-summary-box-inner">
<span><p>Emotional expressions are the behaviors that communicate our emotional state
or attitude to others. They are expressed through verbal and non-verbal
communication. Complex human behavior can be understood by studying physical
features from multiple modalities; mainly facial, vocal and physical gestures.
Recently, spontaneous multi-modal emotion recognition has been extensively
studied for human behavior analysis. In this paper, we propose a new deep
learning-based approach for audio-visual emotion recognition. Our approach
leverages recent advances in deep learning like knowledge distillation and
high-performing deep architectures. The deep feature representations of the
audio and visual modalities are fused based on a model-level fusion strategy. A
recurrent neural network is then used to capture the temporal dynamics. Our
proposed approach substantially outperforms state-of-the-art approaches in
predicting valence on the RECOLA dataset. Moreover, our proposed visual facial
expression feature extraction network outperforms state-of-the-art results on
the AffectNet and Google Facial Expression Comparison datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning without Seeing nor Knowing: Towards Open Zero-Shot Learning. (arXiv:2103.12437v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12437">
<div class="article-summary-box-inner">
<span><p>In Generalized Zero-Shot Learning (GZSL), unseen categories (for which no
visual data are available at training time) can be predicted by leveraging
their class embeddings (e.g., a list of attributes describing them) together
with a complementary pool of seen classes (paired with both visual data and
class embeddings). Despite GZSL is arguably challenging, we posit that knowing
in advance the class embeddings, especially for unseen categories, is an actual
limit of the applicability of GZSL towards real-world scenarios. To relax this
assumption, we propose Open Zero-Shot Learning (OZSL) to extend GZSL towards
the open-world settings. We formalize OZSL as the problem of recognizing seen
and unseen classes (as in GZSL) while also rejecting instances from unknown
categories, for which neither visual data nor class embeddings are provided. We
formalize the OZSL problem introducing evaluation protocols, error metrics and
benchmark datasets. We also suggest to tackle the OZSL problem by proposing the
idea of performing unknown feature generation (instead of only unseen features
generation as done in GZSL). We achieve this by optimizing a generative process
to sample unknown class embeddings as complementary to the seen and the unseen.
We intend these results to be the ground to foster future research, extending
the standard closed-world zero-shot learning (GZSL) with the novel open-world
counterpart (OZSL).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">D2C-SR: A Divergence to Convergence Approach for Real-World Image Super-Resolution. (arXiv:2103.14373v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14373">
<div class="article-summary-box-inner">
<span><p>In this paper, we present D2C-SR, a novel framework for the task of
real-world image super-resolution. As an ill-posed problem, the key challenge
in super-resolution related tasks is there can be multiple predictions for a
given low-resolution input. Most classical deep learning based approaches
ignored the fundamental fact and lack explicit modeling of the underlying
high-frequency distribution which leads to blurred results. Recently, some
methods of GAN-based or learning super-resolution space can generate simulated
textures but do not promise the accuracy of the textures which have low
quantitative performance. Rethinking both, we learn the distribution of
underlying high-frequency details in a discrete form and propose a two-stage
pipeline: divergence stage to convergence stage. At divergence stage, we
propose a tree-based structure deep network as our divergence backbone.
Divergence loss is proposed to encourage the generated results from the
tree-based network to diverge into possible high-frequency representations,
which is our way of discretely modeling the underlying high-frequency
distribution. At convergence stage, we assign spatial weights to fuse these
divergent predictions to obtain the final output with more accurate details.
Our approach provides a convenient end-to-end manner to inference. We conduct
evaluations on several real-world benchmarks, including a new proposed
D2CRealSR dataset with x8 scaling factor. Our experiments demonstrate that
D2C-SR achieves better accuracy and visual improvements against
state-of-the-art methods, with a significantly less parameters number.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bayesian Deep Neural Networks for Supervised Learning Single-View Depth. (arXiv:2104.14202v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14202">
<div class="article-summary-box-inner">
<span><p>Uncertainty quantification is a key aspect of robotic perception, as
overconfident or point estimators can lead to collisions and damages to the
environment and the robot. In this paper, we evaluate scalable approaches to
uncertainty quantification in single-view supervised depth learning,
specifically MC dropout and deep ensembles. For MC dropout,in particular, we
explore deeply the effect of the dropout at different levels in the
architecture. We demonstrate that adding dropout in the encoder offer better
results than adding it in the decoder, the latest being the usual approach in
the literature for similar problems. We also show the use of depth uncertainty
in the application of pseudo-RGBD ICP and demonstrate its potential for
improving the accuracy in such a task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NURBS-Diff: A differentiable programming module for NURBS. (arXiv:2104.14547v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14547">
<div class="article-summary-box-inner">
<span><p>Boundary representations (B-reps) using Non-Uniform Rational B-splines
(NURBS) are the de facto standard used in CAD, but their utility in deep
learning-based approaches is not well researched. We propose a differentiable
NURBS module to integrate the NURBS representation of CAD models with deep
learning methods. We mathematically define the derivatives of the NURBS curves
or surfaces with respect to the input parameters. These derivatives are used to
define an approximate Jacobian that can be used to perform the "backward"
evaluation used while training deep learning models. We have implemented our
NURBS module using GPU-accelerated algorithms and integrated it with PyTorch, a
popular deep learning framework. We demonstrate the efficacy of our NURBS
module in performing CAD operations such as curve or surface fitting and
surface offsetting. Further, we show its utility in deep learning for
unsupervised point cloud reconstruction. These examples show that our module
performs better for certain deep learning frameworks and can be directly
integrated with any deep-learning framework requiring NURBS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention-augmented Spatio-Temporal Segmentation for Land Cover Mapping. (arXiv:2105.02963v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02963">
<div class="article-summary-box-inner">
<span><p>The availability of massive earth observing satellite data provide huge
opportunities for land use and land cover mapping. However, such mapping effort
is challenging due to the existence of various land cover classes, noisy data,
and the lack of proper labels. Also, each land cover class typically has its
own unique temporal pattern and can be identified only during certain periods.
In this article, we introduce a novel architecture that incorporates the UNet
structure with Bidirectional LSTM and Attention mechanism to jointly exploit
the spatial and temporal nature of satellite data and to better identify the
unique temporal patterns of each land cover. We evaluate this method for
mapping crops in multiple regions over the world. We compare our method with
other state-of-the-art methods both quantitatively and qualitatively on two
real-world datasets which involve multiple land cover classes. We also
visualise the attention weights to study its effectiveness in mitigating noise
and identifying discriminative time period.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Temporal-Spatial Feature Pyramid for Video Saliency Detection. (arXiv:2105.04213v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04213">
<div class="article-summary-box-inner">
<span><p>Multi-level features are important for saliency detection. Better combination
and use of multi-level features with time information can greatly improve the
accuracy of the video saliency model. In order to fully combine multi-level
features and make it serve the video saliency model, we propose a 3D fully
convolutional encoder-decoder architecture for video saliency detection, which
combines scale, space and time information for video saliency modeling. The
encoder extracts multi-scale temporal-spatial features from the input
continuous video frames, and then constructs temporal-spatial feature pyramid
through temporal-spatial convolution and top-down feature integration. The
decoder performs hierarchical decoding of temporal-spatial features from
different scales, and finally produces a saliency map from the integration of
multiple video frames. Our model is simple yet effective, and can run in real
time. We perform abundant experiments, and the results indicate that the
well-designed structure can improve the precision of video saliency detection
significantly. Experimental results on three purely visual video saliency
benchmarks and six audio-video saliency benchmarks demonstrate that our method
outperforms the existing state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CDN-MEDAL: Two-stage Density and Difference Approximation Framework for Motion Analysis. (arXiv:2106.03776v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03776">
<div class="article-summary-box-inner">
<span><p>Background modeling is a promising research area in video analysis with a
variety of video surveillance applications. Recent years have witnessed the
proliferation of deep neural networks via effective learning-based approaches
in motion analysis. However, these techniques only provide a limited
description of the observed scenes' insufficient properties where a
single-valued mapping is learned to approximate the temporal conditional
averages of the target background. On the other hand, statistical learning in
imagery domains has become one of the most prevalent approaches with high
adaptation to dynamic context transformation, notably Gaussian Mixture Models,
combined with a foreground extraction step. In this work, we propose a novel,
two-stage method of change detection with two convolutional neural networks.
The first architecture is grounded on the unsupervised Gaussian mixtures
statistical learning to describe the scenes' salient features. The second one
implements a light-weight pipeline of foreground detection. Our two-stage
framework contains approximately 3.5K parameters in total but still maintains
rapid convergence to intricate motion patterns. Our experiments on publicly
available datasets show that our proposed networks are not only capable of
generalizing regions of moving objects in unseen cases with promising results
but also are competitive in performance efficiency and effectiveness regarding
foreground segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse PointPillars: Maintaining and Exploiting Input Sparsity to Improve Runtime on Embedded Systems. (arXiv:2106.06882v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06882">
<div class="article-summary-box-inner">
<span><p>Bird's Eye View (BEV) is a popular representation for processing 3D point
clouds, and by its nature is fundamentally sparse. Motivated by the
computational limitations of mobile robot platforms, we take a fast,
high-performance BEV 3D object detector - PointPillars - and modify its
backbone to maintain and exploit this input sparsity, leading to decreased
runtimes. We present results on KITTI, a canonical 3D detection dataset, and
Matterport-Chair, a novel Matterport3D-derived chair detection dataset from
scenes in real furnished homes. We evaluate runtime characteristics using a
desktop GPU, an embedded ML accelerator, and a robot CPU, demonstrating that
our method results in significant runtime decreases (2x or more) for embedded
systems with only a modest decrease in detection quality. Our work represents a
new approach for practitioners to optimize models for embedded systems by
maintaining and exploiting input sparsity throughout their entire pipeline to
reduce runtime and resource usage while preserving detection performance. All
models, weights, experimental configurations, and datasets used are publicly
available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SAR Image Change Detection Based on Multiscale Capsule Network. (arXiv:2106.06896v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06896">
<div class="article-summary-box-inner">
<span><p>Traditional change detection methods based on convolutional neural networks
(CNNs) face the challenges of speckle noise and deformation sensitivity for
synthetic aperture radar images. To mitigate these issues, we proposed a
Multiscale Capsule Network (Ms-CapsNet) to extract the discriminative
information between the changed and unchanged pixels. On the one hand, the
capsule module is employed to exploit the spatial relationship of features.
Therefore, equivariant properties can be achieved by aggregating the features
from different positions. On the other hand, an adaptive fusion convolution
(AFC) module is designed for the proposed Ms-CapsNet. Higher semantic features
can be captured for the primary capsules. Feature extracted by the AFC module
significantly improves the robustness to speckle noise. The effectiveness of
the proposed Ms-CapsNet is verified on three real SAR datasets. The comparison
experiments with four state-of-the-art methods demonstrated the efficiency of
the proposed method. Our codes are available at
https://github.com/summitgao/SAR_CD_MS_CapsNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MIMIR: Deep Regression for Automated Analysis of UK Biobank Body MRI. (arXiv:2106.11731v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11731">
<div class="article-summary-box-inner">
<span><p>UK Biobank (UKB) conducts large-scale examinations of more than half a
million volunteers, collecting health-related information on genetics,
lifestyle, blood biochemistry, and more. Medical imaging of 100,000 subjects,
with 70,000 follow-up sessions, enables measurements of organs, muscle, and
body composition. With up to 170,000 mounting MR images, various methodologies
are accordingly engaged in large-scale image analysis. This work presents an
experimental inference engine that can automatically predict a comprehensive
profile of subject metadata from UKB neck-to-knee body MRI. It was evaluated in
cross-validation for baseline characteristics such as age, height, weight, and
sex, but also measurements of body composition, organ volumes, and abstract
properties like grip strength, pulse rate, and type 2 diabetic status. It
predicted subsequently released test data covering twelve body composition
metrics with a 3% median error. The proposed system can automatically analyze
one thousand subjects within ten minutes, providing individual confidence
intervals. The underlying methodology utilizes convolutional neural networks
for image-based mean-variance regression on two-dimensional representations of
the MRI data. This work aims to make the proposed system available for free to
researchers, who can use it to obtain fast and fully-automated estimates of 72
different measurements immediately upon release of new UKB image data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast and Accurate Road Crack Detection Based on Adaptive Cost-Sensitive Loss Function. (arXiv:2106.15510v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15510">
<div class="article-summary-box-inner">
<span><p>Numerous detection problems in computer vision, including road crack
detection, suffer from exceedingly foreground-background imbalance.
Fortunately, modification of loss function appears to solve this puzzle once
and for all. In this paper, we propose a pixel-based adaptive weighted
cross-entropy loss in conjunction with Jaccard distance to facilitate
high-quality pixel-level road crack detection. Our work profoundly demonstrates
the influence of loss functions on detection outcomes, and sheds light on the
sophisticated consecutive improvements in the realm of crack detection.
Specifically, to verify the effectiveness of the proposed loss, we conduct
extensive experiments on four public databases, i.e., CrackForest, AigleRN,
Crack360, and BJN260. Compared with the vanilla weighted cross-entropy, the
proposed loss significantly speeds up the training process while retaining the
test accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">P-WAE: Generalized Patch-Wasserstein Autoencoder for Anomaly Screening. (arXiv:2108.03815v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03815">
<div class="article-summary-box-inner">
<span><p>Anomaly detection plays a pivotal role in numerous real-world scenarios, such
as industrial automation and manufacturing intelligence. Recently, variational
inference-based anomaly analysis has attracted researchers' and developers'
attention. It aims to model the defect-free distribution so that anomalies can
be classified as out-of-distribution samples. Nevertheless, there are two
disturbing factors that need us to prioritize: (i) the simplistic prior latent
distribution inducing limited expressive capability; (ii) the strong
probability distance notion results in collapsed features. In this paper, we
propose a novel Patch-wise Wasserstein AutoEncoder (P-WAE) architecture to
alleviate those challenges. In particular, a patch-wise variational inference
model coupled with solving the jigsaw puzzle is designed, which is a simple yet
effective way to increase the expressiveness of the latent manifold. This makes
using the model on high-dimensional practical data possible. In addition, we
leverage a weaker measure, sliced-Wasserstein distance, to achieve the
equilibrium between the reconstruction fidelity and generalized
representations. Comprehensive experiments, conducted on the MVTec AD dataset,
demonstrate the superior performance of our proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-repository of screening mammography classifiers. (arXiv:2108.04800v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04800">
<div class="article-summary-box-inner">
<span><p>Artificial intelligence (AI) is showing promise in improving clinical
diagnosis. In breast cancer screening, several recent studies show that AI has
the potential to improve radiologists' accuracy, subsequently helping in early
cancer diagnosis and reducing unnecessary workup. As the number of proposed
models and their complexity grows, it is becoming increasingly difficult to
re-implement them in order to reproduce the results and to compare different
approaches. To enable reproducibility of research in this application area and
to enable comparison between different methods, we release a meta-repository
containing deep learning models for classification of screening mammograms.
This meta-repository creates a framework that enables the evaluation of machine
learning models on any private or public screening mammography data set. At its
inception, our meta-repository contains five state-of-the-art models with
open-source implementations and cross-platform compatibility. We compare their
performance on six international data sets: two New York University breast
cancer screening data sets, DDSM, INbreast, OPTIMAM and Chinese Mammography
Database. Our framework has a flexible design that can be generalized to other
medical image analysis tasks. The meta-repository is available at
https://www.github.com/nyukat/mammography_metarepository.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Unified Objective for Novel Class Discovery. (arXiv:2108.08536v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08536">
<div class="article-summary-box-inner">
<span><p>In this paper, we study the problem of Novel Class Discovery (NCD). NCD aims
at inferring novel object categories in an unlabeled set by leveraging from
prior knowledge of a labeled set containing different, but related classes.
Existing approaches tackle this problem by considering multiple objective
functions, usually involving specialized loss terms for the labeled and the
unlabeled samples respectively, and often requiring auxiliary regularization
terms. In this paper, we depart from this traditional scheme and introduce a
UNified Objective function (UNO) for discovering novel classes, with the
explicit purpose of favoring synergy between supervised and unsupervised
learning. Using a multi-view self-labeling strategy, we generate pseudo-labels
that can be treated homogeneously with ground truth labels. This leads to a
single classification objective operating on both known and unknown classes.
Despite its simplicity, UNO outperforms the state of the art by a significant
margin on several benchmarks (~+10% on CIFAR-100 and +8% on ImageNet). The
project page is available at: https://ncd-uno.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified Representation of Geometric Primitives for Graph-SLAM Optimization Using Decomposed Quadrics. (arXiv:2108.08957v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08957">
<div class="article-summary-box-inner">
<span><p>In Simultaneous Localization And Mapping (SLAM) problems, high-level
landmarks have the potential to build compact and informative maps compared to
traditional point-based landmarks. In this work, we focus on the
parameterization of frequently used geometric primitives including points,
lines, planes, ellipsoids, cylinders, and cones. We first present a unified
representation based on quadrics, leading to a consistent and concise
formulation. Then we further study a decomposed model of quadrics that
discloses the symmetric and degenerated properties of a primitive. Based on the
decomposition, we develop geometrically meaningful quadrics factors in the
settings of a graph-SLAM problem. Then in simulation experiments, it is shown
that the decomposed formulation has better efficiency and robustness to
observation noises than baseline parameterizations. Finally, in real-world
experiments, the proposed back-end framework is demonstrated to be capable of
building compact and regularized maps.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Understanding the Generative Capability of Adversarially Robust Classifiers. (arXiv:2108.09093v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09093">
<div class="article-summary-box-inner">
<span><p>Recently, some works found an interesting phenomenon that adversarially
robust classifiers can generate good images comparable to generative models. We
investigate this phenomenon from an energy perspective and provide a novel
explanation. We reformulate adversarial example generation, adversarial
training, and image generation in terms of an energy function. We find that
adversarial training contributes to obtaining an energy function that is flat
and has low energy around the real data, which is the key for generative
capability. Based on our new understanding, we further propose a better
adversarial training method, Joint Energy Adversarial Training (JEAT), which
can generate high-quality images and achieve new state-of-the-art robustness
under a wide range of attacks. The Inception Score of the images (CIFAR-10)
generated by JEAT is 8.80, much better than original robust classifiers (7.50).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detection and Localization of Multiple Image Splicing Using MobileNet V1. (arXiv:2108.09674v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09674">
<div class="article-summary-box-inner">
<span><p>In modern society, digital images have become a prominent source of
information and medium of communication. They can, however, be simply altered
using freely available image editing software. Two or more images are combined
to generate a new image that can transmit information across social media
platforms to influence the people in the society. This information may have
both positive and negative consequences. Hence there is a need to develop a
technique that will detect and locates a multiple image splicing forgery in an
image. This research work proposes multiple image splicing forgery detection
using Mask R-CNN, with a backbone as a MobileNet V1. It also calculates the
percentage score of a forged region of multiple spliced images. The comparative
analysis of the proposed work with the variants of ResNet is performed. The
proposed model is trained and tested using our MISD (Multiple Image Splicing
Dataset), and it is observed that the proposed model outperforms the variants
of ResNet models (ResNet 51,101 and 151).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Matching in the Dark: A Dataset for Matching Image Pairs of Low-light Scenes. (arXiv:2109.03585v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03585">
<div class="article-summary-box-inner">
<span><p>This paper considers matching images of low-light scenes, aiming to widen the
frontier of SfM and visual SLAM applications. Recent image sensors can record
the brightness of scenes with more than eight-bit precision, available in their
RAW-format image. We are interested in making full use of such high-precision
information to match extremely low-light scene images that conventional methods
cannot handle. For extreme low-light scenes, even if some of their brightness
information exists in the RAW format images' low bits, the standard raw image
processing on cameras fails to utilize them properly. As was recently shown by
Chen et al., CNNs can learn to produce images with a natural appearance from
such RAW-format images. To consider if and how well we can utilize such
information stored in RAW-format images for image matching, we have created a
new dataset named MID (matching in the dark). Using it, we experimentally
evaluated combinations of eight image-enhancing methods and eleven image
matching methods consisting of classical/neural local descriptors and
classical/neural initial point-matching methods. The results show the advantage
of using the RAW-format images and the strengths and weaknesses of the above
component methods. They also imply there is room for further research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised clothing change adaptive person ReID. (arXiv:2109.03702v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03702">
<div class="article-summary-box-inner">
<span><p>Clothing changes and lack of data labels are both crucial challenges in
person ReID. For the former challenge, people may occur multiple times at
different locations wearing different clothing. However, most of the current
person ReID research works focus on the benchmarks in which a person's clothing
is kept the same all the time. For the last challenge, some researchers try to
make model learn information from a labeled dataset as a source to an unlabeled
dataset. Whereas purely unsupervised training is less used. In this paper, we
aim to solve both problems at the same time. We design a novel unsupervised
model, Sync-Person-Cloud ReID, to solve the unsupervised clothing change person
ReID problem. We developer a purely unsupervised clothing change person ReID
pipeline with person sync augmentation operation and same person feature
restriction. The person sync augmentation is to supply additional same person
resources. These same person's resources can be used as part supervised input
by same person feature restriction. The extensive experiments on clothing
change ReID datasets show the out-performance of our methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">fastMRI+: Clinical Pathology Annotations for Knee and Brain Fully Sampled Multi-Coil MRI Data. (arXiv:2109.03812v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03812">
<div class="article-summary-box-inner">
<span><p>Improving speed and image quality of Magnetic Resonance Imaging (MRI) via
novel reconstruction approaches remains one of the highest impact applications
for deep learning in medical imaging. The fastMRI dataset, unique in that it
contains large volumes of raw MRI data, has enabled significant advances in
accelerating MRI using deep learning-based reconstruction methods. While the
impact of the fastMRI dataset on the field of medical imaging is unquestioned,
the dataset currently lacks clinical expert pathology annotations, critical to
addressing clinically relevant reconstruction frameworks and exploring
important questions regarding rendering of specific pathology using such novel
approaches. This work introduces fastMRI+, which consists of 16154
subspecialist expert bounding box annotations and 13 study-level labels for 22
different pathology categories on the fastMRI knee dataset, and 7570
subspecialist expert bounding box annotations and 643 study-level labels for 30
different pathology categories for the fastMRI brain dataset. The fastMRI+
dataset is open access and aims to support further research and advancement of
medical imaging in MRI reconstruction and beyond.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Resolving gas bubbles ascending in liquid metal from low-SNR neutron radiography images. (arXiv:2109.04883v2 [physics.flu-dyn] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04883">
<div class="article-summary-box-inner">
<span><p>We demonstrate a new image processing methodology for resolving gas bubbles
travelling through liquid metal from dynamic neutron radiography images with
intrinsically low signal-to-noise ratio. Image pre-processing, denoising and
bubble segmentation are described in detail, with practical recommendations.
Experimental validation is presented - stationary and moving reference bodies
with neutron-transparent cavities are radiographed with imaging conditions
similar to the cases with bubbles in liquid metal. The new methods are applied
to our experimental data from previous and recent imaging campaigns, and the
performance of the methods proposed in this paper is compared against our
previously developed methods. Significant improvements are observed as well as
the capacity to reliably extract physically meaningful information from
measurements performed under highly adverse imaging conditions. The showcased
image processing solution and separate elements thereof are readily extendable
beyond the present application, and have been made open-source.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A semi-supervised self-training method to develop assistive intelligence for segmenting multiclass bridge elements from inspection videos. (arXiv:2109.05078v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05078">
<div class="article-summary-box-inner">
<span><p>Bridge inspection is an important step in preserving and rehabilitating
transportation infrastructure for extending their service lives. The
advancement of mobile robotic technology allows the rapid collection of a large
amount of inspection video data. However, the data are mainly images of complex
scenes, wherein a bridge of various structural elements mix with a cluttered
background. Assisting bridge inspectors in extracting structural elements of
bridges from the big complex video data, and sorting them out by classes, will
prepare inspectors for the element-wise inspection to determine the condition
of bridges. This paper is motivated to develop an assistive intelligence model
for segmenting multiclass bridge elements from inspection videos captured by an
aerial inspection platform. With a small initial training dataset labeled by
inspectors, a Mask Region-based Convolutional Neural Network (Mask R-CNN)
pre-trained on a large public dataset was transferred to the new task of
multiclass bridge element segmentation. Besides, the temporal coherence
analysis attempts to recover false negatives and identify the weakness that the
neural network can learn to improve. Furthermore, a semi-supervised
self-training (S$^3$T) method was developed to engage experienced inspectors in
refining the network iteratively. Quantitative and qualitative results from
evaluating the developed deep neural network demonstrate that the proposed
method can utilize a small amount of time and guidance from experienced
inspectors (3.58 hours for labeling 66 images) to build the network of
excellent performance (91.8% precision, 93.6% recall, and 92.7% f1-score).
Importantly, the paper illustrates an approach to leveraging the domain
knowledge and experiences of bridge professionals into computational
intelligence models to efficiently adapt the models to varied bridges in the
National Bridge Inventory.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Re-parameterization Residual Attention Network For Nonhomogeneous Image Dehazing. (arXiv:2109.05479v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05479">
<div class="article-summary-box-inner">
<span><p>This paper proposes an end-to-end Efficient Re-parameterizationResidual
Attention Network(ERRA-Net) to directly restore the nonhomogeneous hazy image.
The contribution of this paper mainly has the following three aspects: 1) A
novel Multi-branch Attention (MA) block. The spatial attention mechanism better
reconstructs high-frequency features, and the channel attention mechanism
treats the features of different channels differently. Multi-branch structure
dramatically improves the representation ability of the model and can be
changed into a single path structure after re-parameterization to speed up the
process of inference. Local Residual Connection allows the low-frequency
information in the nonhomogeneous area to pass through the block without
processing so that the block can focus on detailed features. 2) A lightweight
network structure. We use cascaded MA blocks to extract high-frequency features
step by step, and the Multi-layer attention fusion tail combines the shallow
and deep features of the model to get the residual of the clean image finally.
3)We propose two novel loss functions to help reconstruct the hazy image
ColorAttenuation loss and Laplace Pyramid loss. ERRA-Net has an impressive
speed, processing 1200x1600 HD quality images with an average runtime of 166.11
fps. Extensive evaluations demonstrate that ERSANet performs favorably against
the SOTA approaches on the real-world hazy images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatial-Separated Curve Rendering Network for Efficient and High-Resolution Image Harmonization. (arXiv:2109.05750v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05750">
<div class="article-summary-box-inner">
<span><p>Image harmonization aims to modify the color of the composited region with
respect to the specific background. Previous works model this task as a
pixel-wise image-to-image translation using UNet family structures. However,
the model size and computational cost limit the performability of their models
on edge devices and higher-resolution images. To this end, we propose a novel
spatial-separated curve rendering network (S$^2$CRNet) for efficient and
high-resolution image harmonization for the first time. In S$^2$CRNet, we
firstly extract the spatial-separated embeddings from the thumbnails of the
masked foreground and background individually. Then, we design a curve
rendering module (CRM), which learns and combines the spatial-specific
knowledge using linear layers to generate the parameters of the pixel-wise
curve mapping in the foreground region. Finally, we directly render the
original high-resolution images using the learned color curve. Besides, we also
make two extensions of the proposed framework via the Cascaded-CRM and
Semantic-CRM for cascaded refinement and semantic guidance, respectively.
Experiments show that the proposed method reduces more than 90% parameters
compared with previous methods but still achieves the state-of-the-art
performance on both synthesized iHarmony4 and real-world DIH test set.
Moreover, our method can work smoothly on higher resolution images in real-time
which is more than 10$\times$ faster than the existing methods. The code and
pre-trained models will be made available and released at
https://github.com/stefanLeong/S2CRNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Language Models Encode Perceptual Structure Without Grounding? A Case Study in Color. (arXiv:2109.06129v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06129">
<div class="article-summary-box-inner">
<span><p>Pretrained language models have been shown to encode relational information,
such as the relations between entities or concepts in knowledge-bases --
(Paris, Capital, France). However, simple relations of this type can often be
recovered heuristically and the extent to which models implicitly reflect
topological structure that is grounded in world, such as perceptual structure,
is unknown. To explore this question, we conduct a thorough case study on
color. Namely, we employ a dataset of monolexemic color terms and color chips
represented in CIELAB, a color space with a perceptually meaningful distance
metric.
</p>
<p>Using two methods of evaluating the structural alignment of colors in this
space with text-derived color term representations, we find significant
correspondence. Analyzing the differences in alignment across the color
spectrum, we find that warmer colors are, on average, better aligned to the
perceptual color space than cooler ones, suggesting an intriguing connection to
findings from recent work on efficient communication in color naming. Further
analysis suggests that differences in alignment are, in part, mediated by
collocationality and differences in syntactic usage, posing questions as to the
relationship between color perception and usage and context.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-09-15 23:02:29.399764435 UTC">2021-09-15 23:02:29 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>