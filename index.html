<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-05-26T01:30:00Z">05-26</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Garden-Path Traversal within GPT-2. (arXiv:2205.12302v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12302">
<div class="article-summary-box-inner">
<span><p>In recent years, massive language models consisting exclusively of
transformer decoders, led by the GPT-x family, have become increasingly
popular. While studies have examined the behavior of these models, they tend to
only focus on the output of the language model, avoiding analyzing their
internal states despite such analyses being popular tools used within BERTology
to study transformer encoders. We present a collection of methods for analyzing
GPT-2's hidden states, and use the model's navigation of garden path sentences
as a case study to demonstrate the utility of studying this model's behavior
beyond its output alone. To support this analysis, we introduce a novel dataset
consisting of 3 different types of garden path sentences, along with scripts to
manipulate them. We find that measuring Manhattan distances and cosine
similarities between hidden states shows that GPT-2 navigates these sentences
more intuitively than conventional methods that predict from the model's output
alone.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive multilingual speech recognition with pretrained models. (arXiv:2205.12304v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12304">
<div class="article-summary-box-inner">
<span><p>Multilingual speech recognition with supervised learning has achieved great
results as reflected in recent research. With the development of pretraining
methods on audio and text data, it is imperative to transfer the knowledge from
unsupervised multilingual models to facilitate recognition, especially in many
languages with limited data. Our work investigated the effectiveness of using
two pretrained models for two modalities: wav2vec 2.0 for audio and MBART50 for
text, together with the adaptive weight techniques to massively improve the
recognition quality on the public datasets containing CommonVoice and Europarl.
Overall, we noticed an 44% improvement over purely supervised learning, and
more importantly, each technique provides a different reinforcement in
different languages. We also explore other possibilities to potentially obtain
the best model by slightly adding either depth or relative attention to the
architecture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structured Prompt Tuning. (arXiv:2205.12309v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12309">
<div class="article-summary-box-inner">
<span><p>We propose structured prompt tuning, a simple and effective method to improve
prompt tuning. Instead of prepending a sequence of tunable embeddings to the
input, we generate the soft prompt embeddings through a hypernetwork. Our
approach subsumes the standard prompt tuning, allows more flexibility in model
design and can be applied to both single-task and multi-task training settings.
Empirically, structured prompt tuning shows a gain of +1.2$~1.5 points on the
GLUE benchmark and is less sensitive to the change of learning rate, compared
to standard prompt tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scoring Coreference Chains with Split-Antecedent Anaphors. (arXiv:2205.12323v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12323">
<div class="article-summary-box-inner">
<span><p>Anaphoric reference is an aspect of language interpretation covering a
variety of types of interpretation beyond the simple case of identity reference
to entities introduced via nominal expressions covered by the traditional
coreference task in its most recent incarnation in ONTONOTES and similar
datasets. One of these cases that go beyond simple coreference is anaphoric
reference to entities that must be added to the discourse model via
accommodation, and in particular split-antecedent references to entities
constructed out of other entities, as in split-antecedent plurals and in some
cases of discourse deixis. Although this type of anaphoric reference is now
annotated in many datasets, systems interpreting such references cannot be
evaluated using the Reference coreference scorer Pradhan et al. (2014). As part
of the work towards a new scorer for anaphoric reference able to evaluate all
aspects of anaphoric interpretation in the coverage of the Universal Anaphora
initiative, we propose in this paper a solution to the technical problem of
generalizing existing metrics for identity anaphora so that they can also be
used to score cases of split-antecedents. This is the first such proposal in
the literature on anaphora or coreference, and has been successfully used to
score both split-antecedent plural references and discourse deixis in the
recent CODI/CRAC anaphora resolution in dialogue shared tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilevel sentiment analysis in arabic. (arXiv:2205.12328v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12328">
<div class="article-summary-box-inner">
<span><p>In this study, we aimed to improve the performance results of Arabic
sentiment analysis. This can be achieved by investigating the most successful
machine learning method and the most useful feature vector to classify
sentiments in both term and document levels into two (positive or negative)
categories. Moreover, specification of one polarity degree for the term that
has more than one is investigated. Also to handle the negations and
intensifications, some rules are developed. According to the obtained results,
Artificial Neural Network classifier is nominated as the best classifier in
both term and document level sentiment analysis (SA) for Arabic Language.
Furthermore, the average F-score achieved in the term level SA for both
positive and negative testing classes is 0.92. In the document level SA, the
average F-score for positive testing classes is 0.94, while for negative
classes is 0.93.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Certified Robustness Against Natural Language Attacks by Causal Intervention. (arXiv:2205.12331v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12331">
<div class="article-summary-box-inner">
<span><p>Deep learning models have achieved great success in many fields, yet they are
vulnerable to adversarial examples. This paper follows a causal perspective to
look into the adversarial vulnerability and proposes Causal Intervention by
Semantic Smoothing (CISS), a novel framework towards robustness against natural
language attacks. Instead of merely fitting observational data, CISS learns
causal effects p(y|do(x)) by smoothing in the latent semantic space to make
robust predictions, which scales to deep architectures and avoids tedious
construction of noise customized for specific attacks. CISS is provably robust
against word substitution attacks, as well as empirically robust even when
perturbations are strengthened by unknown attack algorithms. For example, on
YELP, CISS surpasses the runner-up by 6.7% in terms of certified robustness
against word substitutions, and achieves 79.4% empirical robustness when
syntactic attacks are integrated.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">K-12BERT: BERT for K-12 education. (arXiv:2205.12335v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12335">
<div class="article-summary-box-inner">
<span><p>Online education platforms are powered by various NLP pipelines, which
utilize models like BERT to aid in content curation. Since the inception of the
pre-trained language models like BERT, there have also been many efforts toward
adapting these pre-trained models to specific domains. However, there has not
been a model specifically adapted for the education domain (particularly K-12)
across subjects to the best of our knowledge. In this work, we propose to train
a language model on a corpus of data curated by us across multiple subjects
from various sources for K-12 education. We also evaluate our model, K12-BERT,
on downstream tasks like hierarchical taxonomy tagging.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Medical Scientific Table-to-Text Generation with Human-in-the-Loop under the Data Sparsity Constraint. (arXiv:2205.12368v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12368">
<div class="article-summary-box-inner">
<span><p>Structured (tabular) data in the preclinical and clinical domains contains
valuable information about individuals and an efficient table-to-text
summarization system can drastically reduce manual efforts to condense this
data into reports. However, in practice, the problem is heavily impeded by the
data paucity, data sparsity and inability of the state-of-the-art natural
language generation models (including T5, PEGASUS and GPT-Neo) to produce
accurate and reliable outputs. In this paper, we propose a novel table-to-text
approach and tackle these problems with a novel two-step architecture which is
enhanced by auto-correction, copy mechanism and synthetic data augmentation.
The study shows that the proposed approach selects salient biomedical entities
and values from structured data with improved precision (up to 0.13 absolute
increase) of copying the tabular values to generate coherent and accurate text
for assay validation reports and toxicology reports. Moreover, we also
demonstrate a light-weight adaptation of the proposed system to new datasets by
fine-tuning with as little as 40\% training examples. The outputs of our model
are validated by human experts in the Human-in-the-Loop scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Model Editing Processes. (arXiv:2205.12374v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12374">
<div class="article-summary-box-inner">
<span><p>Most existing sequence generation models produce outputs in one pass, usually
left-to-right. However, this is in contrast with a more natural approach that
humans use in generating content; iterative refinement and editing. Recent work
has introduced edit-based models for various tasks (such as neural machine
translation and text style transfer), but these generally model a single edit
step. In this work, we propose modeling editing processes, modeling the whole
process of iteratively generating sequences. We form a conceptual framework to
describe the likelihood of multi-step edits, and describe neural models that
can learn a generative model of sequences based on these multistep edits. We
introduce baseline results and metrics on this task, finding that modeling
editing processes improves performance on a variety of axes on both our
proposed task and related downstream tasks compared to previous single-step
models of edits.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VoynaSlov: A Data Set of Russian Social Media Activity during the 2022 Ukraine-Russia War. (arXiv:2205.12382v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12382">
<div class="article-summary-box-inner">
<span><p>In this report, we describe a new data set called VoynaSlov which contains
21M+ Russian-language social media activities (i.e. tweets, posts, comments)
made by Russian media outlets and by the general public during the time of war
between Ukraine and Russia. We scraped the data from two major platforms that
are widely used in Russia: Twitter and VKontakte (VK), a Russian social media
platform based in Saint Petersburg commonly referred to as "Russian Facebook".
We provide descriptions of our data collection process and data statistics that
compare state-affiliated and independent Russian media, and also the two
platforms, VK and Twitter. The main differences that distinguish our data from
previously released data related to the ongoing war are its focus on Russian
media and consideration of state-affiliation as well as the inclusion of data
from VK, which is more suitable than Twitter for understanding Russian public
sentiment considering its wide use within Russia. We hope our data set can
facilitate future research on information warfare and ultimately enable the
reduction and prevention of disinformation and opinion manipulation campaigns.
The data set is available at https://github.com/chan0park/VoynaSlov and will be
regularly updated as we continuously collect more data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PLAtE: A Large-scale Dataset for List Page Web Extraction. (arXiv:2205.12386v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12386">
<div class="article-summary-box-inner">
<span><p>Recently, neural models have been leveraged to significantly improve the
performance of information extraction from semi-structured websites. However, a
barrier for continued progress is the small number of datasets large enough to
train these models. In this work, we introduce the PLAtE (Pages of Lists
Attribute Extraction) dataset as a challenging new web extraction task. PLAtE
focuses on shopping data, specifically extractions from product review pages
with multiple items. PLAtE encompasses both the tasks of: (1) finding
product-list segmentation boundaries and (2) extracting attributes for each
product. PLAtE is composed of 53, 905 items from 6, 810 pages, making it the
first large-scale list page web extraction dataset. We construct PLAtE by
collecting list pages from Common Crawl, then annotating them on Mechanical
Turk. Quantitative and qualitative analyses are performed to demonstrate PLAtE
has high-quality annotations. We establish strong baseline performance on PLAtE
with a SOTA model achieving an F1-score of 0.750 for attribute classification
and 0.915 for segmentation, indicating opportunities for future research
innovations in web extraction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toxicity Detection with Generative Prompt-based Inference. (arXiv:2205.12390v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12390">
<div class="article-summary-box-inner">
<span><p>Due to the subtleness, implicity, and different possible interpretations
perceived by different people, detecting undesirable content from text is a
nuanced difficulty. It is a long-known risk that language models (LMs), once
trained on corpus containing undesirable content, have the power to manifest
biases and toxicity. However, recent studies imply that, as a remedy, LMs are
also capable of identifying toxic content without additional fine-tuning.
Prompt-methods have been shown to effectively harvest this surprising
self-diagnosing capability. However, existing prompt-based methods usually
specify an instruction to a language model in a discriminative way. In this
work, we explore the generative variant of zero-shot prompt-based toxicity
detection with comprehensive trials on prompt engineering. We evaluate on three
datasets with toxicity labels annotated on social media posts. Our analysis
highlights the strengths of our generative classification approach both
quantitatively and qualitatively. Interesting aspects of self-diagnosis and its
ethical implications are discussed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward Understanding Bias Correlations for Mitigation in NLP. (arXiv:2205.12391v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12391">
<div class="article-summary-box-inner">
<span><p>Natural Language Processing (NLP) models have been found discriminative
against groups of different social identities such as gender and race. With the
negative consequences of these undesired biases, researchers have responded
with unprecedented effort and proposed promising approaches for bias
mitigation. In spite of considerable practical importance, current algorithmic
fairness literature lacks an in-depth understanding of the relations between
different forms of biases. Social bias is complex by nature. Numerous studies
in social psychology identify the "generalized prejudice", i.e., generalized
devaluing sentiments across different groups. For example, people who devalue
ethnic minorities are also likely to devalue women and gays. Therefore, this
work aims to provide a first systematic study toward understanding bias
correlations in mitigation. In particular, we examine bias mitigation in two
common NLP tasks -- toxicity detection and word embeddings -- on three social
identities, i.e., race, gender, and religion. Our findings suggest that biases
are correlated and present scenarios in which independent debiasing approaches
dominant in current literature may be insufficient. We further investigate
whether jointly mitigating correlated biases is more desired than independent
and individual debiasing. Lastly, we shed light on the inherent issue of
debiasing-accuracy trade-off in bias mitigation. This study serves to motivate
future research on joint bias mitigation that accounts for correlated biases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emergent Communication through Metropolis-Hastings Naming Game with Deep Generative Models. (arXiv:2205.12392v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12392">
<div class="article-summary-box-inner">
<span><p>Emergent communication, also known as symbol emergence, seeks to investigate
computational models that can better explain human language evolution and the
creation of symbol systems. This study aims to provide a new model for emergent
communication, which is based on a probabilistic generative model. We define
the Metropolis-Hastings (MH) naming game by generalizing a model proposed by
Hagiwara et al. \cite{hagiwara2019symbol}. The MH naming game is a sort of MH
algorithm for an integrative probabilistic generative model that combines two
agents playing the naming game. From this viewpoint, symbol emergence is
regarded as decentralized Bayesian inference, and semiotic communication is
regarded as inter-personal cross-modal inference. We also offer Inter-GMM+VAE,
a deep generative model for simulating emergent communication, in which two
agents create internal representations and categories and share signs (i.e.,
names of objects) from raw visual images observed from different viewpoints.
The model has been validated on MNIST and Fruits 360 datasets. Experiment
findings show that categories are formed from real images observed by agents,
and signs are correctly shared across agents by successfully utilizing both of
the agents' views via the MH naming game. Furthermore, it has been verified
that the visual images were recalled from the signs uttered by the agents.
Notably, emergent communication without supervision and reward feedback
improved the performance of unsupervised representation learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Continual-T0: Progressively Instructing 50+ Tasks to Language Models Without Forgetting. (arXiv:2205.12393v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12393">
<div class="article-summary-box-inner">
<span><p>Recent work on large language models relies on the intuition that most
natural language processing tasks can be described via natural language
instructions. Language models trained on these instructions show strong
zero-shot performance on several standard datasets. However, these models even
though impressive still perform poorly on a wide range of tasks outside of
their respective training and evaluation sets. To address this limitation, we
argue that a model should be able to keep extending its knowledge and
abilities, without forgetting previous skills. In spite of the limited success
of Continual Learning we show that Language Models can be continual learners.
We empirically investigate the reason for this success and conclude that
Continual Learning emerges from self-supervision pre-training. Our resulting
model Continual-T0 (CT0) is able to learn diverse new tasks, while still
maintaining good performance on previous tasks, spanning remarkably through 70
datasets in total. Finally, we show that CT0 is able to combine instructions in
ways it was never trained for, demonstrating some compositionality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MaskEval: Weighted MLM-Based Evaluation for Text Summarization and Simplification. (arXiv:2205.12394v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12394">
<div class="article-summary-box-inner">
<span><p>In text summarization and simplification, system outputs must be evaluated
along multiple dimensions such as relevance, factual consistency, fluency, and
grammaticality, and a wide range of possible outputs could be of high quality.
These properties make the development of an adaptable, reference-less
evaluation metric both necessary and challenging. We introduce MaskEval, a
reference-less metric for text summarization and simplification that operates
by performing masked language modeling (MLM) on the concatenation of the
candidate and the source texts. It features an attention-like weighting
mechanism to modulate the relative importance of each MLM step, which crucially
allows MaskEval to be adapted to evaluate different quality dimensions. We
demonstrate its effectiveness on English summarization and on multilingual text
simplification in terms of correlations with human judgments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recipe2Vec: Multi-modal Recipe Representation Learning with Graph Neural Networks. (arXiv:2205.12396v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12396">
<div class="article-summary-box-inner">
<span><p>Learning effective recipe representations is essential in food studies.
Unlike what has been developed for image-based recipe retrieval or learning
structural text embeddings, the combined effect of multi-modal information
(i.e., recipe images, text, and relation data) receives less attention. In this
paper, we formalize the problem of multi-modal recipe representation learning
to integrate the visual, textual, and relational information into recipe
embeddings. In particular, we first present Large-RG, a new recipe graph data
with over half a million nodes, making it the largest recipe graph to date. We
then propose Recipe2Vec, a novel graph neural network based recipe embedding
model to capture multi-modal information. Additionally, we introduce an
adversarial attack strategy to ensure stable learning and improve performance.
Finally, we design a joint objective function of node classification and
adversarial learning to optimize the model. Extensive experiments demonstrate
that Recipe2Vec outperforms state-of-the-art baselines on two classic food
study tasks, i.e., cuisine category classification and region prediction.
Dataset and codes are available at https://github.com/meettyj/Recipe2Vec.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse Mixers: Combining MoE and Mixing to build a more efficient BERT. (arXiv:2205.12399v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12399">
<div class="article-summary-box-inner">
<span><p>We combine the capacity of sparsely gated Mixture-of-Experts (MoE) with the
speed and stability of linear, mixing transformations to design the Sparse
Mixer encoder model. The Sparse Mixer slightly outperforms (&lt;1%) BERT on GLUE
and SuperGLUE, but more importantly trains 65% faster and runs inference 61%
faster. We also present a faster variant, prosaically named Fast Sparse Mixer,
that marginally underperforms (&lt;0.2%) BERT on SuperGLUE, but trains and runs
nearly twice as fast: 89% faster training and 98% faster inference. We justify
the design of these two models by carefully ablating through various mixing
mechanisms, MoE configurations and model hyperparameters. The Sparse Mixer
overcomes many of the latency and stability concerns of MoE models and offers
the prospect of serving sparse student models, without resorting to distilling
them to dense variants.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FLUTE: Figurative Language Understanding and Textual Explanations. (arXiv:2205.12404v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12404">
<div class="article-summary-box-inner">
<span><p>In spite of the prevalence of figurative language, transformer-based models
struggle to demonstrate an understanding of it. Meanwhile, even classical
natural language inference (NLI) tasks have been plagued by spurious
correlations and annotation artifacts. Datasets like eSNLI have been released,
allowing to probe whether language models are right for the right reasons. Yet
no such data exists for figurative language, making it harder to asses genuine
understanding of such expressions. In light of the above, we release FLUTE, a
dataset of 8,000 figurative NLI instances with explanations, spanning three
categories: Sarcasm, Simile, and Metaphor. We collect the data through the
Human-AI collaboration framework based on GPT-3, crowdworkers, and expert
annotation. We show how utilizing GPT-3 in conjunction with human experts can
aid in scaling up the creation of datasets even for such complex linguistic
phenomena as figurative language. Baseline performance of the T5 model shows
our dataset is a challenging testbed for figurative language understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AdaMix: Mixture-of-Adapter for Parameter-efficient Tuning of Large Language Models. (arXiv:2205.12410v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12410">
<div class="article-summary-box-inner">
<span><p>Fine-tuning large-scale pre-trained language models to downstream tasks
require updating hundreds of millions of parameters. This not only increases
the serving cost to store a large copy of the model weights for every task, but
also exhibits instability during few-shot task adaptation. Parameter-efficient
techniques have been developed that tune small trainable components (e.g.,
adapters) injected in the large model while keeping most of the model weights
frozen. The prevalent mechanism to increase adapter capacity is to increase the
bottleneck dimension which increases the adapter parameters. In this work, we
introduce a new mechanism to improve adapter capacity without increasing
parameters or computational cost by two key techniques. (i) We introduce
multiple shared adapter components in each layer of the Transformer
architecture. We leverage sparse learning via random routing to update the
adapter parameters (encoder is kept frozen) resulting in the same amount of
computational cost (FLOPs) as that of training a single adapter. (ii) We
propose a simple merging mechanism to average the weights of multiple adapter
components to collapse to a single adapter in each Transformer layer, thereby,
keeping the overall parameters also the same but with significant performance
improvement. We demonstrate these techniques to work well across multiple task
settings including fully supervised and few-shot Natural Language Understanding
tasks. By only tuning 0.23% of a pre-trained language model's parameters, our
model outperforms the full model fine-tuning performance and several competing
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Linear Connectivity Reveals Generalization Strategies. (arXiv:2205.12411v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12411">
<div class="article-summary-box-inner">
<span><p>It is widely accepted in the mode connectivity literature that when two
neural networks are trained similarly on the same data, they are connected by a
path through parameter space over which test set accuracy is maintained. Under
some circumstances, including transfer learning from pretrained models, these
paths are presumed to be linear. In contrast to existing results, we find that
among text classifiers (trained on MNLI, QQP, and CoLA), some pairs of
finetuned models have large barriers of increasing loss on the linear paths
between them. On each task, we find distinct clusters of models which are
linearly connected on the test loss surface, but are disconnected from models
outside the cluster -- models that occupy separate basins on the surface. By
measuring performance on specially-crafted diagnostic datasets, we find that
these clusters correspond to different generalization strategies: one cluster
behaves like a bag of words model under domain shift, while another cluster
uses syntactic heuristics. Our work demonstrates how the geometry of the loss
surface can guide models towards different heuristic functions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counterfactual Data Augmentation improves Factuality of Abstractive Summarization. (arXiv:2205.12416v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12416">
<div class="article-summary-box-inner">
<span><p>Abstractive summarization systems based on pretrained language models often
generate coherent but factually inconsistent sentences. In this paper, we
present a counterfactual data augmentation approach where we augment data with
perturbed summaries that increase the training data diversity. Specifically, we
present three augmentation approaches based on replacing (i) entities from
other and the same category and (ii) nouns with their corresponding WordNet
hypernyms. We show that augmenting the training data with our approach improves
the factual correctness of summaries without significantly affecting the ROUGE
score. We show that in two commonly used summarization datasets (CNN/Dailymail
and XSum), we improve the factual correctness by about 2.5 points on average
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Action Conditions from Instructional Manuals for Instruction Understanding. (arXiv:2205.12420v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12420">
<div class="article-summary-box-inner">
<span><p>The ability to infer pre- and postconditions of an action is vital for
comprehending complex instructions, and is essential for applications such as
autonomous instruction-guided agents and assistive AI that supports humans to
perform physical tasks. In this work, we propose a task dubbed action condition
inference, and collecting a high-quality, human annotated dataset of
preconditions and postconditions of actions in instructional manuals. We
propose a weakly supervised approach to automatically construct large-scale
training instances from online instructional manuals, and curate a densely
human-annotated and validated dataset to study how well the current NLP models
can infer action-condition dependencies in the instruction texts. We design two
types of models differ by whether contextualized and global information is
leveraged, as well as various combinations of heuristics to construct the weak
supervisions. Our experimental results show a &gt;20% F1-score improvement with
considering the entire instruction contexts and a &gt;6% F1-score benefit with the
proposed heuristics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Programming by Example with a Natural Language Prior. (arXiv:2205.12422v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12422">
<div class="article-summary-box-inner">
<span><p>We introduce APEL, a new framework that enables non-programmers to indirectly
annotate natural language utterances with executable meaning representations,
such as SQL programs. Based on a natural language utterance, we first run a
seed semantic parser to generate a prior over a list of candidate programs. To
obtain information about which candidate is correct, we synthesize an input on
which the more likely programs tend to produce different outputs, and ask an
annotator which output is appropriate for the utterance. Hence, the annotator
does not have to directly inspect the programs. To further reduce effort
required from annotators, we aim to synthesize simple input databases that
nonetheless have high information gain. With human annotators and Bayesian
inference to handle annotation errors, we outperform Codex's top-1 performance
(59%) and achieve the same accuracy as the original expert annotators (75%), by
soliciting answers for each utterance on only 2 databases with an average of 9
records each. In contrast, it would be impractical to solicit outputs on the
original 30K-record databases provided by SPIDER
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Understanding Label Regularization for Fine-tuning Pre-trained Language Models. (arXiv:2205.12428v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12428">
<div class="article-summary-box-inner">
<span><p>Knowledge Distillation (KD) is a prominent neural model compression technique
which heavily relies on teacher network predictions to guide the training of a
student model. Considering the ever-growing size of pre-trained language models
(PLMs), KD is often adopted in many NLP tasks involving PLMs. However, it is
evident that in KD, deploying the teacher network during training adds to the
memory and computational requirements of training. In the computer vision
literature, the necessity of the teacher network is put under scrutiny by
showing that KD is a label regularization technique that can be replaced with
lighter teacher-free variants such as the label-smoothing technique. However,
to the best of our knowledge, this issue is not investigated in NLP. Therefore,
this work concerns studying different label regularization techniques and
whether we actually need the teacher labels to fine-tune smaller PLM student
networks on downstream tasks. In this regard, we did a comprehensive set of
experiments on different PLMs such as BERT, RoBERTa, and GPT with more than 600
distinct trials and ran each configuration five times. This investigation led
to a surprising observation that KD and other label regularization techniques
do not play any meaningful role over regular fine-tuning when the student model
is pre-trained. We further explore this phenomenon in different settings of NLP
and computer vision tasks and demonstrate that pre-training itself acts as a
kind of regularization, and additional label regularization is unnecessary.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Natural Language Proofs with Verifier-Guided Search. (arXiv:2205.12443v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12443">
<div class="article-summary-box-inner">
<span><p>Deductive reasoning (drawing conclusions from assumptions) is a challenging
problem in NLP. In this work, we focus on proof generation: given a hypothesis
and a set of supporting facts in natural language, the model generates a proof
tree indicating how to deduce the hypothesis from supporting facts. Instead of
generating the entire proof in one shot, prior work has demonstrated the
promise of stepwise generation but achieved limited success on real-world data.
Existing stepwise methods struggle to generate proof steps that are both valid
and relevant. In this paper, we present a novel stepwise method NLProofS
(Natural Language Proof Search), which learns to generate relevant steps
conditioning on the hypothesis. At the core of our approach, we train an
independent verifier to check the validity of proof steps. Instead of
generating steps greedily, we search for proofs maximizing a global proof score
judged by the verifier. NLProofS achieves state-of-the-art performance on
EntailmentBank and RuleTaker. For example, it improves the percentage of
correctly predicted proofs from 20.9% to 33.3% in the distractor setting of
EntailmentBank. This is the first time stepwise methods have led to better
generation of challenging human-authored proofs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FLEURS: Few-shot Learning Evaluation of Universal Representations of Speech. (arXiv:2205.12446v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12446">
<div class="article-summary-box-inner">
<span><p>We introduce FLEURS, the Few-shot Learning Evaluation of Universal
Representations of Speech benchmark. FLEURS is an n-way parallel speech dataset
in 102 languages built on top of the machine translation FLoRes-101 benchmark,
with approximately 12 hours of speech supervision per language. FLEURS can be
used for a variety of speech tasks, including Automatic Speech Recognition
(ASR), Speech Language Identification (Speech LangID), Translation and
Retrieval. In this paper, we provide baselines for the tasks based on
multilingual pre-trained models like mSLAM. The goal of FLEURS is to enable
speech technology in more languages and catalyze research in low-resource
speech understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse*BERT: Sparse Models are Robust. (arXiv:2205.12452v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12452">
<div class="article-summary-box-inner">
<span><p>Large Language Models have become the core architecture upon which most
modern natural language processing (NLP) systems build. These models can
consistently deliver impressive accuracy and robustness across tasks and
domains, but their high computational overhead can make inference difficult and
expensive. To make the usage of these models less costly recent work has
explored leveraging structured and unstructured pruning, quantization, and
distillation as ways to improve inference speed and decrease size. This paper
studies how models pruned using Gradual Unstructured Magnitude Pruning can
transfer between domains and tasks. Our experimentation shows that models that
are pruned during pretraining using general domain masked language models can
transfer to novel domains and tasks without extensive hyperparameter
exploration or specialized approaches. We demonstrate that our general sparse
model Sparse*BERT can become SparseBioBERT simply by pretraining the compressed
architecture on unstructured biomedical text. Moreover, we show that
SparseBioBERT can match the quality of BioBERT with only 10\% of the
parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Know Where You're Going: Meta-Learning for Parameter-Efficient Fine-tuning. (arXiv:2205.12453v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12453">
<div class="article-summary-box-inner">
<span><p>A recent family of techniques, dubbed as lightweight fine-tuning methods,
facilitates parameter-efficient transfer learning by updating only a small set
of additional parameters while keeping the parameters of the pretrained
language model frozen. While proven to be an effective method, there are no
existing studies on if and how such knowledge of the downstream fine-tuning
approach should affect the pretraining stage. In this work, we show that taking
the ultimate choice of fine-tuning method into consideration boosts the
performance of parameter-efficient fine-tuning. By relying on
optimization-based meta-learning using MAML with certain modifications for our
distinct purpose, we prime the pretrained model specifically for
parameter-efficient fine-tuning, resulting in gains of up to 1.7 points on
cross-lingual NER fine-tuning. Our ablation settings and analyses further
reveal that the tweaks we introduce in MAML are crucial for the attained gains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Information Inconsistency in Multilingual Open-Domain Question Answering. (arXiv:2205.12456v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12456">
<div class="article-summary-box-inner">
<span><p>Retrieval based open-domain QA systems use retrieved documents and
answer-span selection over retrieved documents to find best-answer candidates.
We hypothesize that multilingual Question Answering (QA) systems are prone to
information inconsistency when it comes to documents written in different
languages, because these documents tend to provide a model with varying
information about the same topic. To understand the effects of the biased
availability of information and cultural influence, we analyze the behavior of
multilingual open-domain question answering models with a focus on retrieval
bias. We analyze if different retriever models present different passages given
the same question in different languages on TyDi QA and XOR-TyDi QA, two
multilingualQA datasets. We speculate that the content differences in documents
across languages might reflect cultural divergences and/or social biases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving CTC-based ASR Models with Gated Interlayer Collaboration. (arXiv:2205.12462v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12462">
<div class="article-summary-box-inner">
<span><p>For Automatic Speech Recognition (ASR), the CTC-based methods have become a
dominant paradigm due to its simple architecture and efficient
non-autoregressive inference manner. However, these methods without external
language models usually lack the capacity of modeling the conditional
dependencies and the textual interaction. In this work, we present a Gated
Interlayer Collaboration (GIC) mechanism which introduces the contextual
information into the models and relaxes the conditional independence assumption
of the CTC-based models. Specifically, we train the model with intermediate CTC
losses calculated by the interlayer outputs of the model, in which the
probability distributions of the intermediate layers naturally serve as soft
label sequences. The GIC block consists of an embedding layer to obtain the
textual embedding of the soft label at each position, and a gate unit to fuse
the textual embedding and the acoustic features. Experiments on AISHELL-1 and
AIDATATANG benchmarks show that the proposed method outperforms the recently
published CTC-based ASR models. Specifically, our method achieves CER of
4.0%/4.4% on AISHELL-1 dev/test sets and CER of 3.8%/4.4% on AIDATATANG
dev/test sets using CTC greedy search decoding without external language
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">R2D2: Robust Data-to-Text with Replacement Detection. (arXiv:2205.12467v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12467">
<div class="article-summary-box-inner">
<span><p>Unfaithful text generation is a common problem for text generation systems.
In the case of Data-to-Text (D2T) systems, the factuality of the generated text
is particularly crucial for any real-world applications. We introduce R2D2, a
training framework that addresses unfaithful Data-to-Text generation by
training a system both as a generator and a faithfulness discriminator with
additional replacement detection and unlikelihood learning tasks. To facilitate
such training, we propose two methods for sampling unfaithful sentences. We
argue that the poor entity retrieval capability of D2T systems is one of the
primary sources of unfaithfulness, so in addition to the existing metrics, we
further propose NER-based metrics to evaluate the fidelity of D2T generations.
Our experimental results show that R2D2 systems could effectively mitigate the
unfaithful text generation, and they achieve new state-of-the-art results on
FeTaQA, LogicNLG, and ToTTo, all with significant improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Logical Satisfiability of Counterfactuals for Faithful Explanations in NLI. (arXiv:2205.12469v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12469">
<div class="article-summary-box-inner">
<span><p>Evaluating an explanation's faithfulness is desired for many reasons such as
trust, interpretability and diagnosing the sources of model's errors. In this
work, which focuses on the NLI task, we introduce the methodology of
Faithfulness-through-Counterfactuals, which first generates a counterfactual
hypothesis based on the logical predicates expressed in the explanation, and
then evaluates if the model's prediction on the counterfactual is consistent
with that expressed logic (i.e. if the new formula is \textit{logically
satisfiable}). In contrast to existing approaches, this does not require any
explanations for training a separate verification model. We first validate the
efficacy of automatic counterfactual hypothesis generation, leveraging on the
few-shot priming paradigm. Next, we show that our proposed metric distinguishes
between human-model agreement and disagreement on new counterfactual input. In
addition, we conduct a sensitivity analysis to validate that our metric is
sensitive to unfaithful explanations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning a Better Initialization for Soft Prompts via Meta-Learning. (arXiv:2205.12471v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12471">
<div class="article-summary-box-inner">
<span><p>Prompt tuning (PT) is an effective approach to adapting pre-trained language
models to downstream tasks. Without a good initialization, prompt tuning
doesn't perform well under few-shot settings. So pre-trained prompt tuning
(PPT) is proposed to initialize prompts by leveraging pre-training data. We
propose MetaPT (Meta-learned Prompt Tuning) to further improve PPT's
initialization by considering latent structure within the pre-training data.
Specifically, we introduce the structure by first clustering pre-training data
into different auxiliary tasks with unsupervised methods. Then we use these
tasks to pre-train prompts with a meta-learning algorithm. Such a process can
make prompts learn a better initialization by discovering commonalities among
these auxiliary tasks. We evaluate our method on seven downstream tasks. Our
MetaPT achieves better and more stable performance than the state-of-the-art
method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low Resource Style Transfer via Domain Adaptive Meta Learning. (arXiv:2205.12475v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12475">
<div class="article-summary-box-inner">
<span><p>Text style transfer (TST) without parallel data has achieved some practical
success. However, most of the existing unsupervised text style transfer methods
suffer from (i) requiring massive amounts of non-parallel data to guide
transferring different text styles. (ii) colossal performance degradation when
fine-tuning the model in new domains. In this work, we propose DAML-ATM (Domain
Adaptive Meta-Learning with Adversarial Transfer Model), which consists of two
parts: DAML and ATM. DAML is a domain adaptive meta-learning approach to learn
general knowledge in multiple heterogeneous source domains, capable of adapting
to new unseen domains with a small amount of data. Moreover, we propose a new
unsupervised TST approach Adversarial Transfer Model (ATM), composed of a
sequence-to-sequence pre-trained language model and uses adversarial style
training for better content preservation and style transfer. Results on
multi-domain datasets demonstrate that our approach generalizes well on unseen
low-resource domains, achieving state-of-the-art results against ten strong
baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Locality in Abstractive Text Summarization. (arXiv:2205.12476v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12476">
<div class="article-summary-box-inner">
<span><p>Despite the successes of neural attention models for natural language
generation tasks, the quadratic memory complexity of the self-attention module
with respect to the input length hinders their applications in long text
summarization. Instead of designing more efficient attention modules, we
approach this problem by investigating if models with a restricted context can
have competitive performance compared with the memory-efficient attention
models that maintain a global context by treating the input as an entire
sequence. Our model is applied to individual pages, which contain parts of
inputs grouped by the principle of locality, during both encoding and decoding
stages. We empirically investigated three kinds of localities in text
summarization at different levels, ranging from sentences to documents. Our
experimental results show that our model can have better performance compared
with strong baseline models with efficient attention modules, and our analysis
provides further insights of our locality-aware modeling strategy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GisPy: A Tool for Measuring Gist Inference Score in Text. (arXiv:2205.12484v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12484">
<div class="article-summary-box-inner">
<span><p>Decision making theories such as Fuzzy-Trace Theory (FTT) suggest that
individuals tend to rely on gist, or bottom-line meaning, in the text when
making decisions. In this work, we delineate the process of developing GisPy,
an open-source tool in Python for measuring the Gist Inference Score (GIS) in
text. Evaluation of GisPy on documents in three benchmarks from the news and
scientific text domains demonstrates that scores generated by our tool
significantly distinguish low vs. high gist documents. Our tool is publicly
available to use at: https://github.com/phosseini/GisPy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conditional set generation using Seq2seq models. (arXiv:2205.12485v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12485">
<div class="article-summary-box-inner">
<span><p>Conditional set generation learns a mapping from an input sequence of tokens
to a set. Several NLP tasks, such as entity typing and dialogue emotion
tagging, are instances of set generation. Sequence-to-sequence~(Seq2seq) models
are a popular choice to model set generation, but they treat a set as a
sequence and do not fully leverage its key properties, namely order-invariance
and cardinality. We propose a novel algorithm for effectively sampling
informative orders over the combinatorial space of label orders. Further, we
jointly model the set cardinality and output by adding the set size as the
first element and taking advantage of the autoregressive factorization used by
Seq2seq models. Our method is a model-independent data augmentation approach
that endows any Seq2seq model with the signals of order-invariance and
cardinality. Training a Seq2seq model on this new augmented data~(without any
additional annotations) gets an average relative improvement of 20% for four
benchmarks datasets across models spanning from BART-base, T5-xxl, and GPT-3.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Factorizing Content and Budget Decisions in Abstractive Summarization of Long Documents by Sampling Summary Views. (arXiv:2205.12486v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12486">
<div class="article-summary-box-inner">
<span><p>We argue that disentangling content selection from the budget used to cover
salient content improves the performance and applicability of abstractive
summarizers. Our method, FactorSum, does this disentanglement by factorizing
summarization into two steps through an energy function: (1) generation of
abstractive summary views; (2) combination of these views into a final summary,
following a budget and content guidance. This guidance may come from different
sources, including from an advisor model such as BART or BigBird, or in oracle
mode -- from the reference. This factorization achieves significantly higher
ROUGE scores on multiple benchmarks for long document summarization, namely
PubMed, arXiv, and GovReport. Most notably, our model is effective for domain
adaptation. When trained only on PubMed samples, it achieves a 46.29 ROUGE-1
score on arXiv, which indicates a strong performance due to more flexible
budget adaptation and content selection less dependent on domain-specific
textual structure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Multimodal Fact-Checking and Explanation Generation: A Challenging Dataset and Models. (arXiv:2205.12487v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12487">
<div class="article-summary-box-inner">
<span><p>We propose the end-to-end multimodal fact-checking and explanation
generation, where the input is a claim and a large collection of web sources,
including articles, images, videos, and tweets, and the goal is to assess the
truthfulness of the claim by retrieving relevant evidence and predicting a
truthfulness label (i.e., support, refute and not enough information), and
generate a rationalization statement to explain the reasoning and ruling
process. To support this research, we construct Mocheg, a large-scale dataset
that consists of 21,184 claims where each claim is assigned with a truthfulness
label and ruling statement, with 58,523 evidence in the form of text and
images. To establish baseline performances on Mocheg, we experiment with
several state-of-the-art neural architectures on the three pipelined subtasks:
multimodal evidence retrieval, claim verification, and explanation generation,
and demonstrate the current state-of-the-art performance of end-to-end
multimodal fact-checking is still far from satisfying. To the best of our
knowledge, we are the first to build the benchmark dataset and solutions for
end-to-end multimodal fact-checking and justification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improve Event Extraction via Self-Training with Gradient Guidance. (arXiv:2205.12490v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12490">
<div class="article-summary-box-inner">
<span><p>Data scarcity and imbalance have been the main factors that hinder the
progress of event extraction (EE). In this work, we propose a self-training
with gradient guidance (STGG) framework which consists of (1) a base event
extraction model which is firstly trained on existing event annotations and
then applied to large-scale unlabeled corpora to predict new event mentions,
and (2) a scoring model that takes in each predicted event trigger and argument
as well as their path in the Abstract Meaning Representation (AMR) graph to
estimate a probability score indicating the correctness of the event
prediction. The new event predictions along with their correctness scores are
then used as pseudo labeled examples to improve the base event extraction model
while the magnitude and direction of its gradients are guided by the
correctness scores. Experimental results on three benchmark datasets, including
ACE05-E, ACE05-E+ and ERE-EN, demonstrate the effectiveness of the STGG
framework on event extraction task with up to 1.9 F-score improvement over the
base event extraction models. Our experimental analysis further shows that STGG
is a general framework as it can be applied to any base event extraction models
and improve their performance by leveraging broad unlabeled data, even when the
high-quality AMR graph annotations are not available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-grained Contrastive Learning for Relation Extraction. (arXiv:2205.12491v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12491">
<div class="article-summary-box-inner">
<span><p>Recent relation extraction (RE) works have shown encouraging improvements by
conducting contrastive learning on silver labels generated by distant
supervision before fine-tuning on gold labels. Existing methods typically
assume all these silver labels are accurate and therefore treat them equally in
contrastive learning; however, distant supervision is inevitably noisy -- some
silver labels are more reliable than others. In this paper, we first assess the
quality of silver labels via a simple and automatic approach we call "learning
order denoising," where we train a language model to learn these relations and
record the order of learned training instances. We show that learning order
largely corresponds to label accuracy -- early learned silver labels have, on
average, more accurate labels compared to later learned silver labels. We then
propose a novel fine-grained contrastive learning (FineCL) for RE, which
leverages this additional, fine-grained information about which silver labels
are and are not noisy to improve the quality of learned relationship
representations for RE. Experiments on many RE benchmarks show consistent,
significant performance gains of FineCL over state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ToKen: Task Decomposition and Knowledge Infusion for Few-Shot Hate Speech Detection. (arXiv:2205.12495v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12495">
<div class="article-summary-box-inner">
<span><p>Hate speech detection is complex; it relies on commonsense reasoning,
knowledge of stereotypes, and an understanding of social nuance that differs
from one culture to the next. It is also difficult to collect a large-scale
hate speech annotated dataset. In this work, we frame this problem as a
few-shot learning task, and show significant gains with decomposing the task
into its "constituent" parts. In addition, we see that infusing knowledge from
reasoning datasets (e.g. Atomic2020) improves the performance even further.
Moreover, we observe that the trained models generalize to out-of-distribution
datasets, showing the superiority of task decomposition and knowledge infusion
compared to previously used methods. Concretely, our method outperforms the
baseline by 17.83% absolute gain in the 16-shot case.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teaching Broad Reasoning Skills via Decomposition-Guided Contexts. (arXiv:2205.12496v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12496">
<div class="article-summary-box-inner">
<span><p>Question-answering datasets require a broad set of reasoning skills. We show
how to use question decompositions to teach language models these broad
reasoning skills in a robust fashion. Specifically, we use widely available
QDMR representations to programmatically create synthetic contexts for real
questions in six multihop reasoning datasets. These contexts are carefully
designed to avoid common reasoning shortcuts prevalent in real contexts that
prevent models from learning the right skills. This results in a pretraining
dataset, named TeaBReaC, containing 525K multihop questions (with associated
formal programs) covering about 900 reasoning patterns. We show that
pretraining standard language models (LMs) on TeaBReaC before fine-tuning them
on target datasets improves their performance by up to 13 EM points across 3
multihop QA datasets, with a 30 point gain on more complex questions. The
resulting models also demonstrate higher robustness, with a 6-11 point
improvement on two contrast sets. Furthermore, TeaBReaC pretraining
substantially improves model performance and robustness even when starting with
numeracy-aware LMs pretrained using recent methods (e.g., PReasM). Our work
thus shows how one can effectively use decomposition-guided contexts to
robustly teach multihop reasoning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Dialog Must Go On: Improving Visual Dialog via Generative Self-Training. (arXiv:2205.12502v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12502">
<div class="article-summary-box-inner">
<span><p>Visual dialog (VisDial) is a task of answering a sequence of questions
grounded in an image, using the dialog history as context. Prior work has
trained the dialog agents solely on VisDial data via supervised learning or
leveraged pre-training on related vision-and-language datasets. This paper
presents a semi-supervised learning approach for visually-grounded dialog,
called Generative Self-Training (GST), to leverage unlabeled images on the Web.
Specifically, GST first retrieves in-domain images through out-of-distribution
detection and generates synthetic dialogs regarding the images via multimodal
conditional text generation. GST then trains a dialog agent on the synthetic
and the original VisDial data. As a result, GST scales the amount of training
data up to an order of magnitude that of VisDial (1.2M to 12.9M QA data). For
robust training of the generated dialogs, we also propose perplexity-based data
selection and multimodal consistency regularization. Evaluation on VisDial v1.0
and v0.9 datasets shows that GST achieves new state-of-the-art results on both
datasets. We further observe strong performance gains in the low-data regime
(up to 9.35 absolute points on NDCG).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GENEVA: Pushing the Limit of Generalizability for Event Argument Extraction with 100+ Event Types. (arXiv:2205.12505v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12505">
<div class="article-summary-box-inner">
<span><p>Numerous events occur worldwide and are documented in the news, social media,
and various online platforms in raw text. Extracting useful and succinct
information about these events is crucial to various downstream applications.
Event Argument Extraction (EAE) deals with the task of extracting
event-specific information from natural language text. In order to cater to new
events and domains in a realistic low-data setting, there is a growing urgency
for EAE models to be generalizable. Consequentially, there is a necessity for
benchmarking setups to evaluate the generalizability of EAE models. But most
existing benchmarking datasets like ACE and ERE have limited coverage in terms
of events and cannot adequately evaluate the generalizability of EAE models. To
alleviate this issue, we introduce a new dataset GENEVA covering a diverse
range of 115 events and 187 argument roles. Using this dataset, we create four
benchmarking test suites to assess the model's generalization capability from
different perspectives. We benchmark various representative models on these
test suites and compare their generalizability relatively. Finally, we propose
a new model SCAD that outperforms the previous models and serves as a strong
benchmark for these test suites.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Memorization in NLP Fine-tuning Methods. (arXiv:2205.12506v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12506">
<div class="article-summary-box-inner">
<span><p>Large language models are shown to present privacy risks through memorization
of training data, and several recent works have studied such risks for the
pre-training phase. Little attention, however, has been given to the
fine-tuning phase and it is not well understood how different fine-tuning
methods (such as fine-tuning the full model, the model head, and adapter)
compare in terms of memorization risk. This presents increasing concern as the
"pre-train and fine-tune" paradigm proliferates. In this paper, we empirically
study memorization of fine-tuning methods using membership inference and
extraction attacks, and show that their susceptibility to attacks is very
different. We observe that fine-tuning the head of the model has the highest
susceptibility to attacks, whereas fine-tuning smaller adapters appears to be
less vulnerable to known extraction attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Calibration for Question Answering. (arXiv:2205.12507v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12507">
<div class="article-summary-box-inner">
<span><p>Model calibration aims to adjust (calibrate) models' confidence so that they
match expected accuracy. We argue that the traditional evaluation of
calibration (expected calibration error; ECE) does not reflect usefulness of
the model confidence. For example, after conventional temperature scaling,
confidence scores become similar for all predictions, which makes it hard for
users to distinguish correct predictions from wrong ones, even though it
achieves low ECE. Building on those observations, we propose a new calibration
metric, MacroCE, that better captures whether the model assigns low confidence
to wrong predictions and high confidence to correct predictions. We examine
various conventional calibration methods including temperature scaling,
feature-based classifier, neural answer reranking, and label smoothing, all of
which do not bring significant gains under our new MacroCE metric. Towards more
effective calibration, we propose a new calibration method based on the model's
prediction consistency along the training trajectory. This new method, which we
name as consistency calibration, shows promise for better calibration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Translation Robustness to Natural Asemantic Variation. (arXiv:2205.12514v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12514">
<div class="article-summary-box-inner">
<span><p>We introduce and formalize an under-studied linguistic phenomenon we call
Natural Asemantic Variation (NAV) and investigate it in the context of Machine
Translation (MT) robustness. Standard MT models are shown to be less robust to
rarer, nuanced language forms, and current robustness techniques do not account
for this kind of perturbation despite their prevalence in "real world" data.
Experiment results provide more insight into the nature of NAV and we
demonstrate strategies to improve performance on NAV. We also show that NAV
robustness can be transferred across languages and fine that synthetic
perturbations can achieve some but not all of the benefits of human-generated
NAV data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset. (arXiv:2205.12522v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12522">
<div class="article-summary-box-inner">
<span><p>Research in massively multilingual image captioning has been severely
hampered by a lack of high-quality evaluation datasets. In this paper we
present the Crossmodal-3600 dataset (XM3600 in short), a geographically diverse
set of 3600 images annotated with human-generated reference captions in 36
languages. The images were selected from across the world, covering regions
where the 36 languages are spoken, and annotated with captions that achieve
consistency in terms of style across all languages, while avoiding annotation
artifacts due to direct translation. We apply this benchmark to model selection
for massively multilingual image captioning models, and show superior
correlation results with human evaluations when using XM3600 as golden
references for automatic metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation. (arXiv:2205.12523v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12523">
<div class="article-summary-box-inner">
<span><p>Direct speech-to-speech translation (S2ST) systems leverage recent progress
in speech representation learning, where a sequence of discrete representations
(units) derived in a self-supervised manner, are predicted from the model and
passed to a vocoder for speech synthesis, still facing the following
challenges: 1) Acoustic multimodality: the discrete units derived from speech
with same content could be indeterministic due to the acoustic property (e.g.,
rhythm, pitch, and energy), which causes deterioration of translation accuracy;
2) high latency: current S2ST systems utilize autoregressive models which
predict each unit conditioned on the sequence previously generated, failing to
take full advantage of parallelism. In this work, we propose TranSpeech, a
speech-to-speech translation model with bilateral perturbation. To alleviate
the acoustic multimodal problem, we propose bilateral perturbation, which
consists of the style normalization and information enhancement stages, to
learn only the linguistic information from speech samples and generate more
deterministic representations. With reduced multimodality, we step forward and
become the first to establish a non-autoregressive S2ST technique, which
repeatedly masks and predicts unit choices and produces high-accuracy results
in just a few cycles. Experimental results on three language pairs demonstrate
the state-of-the-art results by up to 2.5 BLEU points over the best
publicly-available textless S2ST baseline. Moreover, TranSpeech shows a
significant improvement in inference latency, enabling speedup up to 21.4x than
autoregressive technique. Audio samples are available at
\url{https://TranSpeech.github.io/}
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Segmenting Numerical Substitution Ciphers. (arXiv:2205.12527v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12527">
<div class="article-summary-box-inner">
<span><p>Deciphering historical substitution ciphers is a challenging problem. Example
problems that have been previously studied include detecting cipher type,
detecting plaintext language, and acquiring the substitution key for segmented
ciphers. However, attacking unsegmented, space-free ciphers is still a
challenging task. Segmentation (i.e. finding substitution units) is the first
step towards cracking those ciphers. In this work, we propose the first
automatic methods to segment those ciphers using Byte Pair Encoding (BPE) and
unigram language models. Our methods achieve an average segmentation error of
2\% on 100 randomly-generated monoalphabetic ciphers and 27\% on 3 real
homophonic ciphers. We also propose a method for solving non-deterministic
ciphers with existing keys using a lattice and a pretrained language model. Our
method leads to the full solution of the IA cipher; a real historical cipher
that has not been fully solved until this work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LOPS: Learning Order Inspired Pseudo-Label Selection for Weakly Supervised Text Classification. (arXiv:2205.12528v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12528">
<div class="article-summary-box-inner">
<span><p>Weakly supervised text classification methods typically train a deep neural
classifier based on pseudo-labels. The quality of pseudo-labels is crucial to
final performance but they are inevitably noisy due to their heuristic nature,
so selecting the correct ones has a huge potential for performance boost. One
straightforward solution is to select samples based on the softmax probability
scores in the neural classifier corresponding to their pseudo-labels. However,
we show through our experiments that such solutions are ineffective and
unstable due to the erroneously high-confidence predictions from poorly
calibrated models. Recent studies on the memorization effects of deep neural
models suggest that these models first memorize training samples with clean
labels and then those with noisy labels. Inspired by this observation, we
propose a novel pseudo-label selection method LOPS that takes learning order of
samples into consideration. We hypothesize that the learning order reflects the
probability of wrong annotation in terms of ranking, and therefore, propose to
select the samples that are learnt earlier. LOPS can be viewed as a strong
performance-boost plug-in to most of existing weakly-supervised text
classification methods, as confirmed in extensive experiments on four
real-world datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is a Question Decomposition Unit All We Need?. (arXiv:2205.12538v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12538">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LMs) have achieved state-of-the-art performance on
many Natural Language Processing (NLP) benchmarks. With the growing number of
new benchmarks, we build bigger and more complex LMs. However, building new LMs
may not be an ideal option owing to the cost, time and environmental impact
associated with it. We explore an alternative route: can we modify data by
expressing it in terms of the model's strengths, so that a question becomes
easier for models to answer? We investigate if humans can decompose a hard
question into a set of simpler questions that are relatively easier for models
to solve. We analyze a range of datasets involving various forms of reasoning
and find that it is indeed possible to significantly improve model performance
(24% for GPT3 and 29% for RoBERTa-SQuAD along with a symbolic calculator) via
decomposition. Our approach provides a viable option to involve people in NLP
research in a meaningful way. Our findings indicate that Human-in-the-loop
Question Decomposition (HQD) can potentially provide an alternate path to
building large LMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ER-TEST: Evaluating Explanation Regularization Methods for NLP Models. (arXiv:2205.12542v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12542">
<div class="article-summary-box-inner">
<span><p>Neural language models' (NLMs') reasoning processes are notoriously hard to
explain. Recently, there has been much progress in automatically generating
machine rationales of NLM behavior, but less in utilizing the rationales to
improve NLM behavior. For the latter, explanation regularization (ER) aims to
improve NLM generalization by pushing the machine rationales to align with
human rationales. Whereas prior works primarily evaluate such ER models via
in-distribution (ID) generalization, ER's impact on out-of-distribution (OOD)
is largely underexplored. Plus, little is understood about how ER model
performance is affected by the choice of ER criteria or by the number/choice of
training instances with human rationales. In light of this, we propose ER-TEST,
a protocol for evaluating ER models' OOD generalization along three dimensions:
(1) unseen datasets, (2) contrast set tests, and (3) functional tests. Using
ER-TEST, we study three key questions: (A) Which ER criteria are most effective
for the given OOD setting? (B) How is ER affected by the number/choice of
training instances with human rationales? (C) Is ER effective with distantly
supervised human rationales? ER-TEST enables comprehensive analysis of these
questions by considering a diverse range of tasks and datasets. Through
ER-TEST, we show that ER has little impact on ID performance, but can yield
large gains on OOD performance w.r.t. (1)-(3). Also, we find that the best ER
criterion is task-dependent, while ER can improve OOD performance even with
limited and distantly-supervised human rationales.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RLPrompt: Optimizing Discrete Text Prompts With Reinforcement Learning. (arXiv:2205.12548v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12548">
<div class="article-summary-box-inner">
<span><p>Prompting has shown impressive success in enabling large pretrained language
models (LMs) to perform diverse NLP tasks, especially when only few downstream
data are available. Automatically finding the optimal prompt for each task,
however, is challenging. Most existing work resorts to tuning soft prompt
(e.g., embeddings) which falls short of interpretability, reusability across
LMs, and applicability when gradients are not accessible. Discrete prompt, on
the other hand, is difficult to optimize, and is often created by "enumeration
(e.g., paraphrasing)-then-selection" heuristics that do not explore the prompt
space systematically. This paper proposes RLPrompt, an efficient discrete
prompt optimization approach with reinforcement learning (RL). RLPrompt
formulates a parameter-efficient policy network that generates the desired
discrete prompt after training with reward. To overcome the complexity and
stochasticity of reward signals by the large LM environment, we incorporate
effective reward stabilization that substantially enhances the training
efficiency. RLPrompt is flexibly applicable to different types of LMs, such as
masked (e.g., BERT) and left-to-right models (e.g., GPTs), for both
classification and generation tasks. Experiments on few-shot classification and
unsupervised text style transfer show superior performance over a wide range of
existing finetuning or prompting methods. Interestingly, the resulting
optimized prompts are often ungrammatical gibberish text; and surprisingly,
those gibberish prompts are transferrable between different LMs to retain
significant performance, indicating LM prompting may not follow human language
patterns.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Helpfulness and Fairness of Task-Oriented Dialogue Systems. (arXiv:2205.12554v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12554">
<div class="article-summary-box-inner">
<span><p>Task-oriented dialogue systems aim to answer questions from users and provide
immediate help. Therefore, how humans perceive their helpfulness is important.
However, neither the human-perceived helpfulness of task-oriented dialogue
systems nor its fairness implication has been studied yet. In this paper, we
define a dialogue response as helpful if it is relevant &amp; coherent, useful, and
informative to a query and study computational measurements of helpfulness.
Then, we propose utilizing the helpfulness level of different groups to gauge
the fairness of a dialogue system. To study this, we collect human annotations
for the helpfulness of dialogue responses and build a classifier that can
automatically determine the helpfulness of a response. We design experiments
under 3 information-seeking scenarios and collect instances for each from
Wikipedia. With collected instances, we use carefully-constructed questions to
query the state-of-the-art dialogue systems. Through analysis, we find that
dialogue systems tend to be more helpful for highly-developed countries than
less-developed countries, uncovering a fairness issue underlying these dialogue
systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Constrained Sampling from Language Models via Langevin Dynamics in Embedding Spaces. (arXiv:2205.12558v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12558">
<div class="article-summary-box-inner">
<span><p>Large pre-trained language models are well-established for their ability to
generate text seemingly indistinguishable from humans. In this work, we study
the problem of constrained sampling from such language models. That is,
generating text that satisfies user-defined constraints. Typical decoding
strategies which generate samples left-to-right are not always conducive to
imposing such constraints globally. Instead, we propose MuCoLa -- a sampling
procedure that combines the log-likelihood of the language model with arbitrary
differentiable constraints into a single energy function; and generates samples
by initializing the entire output sequence with noise and following a Markov
chain defined by Langevin Dynamics using the gradients of this energy. We
evaluate our approach on different text generation tasks with soft and hard
constraints as well as their combinations with competitive results for toxicity
avoidance, sentiment control, and keyword-guided generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EDIN: An End-to-end Benchmark and Pipeline for Unknown Entity Discovery and Indexing. (arXiv:2205.12570v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12570">
<div class="article-summary-box-inner">
<span><p>Existing work on Entity Linking mostly assumes that the reference knowledge
base is complete, and therefore all mentions can be linked. In practice this is
hardly ever the case, as knowledge bases are incomplete and because novel
concepts arise constantly. This paper created the Unknown Entity Discovery and
Indexing (EDIN) benchmark where unknown entities, that is entities without a
description in the knowledge base and labeled mentions, have to be integrated
into an existing entity linking system. By contrasting EDIN with zero-shot
entity linking, we provide insight on the additional challenges it poses.
Building on dense-retrieval based entity linking, we introduce the end-to-end
EDIN pipeline that detects, clusters, and indexes mentions of unknown entities
in context. Experiments show that indexing a single embedding per entity
unifying the information of multiple mentions works better than indexing
mentions independently.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Simple and Unified Tagging Model with Priming for Relational Structure Predictions. (arXiv:2205.12585v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12585">
<div class="article-summary-box-inner">
<span><p>Relational structure extraction covers a wide range of tasks and plays an
important role in natural language processing. Recently, many approaches tend
to design sophisticated graphical models to capture the complex relations
between objects that are described in a sentence. In this work, we demonstrate
that simple tagging models can surprisingly achieve competitive performances
with a small trick -- priming. Tagging models with priming append information
about the operated objects to the input sequence of pretrained language model.
Making use of the contextualized nature of pretrained language model, the
priming approach help the contextualized representation of the sentence better
embed the information about the operated objects, hence, becomes more suitable
for addressing relational structure extraction. We conduct extensive
experiments on three different tasks that span ten datasets across five
different languages, and show that our model is a general and effective model,
despite its simplicity. We further carry out comprehensive analysis to
understand our model and propose an efficient approximation to our method,
which can perform almost the same performance but with faster inference speed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Perturbation Augmentation for Fairer NLP. (arXiv:2205.12586v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12586">
<div class="article-summary-box-inner">
<span><p>Unwanted and often harmful social biases are becoming ever more salient in
NLP research, affecting both models and datasets. In this work, we ask: does
training on demographically perturbed data lead to more fair language models?
We collect a large dataset of human annotated text perturbations and train an
automatic perturber on it, which we show to outperform heuristic alternatives.
We find: (i) Language models (LMs) pre-trained on demographically perturbed
corpora are more fair, at least, according to our current best metrics for
measuring model fairness, and (ii) LMs finetuned on perturbed GLUE datasets
exhibit less demographic bias on downstream tasks. We find that improved
fairness does not come at the expense of accuracy. Although our findings appear
promising, there are still some limitations, as well as outstanding questions
about how best to evaluate the (un)fairness of large language models. We hope
that this initial exploration of neural demographic perturbation will help
drive more improvement towards fairer NLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RSTGen: Imbuing Fine-Grained Interpretable Control into Long-FormText Generators. (arXiv:2205.12590v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12590">
<div class="article-summary-box-inner">
<span><p>In this paper, we study the task of improving the cohesion and coherence of
long-form text generated by language models. To this end, we propose RSTGen, a
framework that utilises Rhetorical Structure Theory (RST), a classical language
theory, to control the discourse structure, semantics and topics of generated
text. Firstly, we demonstrate our model's ability to control structural
discourse and semantic features of generated text in open generation
evaluation. Then we experiment on the two challenging long-form text tasks of
argument generation and story generation. Evaluation using automated metrics
and a metric with high correlation to human evaluation, shows that our model
performs competitively against existing models, while offering significantly
more controls over generated text than alternative methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Less Learn Shortcut: Analyzing and Mitigating Learning of Spurious Feature-Label Correlation. (arXiv:2205.12593v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12593">
<div class="article-summary-box-inner">
<span><p>Many recent works indicate that the deep neural networks tend to take dataset
biases as shortcuts to make decision, rather than understand the tasks, which
results in failures on the real-world applications. In this work, we focus on
the spurious correlation between feature and label, which derive from the
biased data distribution in the training data, and analyze it concretely. In
particular, we define the word highly co-occurring with a specific label as
biased word, and the example containing biased word as biased example. Our
analysis reveals that the biased examples with spurious correlations are easier
for models to learn, and when predicting, the biased words make significantly
higher contributions to models' predictions than other words, and the models
tend to assign the labels over-relying on the spurious correlation between
words and labels. To mitigate the model's over-reliance on the shortcut, we
propose a training strategy Less-Learn-Shortcut (LLS): we quantify the biased
degree of the biased examples, and down-weight them with the biased degree.
Experimental results on QM and NLI tasks show that the models improve the
performances both on in-domain and adversarial data (1.57% on DuQM and 2.12% on
HANS) with our LLS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RobustLR: Evaluating Robustness to Logical Perturbation in Deductive Reasoning. (arXiv:2205.12598v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12598">
<div class="article-summary-box-inner">
<span><p>Transformers have been shown to be able to perform deductive reasoning on a
logical rulebase containing rules and statements written in English natural
language. While the progress is promising, it is currently unclear if these
models indeed perform logical reasoning by understanding the underlying logical
semantics in the language. To this end, we propose RobustLR, a suite of
evaluation datasets that evaluate the robustness of these models to minimal
logical edits in rulebases and some standard logical equivalence conditions. In
our experiments with RoBERTa and T5, we find that the models trained in prior
works do not perform consistently on the different perturbations in RobustLR,
thus showing that the models are not robust to the proposed logical
perturbations. Further, we find that the models find it especially hard to
learn logical negation and disjunction operators. Overall, using our evaluation
sets, we demonstrate some shortcomings of the deductive reasoning-based
language models, which can eventually help towards designing better models for
logical reasoning over natural language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ORCA: Interpreting Prompted Language Models via Locating Supporting Data Evidence in the Ocean of Pretraining Data. (arXiv:2205.12600v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12600">
<div class="article-summary-box-inner">
<span><p>Large pretrained language models have been performing increasingly well in a
variety of downstream tasks via prompting. However, it remains unclear from
where the model learns the task-specific knowledge, especially in a zero-shot
setup. In this work, we want to find evidence of the model's task-specific
competence from pretraining and are specifically interested in locating a very
small subset of pretraining data that directly supports the model in the task.
We call such a subset supporting data evidence and propose a novel method ORCA
to effectively identify it, by iteratively using gradient information related
to the downstream task. This supporting data evidence offers interesting
insights about the prompted language models: in the tasks of sentiment analysis
and textual entailment, BERT shows a substantial reliance on BookCorpus, the
smaller corpus of BERT's two pretraining corpora, as well as on pretraining
examples that mask out synonyms to the task verbalizers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Intermediate Training on Question Answering Datasets Improves Generative Data Augmentation. (arXiv:2205.12604v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12604">
<div class="article-summary-box-inner">
<span><p>Manually annotating datasets requires domain experts to read through many
documents and carefully label them, which is often expensive. Recently,
pre-trained generative language models (GLMs) have demonstrated exceptional
abilities in generating text which motivates to leverage them for generative
data augmentation. We improve generative data augmentation by formulating the
data generation as context generation task and use question answering (QA)
datasets for intermediate training. Specifically, we view QA to be more as a
format than of a task and train GLMs as context generators for a given question
and its respective answer. Then, we cast downstream tasks into question
answering format and adapt the fine-tuned context generators to the target task
domain. Finally, we use the fine-tuned GLM to generate relevant contexts, which
is further used as synthetic training data for their corresponding tasks. We
perform extensive experiments, case studies, and ablation studies on multiple
sentiment and topic classification datasets and demonstrate substantial
improvements in performance in few-shot, zero-shot settings. Remarkably, on the
SST-2 dataset, intermediate training on SocialIQA dataset achieves an
improvement of 40% on Macro-F1 score. Through thorough analyses, we observe
that QA datasets that requires high-level reasoning abilities (e.g.,
abstractive and common-sense QA datasets) tend to give the best boost in
performance in both few-shot and zero-shot settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards More Realistic Generation of Information-Seeking Conversations. (arXiv:2205.12609v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12609">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce a novel framework SimSeek (simulating
information-seeking conversation from unlabeled documents) and compare two
variants of it to provide a deeper perspective into the information-seeking
behavior. We first introduce a strong simulator for information-symmetric
conversation, SimSeek-sym, where questioner and answerer share all knowledge
when conversing with one another. Although it simulates reasonable
conversations, we take a further step toward more realistic information-seeking
conversation. Hence, we propose SimSeek-asym that assumes information asymmetry
between two agents, which encourages the questioner to seek new information
from an inaccessible document. In our experiments, we demonstrate that
SimSeek-asym successfully generates information-seeking conversations for two
downstream tasks, CQA and conversational search. In particular, SimSeek-asym
improves baseline models by 1.1-1.9 F1 score in QuAC, and by 1.1 of MRR in
OR-QuAC. Moreover, we thoroughly analyze our synthetic datasets to identify
crucial factors for realistic information-seeking conversation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DisinfoMeme: A Multimodal Dataset for Detecting Meme Intentionally Spreading Out Disinformation. (arXiv:2205.12617v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12617">
<div class="article-summary-box-inner">
<span><p>Disinformation has become a serious problem on social media. In particular,
given their short format, visual attraction, and humorous nature, memes have a
significant advantage in dissemination among online communities, making them an
effective vehicle for the spread of disinformation. We present DisinfoMeme to
help detect disinformation memes. The dataset contains memes mined from Reddit
covering three current topics: the COVID-19 pandemic, the Black Lives Matter
movement, and veganism/vegetarianism. The dataset poses multiple unique
challenges: limited data and label imbalance, reliance on external knowledge,
multimodal reasoning, layout dependency, and noise from OCR. We test multiple
widely-used unimodal and multimodal models on this dataset. The experiments
show that the room for improvement is still huge for current models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unbiased and Efficient Sampling of Dependency Trees. (arXiv:2205.12621v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12621">
<div class="article-summary-box-inner">
<span><p>Distributions over spanning trees are the most common way of computational
modeling of dependency syntax. However, most treebanks require that every valid
dependency tree has a single edge coming out of the ROOT node, a constraint
that is not part of the definition of spanning trees. For this reason all
standard inference algorithms for spanning trees are sub-optimal for modeling
dependency trees.
</p>
<p>Zmigrod et al. (2021b) have recently proposed algorithms for sampling with
and without replacement from the single-root dependency tree distribution. In
this paper we show that their fastest algorithm for sampling with replacement,
Wilson-RC, is in fact producing biased samples and we provide two alternatives
that are unbiased. Additionally, we propose two algorithms (one incremental,
one parallel) that reduce the asymptotic runtime of their algorithm for
sampling $k$ trees without replacement to $\mathcal{O}(kn^3)$. These algorithms
are both asymptotically and practically more efficient.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are Large Pre-Trained Language Models Leaking Your Personal Information?. (arXiv:2205.12628v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12628">
<div class="article-summary-box-inner">
<span><p>Large Pre-Trained Language Models (PLMs) have facilitated and dominated many
NLP tasks in recent years. However, despite the great success of PLMs, there
are also privacy concerns brought with PLMs. For example, recent studies show
that PLMs memorize a lot of training data, including sensitive information,
while the information may be leaked unintentionally and be utilized by
malicious attackers.
</p>
<p>In this paper, we propose to measure whether PLMs are prone to leaking
personal information. Specifically, we attempt to query PLMs for email
addresses with contexts of the email address or prompts containing the owner's
name. We find that PLMs do leak personal information due to memorization.
However, the risk of specific personal information being extracted by attackers
is low because the models are weak at associating the personal information with
its owner. We hope this work could help the community to better understand the
privacy risk of PLMs and bring new insights to make PLMs safe.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Knowledge Alignment with Reinforcement Learning. (arXiv:2205.12630v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12630">
<div class="article-summary-box-inner">
<span><p>Large language models readily adapt to novel settings, even without
task-specific training data. Can their zero-shot capacity be extended to
multimodal inputs? In this work, we propose ESPER which extends language-only
zero-shot models to unseen multimodal tasks, like image and audio captioning.
Our key novelty is to use reinforcement learning to align multimodal inputs to
language model generations without direct supervision: for example, in the
image case our reward optimization relies only on cosine similarity derived
from CLIP, and thus requires no additional explicitly paired (image, caption)
data. Because the parameters of the language model are left unchanged, the
model maintains its capacity for zero-shot generalization. Experiments
demonstrate that ESPER outperforms baselines and prior work on a variety of
zero-shot tasks; these include a new benchmark we collect+release, ESP dataset,
which tasks models with generating several diversely-styled captions for each
image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring industrial safety knowledge via Zipf law. (arXiv:2205.12636v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12636">
<div class="article-summary-box-inner">
<span><p>The hazard and operability analysis (HAZOP) report contains precious
industrial safety knowledge (ISK) with expert experience and process nature,
which is of great significance to the development of industrial intelligence.
Subject to the attributes of ISK, existing researches mine them through
sequence labeling in deep learning. Yet, there are two thorny issues: (1)
Uneven distribution of ISK and (2) Consistent importance of ISK: for safety
review. In this study, we propose a novel generative mining strategy called
CRGM to explore ISK. Inspired Zipf law in linguistics, CRGM consists of
common-rare discriminator, induction-extension generator and ISK extractor.
Firstly, the common-rare discriminator divides HAZOP descriptions into common
words and rare words, and obtains the common description and the rare
description, where the latter contains more industrial substances. Then, they
are operated by the induction-extension generator in the way of deep text
generation, the common description is induced and the rare description is
extended, the material knowledge and the equipment knowledge can be enriched.
Finally, the ISK extractor processes the material knowledge and equipment
knowledge from the generated description through the rule template method, the
additional ISK is regarded as the supplement of the training set to train the
proposed sequence labeling model. We conduct multiple evaluation experiments on
two industrial safety datasets. The results show that CRGM has promising and
gratifying aptitudes, greatly improves the performance of the model, and is
efficient and generalized. Our sequence labeling model also shows the expected
performance, which is better than the existing research. Our research provides
a new perspective for exploring ISK, we hope it can contribute support for the
intelligent progress of industrial safety.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does Your Model Classify Entities Reasonably? Diagnosing and Mitigating Spurious Correlations in Entity Typing. (arXiv:2205.12640v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12640">
<div class="article-summary-box-inner">
<span><p>The entity typing task aims at predicting one or more words or phrases that
describe the type(s) of a specific mention in a sentence. Due to shortcuts from
surface patterns to annotated entity labels and biased training, existing
entity typing models are subject to the problem of spurious correlations. To
comprehensively investigate the faithfulness and reliability of entity typing
methods, we first systematically define distinct kinds of model biases that are
reflected mainly from spurious correlations. Particularly, we identify six
types of existing model biases, including mention-context bias, lexical
overlapping bias, named entity bias, pronoun bias, dependency bias, and
overgeneralization bias. To mitigate these model biases, we then introduce a
counterfactual data augmentation method. By augmenting the original training
set with their bias-free counterparts, models are forced to fully comprehend
the sentences and discover the fundamental cues for entity typing, rather than
relying on spurious correlations for shortcuts. Experimental results on the
UFET dataset show that our counterfactual data augmentation approach helps
improve generalization of different entity typing models with consistently
better performance on both in- and out-of-distribution test sets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Asking the Right Questions in Low Resource Template Extraction. (arXiv:2205.12643v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12643">
<div class="article-summary-box-inner">
<span><p>Information Extraction (IE) researchers are mapping tasks to Question
Answering (QA) in order to leverage existing large QA resources, and thereby
improve data efficiency. Especially in template extraction (TE), mapping an
ontology to a set of questions can be more time-efficient than collecting
labeled examples. We ask whether end users of TE systems can design these
questions, and whether it is beneficial to involve an NLP practitioner in the
process. We compare questions to other ways of phrasing natural language
prompts for TE. We propose a novel model to perform TE with prompts, and find
it benefits from questions over other styles of prompts, and that they do not
require an NLP background to author.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LingMess: Linguistically Informed Multi Expert Scorers for Coreference Resolution. (arXiv:2205.12644v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12644">
<div class="article-summary-box-inner">
<span><p>While coreference resolution typically involves various linguistic
challenges, recent models are based on a single pairwise scorer for all types
of pairs. We present LingMess, a new coreference model that defines different
categories of coreference cases and optimize multiple pairwise scorers, where
each scorer learns a specific set of linguistic challenges. Our model
substantially improves pairwise scores for most categories and outperforms
cluster-level performance on Ontonotes. Our model is available in
https://github.com/shon-otmazgin/lingmess-coref
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Overcoming Catastrophic Forgetting in Zero-Shot Cross-Lingual Generation. (arXiv:2205.12647v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12647">
<div class="article-summary-box-inner">
<span><p>In this paper, we explore the challenging problem of performing a generative
task (i.e., summarization) in a target language when labeled data is only
available in English. We assume a strict setting with no access to parallel
data or machine translation. Prior work has shown, and we confirm, that
standard transfer learning techniques struggle in this setting, as a generative
multilingual model fine-tuned purely on English catastrophically forgets how to
generate non-English. Given the recent rise of parameter-efficient adaptation
techniques (e.g., prompt tuning), we conduct the first investigation into how
well these methods can overcome catastrophic forgetting to enable zero-shot
cross-lingual generation. We find that parameter-efficient adaptation provides
gains over standard fine-tuning when transferring between less-related
languages, e.g., from English to Thai. However, a significant gap still remains
between these methods and fully-supervised baselines. To improve cross-lingual
transfer further, we explore three approaches: (1) mixing in unlabeled
multilingual data, (2) pre-training prompts on target language data, and (3)
explicitly factoring prompts into recombinable language and task components.
Our methods can provide further quality gains, suggesting that robust zero-shot
cross-lingual generation is within reach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Lexical Replacements for Arabic-English Code-Switched Data Augmentation. (arXiv:2205.12649v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12649">
<div class="article-summary-box-inner">
<span><p>Code-switching (CS) poses several challenges to NLP tasks, where data
sparsity is a main problem hindering the development of CS NLP systems. In this
paper, we investigate data augmentation techniques for synthesizing Dialectal
Arabic-English CS text. We perform lexical replacements using parallel corpora
and alignments where CS points are either randomly chosen or learnt using a
sequence-to-sequence model. We evaluate the effectiveness of data augmentation
on language modeling (LM), machine translation (MT), and automatic speech
recognition (ASR) tasks. Results show that in the case of using 1-1 alignments,
using trained predictive models produces more natural CS sentences, as
reflected in perplexity. By relying on grow-diag-final alignments, we then
identify aligning segments and perform replacements accordingly. By replacing
segments instead of words, the quality of synthesized data is greatly improved.
With this improvement, random-based approach outperforms using trained
predictive models on all extrinsic tasks. Our best models achieve 33.6%
improvement in perplexity, +3.2-5.6 BLEU points on MT task, and 7% relative
improvement on WER for ASR task. We also contribute in filling the gap in
resources by collecting and publishing the first Arabic English CS-English
parallel corpus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LEPUS: Prompt-based Unsupervised Multi-hop Reranking for Open-domain QA. (arXiv:2205.12650v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12650">
<div class="article-summary-box-inner">
<span><p>We study unsupervised multi-hop reranking for multi-hop QA (MQA) with
open-domain questions. Since MQA requires piecing information from multiple
documents, the main challenge thus resides in retrieving and reranking chains
of passages that support the reasoning process. Our approach relies on LargE
models with Prompt-Utilizing reranking Strategy (LEPUS): we construct an
instruction-like prompt based on a candidate document path and compute a
relevance score of the path as the probability of generating a given question,
according to a pre-trained language model. Though unsupervised, LEPUS yields
competitive reranking performance against state-of-the-art methods that are
trained on thousands of examples. Adding a small number of samples (e.g., $2$),
we demonstrate further performance gain using in-context learning. Finally, we
show that when integrated with a reader module, LEPUS can obtain competitive
multi-hop QA performance, e.g., outperforming fully-supervised QA systems.
</p>
<p>Code will be released at https://github.com/mukhal/LEPUS
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. (arXiv:2205.12654v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12654">
<div class="article-summary-box-inner">
<span><p>Scaling multilingual representation learning beyond the hundred most frequent
languages is challenging, in particular to cover the long tail of low-resource
languages. A promising approach has been to train one-for-all multilingual
models capable of cross-lingual transfer, but these models often suffer from
insufficient capacity and interference between unrelated languages. Instead, we
move away from this approach and focus on training multiple language (family)
specific representations, but most prominently enable all languages to still be
encoded in the same representational space. To achieve this, we focus on
teacher-student training, allowing all encoders to be mutually compatible for
bitext mining, and enabling fast learning of new languages. We introduce a new
teacher-student training scheme which combines supervised and self-supervised
training, allowing encoders to take advantage of monolingual training data,
which is valuable in the low-resource setting.
</p>
<p>Our approach significantly outperforms the original LASER encoder. We study
very low-resource languages and handle 50 African languages, many of which are
not covered by any other model. For these languages, we train sentence
encoders, mine bitexts, and validate the bitexts by training NMT systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DialogZoo: Large-Scale Dialog-Oriented Task Learning. (arXiv:2205.12662v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12662">
<div class="article-summary-box-inner">
<span><p>Building unified conversational agents has been a long-standing goal of the
dialogue research community. Most previous works only focus on a subset of
various dialogue tasks. In this work, we aim to build a unified foundation
model which can solve massive diverse dialogue tasks. To achieve this goal, we
first collect a large-scale well-labeled dialogue dataset from 73 publicly
available datasets. In addition to this dataset, we further propose two
dialogue-oriented self-supervised tasks, and finally use the mixture of
supervised and self-supervised datasets to train our foundation model. The
supervised examples make the model learn task-specific skills, while the
self-supervised examples make the model learn more general skills. We evaluate
our model on various downstream dialogue tasks. The experimental results show
that our method not only improves the ability of dialogue generation and
knowledge distillation, but also the representation ability of models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QAMPARI: : An Open-domain Question Answering Benchmark for Questions with Many Answers from Multiple Paragraphs. (arXiv:2205.12665v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12665">
<div class="article-summary-box-inner">
<span><p>Existing benchmarks for open-domain question answering (ODQA) typically focus
on questions whose answers can be extracted from a single paragraph. By
contrast, many natural questions, such as "What players were drafted by the
Brooklyn Nets?" have a list of answers. Answering such questions requires
retrieving and reading from many passages, in a large corpus. We introduce
QAMPARI, an ODQA benchmark, where question answers are lists of entities,
spread across many paragraphs. We created QAMPARI by (a) generating questions
with multiple answers from Wikipedia's knowledge graph and tables, (b)
automatically pairing answers with supporting evidence in Wikipedia paragraphs,
and (c) manually paraphrasing questions and validating each answer. We train
ODQA models from the retrieve-and-read family and find that QAMPARI is
challenging in terms of both passage retrieval and answer generation, reaching
an F1 score of 26.6 at best. Our results highlight the need for developing ODQA
models that handle a broad range of question types, including single and
multi-answer questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discovering Language-neutral Sub-networks in Multilingual Language Models. (arXiv:2205.12672v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12672">
<div class="article-summary-box-inner">
<span><p>Multilingual pre-trained language models perform remarkably well on
cross-lingual transfer for downstream tasks. Despite their impressive
performance, our understanding of their language neutrality (i.e., the extent
to which they use shared representations to encode similar phenomena across
languages) and its role in achieving such performance remain open questions. In
this work, we conceptualize language neutrality of multilingual models as a
function of the overlap between language-encoding sub-networks of these models.
Using mBERT as a foundation, we employ the lottery ticket hypothesis to
discover sub-networks that are individually optimized for various languages and
tasks. Using three distinct tasks and eleven typologically-diverse languages in
our evaluation, we show that the sub-networks found for different languages are
in fact quite similar, supporting the idea that mBERT jointly encodes multiple
languages in shared parameters. We conclude that mBERT is comprised of a
language-neutral sub-network shared among many languages, along with multiple
ancillary language-specific sub-networks, with the former playing a more
prominent role in mBERT's impressive cross-lingual performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning. (arXiv:2205.12673v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12673">
<div class="article-summary-box-inner">
<span><p>Instruction tuning is an emergent paradigm in NLP wherein natural language
instructions are leveraged with language models to induce zero-shot performance
on unseen tasks. Instructions have been shown to enable good performance on
unseen tasks and datasets in both large and small language models. Dialogue is
an especially interesting area to explore instruction tuning because dialogue
systems perform multiple kinds of tasks related to language (e.g., natural
language understanding and generation, domain-specific interaction), yet
instruction tuning has not been systematically explored for dialogue-related
tasks. We introduce InstructDial, an instruction tuning framework for dialogue,
which consists of a repository of 48 diverse dialogue tasks in a unified
text-to-text format created from 59 openly available dialogue datasets. Next,
we explore cross-task generalization ability on models tuned on InstructDial
across diverse dialogue tasks. Our analysis reveals that InstructDial enables
good zero-shot performance on unseen datasets and tasks such as dialogue
evaluation and intent detection, and even better performance in a few-shot
setting. To ensure that models adhere to instructions, we introduce novel
meta-tasks. We establish benchmark zero-shot and few-shot performance of models
trained using the proposed framework on multiple dialogue tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training Language Models with Memory Augmentation. (arXiv:2205.12674v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12674">
<div class="article-summary-box-inner">
<span><p>Recent work has improved language models remarkably by equipping them with a
non-parametric memory component. However, most existing approaches only
introduce memories at testing time, or represent them using a separately
trained encoder -- resulting in sub-optimal training of the language model. In
this work, we present TRIME, a novel yet simple training approach designed for
training language models with memory augmentation. Our approach uses a training
objective that directly takes in-batch examples as accessible memory. We also
present new methods for memory construction and data batching, which are used
for adapting to different sets of memories -- local, long-term, and external
memory -- at testing time. We evaluate our approach on multiple language
modeling and machine translation benchmarks. We find that simply replacing the
vanilla language modeling objective by ours greatly reduces the perplexity,
without modifying the model architecture or incorporating extra context (e.g.,
18.70 $\to$ 17.76 on WikiText-103). We further augment language models with
long-range contexts and external knowledge and demonstrate significant gains
over previous memory-augmented approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Inclusivity, Equity, and Accessibility of NLP Technology: A Case Study for Indian Languages. (arXiv:2205.12676v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12676">
<div class="article-summary-box-inner">
<span><p>In order for NLP technology to be widely applicable and useful, it needs to
be inclusive of users across the world's languages, equitable, i.e., not unduly
biased towards any particular language, and accessible to users, particularly
in low-resource settings where compute constraints are common. In this paper,
we propose an evaluation paradigm that assesses NLP technologies across all
three dimensions, hence quantifying the diversity of users they can serve.
While inclusion and accessibility have received attention in recent literature,
equity is currently unexplored. We propose to address this gap using the Gini
coefficient, a well-established metric used for estimating societal wealth
inequality. Using our paradigm, we highlight the distressed state of diversity
of current technologies for Indian (IN) languages, motivated by their
linguistic diversity and large, varied speaker population. To improve upon
these metrics, we demonstrate the importance of region-specific choices in
model building and dataset creation and also propose a novel approach to
optimal resource allocation during fine-tuning. Finally, we discuss steps that
must be taken to mitigate these biases and call upon the community to
incorporate our evaluation paradigm when building linguistically diverse
technologies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Anisotropic Cross-Lingual Model Editing. (arXiv:2205.12677v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12677">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models learn large amounts of knowledge from their
training corpus, while the memorized facts could become outdated over a few
years. Model editing aims to make post-hoc updates on specific facts in a model
while leaving irrelevant knowledge unchanged. However, existing work studies
only the monolingual scenario. In this paper, we focus on cross-lingual model
editing. Firstly, we propose the definition and metrics of the cross-lingual
model editing, where updates in a single language should take effect in the
others as well. Next, we propose a simple framework to convert a monolingual
model editing approach to its cross-lingual variant using the parallel corpus.
Experiments show that such an approach outperforms monolingual baselines by a
large margin. Furthermore, we propose language anisotropic editing to improve
cross-lingual editing by estimating parameter importance for each language.
Experiments reveal that language anisotropic editing decreases the editing
failing rate by another $26\%$ relatively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ZeroGen$^+$: Self-Guided High-Quality Data Generation in Efficient Zero-Shot Learning. (arXiv:2205.12679v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12679">
<div class="article-summary-box-inner">
<span><p>Nowadays, owing to the superior capacity of the large pre-trained language
models (PLM), the PLM-based zero-shot learning has shown promising performances
on various natural language processing tasks. There are emerging interests in
further exploring the zero-shot learning potential of PLMs. Among them, ZeroGen
attempts to purely use PLM to generate data and train a tiny model without
relying on any task-specific annotation. Despite its remarkable results, we
observe that the synthesized data from PLM contains a significant portion of
samples with low quality, overfitting on such data greatly hampers the
performance of the trained model and makes it unreliable for deployment.Since
no gold data is accessible in zero-shot scenario, it is hard to perform
model/data selection to prevent overfitting to the low-quality data. To address
this problem, we propose a noise-robust bi-level re-weighting framework which
is able to learn the per-sample weights measuring the data quality without
requiring any gold data. With the learnt weights, clean subsets of different
sizes can then be sampled to train the task model. We theoretically and
empirically verify our method is able to construct synthetic dataset with good
quality. Our method yeilds a 7.1% relative improvement than ZeroGen on average
accuracy across five different established text classification tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Refining Query Representations for Dense Retrieval at Test Time. (arXiv:2205.12680v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12680">
<div class="article-summary-box-inner">
<span><p>Dense retrieval uses a contrastive learning framework to learn dense
representations of queries and contexts. Trained encoders are directly used for
each test query, but they often fail to accurately represent out-of-domain
queries. In this paper, we introduce a framework that refines instance-level
query representations at test time, with only the signals coming from the
intermediate retrieval results. We optimize the query representation based on
the retrieval result similar to pseudo relevance feedback (PRF) in information
retrieval. Specifically, we adopt a cross-encoder labeler to provide pseudo
labels over the retrieval result and iteratively refine the query
representation with a gradient descent method, treating each test query as a
single data point to train on. Our theoretical analysis reveals that our
framework can be viewed as a generalization of the classical Rocchio's
algorithm for PRF, which leads us to propose interesting variants of our
method. We show that our test-time query refinement strategy improves the
performance of phrase retrieval (+8.1% Acc@1) and passage retrieval (+3.7%
Acc@20) for open-domain QA with large improvements on out-of-domain queries.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations. (arXiv:2205.12685v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12685">
<div class="article-summary-box-inner">
<span><p>Despite recent explosion in research interests, in-context learning and the
precise impact of the quality of demonstrations remain elusive. While, based on
current literature, it is expected that in-context learning shares a similar
mechanism to supervised learning, Min et al. (2022) recently reported that,
surprisingly, input-label correspondence is less important than other aspects
of prompt demonstrations. Inspired by this counter-intuitive observation, we
re-examine the importance of ground truth labels on in-context learning from
diverse and statistical points of view. With the aid of the newly introduced
metrics, i.e., Ground-truth Label Effect Ratio (GLER), demo-gain, and label
sensitivity, we find that the impact of the correct input-label matching can
vary according to different configurations. Expanding upon the previous key
finding on the role of demonstrations, the complementary and contrastive
results suggest that one might need to take more care when estimating the
impact of each component in in-context learning demonstrations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ProsocialDialog: A Prosocial Backbone for Conversational Agents. (arXiv:2205.12688v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12688">
<div class="article-summary-box-inner">
<span><p>Most existing dialogue systems fail to respond properly to potentially unsafe
user utterances by either ignoring or passively agreeing with them. To address
this issue, we introduce ProsocialDialog, the first large-scale multi-turn
dialogue dataset to teach conversational agents to respond to problematic
content following social norms. Covering diverse unethical, problematic,
biased, and toxic situations, ProsocialDialog contains responses that encourage
prosocial behavior, grounded in commonsense social rules (i.e., rules-of-thumb,
RoTs). Created via a human-AI collaborative framework, ProsocialDialog consists
of 58K dialogues, with 331K utterances, 160K RoTs, and 497K dialogue safety
labels accompanied by free-form rationales.
</p>
<p>With this dataset, we introduce a dialogue safety detection module, Canary,
capable of generating RoTs given conversational context, and a
socially-informed dialogue agent, Prost. Empirical results show that Prost
generates more socially acceptable dialogues compared to other state-of-the-art
language and dialogue models in both in-domain and out-of-domain settings.
Additionally, Canary effectively guides conversational agents and off-the-shelf
language models to generate significantly more prosocial responses. Our work
highlights the promise and importance of creating and steering conversational
AI to be socially responsible.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Language Models are Zero-Shot Clinical Information Extractors. (arXiv:2205.12689v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12689">
<div class="article-summary-box-inner">
<span><p>We show that large language models, such as GPT-3, perform well at zero-shot
information extraction from clinical text despite not being trained
specifically for the clinical domain. We present several examples showing how
to use these models as tools for the diverse tasks of (i) concept
disambiguation, (ii) evidence extraction, (iii) coreference resolution, and
(iv) concept extraction, all on clinical text. The key to good performance is
the use of simple task-specific programs that map from the language model
outputs to the label space of the task. We refer to these programs as
resolvers, a generalization of the verbalizer, which defines a mapping between
output tokens and a discrete label space. We show in our examples that good
resolvers share common components (e.g., "safety checks" that ensure the
language model outputs faithfully match the input data), and that the common
patterns across tasks make resolvers lightweight and easy to create. To better
evaluate these systems, we also introduce two new datasets for benchmarking
zero-shot clinical information extraction based on manual relabeling of the
CASI dataset (Moon et al., 2014) with labels for new tasks. On the clinical
extraction tasks we studied, the GPT-3 + resolver systems significantly
outperform existing zero- and few-shot baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Natural Language in Context. (arXiv:2205.12691v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12691">
<div class="article-summary-box-inner">
<span><p>Recent years have seen an increasing number of applications that have a
natural language interface, either in the form of chatbots or via personal
assistants such as Alexa (Amazon), Google Assistant, Siri (Apple), and Cortana
(Microsoft). To use these applications, a basic dialog between the robot and
the human is required.
</p>
<p>While this kind of dialog exists today mainly within "static" robots that do
not make any movement in the household space, the challenge of reasoning about
the information conveyed by the environment increases significantly when
dealing with robots that can move and manipulate objects in our home
environment.
</p>
<p>In this paper, we focus on cognitive robots, which have some knowledge-based
models of the world and operate by reasoning and planning with this model.
Thus, when the robot and the human communicate, there is already some formalism
they can use - the robot's knowledge representation formalism.
</p>
<p>Our goal in this research is to translate natural language utterances into
this robot's formalism, allowing much more complicated household tasks to be
completed. We do so by combining off-the-shelf SOTA language models, planning
tools, and the robot's knowledge-base for better communication. In addition, we
analyze different directive types and illustrate the contribution of the
world's context to the translation process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Train Flat, Then Compress: Sharpness-Aware Minimization Learns More Compressible Models. (arXiv:2205.12694v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12694">
<div class="article-summary-box-inner">
<span><p>Model compression by way of parameter pruning, quantization, or distillation
has recently gained popularity as an approach for reducing the computational
requirements of modern deep neural network models for NLP. Pruning unnecessary
parameters has emerged as a simple and effective method for compressing large
models that is compatible with a wide variety of contemporary off-the-shelf
hardware (unlike quantization), and that requires little additional training
(unlike distillation). Pruning approaches typically take a large, accurate
model as input, then attempt to discover a smaller subnetwork of that model
capable of achieving end-task accuracy comparable to the full model. Inspired
by previous work suggesting a connection between simpler, more generalizable
models and those that lie within flat basins in the loss landscape, we propose
to directly optimize for flat minima while performing task-specific pruning,
which we hypothesize should lead to simpler parameterizations and thus more
compressible models. In experiments combining sharpness-aware minimization with
both iterative magnitude pruning and structured pruning approaches, we show
that optimizing for flat minima consistently leads to greater compressibility
of parameters compared to standard Adam optimization when fine-tuning BERT
models, leading to higher rates of compression with little to no loss in
accuracy on the GLUE classification benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting DocRED -- Addressing the Overlooked False Negative Problem in Relation Extraction. (arXiv:2205.12696v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12696">
<div class="article-summary-box-inner">
<span><p>The DocRED dataset is one of the most popular and widely used benchmarks for
document-level relation extraction (RE). It adopts a recommend-revise
annotation scheme so as to have a large-scale annotated dataset. However, we
find that the annotation of DocRED is incomplete, i.e., the false negative
samples are prevalent. We analyze the causes and effects of the overwhelming
false negative problem in the DocRED dataset. To address the shortcoming, we
re-annotate 4,053 documents in the DocRED dataset by adding the missed relation
triples back to the original DocRED. We name our revised DocRED dataset
Re-DocRED. We conduct extensive experiments with state-of-the-art neural models
on both datasets, and the experimental results show that the models trained and
evaluated on our Re-DocRED achieve performance improvements of around 13 F1
points. Moreover, we propose different metrics to comprehensively evaluate the
document-level RE task. We make our data publicly available at
https://github.com/tonytan48/Re-DocRED.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PLOG: Table-to-Logic Pretraining for Logical Table-to-Text Generation. (arXiv:2205.12697v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12697">
<div class="article-summary-box-inner">
<span><p>Logical table-to-text generation is a task that involves generating logically
faithful sentences from tables, which requires models to derive logical level
facts from table records via logical inference. It raises a new challenge on
the logical-level content planning of table-to-text models. However, directly
learning the logical inference knowledge from table-text pairs is very
difficult for neural models because of the ambiguity of natural language and
the scarcity of parallel data. Hence even large-scale pre-trained language
models present low logical fidelity on logical table-to-text. In this work, we
propose a PLOG (Pretrained Logical Form Generator) framework to improve the
generation fidelity. Specifically, PLOG is first pretrained on a
table-to-logic-form generation (table-to-logic) task, then finetuned on
downstream table-to-text tasks. The formal definition of logical forms enables
us to collect large amount of accurate logical forms from tables without human
annotation. In addition, PLOG can learn logical inference from table-logic
pairs much more definitely than from table-text pairs. To evaluate our model,
we further collect a controlled logical table-to-text dataset CONTLOG based on
an existing dataset. On two benchmarks, LOGICNLG and CONTLOG, PLOG outperforms
strong baselines by a large margin on the logical fidelity, demonstrating the
effectiveness of table-to-logic pretraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Empathic Conversations: A Multi-level Dataset of Contextualized Conversations. (arXiv:2205.12698v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12698">
<div class="article-summary-box-inner">
<span><p>Empathy is a cognitive and emotional reaction to an observed situation of
others. Empathy has recently attracted interest because it has numerous
applications in psychology and AI, but it is unclear how different forms of
empathy (e.g., self-report vs counterpart other-report, concern vs. distress)
interact with other affective phenomena or demographics like gender and age. To
better understand this, we created the {\it Empathic Conversations} dataset of
annotated negative, empathy-eliciting dialogues in which pairs of participants
converse about news articles. People differ in their perception of the empathy
of others. These differences are associated with certain characteristics such
as personality and demographics. Hence, we collected detailed characterization
of the participants' traits, their self-reported empathetic response to news
articles, their conversational partner other-report, and turn-by-turn
third-party assessments of the level of self-disclosure, emotion, and empathy
expressed. This dataset is the first to present empathy in multiple forms along
with personal distress, emotion, personality characteristics, and person-level
demographic information. We present baseline models for predicting some of
these features from conversations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Textual Backdoor Attacks with Iterative Trigger Injection. (arXiv:2205.12700v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12700">
<div class="article-summary-box-inner">
<span><p>The backdoor attack has become an emerging threat for Natural Language
Processing (NLP) systems. A victim model trained on poisoned data can be
embedded with a "backdoor", making it predict the adversary-specified output
(e.g., the positive sentiment label) on inputs satisfying the trigger pattern
(e.g., containing a certain keyword). In this paper, we demonstrate that it's
possible to design an effective and stealthy backdoor attack by iteratively
injecting "triggers" into a small set of training data. While all triggers are
common words that fit into the context, our poisoning process strongly
associates them with the target label, forming the model backdoor. Experiments
on sentiment analysis and hate speech detection show that our proposed attack
is both stealthy and effective, raising alarm on the usage of untrusted
training data. We further propose a defense method to combat this threat.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Eliciting Transferability in Multi-task Learning with Task-level Mixture-of-Experts. (arXiv:2205.12701v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12701">
<div class="article-summary-box-inner">
<span><p>Recent work suggests that transformer models are capable of multi-task
learning on diverse NLP tasks. However, the potential of these models may be
limited as they use the same set of parameters for all tasks. In contrast,
humans tackle tasks in a more flexible way, by making proper presumptions on
what skills and knowledge are relevant and executing only the necessary
computations. Inspired by this, we propose to use task-level mixture-of-expert
models, which has a collection of transformer layers (i.e., experts) and a
router component to choose among these experts dynamically and flexibly. We
show that the learned routing decisions and experts partially rediscover human
categorization of NLP tasks -- certain experts are strongly associated with
extractive tasks, some with classification tasks, and some with tasks requiring
world knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Label Errors using Pre-Trained Language Models. (arXiv:2205.12702v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12702">
<div class="article-summary-box-inner">
<span><p>We show that large pre-trained language models are extremely capable of
identifying label errors in datasets: simply verifying data points in
descending order of out-of-distribution loss significantly outperforms more
complex mechanisms for detecting label errors on natural language datasets. We
contribute a novel method to produce highly realistic, human-originated label
noise from crowdsourced data, and demonstrate the effectiveness of this method
on TweetNLP, providing an otherwise difficult to obtain measure of realistic
recall.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Would You Ask it that Way? Measuring and Improving Question Naturalness for Knowledge Graph Question Answering. (arXiv:2205.12768v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12768">
<div class="article-summary-box-inner">
<span><p>Knowledge graph question answering (KGQA) facilitates information access by
leveraging structured data without requiring formal query language expertise
from the user. Instead, users can express their information needs by simply
asking their questions in natural language (NL). Datasets used to train KGQA
models that would provide such a service are expensive to construct, both in
terms of expert and crowdsourced labor. Typically, crowdsourced labor is used
to improve template-based pseudo-natural questions generated from formal
queries. However, the resulting datasets often fall short of representing
genuinely natural and fluent language. In the present work, we investigate ways
to characterize and remedy these shortcomings. We create the IQN-KGQA test
collection by sampling questions from existing KGQA datasets and evaluating
them with regards to five different aspects of naturalness. Then, the questions
are rewritten to improve their fluency. Finally, the performance of existing
KGQA models is compared on the original and rewritten versions of the NL
questions. We find that some KGQA systems fare worse when presented with more
realistic formulations of NL questions. The IQN-KGQA test collection is a
resource to help evaluate KGQA systems in a more realistic setting. The
construction of this test collection also sheds light on the challenges of
constructing large-scale KGQA datasets with genuinely NL questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does Moral Code Have a Moral Code? Probing Delphi's Moral Philosophy. (arXiv:2205.12771v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12771">
<div class="article-summary-box-inner">
<span><p>In an effort to guarantee that machine learning model outputs conform with
human moral values, recent work has begun exploring the possibility of
explicitly training models to learn the difference between right and wrong.
This is typically done in a bottom-up fashion, by exposing the model to
different scenarios, annotated with human moral judgements. One question,
however, is whether the trained models actually learn any consistent,
higher-level ethical principles from these datasets -- and if so, what? Here,
we probe the Allen AI Delphi model with a set of standardized morality
questionnaires, and find that, despite some inconsistencies, Delphi tends to
mirror the moral principles associated with the demographic groups involved in
the annotation process. We question whether this is desirable and discuss how
we might move forward with this knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic question generation based on sentence structure analysis using machine learning approach. (arXiv:2205.12811v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12811">
<div class="article-summary-box-inner">
<span><p>Automatic question generation is one of the most challenging tasks of Natural
Language Processing. It requires "bidirectional" language processing: firstly,
the system has to understand the input text (Natural Language Understanding)
and it then has to generate questions also in the form of text (Natural
Language Generation). In this article, we introduce our framework for
generating the factual questions from unstructured text in the English
language. It uses a combination of traditional linguistic approaches based on
sentence patterns with several machine learning methods. We firstly obtain
lexical, syntactic and semantic information from an input text and we then
construct a hierarchical set of patterns for each sentence. The set of features
is extracted from the patterns and it is then used for automated learning of
new transformation rules. Our learning process is totally data-driven because
the transformation rules are obtained from a set of initial sentence-question
pairs. The advantages of this approach lie in a simple expansion of new
transformation rules which allows us to generate various types of questions and
also in the continuous improvement of the system by reinforcement learning. The
framework also includes a question evaluation module which estimates the
quality of generated questions. It serves as a filter for selecting the best
questions and eliminating incorrect ones or duplicates. We have performed
several experiments to evaluate the correctness of generated questions and we
have also compared our system with several state-of-the-art systems. Our
results indicate that the quality of generated questions outperforms the
state-of-the-art systems and our questions are also comparable to questions
created by humans. We have also created and published an interface with all
created datasets and evaluated questions, so it is possible to follow up on our
work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Building Spoken Language Understanding Systems for Low Resourced Languages. (arXiv:2205.12818v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12818">
<div class="article-summary-box-inner">
<span><p>Spoken dialog systems are slowly becoming and integral part of the human
experience due to their various advantages over textual interfaces. Spoken
language understanding (SLU) systems are fundamental building blocks of spoken
dialog systems. But creating SLU systems for low resourced languages is still a
challenge. In a large number of low resourced language, we don't have access to
enough data to build automatic speech recognition (ASR) technologies, which are
fundamental to any SLU system. Also, ASR based SLU systems do not generalize to
unwritten languages. In this paper, we present a series of experiments to
explore extremely low-resourced settings where we perform intent classification
with systems trained on as low as one data-point per intent and with only one
speaker in the dataset. We also work in a low-resourced setting where we do not
use language specific ASR systems to transcribe input speech, which compounds
the challenge of building SLU systems to simulate a true low-resourced setting.
We test our system on Belgian Dutch (Flemish) and English and find that using
phonetic transcriptions to make intent classification systems in such
low-resourced setting performs significantly better than using speech features.
Specifically, when using a phonetic transcription based system over a feature
based system, we see average improvements of 12.37% and 13.08% for binary and
four-class classification problems respectively, when averaged over 49
different experimental settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Paradigm Change for Formal Syntax: Computational Algorithms in the Grammar of English. (arXiv:2205.12825v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12825">
<div class="article-summary-box-inner">
<span><p>Language sciences rely less and less on formal syntax as their base. The
reason is probably its lack of psychological reality, knowingly avoided.
Philosophers of science call for a paradigm shift in which explanations are by
mechanisms, as in biology. We turned to programming languages as heuristic
models for a process-based syntax of English. The combination of a functional
word and a content word was chosen as the topic of modeling. Such combinations
are very frequent, and their output is the important immediate constituents of
sentences. We found their parallel in Object Oriented Programming where an
all-methods element serves as an interface, and the content-full element serves
as its implementation, defining computational objects. The fit of the model was
tested by deriving three functional characteristics crucial for the algorithm
and checking their presence in English grammar. We tested the reality of the
interface-implementation mechanism on psycholinguistic and neurolinguistic
evidence concerning processing, development and loss of syntax. The close fit
and psychological reality of the mechanism suggests that a paradigm shift to an
algorithmic theory of syntax is a possibility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors. (arXiv:2205.12854v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12854">
<div class="article-summary-box-inner">
<span><p>The propensity of abstractive summarization systems to make factual errors
has been the subject of significant study, including work on models to detect
factual errors and annotation of errors in current systems' outputs. However,
the ever-evolving nature of summarization systems, error detectors, and
annotated benchmarks make factuality evaluation a moving target; it is hard to
get a clear picture of how techniques compare. In this work, we collect labeled
factuality errors from across nine datasets of annotated summary outputs and
stratify them in a new way, focusing on what kind of base summarization model
was used. To support finer-grained analysis, we unify the labeled error types
into a single taxonomy and project each of the datasets' errors into this
shared labeled space. We then contrast five state-of-the-art error detection
methods on this benchmark. Our findings show that benchmarks built on modern
summary outputs (those from pre-trained models) show significantly different
results than benchmarks using pre-Transformer models. Furthermore, no one
factuality technique is superior in all settings or for all error types,
suggesting that system developers should take care to choose the right system
for their task at hand.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open-Domain Sign Language Translation Learned from Online Video. (arXiv:2205.12870v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12870">
<div class="article-summary-box-inner">
<span><p>Existing work on sign language translation--that is, translation from sign
language videos into sentences in a written language--has focused mainly on (1)
data collected in a controlled environment or (2) data in a specific domain,
which limits the applicability to real-world settings. In this paper, we
introduce OpenASL, a large-scale ASL-English dataset collected from online
video sites (e.g., YouTube). OpenASL contains 288 hours of ASL videos in
various domains (news, VLOGs, etc.) from over 200 signers and is the largest
publicly available ASL translation dataset to date. To tackle the challenges of
sign language translation in realistic settings and without glosses, we propose
a set of techniques including sign search as a pretext task for pre-training
and fusion of mouthing and handshape features. The proposed techniques produce
consistent and large improvements in translation quality, over baseline models
based on prior work. Our data, code and model will be publicly available at
https://github.com/chevalierNoir/OpenASL
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reasoning over Logically Interacted Conditions for Question Answering. (arXiv:2205.12898v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12898">
<div class="article-summary-box-inner">
<span><p>Some questions have multiple answers that are not equally correct, i.e.
answers are different under different conditions. Conditions are used to
distinguish answers as well as to provide additional information to support
them. In this paper, we study a more challenging task where answers are
constrained by a list of conditions that logically interact, which requires
performing logical reasoning over the conditions to determine the correctness
of the answers. Even more challenging, we only provide evidences for a subset
of the conditions, so some questions may not have deterministic answers. In
such cases, models are asked to find probable answers and identify conditions
that need to be satisfied to make the answers correct. We propose a new model,
TReasoner, for this challenging reasoning task. TReasoner consists of an
entailment module, a reasoning module, and a generation module (if the answers
are free-form text spans). TReasoner achieves state-of-the-art performance on
two benchmark conditional QA datasets, outperforming the previous
state-of-the-art by 3-10 points.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NaturalProver: Grounded Mathematical Proof Generation with Language Models. (arXiv:2205.12910v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12910">
<div class="article-summary-box-inner">
<span><p>Theorem proving in natural mathematical language - the mixture of symbolic
and natural language used by humans - plays a central role in mathematical
advances and education, and tests aspects of reasoning that are core to
intelligence. Yet it has remained underexplored with modern generative models.
We study large-scale language models on two new generation tasks: suggesting
the next step in a mathematical proof, and full proof generation. Naively
applying language models to these problems yields proofs riddled with
hallucinations and logical incoherence. We develop NaturalProver, a language
model that generates proofs by conditioning on background references (e.g.
theorems and definitions that are either retrieved or human-provided), and
optionally enforces their presence with constrained decoding. On theorems from
the NaturalProofs benchmark, NaturalProver improves the quality of next-step
suggestions and generated proofs over fine-tuned GPT-3, according to human
evaluations from university-level mathematics students. NaturalProver is
capable of proving some theorems that require short (2-6 step) proofs, and
providing next-step suggestions that are rated as correct and useful over 40%
of the time, which is to our knowledge the first demonstration of these
capabilities using neural language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">New Intent Discovery with Pre-training and Contrastive Learning. (arXiv:2205.12914v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12914">
<div class="article-summary-box-inner">
<span><p>New intent discovery aims to uncover novel intent categories from user
utterances to expand the set of supported intent classes. It is a critical task
for the development and service expansion of a practical dialogue system.
Despite its importance, this problem remains under-explored in the literature.
Existing approaches typically rely on a large amount of labeled utterances and
employ pseudo-labeling methods for representation learning and clustering,
which are label-intensive, inefficient, and inaccurate. In this paper, we
provide new solutions to two important research questions for new intent
discovery: (1) how to learn semantic utterance representations and (2) how to
better cluster utterances. Particularly, we first propose a multi-task
pre-training strategy to leverage rich unlabeled data along with external
labeled data for representation learning. Then, we design a new contrastive
loss to exploit self-supervisory signals in unlabeled data for clustering.
Extensive experiments on three intent recognition benchmarks demonstrate the
high effectiveness of our proposed method, which outperforms state-of-the-art
methods by a large margin in both unsupervised and semi-supervised scenarios.
The source code will be available at
\url{https://github.com/zhang-yu-wei/MTP-CLNN}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training Heterogeneous Features in Sequence to Sequence Tasks: Latent Enhanced Multi-filter Seq2Seq Model. (arXiv:2105.08840v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08840">
<div class="article-summary-box-inner">
<span><p>In language processing, training data with extremely large variance may lead
to difficulty in the language model's convergence. It is difficult for the
network parameters to adapt sentences with largely varied semantics or
grammatical structures. To resolve this problem, we introduce a model that
concentrates the each of the heterogeneous features in the input sentences.
Building upon the encoder-decoder architecture, we design a latent-enhanced
multi-filter seq2seq model (LEMS) that analyzes the input representations by
introducing a latent space transformation and clustering. The representations
are extracted from the final hidden state of the encoder and lie in the latent
space. A latent space transformation is applied for enhancing the quality of
the representations. Thus the clustering algorithm can easily separate samples
based on the features of these representations. Multiple filters are trained by
the features from their corresponding clusters, and the heterogeneity of the
training data can be resolved accordingly. We conduct two sets of comparative
experiments on semantic parsing and machine translation, using the Geo-query
dataset and Multi30k English-French to demonstrate the enhancement our model
has made respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Core Challenges in Embodied Vision-Language Planning. (arXiv:2106.13948v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13948">
<div class="article-summary-box-inner">
<span><p>Recent advances in the areas of multimodal machine learning and artificial
intelligence (AI) have led to the development of challenging tasks at the
intersection of Computer Vision, Natural Language Processing, and Embodied AI.
Whereas many approaches and previous survey pursuits have characterised one or
two of these dimensions, there has not been a holistic analysis at the center
of all three. Moreover, even when combinations of these topics are considered,
more focus is placed on describing, e.g., current architectural methods, as
opposed to also illustrating high-level challenges and opportunities for the
field. In this survey paper, we discuss Embodied Vision-Language Planning
(EVLP) tasks, a family of prominent embodied navigation and manipulation
problems that jointly use computer vision and natural language. We propose a
taxonomy to unify these tasks and provide an in-depth analysis and comparison
of the new and current algorithmic approaches, metrics, simulated environments,
as well as the datasets used for EVLP tasks. Finally, we present the core
challenges that we believe new EVLP works should seek to address, and we
advocate for task construction that enables model generalizability and furthers
real-world deployment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">So Cloze yet so Far: N400 Amplitude is Better Predicted by Distributional Information than Human Predictability Judgements. (arXiv:2109.01226v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01226">
<div class="article-summary-box-inner">
<span><p>More predictable words are easier to process - they are read faster and
elicit smaller neural signals associated with processing difficulty, most
notably, the N400 component of the event-related brain potential. Thus, it has
been argued that prediction of upcoming words is a key component of language
comprehension, and that studying the amplitude of the N400 is a valuable way to
investigate the predictions we make. In this study, we investigate whether the
linguistic predictions of computational language models or humans better
reflect the way in which natural language stimuli modulate the amplitude of the
N400. One important difference in the linguistic predictions of humans versus
computational language models is that while language models base their
predictions exclusively on the preceding linguistic context, humans may rely on
other factors. We find that the predictions of three top-of-the-line
contemporary language models - GPT-3, RoBERTa, and ALBERT - match the N400 more
closely than human predictions. This suggests that the predictive processes
underlying the N400 may be more sensitive to the surface-level statistics of
language than previously thought.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-Parametric Unsupervised Domain Adaptation for Neural Machine Translation. (arXiv:2109.06604v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.06604">
<div class="article-summary-box-inner">
<span><p>Recently, $k$NN-MT has shown the promising capability of directly
incorporating the pre-trained neural machine translation (NMT) model with
domain-specific token-level $k$-nearest-neighbor ($k$NN) retrieval to achieve
domain adaptation without retraining. Despite being conceptually attractive, it
heavily relies on high-quality in-domain parallel corpora, limiting its
capability on unsupervised domain adaptation, where in-domain parallel corpora
are scarce or nonexistent. In this paper, we propose a novel framework that
directly uses in-domain monolingual sentences in the target language to
construct an effective datastore for $k$-nearest-neighbor retrieval. To this
end, we first introduce an autoencoder task based on the target language, and
then insert lightweight adapters into the original NMT model to map the
token-level representation of this task to the ideal representation of
translation task. Experiments on multi-domain datasets demonstrate that our
proposed approach significantly improves the translation accuracy with
target-side monolingual data, while achieving comparable performance with
back-translation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models. (arXiv:2110.07736v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07736">
<div class="article-summary-box-inner">
<span><p>Recently, NLP models have achieved remarkable progress across a variety of
tasks; however, they have also been criticized for being not robust. Many
robustness problems can be attributed to models exploiting spurious
correlations, or shortcuts between the training data and the task labels. Most
existing work identifies a limited set of task-specific shortcuts via human
priors or error analyses, which requires extensive expertise and efforts. In
this paper, we aim to automatically identify such spurious correlations in NLP
models at scale. We first leverage existing interpretability methods to extract
tokens that significantly affect model's decision process from the input text.
We then distinguish "genuine" tokens and "spurious" tokens by analyzing model
predictions across multiple corpora and further verify them through
knowledge-aware perturbations. We show that our proposed method can effectively
and efficiently identify a scalable set of "shortcuts", and mitigating these
leads to more robust models in multiple applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DuQM: A Chinese Dataset of Linguistically Perturbed Natural Questions for Evaluating the Robustness of Question Matching Models. (arXiv:2112.08609v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.08609">
<div class="article-summary-box-inner">
<span><p>In this paper, we focus on studying robustness evaluation of Chinese question
matching. Most of the previous work on analyzing robustness issue focus on just
one or a few types of artificial adversarial examples. Instead, we argue that
it is necessary to formulate a comprehensive evaluation about the linguistic
capabilities of models on natural texts. For this purpose, we create a Chinese
dataset namely DuQM which contains natural questions with linguistic
perturbations to evaluate the robustness of question matching models. DuQM
contains 3 categories and 13 subcategories with 32 linguistic perturbations.
The extensive experiments demonstrate that DuQM has a better ability to
distinguish different models. Importantly, the detailed breakdown of evaluation
by linguistic phenomenon in DuQM helps us easily diagnose the strength and
weakness of different models. Additionally, our experiment results show that
the effect of artificial adversarial examples does not work on the natural
texts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sharpness-Aware Minimization with Dynamic Reweighting. (arXiv:2112.08772v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.08772">
<div class="article-summary-box-inner">
<span><p>Deep neural networks are often overparameterized and may not easily achieve
model generalization. Adversarial training has shown effectiveness in improving
generalization by regularizing the change of loss on top of adversarially
chosen perturbations. The recently proposed sharpness-aware minimization (SAM)
algorithm conducts adversarial weight perturbation, encouraging the model to
converge to a flat minima. SAM finds a common adversarial weight perturbation
per-batch. Although per-instance adversarial weight perturbations are stronger
adversaries and they can potentially lead to better generalization performance,
their computational cost is very high and thus it is impossible to use
per-instance perturbations efficiently in SAM. In this paper, we tackle this
efficiency bottleneck and propose sharpness-aware minimization with dynamic
reweighting ({\delta}-SAM). Our theoretical analysis motivates that it is
possible to approach the stronger, per-instance adversarial weight
perturbations using reweighted per-batch weight perturbations. {\delta}-SAM
dynamically reweights perturbation within each batch according to the
theoretically principled weighting factors, serving as a good approximation to
per-instance perturbation. Experiments on various natural language
understanding tasks demonstrate the effectiveness of {\delta}-SAM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Examining Single Sentence Label Leakage in Natural Language Inference Datasets. (arXiv:2112.09237v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.09237">
<div class="article-summary-box-inner">
<span><p>Many believe human-level natural language inference (NLI) has already been
achieved. In reality, modern NLI benchmarks have serious flaws, rendering
progress questionable. Chief among them is the problem of single sentence label
leakage, where spurious correlations and biases in datasets enable the accurate
prediction of a sentence pair relation from only a single sentence, something
that should in principle be impossible. This leakage enables models to cheat
rather than learn the desired reasoning capabilities, and hasn't gone away
since its 2018 discovery. We analyze this problem across 10 modern NLI
datasets, and find that new datasets have a single sentence accuracy of 8% over
chance at best and 19% on average. We examine how regular NLI models cheat on
this data and discuss how to ameliorate this.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Web Is Your Oyster - Knowledge-Intensive NLP against a Very Large Web Corpus. (arXiv:2112.09924v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.09924">
<div class="article-summary-box-inner">
<span><p>In order to address increasing demands of real-world applications, the
research for knowledge-intensive NLP (KI-NLP) should advance by capturing the
challenges of a truly open-domain environment: web-scale knowledge, lack of
structure, inconsistent quality and noise. To this end, we propose a new setup
for evaluating existing knowledge intensive tasks in which we generalize the
background corpus to a universal web snapshot. We investigate a slate of NLP
tasks which rely on knowledge - either factual or common sense, and ask systems
to use a subset of CCNet - the Sphere corpus - as a knowledge source. In
contrast to Wikipedia, otherwise a common background corpus in KI-NLP, Sphere
is orders of magnitude larger and better reflects the full diversity of
knowledge on the web. Despite potential gaps in coverage, challenges of scale,
lack of structure and lower quality, we find that retrieval from Sphere enables
a state of the art system to match and even outperform Wikipedia-based models
on several tasks. We also observe that while a dense index can outperform a
sparse BM25 baseline on Wikipedia, on Sphere this is not yet possible. To
facilitate further research and minimise the community's reliance on
proprietary, black-box search engines, we share our indices, evaluation metrics
and infrastructure.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Regularizing End-to-End Speech Translation with Triangular Decomposition Agreement. (arXiv:2112.10991v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.10991">
<div class="article-summary-box-inner">
<span><p>End-to-end speech-to-text translation (E2E-ST) is becoming increasingly
popular due to the potential of its less error propagation, lower latency, and
fewer parameters. Given the triplet training corpus $\langle speech,
transcription, translation\rangle$, the conventional high-quality E2E-ST system
leverages the $\langle speech, transcription\rangle$ pair to pre-train the
model and then utilizes the $\langle speech, translation\rangle$ pair to
optimize it further. However, this process only involves two-tuple data at each
stage, and this loose coupling fails to fully exploit the association between
triplet data. In this paper, we attempt to model the joint probability of
transcription and translation based on the speech input to directly leverage
such triplet data. Based on that, we propose a novel regularization method for
model training to improve the agreement of dual-path decomposition within
triplet data, which should be equal in theory. To achieve this goal, we
introduce two Kullback-Leibler divergence regularization terms into the model
training objective to reduce the mismatch between output probabilities of
dual-path. Then the well-trained model can be naturally transformed as the
E2E-ST models by the pre-defined early stop tag. Experiments on the MuST-C
benchmark demonstrate that our proposed approach significantly outperforms
state-of-the-art E2E-ST baselines on all 8 language pairs, while achieving
better performance in the automatic speech recognition task. Our code is
open-sourced at https://github.com/duyichao/E2E-ST-TDA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Should You Mask 15% in Masked Language Modeling?. (arXiv:2202.08005v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.08005">
<div class="article-summary-box-inner">
<span><p>Masked language models conventionally use a masking rate of 15% due to the
belief that more masking would provide insufficient context to learn good
representations, and less masking would make training too expensive.
Surprisingly, we find that masking up to 40% of input tokens can outperform the
15% baseline, and even masking 80% can preserve most of the performance, as
measured by finetuning on downstream tasks. Increasing the masking rates has
two distinct effects, which we investigate through careful ablations: (1) A
larger proportion of input tokens are corrupted, reducing the context size and
creating a harder task, and (2) models perform more predictions, which benefits
training. We observe that larger models with more capacity to tackle harder
tasks in particular favor higher masking rates. We also find that even more
sophisticated masking schemes such as span masking or PMI masking can benefit
from higher masking rates, albeit to a smaller extent. Our results contribute
to a better understanding of masked language modeling and shed light on more
efficient language pre-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Processing the structure of documents: Logical Layout Analysis of historical newspapers in French. (arXiv:2202.08125v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.08125">
<div class="article-summary-box-inner">
<span><p>Background. In recent years, libraries and archives led important
digitisation campaigns that opened the access to vast collections of historical
documents. While such documents are often available as XML ALTO documents, they
lack information about their logical structure. In this paper, we address the
problem of Logical Layout Analysis applied to historical documents in French.
We propose a rule-based method, that we evaluate and compare with two
Machine-Learning models, namely RIPPER and Gradient Boosting. Our data set
contains French newspapers, periodicals and magazines, published in the first
half of the twentieth century in the Franche-Comt\'e Region. Results. Our
rule-based system outperforms the two other models in nearly all evaluations.
It has especially better Recall results, indicating that our system covers more
types of every logical label than the other two models. When comparing RIPPER
with Gradient Boosting, we can observe that Gradient Boosting has better
Precision scores but RIPPER has better Recall scores. Conclusions. The
evaluation shows that our system outperforms the two Machine Learning models,
and provides significantly higher Recall. It also confirms that our system can
be used to produce annotated data sets that are large enough to envisage
Machine Learning or Deep Learning approaches for the task of Logical Layout
Analysis. Combining rules and Machine Learning models into hybrid systems could
potentially provide even better performances. Furthermore, as the layout in
historical documents evolves rapidly, one possible solution to overcome this
problem would be to apply Rule Learning algorithms to bootstrap rule sets
adapted to different publication periods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Learning of Sociopragmatic Meaning in Social Media. (arXiv:2203.07648v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07648">
<div class="article-summary-box-inner">
<span><p>Recent progress in representation and contrastive learning in NLP has not
widely considered the class of \textit{sociopragmatic meaning} (i.e., meaning
in interaction within different language communities). To bridge this gap, we
propose a novel framework for learning task-agnostic representations
transferable to a wide range of sociopragmatic tasks (e.g., emotion, hate
speech, humor, sarcasm). Our framework outperforms other contrastive learning
frameworks for both in-domain and out-of-domain data, across both the general
and few-shot settings. For example, compared to two popular pre-trained
language models, our method obtains an improvement of $11.66$ average $F_1$ on
$16$ datasets when fine-tuned on only $20$ training samples per dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FastKASSIM: A Fast Tree Kernel-Based Syntactic Similarity Metric. (arXiv:2203.08299v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08299">
<div class="article-summary-box-inner">
<span><p>Syntax is a fundamental component of language, yet few metrics have been
employed to capture syntactic similarity or coherence at the utterance- and
document-level. The existing standard document-level syntactic similarity
metric is computationally expensive and performs inconsistently when faced with
syntactically dissimilar documents. To address these challenges, we present
FastKASSIM, a metric for utterance- and document-level syntactic similarity
which pairs and averages the most similar dependency parse trees between a pair
of documents based on tree kernels. FastKASSIM is more robust to syntactic
dissimilarities and runs up to to 5.32 times faster than the baseline method
over the documents in the r/ChangeMyView corpus. These improvements allow us to
examine hypotheses in two settings with large documents: persuasive online
arguments on r/ChangeMyView, and authorship attribution in the Australian High
Court Judgment corpus. With FastKASSIM, we are able to show that more
syntactically similar arguments tend to be more persuasive, and that syntax
provides a key indicator of writing style.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hyperdecoders: Instance-specific decoders for multi-task NLP. (arXiv:2203.08304v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08304">
<div class="article-summary-box-inner">
<span><p>We investigate input-conditioned hypernetworks for multi-tasking in NLP,
generating parameter-efficient adaptations for a decoder using a hypernetwork
conditioned on the output of an encoder. This approach produces a unique
decoder for every input instance, allowing the network a larger degree of
flexibility than prior work that specializes the decoder for each task. We
apply our method to sequence classification tasks, extractive QA, and
summarisation and find that it surpasses previous parameter efficient
fine-tuning methods and often outperforms fully finetuning the underlying
model. An analysis of the embeddings used by our hypernetwork shows that they
are sensitive to output label and type, suggesting that our approach better
maps from encoder representations to output labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DuReader_retrieval: A Large-scale Chinese Benchmark for Passage Retrieval from Web Search Engine. (arXiv:2203.10232v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.10232">
<div class="article-summary-box-inner">
<span><p>In this paper, we present DuReader-retrieval, a large-scale Chinese dataset
for passage retrieval. DuReader-retrieval contains more than 90K queries and
over 8M unique passages from Baidu search. To ensure the quality of our
benchmark and address the shortcomings in other existing datasets, we (1)
reduce the false negatives in development and testing sets by pooling the
results from multiple retrievers with human annotations, (2) and remove the
training queries that are semantically similar to the development and testing
queries. Additionally, we provide two out-of-domain testing sets for
cross-domain evaluation, as well as a cross-lingual set that has been manually
translated for cross-lingual retrieval. The experiments demonstrate that
DuReader-retrieval is challenging and there is still plenty of room for
improvement, e.g. salient phrase and syntax mismatch between query and
paragraph. These experimental results show that the dense retriever does not
generalize well across domains, and cross-lingual retrieval is essentially
challenging. DuReader-retrieval will be publicly available at
https://github.com/baidu/DuReader/tree/master/DuReader-Retrieval.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">drsphelps at SemEval-2022 Task 2: Learning idiom representations using BERTRAM. (arXiv:2204.02821v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.02821">
<div class="article-summary-box-inner">
<span><p>This paper describes our system for SemEval-2022 Task 2 Multilingual
Idiomaticity Detection and Sentence Embedding sub-task B. We modify a standard
BERT sentence transformer by adding embeddings for each idioms, which are
created using BERTRAM and a small number of contexts. We show that this
technique increases the quality of idiom representations and leads to better
performance on the task. We also perform analysis on our final results and show
that the quality of the produced idiom embeddings is highly sensitive to the
quality of the input contexts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks. (arXiv:2204.02892v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.02892">
<div class="article-summary-box-inner">
<span><p>The field of Natural Language Processing has experienced a dramatic leap in
capabilities with the recent introduction of huge Language Models. Despite this
success, natural language problems that involve several compounded steps are
still practically unlearnable, even by the largest LMs. This complies with
experimental failures for end-to-end learning of composite problems that were
demonstrated in a variety of domains. An effective mitigation is to introduce
intermediate supervision for solving sub-tasks of the compounded problem.
Recently, several works have demonstrated high gains by taking a
straightforward approach for incorporating intermediate supervision in
compounded natural language problems: the sequence-to-sequence LM is fed with
an augmented input, in which the decomposed tasks' labels are simply
concatenated to the original input. In this paper, we prove a positive learning
result that motivates these recent efforts. We show that when concatenating
intermediate supervision to the input and training a sequence-to-sequence model
on this modified input, unlearnable composite problems can become learnable. We
show that this is true for any family of tasks which on the one hand, are
unlearnable, and on the other hand, can be decomposed into a polynomial number
of simple sub-tasks, each of which depends only on O(1) previous sub-task
results. Beyond motivating contemporary empirical efforts for incorporating
intermediate supervision in sequence-to-sequence language models, our positive
theoretical result is the first of its kind in the landscape of results on the
benefits of intermediate supervision for neural-network learning: Until now,
all theoretical results on the subject are negative, i.e., show cases where
learning is impossible without intermediate supervision, while our result is
positive, showing that learning is facilitated in the presence of intermediate
supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment. (arXiv:2204.09148v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.09148">
<div class="article-summary-box-inner">
<span><p>The instruction learning paradigm -- where a model learns to perform new
tasks from task descriptions alone -- has become popular in general-purpose
model research. The capabilities of large transformer models as instruction
learners, however, remain poorly understood. We use a controlled synthetic
environment to characterize such capabilities. Specifically, we use the task of
deciding whether a given string matches a regular expression (viewed as an
instruction) to identify properties of tasks, instructions, and instances that
make instruction learning challenging. For instance, we find that our model, a
fine-tuned T5-based text2text transformer, struggles with large regular
languages, suggesting that less precise instructions are challenging for
models. Additionally, instruction executions that require tracking longer
contexts of prior steps are also more difficult. We use our findings to
systematically construct a challenging instruction learning dataset, which we
call Hard RegSet. Fine-tuning on Hard RegSet, our large transformer learns to
correctly interpret only 65.6% of test instructions (with at least 90%
accuracy), and 11%-24% of the instructions in out-of-distribution
generalization settings. We propose Hard RegSet as a challenging instruction
learning task, and a controlled environment for studying instruction learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MEKER: Memory Efficient Knowledge Embedding Representation for Link Prediction and Question Answering. (arXiv:2204.10629v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.10629">
<div class="article-summary-box-inner">
<span><p>Knowledge Graphs (KGs) are symbolically structured storages of facts. The KG
embedding contains concise data used in NLP tasks requiring implicit
information about the real world. Furthermore, the size of KGs that may be
useful in actual NLP assignments is enormous, and creating embedding over it
has memory cost issues. We represent KG as a 3rd-order binary tensor and move
beyond the standard CP decomposition by using a data-specific generalized
version of it. The generalization of the standard CP-ALS algorithm allows
obtaining optimization gradients without a backpropagation mechanism. It
reduces the memory needed in training while providing computational benefits.
We propose a MEKER, a memory-efficient KG embedding model, which yields
SOTA-comparable performance on link prediction tasks and KG-based Question
Answering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantifying Language Variation Acoustically with Few Resources. (arXiv:2205.02694v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.02694">
<div class="article-summary-box-inner">
<span><p>Deep acoustic models represent linguistic information based on massive
amounts of data. Unfortunately, for regional languages and dialects such
resources are mostly not available. However, deep acoustic models might have
learned linguistic information that transfers to low-resource languages. In
this study, we evaluate whether this is the case through the task of
distinguishing low-resource (Dutch) regional varieties. By extracting
embeddings from the hidden layers of various wav2vec 2.0 models (including new
models which are pre-trained and/or fine-tuned on Dutch) and using dynamic time
warping, we compute pairwise pronunciation differences averaged over 10 words
for over 100 individual dialects from four (regional) languages. We then
cluster the resulting difference matrix in four groups and compare these to a
gold standard, and a partitioning on the basis of comparing phonetic
transcriptions. Our results show that acoustic models outperform the
(traditional) transcription-based approach without requiring phonetic
transcriptions, with the best performance achieved by the multilingual XLSR-53
model fine-tuned on Dutch. On the basis of only six seconds of speech, the
resulting clustering closely matches the gold standard.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-Parametric Domain Adaptation for End-to-End Speech Translation. (arXiv:2205.11211v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11211">
<div class="article-summary-box-inner">
<span><p>End-to-End Speech Translation (E2E-ST) has received increasing attention due
to the potential of its less error propagation, lower latency, and fewer
parameters. However, the effectiveness of neural-based approaches to this task
is severely limited by the available training corpus, especially for domain
adaptation where in-domain triplet training data is scarce or nonexistent. In
this paper, we propose a novel non-parametric method that leverages
domain-specific text translation corpus to achieve domain adaptation for the
E2E-ST system. To this end, we first incorporate an additional encoder into the
pre-trained E2E-ST model to realize text translation modelling, and then unify
the decoder's output representation for text and speech translation tasks by
reducing the correspondent representation mismatch in available triplet
training data. During domain adaptation, a k-nearest-neighbor (kNN) classifier
is introduced to produce the final translation distribution using the external
datastore built by the domain-specific text translation corpus, while the
universal output representation is adopted to perform a similarity search.
Experiments on the Europarl-ST benchmark demonstrate that when in-domain text
translation data is involved only, our proposed approach significantly improves
baseline by 12.82 BLEU on average in all translation directions, even
outperforming the strong in-domain fine-tuning method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Paradox of Learning to Reason from Data. (arXiv:2205.11502v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11502">
<div class="article-summary-box-inner">
<span><p>Logical reasoning is needed in a wide range of NLP tasks. Can a BERT model be
trained end-to-end to solve logical reasoning problems presented in natural
language? We attempt to answer this question in a confined problem space where
there exists a set of parameters that perfectly simulates logical reasoning. We
make observations that seem to contradict each other: BERT attains near-perfect
accuracy on in-distribution test examples while failing to generalize to other
data distributions over the exact same problem space. Our study provides an
explanation for this paradox: instead of learning to emulate the correct
reasoning function, BERT has in fact learned statistical features that
inherently exist in logical reasoning problems. We also show that it is
infeasible to jointly remove statistical features from data, illustrating the
difficulty of learning to reason in general. Our result naturally extends to
other neural models and unveils the fundamental difference between learning to
reason and learning to achieve high performance on NLP benchmarks using
statistical features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Level Modeling Units for End-to-End Mandarin Speech Recognition. (arXiv:2205.11998v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11998">
<div class="article-summary-box-inner">
<span><p>The choice of modeling units affects the performance of the acoustic modeling
and plays an important role in automatic speech recognition (ASR). In mandarin
scenarios, the Chinese characters represent meaning but are not directly
related to the pronunciation. Thus only considering the writing of Chinese
characters as modeling units is insufficient to capture speech features. In
this paper, we present a novel method involves with multi-level modeling units,
which integrates multi-level information for mandarin speech recognition.
Specifically, the encoder block considers syllables as modeling units, and the
decoder block deals with character modeling units. During inference, the input
feature sequences are converted into syllable sequences by the encoder block
and then converted into Chinese characters by the decoder block. This process
is conducted by a unified end-to-end model without introducing additional
conversion models. By introducing InterCE auxiliary task, our method achieves
competitive results with CER of 4.1%/4.6% and 4.6%/5.2% on the widely used
AISHELL-1 benchmark without a language model, using the Conformer and the
Transformer backbones respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">mPLUG: Effective and Efficient Vision-Language Learning by Cross-modal Skip-connections. (arXiv:2205.12005v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12005">
<div class="article-summary-box-inner">
<span><p>Large-scale pretrained foundation models have been an emerging paradigm for
building artificial intelligence (AI) systems, which can be quickly adapted to
a wide range of downstream tasks. This paper presents mPLUG, a new
vision-language foundation model for both cross-modal understanding and
generation. Most existing pre-trained models suffer from the problems of low
computational efficiency and information asymmetry brought by the long visual
sequence in cross-modal alignment. To address these problems, mPLUG introduces
an effective and efficient vision-language architecture with novel cross-modal
skip-connections, which creates inter-layer shortcuts that skip a certain
number of layers for time-consuming full self-attention on the vision side.
mPLUG is pre-trained end-to-end on large-scale image-text pairs with both
discriminative and generative objectives. It achieves state-of-the-art results
on a wide range of vision-language downstream tasks, such as image captioning,
image-text retrieval, visual grounding and visual question answering. mPLUG
also demonstrates strong zero-shot transferability when directly transferred to
multiple video-language tasks.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Action Recognition for American Sign Language. (arXiv:2205.12261v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12261">
<div class="article-summary-box-inner">
<span><p>In this research, we present our findings to recognize American Sign Language
from series of hand gestures. While most researches in literature focus only on
static handshapes, our work target dynamic hand gestures. Since dynamic signs
dataset are very few, we collect an initial dataset of 150 videos for 10 signs
and an extension of 225 videos for 15 signs. We apply transfer learning models
in combination with deep neural networks and background subtraction for videos
in different temporal settings. Our primarily results show that we can get an
accuracy of $0.86$ and $0.71$ using DenseNet201, LSTM with video sequence of 12
frames accordingly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Wavelet Feature Maps Compression for Image-to-Image CNNs. (arXiv:2205.12268v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12268">
<div class="article-summary-box-inner">
<span><p>Convolutional Neural Networks (CNNs) are known for requiring extensive
computational resources, and quantization is among the best and most common
methods for compressing them. While aggressive quantization (i.e., less than
4-bits) performs well for classification, it may cause severe performance
degradation in image-to-image tasks such as semantic segmentation and depth
estimation. In this paper, we propose Wavelet Compressed Convolution (WCC) -- a
novel approach for high-resolution activation maps compression integrated with
point-wise convolutions, which are the main computational cost of modern
architectures. To this end, we use an efficient and hardware-friendly
Haar-wavelet transform, known for its effectiveness in image compression, and
define the convolution on the compressed activation map. We experiment on
various tasks, that benefit from high-resolution input, and by combining WCC
with light quantization, we achieve compression rates equivalent to 1-4bit
activation quantization with relatively small and much more graceful
degradation in performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trajectory Optimization for Physics-Based Reconstruction of 3d Human Pose from Monocular Video. (arXiv:2205.12292v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12292">
<div class="article-summary-box-inner">
<span><p>We focus on the task of estimating a physically plausible articulated human
motion from monocular video. Existing approaches that do not consider physics
often produce temporally inconsistent output with motion artifacts, while
state-of-the-art physics-based approaches have either been shown to work only
in controlled laboratory conditions or consider simplified body-ground contact
limited to feet. This paper explores how these shortcomings can be addressed by
directly incorporating a fully-featured physics engine into the pose estimation
process. Given an uncontrolled, real-world scene as input, our approach
estimates the ground-plane location and the dimensions of the physical body
model. It then recovers the physical motion by performing trajectory
optimization. The advantage of our formulation is that it readily generalizes
to a variety of scenes that might have diverse ground properties and supports
any form of self-contact and contact between the articulated body and scene
geometry. We show that our approach achieves competitive results with respect
to existing physics-based methods on the Human3.6M benchmark, while being
directly applicable without re-training to more complex dynamic motions from
the AIST benchmark and to uncontrolled internet videos.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Face2Text revisited: Improved data set and baseline results. (arXiv:2205.12342v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12342">
<div class="article-summary-box-inner">
<span><p>Current image description generation models do not transfer well to the task
of describing human faces. To encourage the development of more human-focused
descriptions, we developed a new data set of facial descriptions based on the
CelebA image data set. We describe the properties of this data set, and present
results from a face description generator trained on it, which explores the
feasibility of using transfer learning from VGGFace/ResNet CNNs. Comparisons
are drawn through both automated metrics and human evaluation by 76
English-speaking participants. The descriptions generated by the VGGFace-LSTM +
Attention model are closest to the ground truth according to human evaluation
whilst the ResNet-LSTM + Attention model obtained the highest CIDEr and CIDEr-D
results (1.252 and 0.686 respectively). Together, the new data set and these
experimental results provide data and baselines for future work in this area.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Benchmark and Asymmetrical-Similarity Learning for Practical Image Copy Detection. (arXiv:2205.12358v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12358">
<div class="article-summary-box-inner">
<span><p>Image copy detection (ICD) aims to determine whether a query image is an
edited copy of any image from a reference set. Currently, there are very
limited public benchmarks for ICD, while all overlook a critical challenge in
real-world applications, i.e., the distraction from hard negative queries.
Specifically, some queries are not edited copies but are inherently similar to
some reference images. These hard negative queries are easily false recognized
as edited copies, significantly compromising the ICD accuracy. This observation
motivates us to build the first ICD benchmark featuring this characteristic.
Based on existing ICD datasets, this paper constructs a new dataset by
additionally adding 100, 000 and 24, 252 hard negative pairs into the training
and test set, respectively. Moreover, this paper further reveals a unique
difficulty for solving the hard negative problem in ICD, i.e., there is a
fundamental conflict between current metric learning and ICD. This conflict is:
the metric learning adopts symmetric distance while the edited copy is an
asymmetric (unidirectional) process, e.g., a partial crop is close to its
holistic reference image and is an edited copy, while the latter cannot be the
edited copy of the former (in spite the distance is equally small). This
insight results in an Asymmetrical-Similarity Learning (ASL) method, which
allows the similarity in two directions (the query &lt;-&gt; the reference image) to
be different from each other. Experimental results show that ASL outperforms
state-of-the-art methods by a clear margin, confirming that solving the
symmetric-asymmetric conflict is critical for ICD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Jointly Optimizing Color Rendition and In-Camera Backgrounds in an RGB Virtual Production Stage. (arXiv:2205.12403v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12403">
<div class="article-summary-box-inner">
<span><p>While the LED panels used in virtual production systems can display vibrant
imagery with a wide color gamut, they produce problematic color shifts when
used as lighting due to their peaky spectral output from narrow-band red,
green, and blue LEDs. In this work, we present an improved color calibration
process for virtual production stages which ameliorates this color rendition
problem while also passing through accurate in-camera background colors. We do
this by optimizing linear color correction transformations for 1) the LED panel
pixels visible in the field of view of the camera, 2) the pixels outside the
field of view of the camera illuminating the subjects, and, as a post-process,
3) the pixel values recorded by the camera. The result is that footage shot in
an RGB LED panel virtual production stage can exhibit more accurate skin tones
and costume colors while still reproducing the desired colors of the in-camera
background.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Convolutional Neural Processes for Inpainting Satellite Images. (arXiv:2205.12407v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12407">
<div class="article-summary-box-inner">
<span><p>The widespread availability of satellite images has allowed researchers to
model complex systems such as disease dynamics. However, many satellite images
have missing values due to measurement defects, which render them unusable
without data imputation. For example, the scanline corrector for the LANDSAT 7
satellite broke down in 2003, resulting in a loss of around 20\% of its data.
Inpainting involves predicting what is missing based on the known pixels and is
an old problem in image processing, classically based on PDEs or interpolation
methods, but recent deep learning approaches have shown promise. However, many
of these methods do not explicitly take into account the inherent
spatiotemporal structure of satellite images. In this work, we cast satellite
image inpainting as a natural meta-learning problem, and propose using
convolutional neural processes (ConvNPs) where we frame each satellite image as
its own task or 2D regression problem. We show ConvNPs can outperform classical
methods and state-of-the-art deep learning inpainting models on a scanline
inpainting problem for LANDSAT 7 satellite images, assessed on a variety of in
and out-of-distribution images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interaction of a priori Anatomic Knowledge with Self-Supervised Contrastive Learning in Cardiac Magnetic Resonance Imaging. (arXiv:2205.12429v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12429">
<div class="article-summary-box-inner">
<span><p>Training deep learning models on cardiac magnetic resonance imaging (CMR) can
be a challenge due to the small amount of expert generated labels and inherent
complexity of data source. Self-supervised contrastive learning (SSCL) has
recently been shown to boost performance in several medical imaging tasks.
However, it is unclear how much the pre-trained representation reflects the
primary organ of interest compared to spurious surrounding tissue. In this
work, we evaluate the optimal method of incorporating prior knowledge of
anatomy into a SSCL training paradigm. Specifically, we evaluate using a
segmentation network to explicitly local the heart in CMR images, followed by
SSCL pretraining in multiple diagnostic tasks. We find that using a priori
knowledge of anatomy can greatly improve the downstream diagnostic performance.
Furthermore, SSCL pre-training with in-domain data generally improved
downstream performance and more human-like saliency compared to end-to-end
training and ImageNet pre-trained networks. However, introducing anatomic
knowledge to pre-training generally does not have significant impact.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Skin Cancer Diagnostics with an All-Inclusive Smartphone Application. (arXiv:2205.12438v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12438">
<div class="article-summary-box-inner">
<span><p>Among the different types of skin cancer, melanoma is considered to be the
deadliest and is difficult to treat at advanced stages. Detection of melanoma
at earlier stages can lead to reduced mortality rates. Desktop-based
computer-aided systems have been developed to assist dermatologists with early
diagnosis. However, there is significant interest in developing portable,
at-home melanoma diagnostic systems which can assess the risk of cancerous skin
lesions. Here, we present a smartphone application that combines image capture
capabilities with preprocessing and segmentation to extract the Asymmetry,
Border irregularity, Color variegation, and Diameter (ABCD) features of a skin
lesion. Using the feature sets, classification of malignancy is achieved
through support vector machine classifiers. By using adaptive algorithms in the
individual data-processing stages, our approach is made computationally light,
user friendly, and reliable in discriminating melanoma cases from benign ones.
Images of skin lesions are either captured with the smartphone camera or
imported from public datasets. The entire process from image capture to
classification runs on an Android smartphone equipped with a detachable 10x
lens, and processes an image in less than a second. The overall performance
metrics are evaluated on a public database of 200 images with Synthetic
Minority Over-sampling Technique (SMOTE) (80% sensitivity, 90% specificity, 88%
accuracy, and 0.85 area under curve (AUC)) and without SMOTE (55% sensitivity,
95% specificity, 90% accuracy, and 0.75 AUC). The evaluated performance metrics
and computation times are comparable or better than previous methods. This
all-inclusive smartphone application is designed to be easy-to-download and
easy-to-navigate for the end user, which is imperative for the eventual
democratization of such medical diagnostic systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Domain Style Mixing for Face Cartoonization. (arXiv:2205.12450v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12450">
<div class="article-summary-box-inner">
<span><p>Cartoon domain has recently gained increasing popularity. Previous studies
have attempted quality portrait stylization into the cartoon domain; however,
this poses a great challenge since they have not properly addressed the
critical constraints, such as requiring a large number of training images or
the lack of support for abstract cartoon faces. Recently, a layer swapping
method has been used for stylization requiring only a limited number of
training images; however, its use cases are still narrow as it inherits the
remaining issues. In this paper, we propose a novel method called Cross-domain
Style mixing, which combines two latent codes from two different domains. Our
method effectively stylizes faces into multiple cartoon characters at various
face abstraction levels using only a single generator without even using a
large number of training images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Region-aware Knowledge Distillation for Efficient Image-to-Image Translation. (arXiv:2205.12451v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12451">
<div class="article-summary-box-inner">
<span><p>Recent progress in image-to-image translation has witnessed the success of
generative adversarial networks (GANs). However, GANs usually contain a huge
number of parameters, which lead to intolerant memory and computation
consumption and limit their deployment on edge devices. To address this issue,
knowledge distillation is proposed to transfer the knowledge from a cumbersome
teacher model to an efficient student model. However, most previous knowledge
distillation methods are designed for image classification and lead to limited
performance in image-to-image translation. In this paper, we propose
Region-aware Knowledge Distillation ReKo to compress image-to-image translation
models. Firstly, ReKo adaptively finds the crucial regions in the images with
an attention module. Then, patch-wise contrastive learning is adopted to
maximize the mutual information between students and teachers in these crucial
regions. Experiments with eight comparison methods on nine datasets demonstrate
the substantial effectiveness of ReKo on both paired and unpaired
image-to-image translation. For instance, our 7.08X compressed and 6.80X
accelerated CycleGAN student outperforms its teacher by 1.33 and 1.04 FID
scores on Horse to Zebra and Zebra to Horse, respectively. Codes will be
released on GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Lightweight NMS-free Framework for Real-time Visual Fault Detection System of Freight Trains. (arXiv:2205.12458v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12458">
<div class="article-summary-box-inner">
<span><p>Real-time vision-based system of fault detection (RVBS-FD) for freight trains
is an essential part of ensuring railway transportation safety. Most existing
vision-based methods still have high computational costs based on convolutional
neural networks. The computational cost is mainly reflected in the backbone,
neck, and post-processing, i.e., non-maximum suppression (NMS). In this paper,
we propose a lightweight NMS-free framework to achieve real-time detection and
high accuracy simultaneously. First, we use a lightweight backbone for feature
extraction and design a fault detection pyramid to process features. This fault
detection pyramid includes three novel individual modules using attention
mechanism, bottleneck, and dilated convolution for feature enhancement and
computation reduction. Instead of using NMS, we calculate different loss
functions, including classification and location costs in the detection head,
to further reduce computation. Experimental results show that our framework
achieves over 83 frames per second speed with a smaller model size and higher
accuracy than the state-of-the-art detectors. Meanwhile, the hardware resource
requirements of our method are low during the training and testing process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A CNN with Noise Inclined Module and Denoise Framework for Hyperspectral Image Classification. (arXiv:2205.12459v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12459">
<div class="article-summary-box-inner">
<span><p>Deep Neural Networks have been successfully applied in hyperspectral image
classification. However, most of prior works adopt general deep architectures
while ignore the intrinsic structure of the hyperspectral image, such as the
physical noise generation. This would make these deep models unable to generate
discriminative features and provide impressive classification performance. To
leverage such intrinsic information, this work develops a novel deep learning
framework with the noise inclined module and denoise framework for
hyperspectral image classification. First, we model the spectral signature of
hyperspectral image with the physical noise model to describe the high
intraclass variance of each class and great overlapping between different
classes in the image. Then, a noise inclined module is developed to capture the
physical noise within each object and a denoise framework is then followed to
remove such noise from the object. Finally, the CNN with noise inclined module
and the denoise framework is developed to obtain discriminative features and
provides good classification performance of hyperspectral image. Experiments
are conducted over two commonly used real-world datasets and the experimental
results show the effectiveness of the proposed method. The implementation of
the proposed method and other compared methods could be accessed at
https://github.com/shendu-sw/noise-physical-framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">sat2pc: Estimating Point Cloud of Building Roofs from 2D Satellite Images. (arXiv:2205.12464v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12464">
<div class="article-summary-box-inner">
<span><p>Three-dimensional (3D) urban models have gained interest because of their
applications in many use-cases such as urban planning and virtual reality.
However, generating these 3D representations requires LiDAR data, which are not
always readily available. Thus, the applicability of automated 3D model
generation algorithms is limited to a few locations. In this paper, we propose
sat2pc, a deep learning architecture that predicts the point cloud of a
building roof from a single 2D satellite image. Our architecture combines
Chamfer distance and EMD loss, resulting in better 2D to 3D performance. We
extensively evaluate our model and perform ablation studies on a building roof
dataset. Our results show that sat2pc was able to outperform existing baselines
by at least 18.6%. Further, we show that the predicted point cloud captures
more detail and geometric characteristics than other baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Eye-gaze-guided Vision Transformer for Rectifying Shortcut Learning. (arXiv:2205.12466v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12466">
<div class="article-summary-box-inner">
<span><p>Learning harmful shortcuts such as spurious correlations and biases prevents
deep neural networks from learning the meaningful and useful representations,
thus jeopardizing the generalizability and interpretability of the learned
representation. The situation becomes even more serious in medical imaging,
where the clinical data (e.g., MR images with pathology) are limited and scarce
while the reliability, generalizability and transparency of the learned model
are highly required. To address this problem, we propose to infuse human
experts' intelligence and domain knowledge into the training of deep neural
networks. The core idea is that we infuse the visual attention information from
expert radiologists to proactively guide the deep model to focus on regions
with potential pathology and avoid being trapped in learning harmful shortcuts.
To do so, we propose a novel eye-gaze-guided vision transformer (EG-ViT) for
diagnosis with limited medical image data. We mask the input image patches that
are out of the radiologists' interest and add an additional residual connection
in the last encoder layer of EG-ViT to maintain the correlations of all
patches. The experiments on two public datasets of INbreast and SIIM-ACR
demonstrate our EG-ViT model can effectively learn/transfer experts' domain
knowledge and achieve much better performance than baselines. Meanwhile, it
successfully rectifies the harmful shortcut learning and significantly improves
the EG-ViT model's interpretability. In general, EG-ViT takes the advantages of
both human expert's prior knowledge and the power of deep neural networks. This
work opens new avenues for advancing current artificial intelligence paradigms
by infusing human intelligence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Textured Mesh Recovery from Multiple Views with Differentiable Rendering. (arXiv:2205.12468v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12468">
<div class="article-summary-box-inner">
<span><p>Despite of the promising results on shape and color recovery using
self-supervision, the multi-layer perceptrons-based methods usually costs hours
to train the deep neural network due to the implicit surface representation.
Moreover, it is quite computational intensive to render a single image, since a
forward network inference is required for each pixel. To tackle these
challenges, in this paper, we propose an efficient coarse-to-fine approach to
recover the textured mesh from multi-view images. Specifically, we take
advantage of a differentiable Poisson Solver to represent the shape, which is
able to produce topology-agnostic and watertight surfaces. To account for the
depth information, we optimize the shape geometry by minimizing the difference
between the rendered mesh with the depth predicted by the learning-based
multi-view stereo algorithm. In contrast to the implicit neural representation
on shape and color, we introduce a physically based inverse rendering scheme to
jointly estimate the lighting and reflectance of the objects, which is able to
render the high resolution image at real-time. Additionally, we fine-tune the
extracted mesh by inverse rendering to obtain the mesh with fine details and
high fidelity image. We have conducted the extensive experiments on several
multi-view stereo datasets, whose promising results demonstrate the efficacy of
our proposed approach. We will make our full implementation publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Dialog Must Go On: Improving Visual Dialog via Generative Self-Training. (arXiv:2205.12502v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12502">
<div class="article-summary-box-inner">
<span><p>Visual dialog (VisDial) is a task of answering a sequence of questions
grounded in an image, using the dialog history as context. Prior work has
trained the dialog agents solely on VisDial data via supervised learning or
leveraged pre-training on related vision-and-language datasets. This paper
presents a semi-supervised learning approach for visually-grounded dialog,
called Generative Self-Training (GST), to leverage unlabeled images on the Web.
Specifically, GST first retrieves in-domain images through out-of-distribution
detection and generates synthetic dialogs regarding the images via multimodal
conditional text generation. GST then trains a dialog agent on the synthetic
and the original VisDial data. As a result, GST scales the amount of training
data up to an order of magnitude that of VisDial (1.2M to 12.9M QA data). For
robust training of the generated dialogs, we also propose perplexity-based data
selection and multimodal consistency regularization. Evaluation on VisDial v1.0
and v0.9 datasets shows that GST achieves new state-of-the-art results on both
datasets. We further observe strong performance gains in the low-data regime
(up to 9.35 absolute points on NDCG).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text-to-Face Generation with StyleGAN2. (arXiv:2205.12512v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12512">
<div class="article-summary-box-inner">
<span><p>Synthesizing images from text descriptions has become an active research area
with the advent of Generative Adversarial Networks. The main goal here is to
generate photo-realistic images that are aligned with the input descriptions.
Text-to-Face generation (T2F) is a sub-domain of Text-to-Image generation (T2I)
that is more challenging due to the complexity and variation of facial
attributes. It has a number of applications mainly in the domain of public
safety. Even though several models are available for T2F, there is still the
need to improve the image quality and the semantic alignment. In this research,
we propose a novel framework, to generate facial images that are well-aligned
with the input descriptions. Our framework utilizes the high-resolution face
generator, StyleGAN2, and explores the possibility of using it in T2F. Here, we
embed text in the input latent space of StyleGAN2 using BERT embeddings and
oversee the generation of facial images using text descriptions. We trained our
framework on attribute-based descriptions to generate images of 1024x1024 in
resolution. The images generated exhibit a 57% similarity to the ground truth
images, with a face semantic distance of 0.92, outperforming
state-of-the-artwork. The generated images have a FID score of 118.097 and the
experimental results show that our model generates promising images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structure Aware and Class Balanced 3D Object Detection on nuScenes Dataset. (arXiv:2205.12519v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12519">
<div class="article-summary-box-inner">
<span><p>3-D object detection is pivotal for autonomous driving. Point cloud based
methods have become increasingly popular for 3-D object detection, owing to
their accurate depth information. NuTonomy's nuScenes dataset greatly extends
commonly used datasets such as KITTI in size, sensor modalities, categories,
and annotation numbers. However, it suffers from severe class imbalance. The
Class-balanced Grouping and Sampling paper addresses this issue and suggests
augmentation and sampling strategy. However, the localization precision of this
model is affected by the loss of spatial information in the downscaled feature
maps. We propose to enhance the performance of the CBGS model by designing an
auxiliary network, that makes full use of the structure information of the 3D
point cloud, in order to improve the localization accuracy. The detachable
auxiliary network is jointly optimized by two point-level supervisions, namely
foreground segmentation and center estimation. The auxiliary network does not
introduce any extra computation during inference, since it can be detached at
test time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset. (arXiv:2205.12522v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12522">
<div class="article-summary-box-inner">
<span><p>Research in massively multilingual image captioning has been severely
hampered by a lack of high-quality evaluation datasets. In this paper we
present the Crossmodal-3600 dataset (XM3600 in short), a geographically diverse
set of 3600 images annotated with human-generated reference captions in 36
languages. The images were selected from across the world, covering regions
where the 36 languages are spoken, and annotated with captions that achieve
consistency in terms of style across all languages, while avoiding annotation
artifacts due to direct translation. We apply this benchmark to model selection
for massively multilingual image captioning models, and show superior
correlation results with human evaluations when using XM3600 as golden
references for automatic metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accelerating Diffusion Models via Early Stop of the Diffusion Process. (arXiv:2205.12524v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12524">
<div class="article-summary-box-inner">
<span><p>Denoising Diffusion Probabilistic Models (DDPMs) have achieved impressive
performance on various generation tasks. By modeling the reverse process of
gradually diffusing the data distribution into a Gaussian distribution,
generating a sample in DDPMs can be regarded as iteratively denoising a
randomly sampled Gaussian noise. However, in practice DDPMs often need hundreds
even thousands of denoising steps to obtain a high-quality sample from the
Gaussian noise, leading to extremely low inference efficiency. In this work, we
propose a principled acceleration strategy, referred to as Early-Stopped DDPM
(ES-DDPM), for DDPMs. The key idea is to stop the diffusion process early where
only the few initial diffusing steps are considered and the reverse denoising
process starts from a non-Gaussian distribution. By further adopting a powerful
pre-trained generative model, such as GAN and VAE, in ES-DDPM, sampling from
the target non-Gaussian distribution can be efficiently achieved by diffusing
samples obtained from the pre-trained generative model. In this way, the number
of required denoising steps is significantly reduced. In the meantime, the
sample quality of ES-DDPM also improves substantially, outperforming both the
vanilla DDPM and the adopted pre-trained generative model. On extensive
experiments across CIFAR-10, CelebA, ImageNet, LSUN-Bedroom and LSUN-Cat,
ES-DDPM obtains promising acceleration effect and performance improvement over
representative baseline methods. Moreover, ES-DDPM also demonstrates several
attractive properties, including being orthogonal to existing acceleration
methods, as well as simultaneously enabling both global semantic and local
pixel-level control in image generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structured Uncertainty in the Observation Space of Variational Autoencoders. (arXiv:2205.12533v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12533">
<div class="article-summary-box-inner">
<span><p>Variational autoencoders (VAEs) are a popular class of deep generative models
with many variants and a wide range of applications. Improvements upon the
standard VAE mostly focus on the modelling of the posterior distribution over
the latent space and the properties of the neural network decoder. In contrast,
improving the model for the observational distribution is rarely considered and
typically defaults to a pixel-wise independent categorical or normal
distribution. In image synthesis, sampling from such distributions produces
spatially-incoherent results with uncorrelated pixel noise, resulting in only
the sample mean being somewhat useful as an output prediction. In this paper,
we aim to stay true to VAE theory by improving the samples from the
observational distribution. We propose an alternative model for the observation
space, encoding spatial dependencies via a low-rank parameterisation. We
demonstrate that this new observational distribution has the ability to capture
relevant covariance between pixels, resulting in spatially-coherent samples. In
contrast to pixel-wise independent distributions, our samples seem to contain
semantically meaningful variations from the mean allowing the prediction of
multiple plausible outputs with a single forward pass.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Misleading Deep-Fake Detection with GAN Fingerprints. (arXiv:2205.12543v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12543">
<div class="article-summary-box-inner">
<span><p>Generative adversarial networks (GANs) have made remarkable progress in
synthesizing realistic-looking images that effectively outsmart even humans.
Although several detection methods can recognize these deep fakes by checking
for image artifacts from the generation process, multiple counterattacks have
demonstrated their limitations. These attacks, however, still require certain
conditions to hold, such as interacting with the detection method or adjusting
the GAN directly. In this paper, we introduce a novel class of simple
counterattacks that overcomes these limitations. In particular, we show that an
adversary can remove indicative artifacts, the GAN fingerprint, directly from
the frequency spectrum of a generated image. We explore different realizations
of this removal, ranging from filtering high frequencies to more nuanced
frequency-peak cleansing. We evaluate the performance of our attack with
different detection methods, GAN architectures, and datasets. Our results show
that an adversary can often remove GAN fingerprints and thus evade the
detection of generated images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Dense Local Feature Matching and Vehicle Removal for Indoor Visual Localization. (arXiv:2205.12544v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12544">
<div class="article-summary-box-inner">
<span><p>Visual localization is an essential component of intelligent transportation
systems, enabling broad applications that require understanding one's self
location when other sensors are not available. It is mostly tackled by image
retrieval such that the location of a query image is determined by its closest
match in the previously collected images. Existing approaches focus on large
scale localization where landmarks are helpful in finding the location.
However, visual localization becomes challenging in small scale environments
where objects are hardly recognizable. In this paper, we propose a visual
localization framework that robustly finds the match for a query among the
images collected from indoor parking lots. It is a challenging problem when the
vehicles in the images share similar appearances and are frequently replaced
such as parking lots. We propose to employ a deep dense local feature matching
that resembles human perception to find correspondences and eliminating matches
from vehicles automatically with a vehicle detector. The proposed solution is
robust to the scenes with low textures and invariant to false matches caused by
vehicles. We compare our framework with alternatives to validate our
superiority on a benchmark dataset containing 267 pre-collected images and 99
query images taken from 34 sections of a parking lot. Our method achieves 86.9
percent accuracy, outperforming the alternatives.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Some equivalence relation between persistent homology and morphological dynamics. (arXiv:2205.12546v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12546">
<div class="article-summary-box-inner">
<span><p>In Mathematical Morphology (MM), connected filters based on dynamics are used
to filter the extrema of an image. Similarly, persistence is a concept coming
from Persistent Homology (PH) and Morse Theory (MT) that represents the
stability of the extrema of a Morse function. Since these two concepts seem to
be closely related, in this paper we examine their relationship, and we prove
that they are equal on n-D Morse functions, n $\ge$ 1. More exactly, pairing a
minimum with a 1-saddle by dynamics or pairing the same 1-saddle with a minimum
by persistence leads exactly to the same pairing, assuming that the critical
values of the studied Morse function are unique. This result is a step further
to show how much topological data analysis and mathematical morphology are
related, paving the way for a more in-depth study of the relations between
these two research fields.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Breaking the Chain of Gradient Leakage in Vision Transformers. (arXiv:2205.12551v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12551">
<div class="article-summary-box-inner">
<span><p>User privacy is of great concern in Federated Learning, while Vision
Transformers (ViTs) have been revealed to be vulnerable to gradient-based
inversion attacks. We show that the learned low-dimensional spatial prior in
position embeddings (PEs) accelerates the training of ViTs. As a side effect,
it makes the ViTs tend to be position sensitive and at high risk of privacy
leakage. We observe that enhancing the position-insensitive property of a ViT
model is a promising way to protect data privacy against these gradient
attacks. However, simply removing the PEs may not only harm the convergence and
accuracy of ViTs but also places the model at more severe privacy risk. To deal
with the aforementioned contradiction, we propose a simple yet efficient Masked
Jigsaw Puzzle (MJP) method to break the chain of gradient leakage in ViTs. MJP
can be easily plugged into existing ViTs and their derived variants. Extensive
experiments demonstrate that our proposed MJP method not only boosts the
performance on large-scale datasets (i.e., ImageNet-1K), but can also improve
the privacy preservation capacity in the typical gradient attacks by a large
margin. Our code is available at: https://github.com/yhlleo/MJP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spotlights: Probing Shapes from Spherical Viewpoints. (arXiv:2205.12564v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12564">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed the surge of learned representations that
directly build upon point clouds. Though becoming increasingly expressive, most
existing representations still struggle to generate ordered point sets.
Inspired by spherical multi-view scanners, we propose a novel sampling model
called Spotlights to represent a 3D shape as a compact 1D array of depth
values. It simulates the configuration of cameras evenly distributed on a
sphere, where each virtual camera casts light rays from its principal point
through sample points on a small concentric spherical cap to probe for the
possible intersections with the object surrounded by the sphere. The structured
point cloud is hence given implicitly as a function of depths. We provide a
detailed geometric analysis of this new sampling scheme and prove its
effectiveness in the context of the point cloud completion task. Experimental
results on both synthetic and real data demonstrate that our method achieves
competitive accuracy and consistency while having a significantly reduced
computational cost. Furthermore, we show superior performance on the downstream
point cloud registration task over state-of-the-art completion methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Pedestrian Detection to Crosswalk Estimation: An EM Algorithm and Analysis on Diverse Datasets. (arXiv:2205.12579v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12579">
<div class="article-summary-box-inner">
<span><p>In this work, we contribute an EM algorithm for estimation of corner points
and linear crossing segments for both marked and unmarked pedestrian crosswalks
using the detections of pedestrians from processed LiDAR point clouds or camera
images. We demonstrate the algorithmic performance by analyzing three
real-world datasets containing multiple periods of data collection for
four-corner and two-corner intersections with marked and unmarked crosswalks.
Additionally, we include a Python video tool to visualize the crossing
parameter estimation, pedestrian trajectories, and phase intervals in our
public source code.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MUG: Multi-human Graph Network for 3D Mesh Reconstruction from 2D Pose. (arXiv:2205.12583v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12583">
<div class="article-summary-box-inner">
<span><p>Reconstructing multi-human body mesh from a single monocular image is an
important but challenging computer vision problem. In addition to the
individual body mesh models, we need to estimate relative 3D positions among
subjects to generate a coherent representation. In this work, through a single
graph neural network, named MUG (Multi-hUman Graph network), we construct
coherent multi-human meshes using only multi-human 2D pose as input. Compared
with existing methods, which adopt a detection-style pipeline (i.e., extracting
image features and then locating human instances and recovering body meshes
from that) and suffer from the significant domain gap between lab-collected
training datasets and in-the-wild testing datasets, our method benefits from
the 2D pose which has a relatively consistent geometric property across
datasets. Our method works like the following: First, to model the multi-human
environment, it processes multi-human 2D poses and builds a novel heterogeneous
graph, where nodes from different people and within one person are connected to
capture inter-human interactions and draw the body geometry (i.e., skeleton and
mesh structure). Second, it employs a dual-branch graph neural network
structure -- one for predicting inter-human depth relation and the other one
for predicting root-joint-relative mesh coordinates. Finally, the entire
multi-human 3D meshes are constructed by combining the output from both
branches. Extensive experiments demonstrate that MUG outperforms previous
multi-human mesh estimation methods on standard 3D human benchmarks --
Panoptic, MuPoTS-3D and 3DPW.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deniable Steganography. (arXiv:2205.12587v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12587">
<div class="article-summary-box-inner">
<span><p>Steganography conceals the secret message into the cover media, generating a
stego media which can be transmitted on public channels without drawing
suspicion. As its countermeasure, steganalysis mainly aims to detect whether
the secret message is hidden in a given media. Although the steganography
techniques are improving constantly, the sophisticated steganalysis can always
break a known steganographic method to some extent. With a stego media
discovered, the adversary could find out the sender or receiver and coerce them
to disclose the secret message, which we name as coercive attack in this paper.
Inspired by the idea of deniable encryption, we build up the concepts of
deniable steganography for the first time and discuss the feasible
constructions for it. As an example, we propose a receiver-deniable
steganographic scheme to deal with the receiver-side coercive attack using deep
neural networks (DNN). Specifically, besides the real secret message, a piece
of fake message is also embedded into the cover. On the receiver side, the real
message can be extracted with an extraction module; while once the receiver has
to surrender a piece of secret message under coercive attack, he can extract
the fake message to deceive the adversary with another extraction module.
Experiments demonstrate the scalability and sensitivity of the DNN-based
receiver-deniable steganographic scheme.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VTP: Volumetric Transformer for Multi-view Multi-person 3D Pose Estimation. (arXiv:2205.12602v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12602">
<div class="article-summary-box-inner">
<span><p>This paper presents Volumetric Transformer Pose estimator (VTP), the first 3D
volumetric transformer framework for multi-view multi-person 3D human pose
estimation. VTP aggregates features from 2D keypoints in all camera views and
directly learns the spatial relationships in the 3D voxel space in an
end-to-end fashion. The aggregated 3D features are passed through 3D
convolutions before being flattened into sequential embeddings and fed into a
transformer. A residual structure is designed to further improve the
performance. In addition, the sparse Sinkhorn attention is empowered to reduce
the memory cost, which is a major bottleneck for volumetric representations,
while also achieving excellent performance. The output of the transformer is
again concatenated with 3D convolutional features by a residual design. The
proposed VTP framework integrates the high performance of the transformer with
volumetric representations, which can be used as a good alternative to the
convolutional backbones. Experiments on the Shelf, Campus and CMU Panoptic
benchmarks show promising results in terms of both Mean Per Joint Position
Error (MPJPE) and Percentage of Correctly estimated Parts (PCP). Our code will
be available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ReSmooth: Detecting and Utilizing OOD Samples when Training with Data Augmentation. (arXiv:2205.12606v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12606">
<div class="article-summary-box-inner">
<span><p>Data augmentation (DA) is a widely used technique for enhancing the training
of deep neural networks. Recent DA techniques which achieve state-of-the-art
performance always meet the need for diversity in augmented training samples.
However, an augmentation strategy that has a high diversity usually introduces
out-of-distribution (OOD) augmented samples and these samples consequently
impair the performance. To alleviate this issue, we propose ReSmooth, a
framework that firstly detects OOD samples in augmented samples and then
leverages them. To be specific, we first use a Gaussian mixture model to fit
the loss distribution of both the original and augmented samples and
accordingly split these samples into in-distribution (ID) samples and OOD
samples. Then we start a new training where ID and OOD samples are incorporated
with different smooth labels. By treating ID samples and OOD samples unequally,
we can make better use of the diverse augmented data. Further, we incorporate
our ReSmooth framework with negative data augmentation strategies. By properly
handling their intentionally created ODD samples, the classification
performance of negative data augmentations is largely ameliorated. Experiments
on several classification benchmarks show that ReSmooth can be easily extended
to existing augmentation strategies (such as RandAugment, rotate, and jigsaw)
and improve on them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Aesthetic Assessment and Retrieval of Breast Cancer Treatment Outcomes. (arXiv:2205.12611v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12611">
<div class="article-summary-box-inner">
<span><p>Treatments for breast cancer have continued to evolve and improve in recent
years, resulting in a substantial increase in survival rates, with
approximately 80\% of patients having a 10-year survival period. Given the
serious impact that breast cancer treatments can have on a patient's body
image, consequently affecting her self-confidence and sexual and intimate
relationships, it is paramount to ensure that women receive the treatment that
optimizes both survival and aesthetic outcomes. Currently, there is no gold
standard for evaluating the aesthetic outcome of breast cancer treatment. In
addition, there is no standard way to show patients the potential outcome of
surgery. The presentation of similar cases from the past would be extremely
important to manage women's expectations of the possible outcome. In this work,
we propose a deep neural network to perform the aesthetic evaluation. As a
proof-of-concept, we focus on a binary aesthetic evaluation. Besides its use
for classification, this deep neural network can also be used to find the most
similar past cases by searching for nearest neighbours in the highly semantic
space before classification. We performed the experiments on a dataset
consisting of 143 photos of women after conservative treatment for breast
cancer. The results for accuracy and balanced accuracy showed the superior
performance of our proposed model compared to the state of the art in aesthetic
evaluation of breast cancer treatments. In addition, the model showed a good
ability to retrieve similar previous cases, with the retrieved cases having the
same or adjacent class (in the 4-class setting) and having similar types of
asymmetry. Finally, a qualitative interpretability assessment was also
performed to analyse the robustness and trustworthiness of the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Guiding Visual Question Answering with Attention Priors. (arXiv:2205.12616v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12616">
<div class="article-summary-box-inner">
<span><p>The current success of modern visual reasoning systems is arguably attributed
to cross-modality attention mechanisms. However, in deliberative reasoning such
as in VQA, attention is unconstrained at each step, and thus may serve as a
statistical pooling mechanism rather than a semantic operation intended to
select information relevant to inference. This is because at training time,
attention is only guided by a very sparse signal (i.e. the answer label) at the
end of the inference chain. This causes the cross-modality attention weights to
deviate from the desired visual-language bindings. To rectify this deviation,
we propose to guide the attention mechanism using explicit linguistic-visual
grounding. This grounding is derived by connecting structured linguistic
concepts in the query to their referents among the visual objects. Here we
learn the grounding from the pairing of questions and images alone, without the
need for answer annotation or external grounding supervision. This grounding
guides the attention mechanism inside VQA models through a duality of
mechanisms: pre-training attention weight calculation and directly guiding the
weights at inference time on a case-by-case basis. The resultant algorithm is
capable of probing attention-based reasoning models, injecting relevant
associative knowledge, and regulating the core reasoning process. This scalable
enhancement improves the performance of VQA models, fortifies their robustness
to limited access to supervised data, and increases interpretability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DisinfoMeme: A Multimodal Dataset for Detecting Meme Intentionally Spreading Out Disinformation. (arXiv:2205.12617v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12617">
<div class="article-summary-box-inner">
<span><p>Disinformation has become a serious problem on social media. In particular,
given their short format, visual attraction, and humorous nature, memes have a
significant advantage in dissemination among online communities, making them an
effective vehicle for the spread of disinformation. We present DisinfoMeme to
help detect disinformation memes. The dataset contains memes mined from Reddit
covering three current topics: the COVID-19 pandemic, the Black Lives Matter
movement, and veganism/vegetarianism. The dataset poses multiple unique
challenges: limited data and label imbalance, reliance on external knowledge,
multimodal reasoning, layout dependency, and noise from OCR. We test multiple
widely-used unimodal and multimodal models on this dataset. The experiments
show that the room for improvement is still huge for current models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Location-free Human Pose Estimation. (arXiv:2205.12619v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12619">
<div class="article-summary-box-inner">
<span><p>Human pose estimation (HPE) usually requires large-scale training data to
reach high performance. However, it is rather time-consuming to collect
high-quality and fine-grained annotations for human body. To alleviate this
issue, we revisit HPE and propose a location-free framework without supervision
of keypoint locations. We reformulate the regression-based HPE from the
perspective of classification. Inspired by the CAM-based weakly-supervised
object localization, we observe that the coarse keypoint locations can be
acquired through the part-aware CAMs but unsatisfactory due to the gap between
the fine-grained HPE and the object-level localization. To this end, we propose
a customized transformer framework to mine the fine-grained representation of
human context, equipped with the structural relation to capture subtle
differences among keypoints. Concretely, we design a Multi-scale Spatial-guided
Context Encoder to fully capture the global human context while focusing on the
part-aware regions and a Relation-encoded Pose Prototype Generation module to
encode the structural relations. All these works together for strengthening the
weak supervision from image-level category labels on locations. Our model
achieves competitive performance on three datasets when only supervised at a
category-level and importantly, it can achieve comparable results with
fully-supervised methods with only 25\% location labels on MS-COCO and MPII.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Primitive3D: 3D Object Dataset Synthesis from Randomly Assembled Primitives. (arXiv:2205.12627v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12627">
<div class="article-summary-box-inner">
<span><p>Numerous advancements in deep learning can be attributed to the access to
large-scale and well-annotated datasets. However, such a dataset is
prohibitively expensive in 3D computer vision due to the substantial collection
cost. To alleviate this issue, we propose a cost-effective method for
automatically generating a large amount of 3D objects with annotations. In
particular, we synthesize objects simply by assembling multiple random
primitives. These objects are thus auto-annotated with part labels originating
from primitives. This allows us to perform multi-task learning by combining the
supervised segmentation with unsupervised reconstruction. Considering the large
overhead of learning on the generated dataset, we further propose a dataset
distillation strategy to remove redundant samples regarding a target dataset.
We conduct extensive experiments for the downstream tasks of 3D object
classification. The results indicate that our dataset, together with multi-task
pretraining on its annotations, achieves the best performance compared to other
commonly used datasets. Further study suggests that our strategy can improve
the model performance by pretraining and fine-tuning scheme, especially for the
dataset with a small scale. In addition, pretraining with the proposed dataset
distillation method can save 86\% of the pretraining time with negligible
performance degradation. We expect that our attempt provides a new data-centric
perspective for training 3D deep models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Knowledge Alignment with Reinforcement Learning. (arXiv:2205.12630v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12630">
<div class="article-summary-box-inner">
<span><p>Large language models readily adapt to novel settings, even without
task-specific training data. Can their zero-shot capacity be extended to
multimodal inputs? In this work, we propose ESPER which extends language-only
zero-shot models to unseen multimodal tasks, like image and audio captioning.
Our key novelty is to use reinforcement learning to align multimodal inputs to
language model generations without direct supervision: for example, in the
image case our reward optimization relies only on cosine similarity derived
from CLIP, and thus requires no additional explicitly paired (image, caption)
data. Because the parameters of the language model are left unchanged, the
model maintains its capacity for zero-shot generalization. Experiments
demonstrate that ESPER outperforms baselines and prior work on a variety of
zero-shot tasks; these include a new benchmark we collect+release, ESP dataset,
which tasks models with generating several diversely-styled captions for each
image.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NTIRE 2022 Challenge on High Dynamic Range Imaging: Methods and Results. (arXiv:2205.12633v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12633">
<div class="article-summary-box-inner">
<span><p>This paper reviews the challenge on constrained high dynamic range (HDR)
imaging that was part of the New Trends in Image Restoration and Enhancement
(NTIRE) workshop, held in conjunction with CVPR 2022. This manuscript focuses
on the competition set-up, datasets, the proposed methods and their results.
The challenge aims at estimating an HDR image from multiple respective low
dynamic range (LDR) observations, which might suffer from under- or
over-exposed regions and different sources of noise. The challenge is composed
of two tracks with an emphasis on fidelity and complexity constraints: In Track
1, participants are asked to optimize objective fidelity scores while imposing
a low-complexity constraint (i.e. solutions can not exceed a given number of
operations). In Track 2, participants are asked to minimize the complexity of
their solutions while imposing a constraint on fidelity scores (i.e. solutions
are required to obtain a higher fidelity score than the prescribed baseline).
Both tracks use the same data and metrics: Fidelity is measured by means of
PSNR with respect to a ground-truth HDR image (computed both directly and with
a canonical tonemapping operation), while complexity metrics include the number
of Multiply-Accumulate (MAC) operations and runtime (in seconds).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-Time Video Deblurring via Lightweight Motion Compensation. (arXiv:2205.12634v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12634">
<div class="article-summary-box-inner">
<span><p>While motion compensation greatly improves video deblurring quality,
separately performing motion compensation and video deblurring demands huge
computational overhead. This paper proposes a real-time video deblurring
framework consisting of a lightweight multi-task unit that supports both video
deblurring and motion compensation in an efficient way. The multi-task unit is
specifically designed to handle large portions of the two tasks using a single
shared network, and consists of a multi-task detail network and simple networks
for deblurring and motion compensation. The multi-task unit minimizes the cost
of incorporating motion compensation into video deblurring and enables
real-time deblurring. Moreover, by stacking multiple multi-task units, our
framework provides flexible control between the cost and deblurring quality. We
experimentally validate the state-of-the-art deblurring quality of our
approach, which runs at a much faster speed compared to previous methods, and
show practical real-time performance (30.99dB@30fps measured in the DVD
dataset).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MoCoViT: Mobile Convolutional Vision Transformer. (arXiv:2205.12635v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12635">
<div class="article-summary-box-inner">
<span><p>Recently, Transformer networks have achieved impressive results on a variety
of vision tasks. However, most of them are computationally expensive and not
suitable for real-world mobile applications. In this work, we present Mobile
Convolutional Vision Transformer (MoCoViT), which improves in performance and
efficiency by introducing transformer into mobile convolutional networks to
leverage the benefits of both architectures. Different from recent works on
vision transformer, the mobile transformer block in MoCoViT is carefully
designed for mobile devices and is very lightweight, accomplished through two
primary modifications: the Mobile Self-Attention (MoSA) module and the Mobile
Feed Forward Network (MoFFN). MoSA simplifies the calculation of the attention
map through Branch Sharing scheme while MoFFN serves as a mobile version of MLP
in the transformer, further reducing the computation by a large margin.
Comprehensive experiments verify that our proposed MoCoViT family outperform
state-of-the-art portable CNNs and transformer neural architectures on various
vision tasks. On ImageNet classification, it achieves 74.5% top-1 accuracy at
147M FLOPs, gaining 1.2% over MobileNetV3 with less computations. And on the
COCO object detection task, MoCoViT outperforms GhostNet by 2.1 AP in RetinaNet
framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TreEnhance: An Automatic Tree-Search Based Method for Low-Light Image Enhancement. (arXiv:2205.12639v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12639">
<div class="article-summary-box-inner">
<span><p>In this paper we present TreEnhance, an automatic method for low-light image
enhancement capable of improving the quality of digital images. The method
combines tree search theory, and in particular the Monte Carlo Tree Search
(MCTS) algorithm, with deep reinforcement learning. Given as input a low-light
image, TreEnhance produces as output its enhanced version together with the
sequence of image editing operations used to obtain it. The method repeatedly
alternates two main phases. In the generation phase a modified version of MCTS
explores the space of image editing operations and selects the most promising
sequence. In the optimization phase the parameters of a neural network,
implementing the enhancement policy, are updated. After training, two different
inference solutions are proposed for the enhancement of new images: one is
based on MCTS and is more accurate but more time and memory consuming; the
other directly applies the learned policy and is faster but slightly less
precise. Unlike other methods from the state of the art, TreEnhance does not
pose any constraint on the image resolution and can be used in a variety of
scenarios with minimal tuning. We tested the method on two datasets: the
Low-Light dataset and the Adobe Five-K dataset obtaining good results from both
a qualitative and a quantitative point of view.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UniInst: Unique Representation for End-to-End Instance Segmentation. (arXiv:2205.12646v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12646">
<div class="article-summary-box-inner">
<span><p>Existing instance segmentation methods have achieved impressive performance
but still suffer from a common dilemma: redundant representations (e.g.,
multiple boxes, grids, and anchor points) are inferred for one instance, which
leads to multiple duplicated predictions. Thus, mainstream methods usually rely
on a hand-designed non-maximum suppression (NMS) post-processing to select the
optimal prediction result, which hinders end-to-end training. To address this
issue, we propose a box-free and NMS-free end-to-end instance segmentation
framework, termed UniInst, that yields only one unique representation for each
instance. Specifically, we design an instance-aware one-to-one assignment
scheme, namely Only Yield One Representation (OYOR), which dynamically assigns
one unique representation to one instance according to the matching quality
between predictions and ground truths. Then, a novel prediction re-ranking
strategy is elegantly integrated into the framework to address the misalignment
between the classification score and the mask quality, enabling the learned
representation to be more discriminative. With these techniques, our UniInst,
the first FCN-based end-to-end instance segmentation framework, achieves
competitive performance, e.g., 39.0 mask AP with ResNet-50-FPN and 40.2 mask AP
with ResNet-101-FPN, against mainstream methods on the COCO benchmark.
Moreover, the proposed instance-aware method is robust to occlusion scenes,
outperforming common baselines by remarkable mask AP on the heavily-occluded
OCHuman benchmark. Our codes will be available upon publication.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Learning with Boosted Memorization. (arXiv:2205.12693v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12693">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning has achieved a great success in the representation
learning of visual and textual data. However, the current methods are mainly
validated on the well-curated datasets, which do not exhibit the real-world
long-tailed distribution. Recent attempts to consider self-supervised
long-tailed learning are made by rebalancing in the loss perspective or the
model perspective, resembling the paradigms in the supervised long-tailed
learning. Nevertheless, without the aid of labels, these explorations have not
shown the expected significant promise due to the limitation in tail sample
discovery or the heuristic structure design. Different from previous works, we
explore this direction from an alternative perspective, i.e., the data
perspective, and propose a novel Boosted Contrastive Learning (BCL) method.
Specifically, BCL leverages the memorization effect of deep neural networks to
automatically drive the information discrepancy of the sample views in
contrastive learning, which is more efficient to enhance the long-tailed
learning in the label-unaware context. Extensive experiments on a range of
benchmark datasets demonstrate the effectiveness of BCL over several
state-of-the-art methods. Our code is available at
https://github.com/Zhihan-Zhou/Boosted-Contrastive-Learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COVID-19 Severity Classification on Chest X-ray Images. (arXiv:2205.12705v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12705">
<div class="article-summary-box-inner">
<span><p>Biomedical imaging analysis combined with artificial intelligence (AI)
methods has proven to be quite valuable in order to diagnose COVID-19. So far,
various classification models have been used for diagnosing COVID-19. However,
classification of patients based on their severity level is not yet analyzed.
In this work, we classify covid images based on the severity of the infection.
First, we pre-process the X-ray images using a median filter and histogram
equalization. Enhanced X-ray images are then augmented using SMOTE technique
for achieving a balanced dataset. Pre-trained Resnet50, VGG16 model and SVM
classifier are then used for feature extraction and classification. The result
of the classification model confirms that compared with the alternatives, with
chest X-Ray images, the ResNet-50 model produced remarkable classification
results in terms of accuracy (95%), recall (0.94), and F1-Score (0.92), and
precision (0.91).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SIoU Loss: More Powerful Learning for Bounding Box Regression. (arXiv:2205.12740v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12740">
<div class="article-summary-box-inner">
<span><p>The effectiveness of Object Detection, one of the central problems in
computer vision tasks, highly depends on the definition of the loss function -
a measure of how accurately your ML model can predict the expected outcome.
Conventional object detection loss functions depend on aggregation of metrics
of bounding box regression such as the distance, overlap area and aspect ratio
of the predicted and ground truth boxes (i.e. GIoU, CIoU, ICIoU etc). However,
none of the methods proposed and used to date considers the direction of the
mismatch between the desired ground box and the predicted, "experimental" box.
This shortage results in slower and less effective convergence as the predicted
box can "wander around" during the training process and eventually end up
producing a worse model. In this paper a new loss function SIoU was suggested,
where penalty metrics were redefined considering the angle of the vector
between the desired regression. Applied to conventional Neural Networks and
datasets it is shown that SIoU improves both the speed of training and the
accuracy of the inference. The effectiveness of the proposed loss function was
revealed in a number of simulations and tests.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Study on Distribution Shift Robustness From the Perspective of Pre-Training and Data Augmentation. (arXiv:2205.12753v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12753">
<div class="article-summary-box-inner">
<span><p>The performance of machine learning models under distribution shift has been
the focus of the community in recent years. Most of current methods have been
proposed to improve the robustness to distribution shift from the algorithmic
perspective, i.e., designing better training algorithms to help the
generalization in shifted test distributions. This paper studies the
distribution shift problem from the perspective of pre-training and data
augmentation, two important factors in the practice of deep learning that have
not been systematically investigated by existing work. By evaluating seven
pre-trained models, including ResNets and ViT's with self-supervision and
supervision mode, on five important distribution-shift datasets, from WILDS and
DomainBed benchmarks, with five different learning algorithms, we provide the
first comprehensive empirical study focusing on pre-training and data
augmentation. With our empirical result obtained from 1,330 models, we provide
the following main observations: 1) ERM combined with data augmentation can
achieve state-of-the-art performance if we choose a proper pre-trained model
respecting the data property; 2) specialized algorithms further improve the
robustness on top of ERM when handling a specific type of distribution shift,
e.g., GroupDRO for spurious correlation and CORAL for large-scale
out-of-distribution data; 3) Comparing different pre-training modes,
architectures and data sizes, we provide novel observations about pre-training
on distribution shift, which sheds light on designing or selecting pre-training
strategy for different kinds of distribution shifts. In summary, our empirical
study provides a comprehensive baseline for a wide range of pre-training models
fine-tuned with data augmentation, which potentially inspires research
exploiting the power of pre-training and data augmentation in the future of
distribution shift study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems. (arXiv:2205.12755v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12755">
<div class="article-summary-box-inner">
<span><p>Multitask learning assumes that models capable of learning from multiple
tasks can achieve better quality and efficiency via knowledge transfer, a key
feature of human learning. Though, state of the art ML models rely on high
customization for each task and leverage size and data scale rather than
scaling the number of tasks. Also, continual learning, that adds the temporal
aspect to multitask, is often focused to the study of common pitfalls such as
catastrophic forgetting instead of being studied at a large scale as a critical
component to build the next generation artificial intelligence. We propose an
evolutionary method that can generate a large scale multitask model, and can
support the dynamic and continuous addition of new tasks. The generated
multitask model is sparsely activated and integrates a task-based routing that
guarantees bounded compute cost and fewer added parameters per task as the
model expands. The proposed method relies on a knowledge compartmentalization
technique to achieve immunity against catastrophic forgetting and other common
pitfalls such as gradient interference and negative transfer. We empirically
show that the proposed method can jointly solve and achieve competitive results
on 69image classification tasks, for example achieving the best test accuracy
reported fora model trained only on public data for competitive tasks such as
cifar10: 99.43%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AO2-DETR: Arbitrary-Oriented Object Detection Transformer. (arXiv:2205.12785v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12785">
<div class="article-summary-box-inner">
<span><p>Arbitrary-oriented object detection (AOOD) is a challenging task to detect
objects in the wild with arbitrary orientations and cluttered arrangements.
Existing approaches are mainly based on anchor-based boxes or dense points,
which rely on complicated hand-designed processing steps and inductive bias,
such as anchor generation, transformation, and non-maximum suppression
reasoning. Recently, the emerging transformer-based approaches view object
detection as a direct set prediction problem that effectively removes the need
for hand-designed components and inductive biases. In this paper, we propose an
Arbitrary-Oriented Object DEtection TRansformer framework, termed AO2-DETR,
which comprises three dedicated components. More precisely, an oriented
proposal generation mechanism is proposed to explicitly generate oriented
proposals, which provides better positional priors for pooling features to
modulate the cross-attention in the transformer decoder. An adaptive oriented
proposal refinement module is introduced to extract rotation-invariant region
features and eliminate the misalignment between region features and objects.
And a rotation-aware set matching loss is used to ensure the one-to-one
matching process for direct set prediction without duplicate predictions. Our
method considerably simplifies the overall pipeline and presents a new AOOD
paradigm. Comprehensive experiments on several challenging datasets show that
our method achieves superior performance on the AOOD task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-rigid Point Cloud Registration with Neural Deformation Pyramid. (arXiv:2205.12796v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12796">
<div class="article-summary-box-inner">
<span><p>Non-rigid point cloud registration is a key component in many computer vision
and computer graphics applications. The high complexity of the unknown
non-rigid motion make this task a challenging problem. In this paper, we break
down this problem via hierarchical motion decomposition. Our method called
Neural Deformation Pyramid (NDP) represents non-rigid motion using a pyramid
architecture. Each pyramid level, denoted by a Multi-Layer Perception (MLP),
takes as input a sinusoidally encoded 3D point and outputs its motion
increments from the previous level. The sinusoidal function starts with a low
input frequency and gradually increases when the pyramid level goes down. This
allows a multi-level rigid to nonrigid motion decomposition and also speeds up
the solving by 50 times compared to the existing MLP-based approach. Our method
achieves advanced partialto-partial non-rigid point cloud registration results
on the 4DMatch/4DLoMatch benchmark under both no-learned and supervised
settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DistillAdapt: Source-Free Active Visual Domain Adaptation. (arXiv:2205.12840v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12840">
<div class="article-summary-box-inner">
<span><p>We present a novel method, DistillAdapt, for the challenging problem of
Source-Free Active Domain Adaptation (SF-ADA). The problem requires adapting a
pretrained source domain network to a target domain, within a provided budget
for acquiring labels in the target domain, while assuming that the source data
is not available for adaptation due to privacy concerns or otherwise.
DistillAdapt is one of the first approaches for SF-ADA, and holistically
addresses the challenges of SF-ADA via a novel Guided Attention Transfer
Network (GATN) and an active learning heuristic, H_AL. The GATN enables
selective distillation of features from the pre-trained network to the target
network using a small subset of annotated target samples mined by H_AL. H_AL
acquires samples at batch-level and balances transfer-ability from the
pre-trained network and uncertainty of the target network. DistillAdapt is
task-agnostic, and can be applied across visual tasks such as classification,
segmentation and detection. Moreover, DistillAdapt can handle shifts in output
label space. We conduct experiments and extensive ablation studies across 3
visual tasks, viz. digits classification (MNIST, SVHN), synthetic (GTA5) to
real (CityScapes) image segmentation, and document layout detection (PubLayNet
to DSSE). We show that our source-free approach, DistillAdapt, results in an
improvement of 0.5% - 31.3% (across datasets and tasks) over prior adaptation
methods that assume access to large amounts of annotated source data for
adaptation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comparative Study of Gastric Histopathology Sub-size Image Classification: from Linear Regression to Visual Transformer. (arXiv:2205.12843v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12843">
<div class="article-summary-box-inner">
<span><p>Gastric cancer is the fifth most common cancer in the world. At the same
time, it is also the fourth most deadly cancer. Early detection of cancer
exists as a guide for the treatment of gastric cancer. Nowadays, computer
technology has advanced rapidly to assist physicians in the diagnosis of
pathological pictures of gastric cancer. Ensemble learning is a way to improve
the accuracy of algorithms, and finding multiple learning models with
complementarity types is the basis of ensemble learning. The complementarity of
sub-size pathology image classifiers when machine performance is insufficient
is explored in this experimental platform. We choose seven classical machine
learning classifiers and four deep learning classifiers for classification
experiments on the GasHisSDB database. Among them, classical machine learning
algorithms extract five different image virtual features to match multiple
classifier algorithms. For deep learning, we choose three convolutional neural
network classifiers. In addition, we also choose a novel Transformer-based
classifier. The experimental platform, in which a large number of classical
machine learning and deep learning methods are performed, demonstrates that
there are differences in the performance of different classifiers on GasHisSDB.
Classical machine learning models exist for classifiers that classify Abnormal
categories very well, while classifiers that excel in classifying Normal
categories also exist. Deep learning models also exist with multiple models
that can be complementarity. Suitable classifiers are selected for ensemble
learning, when machine performance is insufficient. This experimental platform
demonstrates that multiple classifiers are indeed complementarity and can
improve the efficiency of ensemble learning. This can better assist doctors in
diagnosis, improve the detection of gastric cancer, and increase the cure rate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Gradient Learning for Efficient Camouflaged Object Detection. (arXiv:2205.12853v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12853">
<div class="article-summary-box-inner">
<span><p>This paper introduces DGNet, a novel deep framework that exploits object
gradient supervision for camouflaged object detection (COD). It decouples the
task into two connected branches, i.e., a context and a texture encoder. The
essential connection is the gradient-induced transition, representing a soft
grouping between context and texture features. Benefiting from the simple but
efficient framework, DGNet outperforms existing state-of-the-art COD models by
a large margin. Notably, our efficient version, DGNet-S, runs in real-time (80
fps) and achieves comparable results to the cutting-edge model
JCSOD-CVPR$_{21}$ with only 6.82% parameters. Application results also show
that the proposed DGNet performs well in polyp segmentation, defect detection,
and transparent object segmentation tasks. Codes will be made available at
https://github.com/GewelsJI/DGNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structure Unbiased Adversarial Model for Medical Image Segmentation. (arXiv:2205.12857v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12857">
<div class="article-summary-box-inner">
<span><p>Generative models have been widely proposed in image recognition to generate
more images where the distribution is similar to that of the real images. It
often introduces a discriminator network to discriminate original real data and
generated data.
</p>
<p>However, such discriminator often considers the distribution of the data and
did not pay enough attention to the intrinsic gap due to structure.
</p>
<p>In this paper, we reformulate a new image to image translation problem to
reduce structural gap, in addition to the typical intensity distribution gap.
We further propose a simple yet important Structure Unbiased Adversarial Model
for Medical Image Segmentation (SUAM) with learnable inverse structural
deformation for medical image segmentation. It consists of a structure
extractor, an attention diffeomorphic registration and a structure \&amp; intensity
distribution rendering module. The structure extractor aims to extract the
dominant structure of the input image. The attention diffeomorphic registration
is proposed to reduce the structure gap with an inverse deformation field to
warp the prediction masks back to their original form. The structure rendering
module is to render the deformed structure to an image with targeted intensity
distribution. We apply the proposed SUAM on both optical coherence tomography
(OCT), magnetic resonance imaging (MRI) and computerized tomography (CT) data.
Experimental results show that the proposed method has the capability to
transfer both intensity and structure distributions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Colorization using U-Net with Skip Connections and Fusion Layer on Landscape Images. (arXiv:2205.12867v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12867">
<div class="article-summary-box-inner">
<span><p>We present a novel technique to automatically colorize grayscale images that
combine the U-Net model and Fusion Layer features. This approach allows the
model to learn the colorization of images from pre-trained U-Net. Moreover, the
Fusion layer is applied to merge local information results dependent on small
image patches with global priors of an entire image on each class, forming
visually more compelling colorization results. Finally, we validate our
approach with a user study evaluation and compare it against state-of-the-art,
resulting in improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open-Domain Sign Language Translation Learned from Online Video. (arXiv:2205.12870v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12870">
<div class="article-summary-box-inner">
<span><p>Existing work on sign language translation--that is, translation from sign
language videos into sentences in a written language--has focused mainly on (1)
data collected in a controlled environment or (2) data in a specific domain,
which limits the applicability to real-world settings. In this paper, we
introduce OpenASL, a large-scale ASL-English dataset collected from online
video sites (e.g., YouTube). OpenASL contains 288 hours of ASL videos in
various domains (news, VLOGs, etc.) from over 200 signers and is the largest
publicly available ASL translation dataset to date. To tackle the challenges of
sign language translation in realistic settings and without glosses, we propose
a set of techniques including sign search as a pretext task for pre-training
and fusion of mouthing and handshape features. The proposed techniques produce
consistent and large improvements in translation quality, over baseline models
based on prior work. Our data, code and model will be publicly available at
https://github.com/chevalierNoir/OpenASL
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">You Need to Read Again: Multi-granularity Perception Network for Moment Retrieval in Videos. (arXiv:2205.12886v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12886">
<div class="article-summary-box-inner">
<span><p>Moment retrieval in videos is a challenging task that aims to retrieve the
most relevant video moment in an untrimmed video given a sentence description.
Previous methods tend to perform self-modal learning and cross-modal
interaction in a coarse manner, which neglect fine-grained clues contained in
video content, query context, and their alignment. To this end, we propose a
novel Multi-Granularity Perception Network (MGPN) that perceives intra-modality
and inter-modality information at a multi-granularity level. Specifically, we
formulate moment retrieval as a multi-choice reading comprehension task and
integrate human reading strategies into our framework. A coarse-grained feature
encoder and a co-attention mechanism are utilized to obtain a preliminary
perception of intra-modality and inter-modality information. Then a
fine-grained feature encoder and a conditioned interaction module are
introduced to enhance the initial perception inspired by how humans address
reading comprehension problems. Moreover, to alleviate the huge computation
burden of some existing methods, we further design an efficient choice
comparison module and reduce the hidden size with imperceptible quality loss.
Extensive experiments on Charades-STA, TACoS, and ActivityNet Captions datasets
demonstrate that our solution outperforms existing state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RADNet: Ensemble Model for Robust Glaucoma Classification in Color Fundus Images. (arXiv:2205.12902v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12902">
<div class="article-summary-box-inner">
<span><p>Glaucoma is one of the most severe eye diseases, characterized by rapid
progression and leading to irreversible blindness. It is often the case that
pathology diagnostics is carried out when the one's sight has already
significantly degraded due to the lack of noticeable symptoms at early stage of
the disease. Regular glaucoma screenings of the population shall improve
early-stage detection, however the desirable frequency of etymological checkups
is often not feasible due to excessive load imposed by manual diagnostics on
limited number of specialists. Considering the basic methodology to detect
glaucoma is to analyze fundus images for the \textit{optic-disc-to-optic-cup
ratio}, Machine Learning domain can offer sophisticated tooling for image
processing and classification. In our work, we propose an advanced image
pre-processing technique combined with an ensemble of deep classification
networks. Our \textit{Retinal Auto Detection (RADNet)} model has been
successfully tested on Rotterdam EyePACS AIROGS train dataset with AUC of 0.92,
and then additionally finetuned and tested on a fraction of RIM-ONE DL dataset
with AUC of 0.91.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Context-Aware Video Reconstruction for Rolling Shutter Cameras. (arXiv:2205.12912v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12912">
<div class="article-summary-box-inner">
<span><p>With the ubiquity of rolling shutter (RS) cameras, it is becoming
increasingly attractive to recover the latent global shutter (GS) video from
two consecutive RS frames, which also places a higher demand on realism.
Existing solutions, using deep neural networks or optimization, achieve
promising performance. However, these methods generate intermediate GS frames
through image warping based on the RS model, which inevitably result in black
holes and noticeable motion artifacts. In this paper, we alleviate these issues
by proposing a context-aware GS video reconstruction architecture. It
facilitates the advantages such as occlusion reasoning, motion compensation,
and temporal abstraction. Specifically, we first estimate the bilateral motion
field so that the pixels of the two RS frames are warped to a common GS frame
accordingly. Then, a refinement scheme is proposed to guide the GS frame
synthesis along with bilateral occlusion masks to produce high-fidelity GS
video frames at arbitrary times. Furthermore, we derive an approximated
bilateral motion field model, which can serve as an alternative to provide a
simple but effective GS frame initialization for related tasks. Experiments on
synthetic and real data show that our approach achieves superior performance
over state-of-the-art methods in terms of objective metrics and subjective
visual quality. Code is available at \url{https://github.com/GitCVfb/CVR}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Low Memory Footprint Quantized Neural Network for Depth Completion of Very Sparse Time-of-Flight Depth Maps. (arXiv:2205.12918v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12918">
<div class="article-summary-box-inner">
<span><p>Sparse active illumination enables precise time-of-flight depth sensing as it
maximizes signal-to-noise ratio for low power budgets. However, depth
completion is required to produce dense depth maps for 3D perception. We
address this task with realistic illumination and sensor resolution constraints
by simulating ToF datasets for indoor 3D perception with challenging sparsity
levels. We propose a quantized convolutional encoder-decoder network for this
task. Our model achieves optimal depth map quality by means of input
pre-processing and carefully tuned training with a geometry-preserving loss
function. We also achieve low memory footprint for weights and activations by
means of mixed precision quantization-at-training techniques. The resulting
quantized models are comparable to the state of the art in terms of quality,
but they require very low GPU times and achieve up to 14-fold memory size
reduction for the weights w.r.t. their floating point counterpart with minimal
impact on quality metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DH-GAN: A Physics-driven Untrained Generative Adversarial Network for 3D Microscopic Imaging using Digital Holography. (arXiv:2205.12920v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12920">
<div class="article-summary-box-inner">
<span><p>Digital holography is a 3D imaging technique by emitting a laser beam with a
plane wavefront to an object and measuring the intensity of the diffracted
waveform, called holograms. The object's 3D shape can be obtained by numerical
analysis of the captured holograms and recovering the incurred phase. Recently,
deep learning (DL) methods have been used for more accurate holographic
processing. However, most supervised methods require large datasets to train
the model, which is rarely available in most DH applications due to the
scarcity of samples or privacy concerns. A few one-shot DL-based recovery
methods exist with no reliance on large datasets of paired images. Still, most
of these methods often neglect the underlying physics law that governs wave
propagation. These methods offer a black-box operation, which is not
explainable, generalizable, and transferrable to other samples and
applications. In this work, we propose a new DL architecture based on
generative adversarial networks that uses a discriminative network for
realizing a semantic measure for reconstruction quality while using a
generative network as a function approximator to model the inverse of hologram
formation. We impose smoothness on the background part of the recovered image
using a progressive masking module powered by simulated annealing to enhance
the reconstruction quality. The proposed method is one of its kind that
exhibits high transferability to similar samples, which facilitates its fast
deployment in time-sensitive applications without the need for retraining the
network. The results show a considerable improvement to competitor methods in
reconstruction quality (about 5 dB PSNR gain) and robustness to noise (about
50% reduction in PSNR vs noise increase rate).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Adaptation for Object Detection using SE Adaptors and Center Loss. (arXiv:2205.12923v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12923">
<div class="article-summary-box-inner">
<span><p>Despite growing interest in object detection, very few works address the
extremely practical problem of cross-domain robustness especially for
automative applications. In order to prevent drops in performance due to domain
shift, we introduce an unsupervised domain adaptation method built on the
foundation of faster-RCNN with two domain adaptation components addressing the
shift at the instance and image levels respectively and apply a consistency
regularization between them. We also introduce a family of adaptation layers
that leverage the squeeze excitation mechanism called SE Adaptors to improve
domain attention and thus improves performance without any prior requirement of
knowledge of the new target domain. Finally, we incorporate a center loss in
the instance and image level representations to improve the intra-class
variance. We report all results with Cityscapes as our source domain and Foggy
Cityscapes as the target domain outperforming previous baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pretraining is All You Need for Image-to-Image Translation. (arXiv:2205.12952v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12952">
<div class="article-summary-box-inner">
<span><p>We propose to use pretraining to boost general image-to-image translation.
Prior image-to-image translation methods usually need dedicated architectural
design and train individual translation models from scratch, struggling for
high-quality generation of complex scenes, especially when paired training data
are not abundant. In this paper, we regard each image-to-image translation
problem as a downstream task and introduce a simple and generic framework that
adapts a pretrained diffusion model to accommodate various kinds of
image-to-image translation. We also propose adversarial training to enhance the
texture synthesis in the diffusion model training, in conjunction with
normalized guidance sampling to improve the generation quality. We present
extensive empirical comparison across various tasks on challenging benchmarks
such as ADE20K, COCO-Stuff, and DIODE, showing the proposed pretraining-based
image-to-image translation (PITI) is capable of synthesizing images of
unprecedented realism and faithfulness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural 3D Reconstruction in the Wild. (arXiv:2205.12955v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12955">
<div class="article-summary-box-inner">
<span><p>We are witnessing an explosion of neural implicit representations in computer
vision and graphics. Their applicability has recently expanded beyond tasks
such as shape generation and image-based rendering to the fundamental problem
of image-based 3D reconstruction. However, existing methods typically assume
constrained 3D environments with constant illumination captured by a small set
of roughly uniformly distributed cameras. We introduce a new method that
enables efficient and accurate surface reconstruction from Internet photo
collections in the presence of varying illumination. To achieve this, we
propose a hybrid voxel- and surface-guided sampling technique that allows for
more efficient ray sampling around surfaces and leads to significant
improvements in reconstruction quality. Further, we present a new benchmark and
protocol for evaluating reconstruction performance on such in-the-wild scenes.
We perform extensive experiments, demonstrating that our approach surpasses
both classical and neural reconstruction methods on a wide variety of metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Inception Transformer. (arXiv:2205.12956v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12956">
<div class="article-summary-box-inner">
<span><p>Recent studies show that Transformer has strong capability of building
long-range dependencies, yet is incompetent in capturing high frequencies that
predominantly convey local information. To tackle this issue, we present a
novel and general-purpose Inception Transformer, or iFormer for short, that
effectively learns comprehensive features with both high- and low-frequency
information in visual data. Specifically, we design an Inception mixer to
explicitly graft the advantages of convolution and max-pooling for capturing
the high-frequency information to Transformers. Different from recent hybrid
frameworks, the Inception mixer brings greater efficiency through a channel
splitting mechanism to adopt parallel convolution/max-pooling path and
self-attention path as high- and low-frequency mixers, while having the
flexibility to model discriminative information scattered within a wide
frequency range. Considering that bottom layers play more roles in capturing
high-frequency details while top layers more in modeling low-frequency global
information, we further introduce a frequency ramp structure, i.e. gradually
decreasing the dimensions fed to the high-frequency mixer and increasing those
to the low-frequency mixer, which can effectively trade-off high- and
low-frequency components across different layers. We benchmark the iFormer on a
series of vision tasks, and showcase that it achieves impressive performance on
image classification, COCO detection and ADE20K segmentation. For example, our
iFormer-S hits the top-1 accuracy of 83.4% on ImageNet-1K, much higher than
DeiT-S by 3.6%, and even slightly better than much bigger model Swin-B (83.3%)
with only 1/4 parameters and 1/3 FLOPs. Code and models will be released at
https://github.com/sail-sg/iFormer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LiSHT: Non-Parametric Linearly Scaled Hyperbolic Tangent Activation Function for Neural Networks. (arXiv:1901.05894v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1901.05894">
<div class="article-summary-box-inner">
<span><p>The activation function in neural network is one of the important aspects
which facilitates the deep training by introducing the non-linearity into the
learning process. However, because of zero-hard rectification, some of the
existing activation functions such as ReLU and Swish miss to utilize the large
negative input values and may suffer from the dying gradient problem. Thus, it
is important to look for a better activation function which is free from such
problems. As a remedy, this paper proposes a new non-parametric function,
called Linearly Scaled Hyperbolic Tangent (LiSHT) for Neural Networks (NNs).
The proposed LiSHT activation function is an attempt to scale the non-linear
Hyperbolic Tangent (Tanh) function by a linear function and tackle the dying
gradient problem. The training and classification experiments are performed
over benchmark Iris, MNIST, CIFAR10, CIFAR100 and twitter140 datasets to show
that the proposed activation achieves faster convergence and higher
performance. A very promising performance improvement is observed on three
different type of neural networks including Multi-layer Perceptron (MLP),
Convolutional Neural Network (CNN) and Recurrent neural network like Long-short
term memory (LSTM). The advantages of proposed activation function are also
visualized in terms of the feature activation maps, weight distribution and
loss landscape. The code is available at https://github.com/swalpa/lisht.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Correlation Filters for Unmanned Aerial Vehicle-Based Aerial Tracking: A Review and Experimental Evaluation. (arXiv:2010.06255v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06255">
<div class="article-summary-box-inner">
<span><p>Aerial tracking, which has exhibited its omnipresent dedication and splendid
performance, is one of the most active applications in the remote sensing
field. Especially, unmanned aerial vehicle (UAV)-based remote sensing system,
equipped with a visual tracking approach, has been widely used in aviation,
navigation, agriculture,transportation, and public security, etc. As is
mentioned above, the UAV-based aerial tracking platform has been gradually
developed from research to practical application stage, reaching one of the
main aerial remote sensing technologies in the future. However, due to the
real-world onerous situations, e.g., harsh external challenges, the vibration
of the UAV mechanical structure (especially under strong wind conditions), the
maneuvering flight in complex environment, and the limited computation
resources onboard, accuracy, robustness, and high efficiency are all crucial
for the onboard tracking methods. Recently, the discriminative correlation
filter (DCF)-based trackers have stood out for their high computational
efficiency and appealing robustness on a single CPU, and have flourished in the
UAV visual tracking community. In this work, the basic framework of the
DCF-based trackers is firstly generalized, based on which, 23 state-of-the-art
DCF-based trackers are orderly summarized according to their innovations for
solving various issues. Besides, exhaustive and quantitative experiments have
been extended on various prevailing UAV tracking benchmarks, i.e., UAV123,
UAV123@10fps, UAV20L, UAVDT, DTB70, and VisDrone2019-SOT, which contain 371,903
frames in total. The experiments show the performance, verify the feasibility,
and demonstrate the current challenges of DCF-based trackers onboard UAV
tracking.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RELLIS-3D Dataset: Data, Benchmarks and Analysis. (arXiv:2011.12954v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12954">
<div class="article-summary-box-inner">
<span><p>Semantic scene understanding is crucial for robust and safe autonomous
navigation, particularly so in off-road environments. Recent deep learning
advances for 3D semantic segmentation rely heavily on large sets of training
data, however existing autonomy datasets either represent urban environments or
lack multimodal off-road data. We fill this gap with RELLIS-3D, a multimodal
dataset collected in an off-road environment, which contains annotations for
13,556 LiDAR scans and 6,235 images. The data was collected on the Rellis
Campus of Texas A\&amp;M University and presents challenges to existing algorithms
related to class imbalance and environmental topography. Additionally, we
evaluate the current state-of-the-art deep learning semantic segmentation
models on this dataset. Experimental results show that RELLIS-3D presents
challenges for algorithms designed for segmentation in urban environments. This
novel dataset provides the resources needed by researchers to continue to
develop more advanced algorithms and investigate new research directions to
enhance autonomous navigation in off-road environments. RELLIS-3D is available
at https://github.com/unmannedlab/RELLIS-3D
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D Object Detection for Autonomous Driving: A Survey. (arXiv:2106.10823v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10823">
<div class="article-summary-box-inner">
<span><p>Autonomous driving is regarded as one of the most promising remedies to
shield human beings from severe crashes. To this end, 3D object detection
serves as the core basis of perception stack especially for the sake of path
planning, motion prediction, and collision avoidance etc. Taking a quick glance
at the progress we have made, we attribute challenges to visual appearance
recovery in the absence of depth information from images, representation
learning from partially occluded unstructured point clouds, and semantic
alignments over heterogeneous features from cross modalities. Despite existing
efforts, 3D object detection for autonomous driving is still in its infancy.
Recently, a large body of literature have been investigated to address this 3D
vision task. Nevertheless, few investigations have looked into collecting and
structuring this growing knowledge. We therefore aim to fill this gap in a
comprehensive survey, encompassing all the main concerns including sensors,
datasets, performance metrics and the recent state-of-the-art detection
methods, together with their pros and cons. Furthermore, we provide
quantitative comparisons with the state of the art. A case study on fifteen
selected representative methods is presented, involved with runtime analysis,
error analysis, and robustness analysis. Finally, we provide concluding remarks
after an in-depth analysis of the surveyed works and identify promising
directions for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Core Challenges in Embodied Vision-Language Planning. (arXiv:2106.13948v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13948">
<div class="article-summary-box-inner">
<span><p>Recent advances in the areas of multimodal machine learning and artificial
intelligence (AI) have led to the development of challenging tasks at the
intersection of Computer Vision, Natural Language Processing, and Embodied AI.
Whereas many approaches and previous survey pursuits have characterised one or
two of these dimensions, there has not been a holistic analysis at the center
of all three. Moreover, even when combinations of these topics are considered,
more focus is placed on describing, e.g., current architectural methods, as
opposed to also illustrating high-level challenges and opportunities for the
field. In this survey paper, we discuss Embodied Vision-Language Planning
(EVLP) tasks, a family of prominent embodied navigation and manipulation
problems that jointly use computer vision and natural language. We propose a
taxonomy to unify these tasks and provide an in-depth analysis and comparison
of the new and current algorithmic approaches, metrics, simulated environments,
as well as the datasets used for EVLP tasks. Finally, we present the core
challenges that we believe new EVLP works should seek to address, and we
advocate for task construction that enables model generalizability and furthers
real-world deployment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Temporal Action Localization Using Gated Recurrent Units. (arXiv:2108.03375v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03375">
<div class="article-summary-box-inner">
<span><p>Temporal Action Localization (TAL) task which is to predict the start and end
of each action in a video along with the class label of the action has numerous
applications in the real world. But due to the complexity of this task,
acceptable accuracy rates have not been achieved yet, whereas this is not the
case regarding the action recognition task. In this paper, we propose a new
network based on Gated Recurrent Unit (GRU) and two novel post-processing
methods for TAL task. Specifically, we propose a new design for the output
layer of the conventionally GRU resulting in the so-called GRU-Split network.
Moreover, linear interpolation is used to generate the action proposals with
precise start and end times. Finally, to rank the generated proposals
appropriately, we use a Learn to Rank (LTR) approach. We evaluated the
performance of the proposed method on Thumos14 and ActivityNet-1.3 datasets.
Results show the superiority of the performance of the proposed method compared
to state-of-the-art. Specifically in the mean Average Precision (mAP) metric at
Intersection over Union (IoU) of 0.7 on Thumos14, we get 27.52% accuracy which
is 5.12% better than that of state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Foveated Reconstruction to Preserve Perceived Image Statistics. (arXiv:2108.03499v2 [cs.GR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03499">
<div class="article-summary-box-inner">
<span><p>Foveated image reconstruction recovers full image from a sparse set of
samples distributed according to the human visual system's retinal sensitivity
that rapidly drops with eccentricity. Recently, the use of Generative
Adversarial Networks was shown to be a promising solution for such a task as
they can successfully hallucinate missing image information. Like for other
supervised learning approaches, also for this one, the definition of the loss
function and training strategy heavily influences the output quality. In this
work, we pose the question of how to efficiently guide the training of foveated
reconstruction techniques such that they are fully aware of the human visual
system's capabilities and limitations, and therefore, reconstruct visually
important image features. Our primary goal is to make training procedure less
sensitive to the distortions that humans cannot detect and focus on penalizing
perceptually important artifacts. Due to the nature of GAN-based solutions, we
concentrate on humans' sensitivity to hallucination for different input sample
densities. We present new psychophysical experiments, a dataset, and a
procedure for training foveated image reconstruction. The strategy provides
flexibility to the generator network by penalizing only perceptually important
deviations in the output. As a result, the method aims to preserve perceived
image statistics rather than natural image statistics. We evaluate our strategy
and compare it to alternative solutions using a newly trained objective metric,
a recent foveated video quality metric, and user experiments. Our evaluations
show significant improvements in perceived image reconstruction quality
compared to standard GAN training approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PVT: Point-Voxel Transformer for Point Cloud Learning. (arXiv:2108.06076v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06076">
<div class="article-summary-box-inner">
<span><p>The recently developed pure Transformer architectures have attained promising
accuracy on point cloud learning benchmarks compared to convolutional neural
networks. However, existing point cloud Transformers are computationally
expensive since they waste a significant amount of time on structuring the
irregular data. To solve this shortcoming, we present Sparse Window Attention
(SWA) module to gather coarse-grained local features from non-empty voxels,
which not only bypasses the expensive irregular data structuring and invalid
empty voxel computation, but also obtains linear computational complexity with
respect to voxel resolution. Meanwhile, to gather fine-grained features about
the global shape, we introduce relative attention (RA) module, a more robust
self-attention variant for rigid transformations of objects. Equipped with the
SWA and RA, we construct our neural architecture called PVT that integrates
both modules into a joint framework for point cloud learning. Compared with
previous Transformer-based and attention-based models, our method attains top
accuracy of 94.0% on classification benchmark and 10x inference speedup on
average. Extensive experiments also valid the effectiveness of PVT on part and
semantic segmentation benchmarks (86.6% and 69.2% mIoU, respectively).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning JPEG Compression Artifacts for Image Manipulation Detection and Localization. (arXiv:2108.12947v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12947">
<div class="article-summary-box-inner">
<span><p>Detecting and localizing image manipulation are necessary to counter
malicious use of image editing techniques. Accordingly, it is essential to
distinguish between authentic and tampered regions by analyzing intrinsic
statistics in an image. We focus on JPEG compression artifacts left during
image acquisition and editing. We propose a convolutional neural network (CNN)
that uses discrete cosine transform (DCT) coefficients, where compression
artifacts remain, to localize image manipulation. Standard CNNs cannot learn
the distribution of DCT coefficients because the convolution throws away the
spatial coordinates, which are essential for DCT coefficients. We illustrate
how to design and train a neural network that can learn the distribution of DCT
coefficients. Furthermore, we introduce Compression Artifact Tracing Network
(CAT-Net) that jointly uses image acquisition artifacts and compression
artifacts. It significantly outperforms traditional and deep neural
network-based methods in detecting and localizing tampered regions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Kernel Representation for Image Reconstruction in PET. (arXiv:2110.01174v4 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01174">
<div class="article-summary-box-inner">
<span><p>Image reconstruction for positron emission tomography (PET) is challenging
because of the ill-conditioned tomographic problem and low counting statistics.
Kernel methods address this challenge by using kernel representation to
incorporate image prior information in the forward model of iterative PET image
reconstruction. Existing kernel methods construct the kernels commonly using an
empirical process, which may lead to unsatisfactory performance. In this paper,
we describe the equivalence between the kernel representation and a trainable
neural network model. A deep kernel method is then proposed by exploiting a
deep neural network to enable automated learning of an improved kernel model
and is directly applicable to single subjects in dynamic PET. The training
process utilizes available image prior data to form a set of robust kernels in
an optimized way rather than empirically. The results from computer simulations
and a real patient dataset demonstrate that the proposed deep kernel method can
outperform the existing kernel method and neural network method for dynamic PET
image reconstruction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do we still need ImageNet pre-training in remote sensing scene classification?. (arXiv:2111.03690v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.03690">
<div class="article-summary-box-inner">
<span><p>Due to the scarcity of labeled data, using supervised models pre-trained on
ImageNet is a de facto standard in remote sensing scene classification.
Recently, the availability of larger high resolution remote sensing (HRRS)
image datasets and progress in self-supervised learning have brought up the
questions of whether supervised ImageNet pre-training is still necessary for
remote sensing scene classification and would supervised pre-training on HRRS
image datasets or self-supervised pre-training on ImageNet achieve better
results on target remote sensing scene classification tasks. To answer these
questions, in this paper we both train models from scratch and fine-tune
supervised and self-supervised ImageNet models on several HRRS image datasets.
We also evaluate the transferability of learned representations to HRRS scene
classification tasks and show that self-supervised pre-training outperforms the
supervised one, while the performance of HRRS pre-training is similar to
self-supervised pre-training or slightly lower. Finally, we propose using an
ImageNet pre-trained model combined with a second round of pre-training using
in-domain HRRS images, i.e. domain-adaptive pre-training. The experimental
results show that domain-adaptive pre-training results in models that achieve
state-of-the-art results on HRRS scene classification benchmarks. The source
code and pre-trained models are available at
\url{https://github.com/risojevicv/RSSC-transfer}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Aerial Images Meet Crowdsourced Trajectories: A New Approach to Robust Road Extraction. (arXiv:2111.15119v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.15119">
<div class="article-summary-box-inner">
<span><p>Land remote sensing analysis is a crucial research in earth science. In this
work, we focus on a challenging task of land analysis, i.e., automatic
extraction of traffic roads from remote sensing data, which has widespread
applications in urban development and expansion estimation. Nevertheless,
conventional methods either only utilized the limited information of aerial
images, or simply fused multimodal information (e.g., vehicle trajectories),
thus cannot well recognize unconstrained roads. To facilitate this problem, we
introduce a novel neural network framework termed Cross-Modal Message
Propagation Network (CMMPNet), which fully benefits the complementary different
modal data (i.e., aerial images and crowdsourced trajectories). Specifically,
CMMPNet is composed of two deep Auto-Encoders for modality-specific
representation learning and a tailor-designed Dual Enhancement Module for
cross-modal representation refinement. In particular, the complementary
information of each modality is comprehensively extracted and dynamically
propagated to enhance the representation of another modality. Extensive
experiments on three real-world benchmarks demonstrate the effectiveness of our
CMMPNet for robust road extraction benefiting from blending different modal
data, either using image and trajectory data or image and Lidar data. From the
experimental results, we observe that the proposed approach outperforms current
state-of-the-art methods by large margins.Our source code is resealed on the
project page <a href="http://lingboliu.com/multimodal_road_extraction.html.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Temporally Resolution Decrement: Utilizing the Shape Consistency for Higher Computational Efficiency. (arXiv:2112.00954v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.00954">
<div class="article-summary-box-inner">
<span><p>Image resolution that has close relations with accuracy and computational
cost plays a pivotal role in network training. In this paper, we observe that
the reduced image retains relatively complete shape semantics but loses
extensive texture information. Inspired by the consistency of the shape
semantics as well as the fragility of the texture information, we propose a
novel training strategy named Temporally Resolution Decrement. Wherein, we
randomly reduce the training images to a smaller resolution in the time domain.
During the alternate training with the reduced images and the original images,
the unstable texture information in the images results in a weaker correlation
between the texture-related patterns and the correct label, naturally enforcing
the model to rely more on shape properties that are robust and conform to the
human decision rule. Surprisingly, our approach greatly improves both the
training and inference efficiency of convolutional neural networks. On ImageNet
classification, using only 33\% calculation quantity (randomly reducing the
training image to 112$\times$112 within 90\% epochs) can still improve
ResNet-50 from 76.32\% to 77.71\%. Superimposed with the strong training
procedure of ResNet-50 on ImageNet, our method achieves 80.42\% top-1 accuracy
with saving 37.5\% calculation overhead. To the best of our knowledge this is
the highest ImageNet single-crop accuracy on ResNet-50 under 224$\times$224
without extra data or distillation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating the usefulness of Quantum Blur. (arXiv:2112.01646v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.01646">
<div class="article-summary-box-inner">
<span><p>Though some years remain before quantum computation can outperform
conventional computation, it already provides resources that can be used for
exploratory purposes in various fields. This includes certain tasks for
procedural generation in computer games, music and art. The so-called `Quantum
Blur' method represents the first step on this journey, providing a simple
proof-of-principle example of how quantum software can be useful in these areas
today. Here we analyse the `Quantum Blur' method and compare it to conventional
blur effects. This investigation was guided by discussions with the most
prominent user of the method, to determine which features were found most
useful. In particular we determine how these features depend on the quantum
phenomena of superposition and entanglement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Paced Deep Regression Forests with Consideration on Ranking Fairness. (arXiv:2112.06455v7 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06455">
<div class="article-summary-box-inner">
<span><p>Deep discriminative models (DDMs), e.g. deep regression forests and deep
decision forests, have been extensively studied recently to solve problems such
as facial age estimation, head pose estimation, etc.. Due to a shortage of
well-labeled data that does not have noise and imbalanced distribution
problems, learning DDMs is always challenging. Existing methods usually tackle
these challenges through learning more discriminative features or re-weighting
samples. We argue that learning DDMs gradually, from easy to hard, is more
reasonable, for two reasons. First, this is more consistent with the cognitive
process of human beings. Second, noisy as well as underrepresented examples can
be distinguished by virtue of previously learned knowledge. Thus, we resort to
a gradual learning strategy -- self-paced learning (SPL). Then, a natural
question arises: can SPL lead DDMs to achieve more robust and less biased
solutions? To answer this question, this paper proposes a new SPL method: easy
and underrepresented examples first, for learning DDMs. This tackles the
fundamental ranking and selection problem in SPL from a new perspective:
fairness. Our idea is fundamental and can be easily combined with a variety of
DDMs. Extensive experimental results on three computer vision tasks, i.e.,
facial age estimation, head pose estimation, and gaze estimation, show our new
method gains considerable performance improvement in both accuracy and
fairness. Source code is available at https://github.com/learninginvision/SPU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention-based Proposals Refinement for 3D Object Detection. (arXiv:2201.07070v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.07070">
<div class="article-summary-box-inner">
<span><p>Recent advances in 3D object detection are made by developing the refinement
stage for voxel-based Region Proposal Networks (RPN) to better strike the
balance between accuracy and efficiency. A popular approach among
state-of-the-art frameworks is to divide proposals, or Regions of Interest
(ROI), into grids and extract features for each grid location before
synthesizing them to form ROI features. While achieving impressive
performances, such an approach involves several hand-crafted components (e.g.
grid sampling, set abstraction) which requires expert knowledge to be tuned
correctly. This paper proposes a data-driven approach to ROI feature computing
named APRO3D-Net which consists of a voxel-based RPN and a refinement stage
made of Vector Attention. Unlike the original multi-head attention, Vector
Attention assigns different weights to different channels within a point
feature, thus being able to capture a more sophisticated relation between
pooled points and ROI. Our method achieves a competitive performance of 84.85
AP for class Car at moderate difficulty on the validation set of KITTI and
47.03 mAP (average over 10 classes) on NuScenes while having the least
parameters compared to closely related methods and attaining an inference speed
at 15 FPS on NVIDIA V100 GPU. The code is released at
https://github.com/quan-dao/APRO3D-Net.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Scene Flow Estimation with 4D Automotive Radar. (arXiv:2203.01137v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.01137">
<div class="article-summary-box-inner">
<span><p>Scene flow allows autonomous vehicles to reason about the arbitrary motion of
multiple independent objects which is the key to long-term mobile autonomy.
While estimating the scene flow from LiDAR has progressed recently, it remains
largely unknown how to estimate the scene flow from a 4D radar - an
increasingly popular automotive sensor for its robustness against adverse
weather and lighting conditions. Compared with the LiDAR point clouds, radar
data are drastically sparser, noisier and in much lower resolution. Annotated
datasets for radar scene flow are also in absence and costly to acquire in the
real world. These factors jointly pose the radar scene flow estimation as a
challenging problem. This work aims to address the above challenges and
estimate scene flow from 4D radar point clouds by leveraging self-supervised
learning. A robust scene flow estimation architecture and three novel losses
are bespoken designed to cope with intractable radar data. Real-world
experimental results validate that our method is able to robustly estimate the
radar scene flow in the wild and effectively supports the downstream task of
motion segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Tree-Structured Multi-Task Model Recommender. (arXiv:2203.05092v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.05092">
<div class="article-summary-box-inner">
<span><p>Tree-structured multi-task architectures have been employed to jointly tackle
multiple vision tasks in the context of multi-task learning (MTL). The major
challenge is to determine where to branch out for each task given a backbone
model to optimize for both task accuracy and computation efficiency. To address
the challenge, this paper proposes a recommender that, given a set of tasks and
a convolutional neural network-based backbone model, automatically suggests
tree-structured multi-task architectures that could achieve a high task
performance while meeting a user-specified computation budget without
performing model training. Extensive evaluations on popular MTL benchmarks show
that the recommended architectures could achieve competitive task accuracy and
computation efficiency compared with state-of-the-art MTL methods. Our
tree-structured multi-task model recommender is open-sourced and available at
https://github.com/zhanglijun95/TreeMTL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text2LIVE: Text-Driven Layered Image and Video Editing. (arXiv:2204.02491v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.02491">
<div class="article-summary-box-inner">
<span><p>We present a method for zero-shot, text-driven appearance manipulation in
natural images and videos. Given an input image or video and a target text
prompt, our goal is to edit the appearance of existing objects (e.g., object's
texture) or augment the scene with visual effects (e.g., smoke, fire) in a
semantically meaningful manner. We train a generator using an internal dataset
of training examples, extracted from a single input (image or video and target
text prompt), while leveraging an external pre-trained CLIP model to establish
our losses. Rather than directly generating the edited output, our key idea is
to generate an edit layer (color+opacity) that is composited over the original
input. This allows us to constrain the generation process and maintain high
fidelity to the original input via novel text-driven losses that are applied
directly to the edit layer. Our method neither relies on a pre-trained
generator nor requires user-provided edit masks. We demonstrate localized,
semantic edits on high-resolution natural images and videos across a variety of
objects and scenes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sketch guided and progressive growing GAN for realistic and editable ultrasound image synthesis. (arXiv:2204.06929v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.06929">
<div class="article-summary-box-inner">
<span><p>Ultrasound (US) imaging is widely used for anatomical structure inspection in
clinical diagnosis. The training of new sonographers and deep learning based
algorithms for US image analysis usually requires a large amount of data.
However, obtaining and labeling large-scale US imaging data are not easy tasks,
especially for diseases with low incidence. Realistic US image synthesis can
alleviate this problem to a great extent. In this paper, we propose a
generative adversarial network (GAN) based image synthesis framework. Our main
contributions include: 1) we present the first work that can synthesize
realistic B-mode US images with high-resolution and customized texture editing
features; 2) to enhance structural details of generated images, we propose to
introduce auxiliary sketch guidance into a conditional GAN. We superpose the
edge sketch onto the object mask and use the composite mask as the network
input; 3) to generate high-resolution US images, we adopt a progressive
training strategy to gradually generate high-resolution images from
low-resolution images. In addition, a feature loss is proposed to minimize the
difference of high-level features between the generated and real images, which
further improves the quality of generated images; 4) the proposed US image
synthesis method is quite universal and can also be generalized to the US
images of other anatomical structures besides the three ones tested in our
study (lung, hip joint, and ovary); 5) extensive experiments on three large US
image datasets are conducted to validate our method. Ablation studies,
customized texture editing, user studies, and segmentation tests demonstrate
promising results of our method in synthesizing realistic US images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Controllable Image Captioning. (arXiv:2204.13324v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.13324">
<div class="article-summary-box-inner">
<span><p>State-of-the-art image captioners can generate accurate sentences to describe
images in a sequence to sequence manner without considering the controllability
and interpretability. This, however, is far from making image captioning widely
used as an image can be interpreted in infinite ways depending on the target
and the context at hand. Achieving controllability is important especially when
the image captioner is used by different people with different way of
interpreting the images. In this paper, we introduce a novel framework for
image captioning which can generate diverse descriptions by capturing the
co-dependence between Part-Of-Speech tags and semantics. Our model decouples
direct dependence between successive variables. In this way, it allows the
decoder to exhaustively search through the latent Part-Of-Speech choices, while
keeping decoding speed proportional to the size of the POS vocabulary. Given a
control signal in the form of a sequence of Part-Of-Speech tags, we propose a
method to generate captions through a Transformer network, which predicts words
based on the input Part-Of-Speech tag sequences. Experiments on publicly
available datasets show that our model significantly outperforms
state-of-the-art methods on generating diverse image captions with high
qualities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coupling Deep Imputation with Multitask Learning for Downstream Tasks on Genomics Data. (arXiv:2204.13705v2 [q-bio.GN] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.13705">
<div class="article-summary-box-inner">
<span><p>Genomics data such as RNA gene expression, methylation and micro RNA
expression are valuable sources of information for various clinical predictive
tasks. For example, predicting survival outcomes, cancer histology type and
other patients' related information is possible using not only clinical data
but molecular data as well. Moreover, using these data sources together, for
example in multitask learning, can boost the performance. However, in practice,
there are many missing data points which leads to significantly lower patient
numbers when analysing full cases, which in our setting refers to all
modalities being present.
</p>
<p>In this paper we investigate how imputing data with missing values using deep
learning coupled with multitask learning can help to reach state-of-the-art
performance results using combined genomics modalities, RNA, micro RNA and
methylation. We propose a generalised deep imputation method to impute values
where a patient has all modalities present except one. Interestingly enough,
deep imputation alone outperforms multitask learning alone for the
classification and regression tasks across most combinations of modalities. In
contrast, when using all modalities for survival prediction we observe that
multitask learning alone outperforms deep imputation alone with statistical
significance (adjusted p-value 0.03). Thus, both approaches are complementary
when optimising performance for downstream predictive tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Depth Estimation with Simplified Transformer. (arXiv:2204.13791v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.13791">
<div class="article-summary-box-inner">
<span><p>Transformer and its variants have shown state-of-the-art results in many
vision tasks recently, ranging from image classification to dense prediction.
Despite of their success, limited work has been reported on improving the model
efficiency for deployment in latency-critical applications, such as autonomous
driving and robotic navigation. In this paper, we aim at improving upon the
existing transformers in vision, and propose a method for self-supervised
monocular Depth Estimation with Simplified Transformer (DEST), which is
efficient and particularly suitable for deployment on GPU-based platforms.
Through strategic design choices, our model leads to significant reduction in
model size, complexity, as well as inference latency, while achieving superior
accuracy as compared to state-of-the-art. We also show that our design
generalize well to other dense prediction task without bells and whistles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">From Noisy Prediction to True Label: Noisy Prediction Calibration via Generative Model. (arXiv:2205.00690v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.00690">
<div class="article-summary-box-inner">
<span><p>Noisy labels are inevitable yet problematic in machine learning society. It
ruins the generalization power of a classifier by making the classifier be
trained to be overfitted to wrong labels. Existing methods on noisy label have
focused on modifying classifier training procedure. It results in two possible
problems. First, these methods are not applicable to a pre-trained classifier
without further access into training. Second, it is not easy to train a
classifier and remove all of negative effects from noisy labels simultaneously.
From these problems, we suggests a new branch of approach, Noisy Prediction
Calibration (NPC) in learning with noisy labels. Through the introduction and
estimation of a new type of transition matrix via generative model, NPC
corrects the noisy prediction from the pre-trained classifier to the true label
as a post-processing scheme. We prove that NPC theoretically aligns with the
transition matrix based methods. Yet, NPC provides more accurate pathway to
estimate true label, even without involvement in classifier learning. Also, NPC
is applicable to any classifier trained with noisy label methods, if training
instances and its predictions are available. Our method, NPC, boosts the
classification performances of all baseline models on both synthetic and
real-world datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FreeMatch: Self-adaptive Thresholding for Semi-supervised Learning. (arXiv:2205.07246v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.07246">
<div class="article-summary-box-inner">
<span><p>Pseudo labeling and consistency regularization approaches based on confidence
thresholding have made great progress in semi-supervised learning (SSL).
However, we argue that existing methods might fail to adopt suitable thresholds
since they either use a pre-defined / fixed threshold or an ad-hoc threshold
adjusting scheme, resulting in inferior performance and slow convergence. We
first analyze a motivating example to achieve some intuitions on the
relationship between the desirable threshold and model's learning status. Based
on the analysis, we hence propose FreeMatch to define and adjust the confidence
threshold in a self-adaptive manner according to the model's learning status.
We further introduce a self-adaptive class fairness regularization penalty that
encourages the model to produce diverse predictions during the early stages of
training. Extensive experimental results indicate the superiority of FreeMatch
especially when the labeled data are extremely rare. FreeMatch achieves 5.78%,
13.59%, and 1.28% error rate reduction over the latest state-of-the-art method
FlexMatch on CIFAR-10 with 1 label per class, STL-10 with 4 labels per class,
and ImageNet with 100 labels per class, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLCNet: Rethinking of Ensemble Modeling with Classification Confidence Network. (arXiv:2205.09612v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09612">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a Classification Confidence Network (CLCNet) that
can determine whether the classification model classifies input samples
correctly. It can take a classification result in the form of vector in any
dimension, and return a confidence score as output, which represents the
probability of an instance being classified correctly. We can utilize CLCNet in
a simple cascade structure system consisting of several SOTA (state-of-the-art)
classification models, and our experiments show that the system can achieve the
following advantages: 1. The system can customize the average computation
requirement (FLOPs) per image while inference. 2. Under the same computation
requirement, the performance of the system can exceed any model that has
identical structure with the model in the system, but different in size. In
fact, this is a new type of ensemble modeling. Like general ensemble modeling,
it can achieve higher performance than single classification model, yet our
system requires much less computation than general ensemble modeling. We have
uploaded our code to a github repository:
https://github.com/yaoching0/CLCNet-Rethinking-of-Ensemble-Modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VNT-Net: Rotational Invariant Vector Neuron Transformers. (arXiv:2205.09690v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09690">
<div class="article-summary-box-inner">
<span><p>Learning 3D point sets with rotational invariance is an important and
challenging problem in machine learning. Through rotational invariant
architectures, 3D point cloud neural networks are relieved from requiring a
canonical global pose and from exhaustive data augmentation with all possible
rotations. In this work, we introduce a rotational invariant neural network by
combining recently introduced vector neurons with self-attention layers to
build a point cloud vector neuron transformer network (VNT-Net). Vector neurons
are known for their simplicity and versatility in representing SO(3) actions
and are thereby incorporated in common neural operations. Similarly,
Transformer architectures have gained popularity and recently were shown
successful for images by applying directly on sequences of image patches and
achieving superior performance and convergence. In order to benefit from both
worlds, we combine the two structures by mainly showing how to adapt the
multi-headed attention layers to comply with vector neurons operations. Through
this adaptation attention layers become SO(3) and the overall network becomes
rotational invariant. Experiments demonstrate that our network efficiently
handles 3D point cloud objects in arbitrary poses. We also show that our
network achieves higher accuracy when compared to related state-of-the-art
methods and requires less training due to a smaller number of hyperparameters
in common classification and segmentation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">People Tracking and Re-Identifying in Distributed Contexts: Extension Study of PoseTReID. (arXiv:2205.10086v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10086">
<div class="article-summary-box-inner">
<span><p>In our previous paper, we introduced PoseTReID which is a generic framework
for real-time 2D multi-person tracking in distributed interaction spaces where
long-term people's identities are important for other studies such as behavior
analysis, etc. In this paper, we introduce a further study of PoseTReID
framework in order to give a more complete comprehension of the framework. We
use a well-known bounding box detector YOLO (v4) for the detection to compare
to OpenPose which was used in our last paper, and we use SORT and DeepSORT to
compare to centroid which was also used previously, and most importantly for
the re-identification, we use a bunch of deep leaning methods such as MLFN,
OSNet, and OSNet-AIN with our custom classification layer to compare to FaceNet
which was also used earlier in our last paper. By evaluating on our PoseTReID
datasets, even though those deep learning re-identification methods are
designed for only short-term re-identification across multiple cameras or
videos, it is worth showing that they give impressive results which boost the
overall tracking performance of PoseTReID framework regardless the type of
tracking method. At the same time, we also introduce our research-friendly and
open source Python toolbox pyppbox, which is purely written in Python and
contains all sub-modules which are used in this study along with real-time
online and offline evaluations for our PoseTReID datasets. This pyppbox is
available on GitHub https://github.com/rathaumons/pyppbox .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">muNet: Evolving Pretrained Deep Neural Networks into Scalable Auto-tuning Multitask Systems. (arXiv:2205.10937v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10937">
<div class="article-summary-box-inner">
<span><p>Most uses of machine learning today involve training a model from scratch for
a particular task, or sometimes starting with a model pretrained on a related
task and then fine-tuning on a downstream task. Both approaches offer limited
knowledge transfer between different tasks, time-consuming human-driven
customization to individual tasks and high computational costs especially when
starting from randomly initialized models. We propose a method that uses the
layers of a pretrained deep neural network as building blocks to construct an
ML system that can jointly solve an arbitrary number of tasks. The resulting
system can leverage cross tasks knowledge transfer, while being immune from
common drawbacks of multitask approaches such as catastrophic forgetting,
gradients interference and negative transfer. We define an evolutionary
approach designed to jointly select the prior knowledge relevant for each task,
choose the subset of the model parameters to train and dynamically auto-tune
its hyperparameters. Furthermore, a novel scale control method is employed to
achieve quality/size trade-offs that outperform common fine-tuning techniques.
Compared with standard fine-tuning on a benchmark of 10 diverse image
classification tasks, the proposed model improves the average accuracy by 2.39%
while using 47% less parameters per task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NPU-BOLT: A Dataset for Bolt Object Detection in Natural Scene Images. (arXiv:2205.11191v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11191">
<div class="article-summary-box-inner">
<span><p>Bolt joints are very common and important in engineering structures. Due to
extreme service environment and load factors, bolts often get loose or even
disengaged. To real-time or timely detect the loosed or disengaged bolts is an
urgent need in practical engineering, which is critical to keep structural
safety and service life. In recent years, many bolt loosening detection methods
using deep learning and machine learning techniques have been proposed and are
attracting more and more attention. However, most of these studies use bolt
images captured in laboratory for deep leaning model training. The images are
obtained in a well-controlled light, distance, and view angle conditions. Also,
the bolted structures are well designed experimental structures with brand new
bolts and the bolts are exposed without any shelter nearby. It is noted that in
practical engineering, the above well controlled lab conditions are not easy
realized and the real bolt images often have blur edges, oblique perspective,
partial occlusion and indistinguishable colors etc., which make the trained
models obtained in laboratory conditions loss their accuracy or fails.
Therefore, the aim of this study is to develop a dataset named NPU-BOLT for
bolt object detection in natural scene images and open it to researchers for
public use and further development. In the first version of the dataset, it
contains 337 samples of bolt joints images mainly in the natural environment,
with image data sizes ranging from 400*400 to 6000*4000, totaling approximately
1275 bolt targets. The bolt targets are annotated into four categories named
blur bolt, bolt head, bolt nut and bolt side. The dataset is tested with
advanced object detection models including yolov5, Faster-RCNN and CenterNet.
The effectiveness of the dataset is validated.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Domain Adaptation with Multi-level Contrastive Units for Semantic Segmentation. (arXiv:2205.11192v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11192">
<div class="article-summary-box-inner">
<span><p>To further reduce the cost of semi-supervised domain adaptation (SSDA)
labeling, a more effective way is to use active learning (AL) to annotate a
selected subset with specific properties. However, domain adaptation tasks are
always addressed in two interactive aspects: domain transfer and the
enhancement of discrimination, which requires the selected data to be both
uncertain under the model and diverse in feature space. Contrary to active
learning in classification tasks, it is usually challenging to select pixels
that contain both the above properties in segmentation tasks, leading to the
complex design of pixel selection strategy. To address such an issue, we
propose a novel Active Domain Adaptation scheme with Multi-level Contrastive
Units (ADA-MCU) for semantic image segmentation. A simple pixel selection
strategy followed with the construction of multi-level contrastive units is
introduced to optimize the model for both domain adaptation and active
supervised learning. In practice, MCUs are constructed from intra-image,
cross-image, and cross-domain levels by using both labeled and unlabeled
pixels. At each level, we define contrastive losses from center-to-center and
pixel-to-pixel manners, with the aim of jointly aligning the category centers
and reducing outliers near the decision boundaries. In addition, we also
introduce a categories correlation matrix to implicitly describe the
relationship between categories, which are used to adjust the weights of the
losses for MCUs. Extensive experimental results on standard benchmarks show
that the proposed method achieves competitive performance against
state-of-the-art SSDA methods with 50% fewer labeled pixels and significantly
outperforms state-of-the-art with a large margin by using the same level of
annotation cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discriminative Feature Learning through Feature Distance Loss. (arXiv:2205.11606v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11606">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks have shown remarkable ability to learn
discriminative semantic features in image recognition tasks. Though, for
classification they often concentrate on specific regions in images. This work
proposes a novel method that combines variant rich base models to concentrate
on different important image regions for classification. A feature distance
loss is implemented while training an ensemble of base models to force them to
learn discriminative feature concepts. The experiments on benchmark
convolutional neural networks (VGG16, ResNet, AlexNet), popular datasets
(Cifar10, Cifar100, miniImageNet, NEU, BSD, TEX), and different training
samples (3, 5, 10, 20, 50, 100 per class) show our methods effectiveness and
generalization ability. Our method outperforms ensemble versions of the base
models without feature distance loss, and the Class Activation Maps explicitly
proves the ability to learn different discriminative feature concepts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diffuse Map Guiding Unsupervised Generative Adversarial Network for SVBRDF Estimation. (arXiv:2205.11951v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.11951">
<div class="article-summary-box-inner">
<span><p>Reconstructing materials in the real world has always been a difficult
problem in computer graphics. Accurately reconstructing the material in the
real world is critical in the field of realistic rendering. Traditionally,
materials in computer graphics are mapped by an artist, then mapped onto a
geometric model by coordinate transformation, and finally rendered with a
rendering engine to get realistic materials. For opaque objects, the industry
commonly uses physical-based bidirectional reflectance distribution function
(BRDF) rendering models for material modeling. The commonly used physical-based
rendering models are Cook-Torrance BRDF, Disney BRDF. In this paper, we use the
Cook-Torrance model to reconstruct the materials. The SVBRDF material
parameters include Normal, Diffuse, Specular and Roughness. This paper presents
a Diffuse map guiding material estimation method based on the Generative
Adversarial Network(GAN). This method can predict plausible SVBRDF maps with
global features using only a few pictures taken by the mobile phone. The main
contributions of this paper are: 1) We preprocess a small number of input
pictures to produce a large number of non-repeating pictures for training to
reduce over-fitting. 2) We use a novel method to directly obtain the guessed
diffuse map with global characteristics, which provides more prior information
for the training process. 3) We improve the network architecture of the
generator so that it can generate fine details of normal maps and reduce the
possibility to generate over-flat normal maps. The method used in this paper
can obtain prior knowledge without using dataset training, which greatly
reduces the difficulty of material reconstruction and saves a lot of time to
generate and calibrate datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">mPLUG: Effective and Efficient Vision-Language Learning by Cross-modal Skip-connections. (arXiv:2205.12005v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12005">
<div class="article-summary-box-inner">
<span><p>Large-scale pretrained foundation models have been an emerging paradigm for
building artificial intelligence (AI) systems, which can be quickly adapted to
a wide range of downstream tasks. This paper presents mPLUG, a new
vision-language foundation model for both cross-modal understanding and
generation. Most existing pre-trained models suffer from the problems of low
computational efficiency and information asymmetry brought by the long visual
sequence in cross-modal alignment. To address these problems, mPLUG introduces
an effective and efficient vision-language architecture with novel cross-modal
skip-connections, which creates inter-layer shortcuts that skip a certain
number of layers for time-consuming full self-attention on the vision side.
mPLUG is pre-trained end-to-end on large-scale image-text pairs with both
discriminative and generative objectives. It achieves state-of-the-art results
on a wide range of vision-language downstream tasks, such as image captioning,
image-text retrieval, visual grounding and visual question answering. mPLUG
also demonstrates strong zero-shot transferability when directly transferred to
multiple video-language tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StylizedNeRF: Consistent 3D Scene Stylization as Stylized NeRF via 2D-3D Mutual Learning. (arXiv:2205.12183v2 [cs.GR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.12183">
<div class="article-summary-box-inner">
<span><p>3D scene stylization aims at generating stylized images of the scene from
arbitrary novel views following a given set of style examples, while ensuring
consistency when rendered from different views. Directly applying methods for
image or video stylization to 3D scenes cannot achieve such consistency. Thanks
to recently proposed neural radiance fields (NeRF), we are able to represent a
3D scene in a consistent way. Consistent 3D scene stylization can be
effectively achieved by stylizing the corresponding NeRF. However, there is a
significant domain gap between style examples which are 2D images and NeRF
which is an implicit volumetric representation. To address this problem, we
propose a novel mutual learning framework for 3D scene stylization that
combines a 2D image stylization network and NeRF to fuse the stylization
ability of 2D stylization network with the 3D consistency of NeRF. We first
pre-train a standard NeRF of the 3D scene to be stylized and replace its color
prediction module with a style network to obtain a stylized NeRF. It is
followed by distilling the prior knowledge of spatial consistency from NeRF to
the 2D stylization network through an introduced consistency loss. We also
introduce a mimic loss to supervise the mutual learning of the NeRF style
module and fine-tune the 2D stylization decoder. In order to further make our
model handle ambiguities of 2D stylization results, we introduce learnable
latent codes that obey the probability distributions conditioned on the style.
They are attached to training samples as conditional inputs to better learn the
style module in our novel stylized NeRF. Experimental results demonstrate that
our method is superior to existing approaches in both visual quality and
long-range consistency.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-05-26 23:08:54.601803306 UTC">2022-05-26 23:08:54 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>