<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-10-27T01:30:00Z">10-27</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Findings from Experiments of On-line Joint Reinforcement Learning of Semantic Parser and Dialogue Manager with real Users. (arXiv:2110.13213v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13213">
<div class="article-summary-box-inner">
<span><p>Design of dialogue systems has witnessed many advances lately, yet acquiring
huge set of data remains an hindrance to their fast development for a new task
or language. Besides, training interactive systems with batch data is not
satisfactory. On-line learning is pursued in this paper as a convenient way to
alleviate these difficulties. After the system modules are initiated, a single
process handles data collection, annotation and use in training algorithms. A
new challenge is to control the cost of the on-line learning borne by the user.
Our work focuses on learning the semantic parsing and dialogue management
modules (speech recognition and synthesis offer ready-for-use solutions). In
this context we investigate several variants of simultaneous learning which are
tested in user trials. In our experiments, with varying merits, they can all
achieve good performance with only a few hundreds of training dialogues and
overstep a handcrafted system. The analysis of these experiments gives us some
insights, discussed in the paper, into the difficulty for the system's trainers
to establish a coherent and constant behavioural strategy to enable a fast and
good-quality training phase.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IconQA: A New Benchmark for Abstract Diagram Understanding and Visual Language Reasoning. (arXiv:2110.13214v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13214">
<div class="article-summary-box-inner">
<span><p>Current visual question answering (VQA) tasks mainly consider answering
human-annotated questions for natural images. However, aside from natural
images, abstract diagrams with semantic richness are still understudied in
visual understanding and reasoning research. In this work, we introduce a new
challenge of Icon Question Answering (IconQA) with the goal of answering a
question in an icon image context. We release IconQA, a large-scale dataset
that consists of 107,439 questions and three sub-tasks: multi-image-choice,
multi-text-choice, and filling-in-the-blank. The IconQA dataset is inspired by
real-world diagram word problems that highlight the importance of abstract
diagram understanding and comprehensive cognitive reasoning. Thus, IconQA
requires not only perception skills like object recognition and text
understanding, but also diverse cognitive reasoning skills, such as geometric
reasoning, commonsense reasoning, and arithmetic reasoning. To facilitate
potential IconQA models to learn semantic representations for icon images, we
further release an icon dataset Icon645 which contains 645,687 colored icons on
377 classes. We conduct extensive user studies and blind experiments and
reproduce a wide range of advanced VQA methods to benchmark the IconQA task.
Also, we develop a strong IconQA baseline Patch-TRM that applies a pyramid
cross-modal Transformer with input diagram embeddings pre-trained on the icon
dataset. IconQA and Icon645 are available at https://iconqa.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distributionally Robust Recurrent Decoders with Random Network Distillation. (arXiv:2110.13229v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13229">
<div class="article-summary-box-inner">
<span><p>Neural machine learning models can successfully model language that is
similar to their training distribution, but they are highly susceptible to
degradation under distribution shift, which occurs in many practical
applications when processing out-of-domain (OOD) text. This has been attributed
to "shortcut learning": relying on weak correlations over arbitrary large
contexts.
</p>
<p>We propose a method based on OOD detection with Random Network Distillation
to allow an autoregressive language model to automatically disregard OOD
context during inference, smoothly transitioning towards a less expressive but
more robust model as the data becomes more OOD while retaining its full context
capability when operating in-distribution. We apply our method to a GRU
architecture, demonstrating improvements on multiple language modeling (LM)
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving the Diversity of Unsupervised Paraphrasing with Embedding Outputs. (arXiv:2110.13231v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13231">
<div class="article-summary-box-inner">
<span><p>We present a novel technique for zero-shot paraphrase generation. The key
contribution is an end-to-end multilingual paraphrasing model that is trained
using translated parallel corpora to generate paraphrases into "meaning spaces"
-- replacing the final softmax layer with word embeddings. This architectural
modification, plus a training procedure that incorporates an autoencoding
objective, enables effective parameter sharing across languages for more fluent
monolingual rewriting, and facilitates fluency and diversity in generation. Our
continuous-output paraphrase generation models outperform zero-shot
paraphrasing baselines when evaluated on two languages using a battery of
computational metrics as well as in human assessment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepHelp: Deep Learning for Shout Crisis Text Conversations. (arXiv:2110.13244v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13244">
<div class="article-summary-box-inner">
<span><p>The Shout Crisis Text Line provides individuals undergoing mental health
crises an opportunity to have an anonymous text message conversation with a
trained Crisis Volunteer (CV). This project partners with Shout and its parent
organisation, Mental Health Innovations, to explore the applications of Machine
Learning in understanding Shout's conversations and improving its service. The
overarching aim of this project is to develop a proof-of-concept model to
demonstrate the potential of applying deep learning to crisis text messages.
</p>
<p>Specifically, this project aims to use deep learning to (1) predict an
individual's risk of suicide or self-harm, (2) assess conversation success and
CV skill using robust metrics, and (3) extrapolate demographic information from
a texter survey to conversations where the texter did not complete the survey.
To these ends, contributions to deep learning include a modified
Transformer-over-BERT model; a framework for multitask learning to improve
generalisation in the presence of sparse labels; and a mathematical model for
using imperfect machine learning models to estimate population parameters from
a biased training set.
</p>
<p>Key results include a deep learning model with likely better performance at
predicting suicide risk than trained CVs and the ability to predict whether a
texter is 21 or under with 88.4% accuracy. We produce three metrics for
conversation success and evaluate the validity and usefulness for each.
Finally, reversal of participation bias provides evidence that women, who make
up 80.3% of conversations with an associated texter survey, make up closer to
73.5%- 74.8% of all conversations; and that if, after every conversation, the
texter had shared whether they found their conversation helpful, affirmative
answers would fall from 85.1% to 45.45% - 46.51%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exposure of occupations to technologies of the fourth industrial revolution. (arXiv:2110.13317v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13317">
<div class="article-summary-box-inner">
<span><p>The fourth industrial revolution (4IR) is likely to have a substantial impact
on the economy. Companies need to build up capabilities to implement new
technologies, and automation may make some occupations obsolete. However,
where, when, and how the change will happen remain to be determined. Robust
empirical indicators of technological progress linked to occupations can help
to illuminate this change. With this aim, we provide such an indicator based on
patent data. Using natural language processing, we calculate patent exposure
scores for more than 900 occupations, which represent the technological
progress related to them. To provide a lens on the impact of the 4IR, we
differentiate between traditional and 4IR patent exposure. Our method differs
from previous approaches in that it both accounts for the diversity of
task-level patent exposures within an occupation and reflects work activities
more accurately. We find that exposure to 4IR patents differs from traditional
patent exposure. Manual tasks, and accordingly occupations such as construction
and production, are exposed mainly to traditional (non-4IR) patents but have
low exposure to 4IR patents. The analysis suggests that 4IR technologies may
have a negative impact on job growth; this impact appears 10 to 20 years after
patent filing. Further, we compared the 4IR exposure to other automation and AI
exposure scores. Whereas many measures refer to theoretical automation
potential, our patent-based indicator reflects actual technology diffusion. Our
work not only allows analyses of the impact of 4IR technologies as a whole, but
also provides exposure scores for more than 300 technology fields, such as AI
and smart office technologies. Finally, the work provides a general mapping of
patents to tasks and occupations, which enables future researchers to construct
individual exposure measures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task-Specific Dependency-based Word Embedding Methods. (arXiv:2110.13376v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13376">
<div class="article-summary-box-inner">
<span><p>Two task-specific dependency-based word embedding methods are proposed for
text classification in this work. In contrast with universal word embedding
methods that work for generic tasks, we design task-specific word embedding
methods to offer better performance in a specific task. Our methods follow the
PPMI matrix factorization framework and derive word contexts from the
dependency parse tree. The first one, called the dependency-based word
embedding (DWE), chooses keywords and neighbor words of a target word in the
dependency parse tree as contexts to build the word-context matrix. The second
method, named class-enhanced dependency-based word embedding (CEDWE), learns
from word-context as well as word-class co-occurrence statistics. DWE and CEDWE
are evaluated on popular text classification datasets to demonstrate their
effectiveness. It is shown by experimental results they outperform several
state-of-the-art word embedding methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unified Instance and Knowledge Alignment Pretraining for Aspect-based Sentiment Analysis. (arXiv:2110.13398v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13398">
<div class="article-summary-box-inner">
<span><p>Aspect-based Sentiment Analysis (ABSA) aims to determine the sentiment
polarity towards an aspect. Because of the expensive and limited labelled data,
the pretraining strategy has become the de-facto standard for ABSA. However,
there always exists severe domain shift between the pretraining and downstream
ABSA datasets, hindering the effective knowledge transfer when directly
finetuning and making the downstream task performs sub-optimal. To mitigate
such domain shift, we introduce a unified alignment pretraining framework into
the vanilla pretrain-finetune pipeline with both instance- and knowledge-level
alignments. Specifically, we first devise a novel coarse-to-fine retrieval
sampling approach to select target domain-related instances from the
large-scale pretraining dataset, thus aligning the instances between
pretraining and target domains (\textit{First Stage}). Then, we introduce a
knowledge guidance-based strategy to further bridge the domain gap at the
knowledge level. In practice, we formulate the model pretrained on the sampled
instances into a knowledge guidance model and a learner model, respectively. On
the target dataset, we design an on-the-fly teacher-student joint fine-tuning
approach to progressively transfer the knowledge from the knowledge guidance
model to the learner model (\textit{Second Stage}). Thereby, the learner model
can maintain more domain-invariant knowledge when learning new knowledge from
the target dataset. In the \textit{Third Stage,} the learner model is finetuned
to better adapt its learned knowledge to the target dataset. Extensive
experiments and analyses on several ABSA benchmarks demonstrate the
effectiveness and universality of our proposed pretraining framework. Notably,
our pretraining framework pushes several strong baseline models up to the new
state-of-the-art records. We release our code and models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AVocaDo: Strategy for Adapting Vocabulary to Downstream Domain. (arXiv:2110.13434v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13434">
<div class="article-summary-box-inner">
<span><p>During the fine-tuning phase of transfer learning, the pretrained vocabulary
remains unchanged, while model parameters are updated. The vocabulary generated
based on the pretrained data is suboptimal for downstream data when domain
discrepancy exists. We propose to consider the vocabulary as an optimizable
parameter, allowing us to update the vocabulary by expanding it with
domain-specific vocabulary based on a tokenization statistic. Furthermore, we
preserve the embeddings of the added words from overfitting to downstream data
by utilizing knowledge learned from a pretrained language model with a
regularization term. Our method achieved consistent performance improvements on
diverse domains (i.e., biomedical, computer science, news, and reviews).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decomposing Complex Questions Makes Multi-Hop QA Easier and More Interpretable. (arXiv:2110.13472v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13472">
<div class="article-summary-box-inner">
<span><p>Multi-hop QA requires the machine to answer complex questions through finding
multiple clues and reasoning, and provide explanatory evidence to demonstrate
the machine reasoning process. We propose Relation Extractor-Reader and
Comparator (RERC), a three-stage framework based on complex question
decomposition, which is the first work that the RERC model has been proposed
and applied in solving the multi-hop QA challenges. The Relation Extractor
decomposes the complex question, and then the Reader answers the sub-questions
in turn, and finally the Comparator performs numerical comparison and
summarizes all to get the final answer, where the entire process itself
constitutes a complete reasoning evidence path. In the 2WikiMultiHopQA dataset,
our RERC model has achieved the most advanced performance, with a winning joint
F1 score of 53.58 on the leaderboard. All indicators of our RERC are close to
human performance, with only 1.95 behind the human level in F1 score of support
fact. At the same time, the evidence path provided by our RERC framework has
excellent readability and faithfulness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simultaneous Neural Machine Translation with Constituent Label Prediction. (arXiv:2110.13480v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13480">
<div class="article-summary-box-inner">
<span><p>Simultaneous translation is a task in which translation begins before the
speaker has finished speaking, so it is important to decide when to start the
translation process. However, deciding whether to read more input words or
start to translate is difficult for language pairs with different word orders
such as English and Japanese. Motivated by the concept of pre-reordering, we
propose a couple of simple decision rules using the label of the next
constituent predicted by incremental constituent label prediction. In
experiments on English-to-Japanese simultaneous translation, the proposed
method outperformed baselines in the quality-latency trade-off.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing the Sufficiency of Arguments through Conclusion Generation. (arXiv:2110.13495v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13495">
<div class="article-summary-box-inner">
<span><p>The premises of an argument give evidence or other reasons to support a
conclusion. However, the amount of support required depends on the generality
of a conclusion, the nature of the individual premises, and similar. An
argument whose premises make its conclusion rationally worthy to be drawn is
called sufficient in argument quality research. Previous work tackled
sufficiency assessment as a standard text classification problem, not modeling
the inherent relation of premises and conclusion. In this paper, we hypothesize
that the conclusion of a sufficient argument can be generated from its
premises. To study this hypothesis, we explore the potential of assessing
sufficiency based on the output of large-scale pre-trained language models. Our
best model variant achieves an F1-score of .885, outperforming the previous
state-of-the-art and being on par with human experts. While manual evaluation
reveals the quality of the generated conclusions, their impact remains low
ultimately.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Part & Whole Extraction: Towards A Deep Understanding of Quantitative Facts for Percentages in Text. (arXiv:2110.13505v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13505">
<div class="article-summary-box-inner">
<span><p>We study the problem of quantitative facts extraction for text with
percentages. For example, given the sentence "30 percent of Americans like
watching football, while 20% prefer to watch NBA.", our goal is to obtain a
deep understanding of the percentage numbers ("30 percent" and "20%") by
extracting their quantitative facts: part ("like watching football" and "prefer
to watch NBA") and whole ("Americans). These quantitative facts can empower new
applications like automated infographic generation. We formulate part and whole
extraction as a sequence tagging problem. Due to the large gap between
part/whole and its corresponding percentage, we introduce skip mechanism in
sequence modeling, and achieved improved performance on both our task and the
CoNLL-2003 named entity recognition task. Experimental results demonstrate that
learning to skip in sequence tagging is promising.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Probabilistic Entity Representation Model for Chain Reasoning over Knowledge Graphs. (arXiv:2110.13522v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13522">
<div class="article-summary-box-inner">
<span><p>Logical reasoning over Knowledge Graphs (KGs) is a fundamental technique that
can provide efficient querying mechanism over large and incomplete databases.
Current approaches employ spatial geometries such as boxes to learn query
representations that encompass the answer entities and model the logical
operations of projection and intersection. However, their geometry is
restrictive and leads to non-smooth strict boundaries, which further results in
ambiguous answer entities. Furthermore, previous works propose transformation
tricks to handle unions which results in non-closure and, thus, cannot be
chained in a stream. In this paper, we propose a Probabilistic Entity
Representation Model (PERM) to encode entities as a Multivariate Gaussian
density with mean and covariance parameters to capture its semantic position
and smooth decision boundary, respectively. Additionally, we also define the
closed logical operations of projection, intersection, and union that can be
aggregated using an end-to-end objective function. On the logical query
reasoning problem, we demonstrate that the proposed PERM significantly
outperforms the state-of-the-art methods on various public benchmark KG
datasets on standard evaluation metrics. We also evaluate PERM's competence on
a COVID-19 drug-repurposing case study and show that our proposed work is able
to recommend drugs with substantially better F1 than current methods. Finally,
we demonstrate the working of our PERM's query answering process through a
low-dimensional visualization of the Gaussian representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Open Rule Induction. (arXiv:2110.13577v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13577">
<div class="article-summary-box-inner">
<span><p>Rules have a number of desirable properties. It is easy to understand, infer
new knowledge, and communicate with other inference systems. One weakness of
the previous rule induction systems is that they only find rules within a
knowledge base (KB) and therefore cannot generalize to more open and complex
real-world rules. Recently, the language model (LM)-based rule generation are
proposed to enhance the expressive power of the rules. In this paper, we
revisit the differences between KB-based rule induction and LM-based rule
generation. We argue that, while KB-based methods inducted rules by discovering
data commonalities, the current LM-based methods are "learning rules from
rules". This limits these methods to only produce "canned" rules whose patterns
are constrained by the annotated rules, while discarding the rich expressive
power of LMs for free text.
</p>
<p>Therefore, in this paper, we propose the open rule induction problem, which
aims to induce open rules utilizing the knowledge in LMs. Besides, we propose
the Orion (\underline{o}pen \underline{r}ule \underline{i}nducti\underline{on})
system to automatically mine open rules from LMs without supervision of
annotated rules. We conducted extensive experiments to verify the quality and
quantity of the inducted open rules. Surprisingly, when applying the open rules
in downstream tasks (i.e. relation extraction), these automatically inducted
rules even outperformed the manually annotated rules.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">s2s-ft: Fine-Tuning Pretrained Transformer Encoders for Sequence-to-Sequence Learning. (arXiv:2110.13640v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13640">
<div class="article-summary-box-inner">
<span><p>Pretrained bidirectional Transformers, such as BERT, have achieved
significant improvements in a wide variety of language understanding tasks,
while it is not straightforward to directly apply them for natural language
generation. In this paper, we present a sequence-to-sequence fine-tuning
toolkit s2s-ft, which adopts pretrained Transformers for conditional generation
tasks. Inspired by UniLM, we implement three sequence-to-sequence fine-tuning
algorithms, namely, causal fine-tuning, masked fine-tuning, and pseudo-masked
fine-tuning. By leveraging the existing pretrained bidirectional Transformers,
experimental results show that s2s-ft achieves strong performance on several
benchmarks of abstractive summarization, and question generation. Moreover, we
demonstrate that the package s2s-ft supports both monolingual and multilingual
NLG tasks. The s2s-ft toolkit is available at
https://github.com/microsoft/unilm/tree/master/s2s-ft.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can Character-based Language Models Improve Downstream Task Performance in Low-Resource and Noisy Language Scenarios?. (arXiv:2110.13658v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13658">
<div class="article-summary-box-inner">
<span><p>Recent impressive improvements in NLP, largely based on the success of
contextual neural language models, have been mostly demonstrated on at most a
couple dozen high-resource languages. Building language models and, more
generally, NLP systems for non-standardized and low-resource languages remains
a challenging task. In this work, we focus on North-African colloquial
dialectal Arabic written using an extension of the Latin script, called
NArabizi, found mostly on social media and messaging communication. In this
low-resource scenario with data displaying a high level of variability, we
compare the downstream performance of a character-based language model on
part-of-speech tagging and dependency parsing to that of monolingual and
multilingual models. We show that a character-based model trained on only 99k
sentences of NArabizi and fined-tuned on a small treebank of this language
leads to performance close to those obtained with the same architecture
pre-trained on large multilingual and monolingual models. Confirming these
results a on much larger data set of noisy French user-generated content, we
argue that such character-based language models can be an asset for NLP in
low-resource and high language variability set-tings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BioIE: Biomedical Information Extraction with Multi-head Attention Enhanced Graph Convolutional Network. (arXiv:2110.13683v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13683">
<div class="article-summary-box-inner">
<span><p>Constructing large-scaled medical knowledge graphs can significantly boost
healthcare applications for medical surveillance, bring much attention from
recent research. An essential step in constructing large-scale MKG is
extracting information from medical reports. Recently, information extraction
techniques have been proposed and show promising performance in biomedical
information extraction. However, these methods only consider limited types of
entity and relation due to the noisy biomedical text data with complex entity
correlations. Thus, they fail to provide enough information for constructing
MKGs and restrict the downstream applications. To address this issue, we
propose Biomedical Information Extraction, a hybrid neural network to extract
relations from biomedical text and unstructured medical reports. Our model
utilizes a multi-head attention enhanced graph convolutional network to capture
the complex relations and context information while resisting the noise from
the data. We evaluate our model on two major biomedical relationship extraction
tasks, chemical-disease relation and chemical-protein interaction, and a
cross-hospital pan-cancer pathology report corpus. The results show that our
method achieves superior performance than baselines. Furthermore, we evaluate
the applicability of our method under a transfer learning setting and show that
BioIE achieves promising performance in processing medical text from different
formats and writing styles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Explicit-Joint and Supervised-Contrastive Learning Framework for Few-Shot Intent Classification and Slot Filling. (arXiv:2110.13691v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13691">
<div class="article-summary-box-inner">
<span><p>Intent classification (IC) and slot filling (SF) are critical building blocks
in task-oriented dialogue systems. These two tasks are closely-related and can
flourish each other. Since only a few utterances can be utilized for
identifying fast-emerging new intents and slots, data scarcity issue often
occurs when implementing IC and SF. However, few IC/SF models perform well when
the number of training samples per class is quite small. In this paper, we
propose a novel explicit-joint and supervised-contrastive learning framework
for few-shot intent classification and slot filling. Its highlights are as
follows. (i) The model extracts intent and slot representations via
bidirectional interactions, and extends prototypical network to achieve
explicit-joint learning, which guarantees that IC and SF tasks can mutually
reinforce each other. (ii) The model integrates with supervised contrastive
learning, which ensures that samples from same class are pulled together and
samples from different classes are pushed apart. In addition, the model follows
a not common but practical way to construct the episode, which gets rid of the
traditional setting with fixed way and shot, and allows for unbalanced
datasets. Extensive experiments on three public datasets show that our model
can achieve promising performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Annotating Implicit Reasoning in Arguments with Causal Links. (arXiv:2110.13692v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13692">
<div class="article-summary-box-inner">
<span><p>Most of the existing work that focus on the identification of implicit
knowledge in arguments generally represent implicit knowledge in the form of
commonsense or factual knowledge. However, such knowledge is not sufficient to
understand the implicit reasoning link between individual argumentative
components (i.e., claim and premise). In this work, we focus on identifying the
implicit knowledge in the form of argumentation knowledge which can help in
understanding the reasoning link in arguments. Being inspired by the Argument
from Consequences scheme, we propose a semi-structured template to represent
such argumentation knowledge that explicates the implicit reasoning in
arguments via causality. We create a novel two-phase annotation process with
simplified guidelines and show how to collect and filter high-quality implicit
reasonings via crowdsourcing. We find substantial inter-annotator agreement for
quality evaluation between experts, but find evidence that casts a few
questions on the feasibility of collecting high-quality semi-structured
implicit reasoning through our crowdsourcing process. We release our
materials(i.e., crowdsourcing guidelines and collected implicit reasonings) to
facilitate further research towards the structured representation of
argumentation knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DASentimental: Detecting depression, anxiety and stress in texts via emotional recall, cognitive networks and machine learning. (arXiv:2110.13710v1 [cs.CY])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13710">
<div class="article-summary-box-inner">
<span><p>Most current affect scales and sentiment analysis on written text focus on
quantifying valence (sentiment) -- the most primary dimension of emotion.
However, emotions are broader and more complex than valence. Distinguishing
negative emotions of similar valence could be important in contexts such as
mental health. This project proposes a semi-supervised machine learning model
(DASentimental) to extract depression, anxiety and stress from written text.
First, we trained the model to spot how sequences of recalled emotion words by
$N=200$ individuals correlated with their responses to the Depression Anxiety
Stress Scale (DASS-21). Within the framework of cognitive network science, we
model every list of recalled emotions as a walk over a networked mental
representation of semantic memory, with emotions connected according to free
associations in people's memory. Among several tested machine learning
approaches, we find that a multilayer perceptron neural network trained on word
sequences and semantic network distances can achieve state-of-art,
cross-validated predictions for depression ($R = 0.7$), anxiety ($R = 0.44$)
and stress ($R = 0.52$). Though limited by sample size, this first-of-its-kind
approach enables quantitative explorations of key semantic dimensions behind
DAS levels. We find that semantic distances between recalled emotions and the
dyad "sad-happy" are crucial features for estimating depression levels but are
less important for anxiety and stress. We also find that semantic distance of
recalls from "fear" can boost the prediction of anxiety but it becomes
redundant when the "sad-happy" dyad is considered. Adopting DASentimental as a
semi-supervised learning tool to estimate DAS in text, we apply it to a dataset
of 142 suicide notes. We conclude by discussing key directions for future
research enabled by artificial intelligence detecting stress, anxiety and
depression.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Transformers Are More Efficient Language Models. (arXiv:2110.13711v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13711">
<div class="article-summary-box-inner">
<span><p>Transformer models yield impressive results on many NLP and sequence modeling
tasks. Remarkably, Transformers can handle long sequences which allows them to
produce long coherent outputs: full paragraphs produced by GPT-3 or
well-structured images produced by DALL-E. These large language models are
impressive but also very inefficient and costly, which limits their
applications and accessibility. We postulate that having an explicit
hierarchical architecture is the key to Transformers that efficiently handle
long sequences. To verify this claim, we first study different ways to
downsample and upsample activations in Transformers so as to make them
hierarchical. We use the best performing upsampling and downsampling layers to
create Hourglass - a hierarchical Transformer language model. Hourglass
improves upon the Transformer baseline given the same amount of computation and
can yield the same results as Transformers more efficiently. In particular,
Hourglass sets new state-of-the-art for Transformer models on the ImageNet32
generation task and improves language modeling efficiency on the widely studied
enwik8 benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConE: Cone Embeddings for Multi-Hop Reasoning over Knowledge Graphs. (arXiv:2110.13715v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13715">
<div class="article-summary-box-inner">
<span><p>Query embedding (QE) -- which aims to embed entities and first-order logical
(FOL) queries in low-dimensional spaces -- has shown great power in multi-hop
reasoning over knowledge graphs. Recently, embedding entities and queries with
geometric shapes becomes a promising direction, as geometric shapes can
naturally represent answer sets of queries and logical relationships among
them. However, existing geometry-based models have difficulty in modeling
queries with negation, which significantly limits their applicability. To
address this challenge, we propose a novel query embedding model, namely Cone
Embeddings (ConE), which is the first geometry-based QE model that can handle
all the FOL operations, including conjunction, disjunction, and negation.
Specifically, ConE represents entities and queries as Cartesian products of
two-dimensional cones, where the intersection and union of cones naturally
model the conjunction and disjunction operations. By further noticing that the
closure of complement of cones remains cones, we design geometric complement
operators in the embedding space for the negation operations. Experiments
demonstrate that ConE significantly outperforms existing state-of-the-art
methods on benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">As long as you talk about me: The importance of family firm brands and the contingent role of family-firm identity. (arXiv:2110.13815v1 [econ.GN])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13815">
<div class="article-summary-box-inner">
<span><p>This study explores the role of external audiences in determining the
importance of family firm brands and the relationship with firm performance.
Drawing on text mining and social network analysis techniques, and considering
the brand prevalence, diversity, and connectivity dimensions, we use the
semantic brand score to measure the importance the media give to family firm
brands. The analysis of a sample of 52,555 news articles published in 2017
about 63 Italian entrepreneurial families reveals that brand importance is
positively associated with family firm revenues, and this relationship is
stronger when there is identity match between the family and the firm. This
study advances current literature by offering a rich and multifaceted
perspective on how external audiences perceptions of the brand shape family
firm performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing Evaluation Metrics for Speech-to-Speech Translation. (arXiv:2110.13877v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13877">
<div class="article-summary-box-inner">
<span><p>Speech-to-speech translation combines machine translation with speech
synthesis, introducing evaluation challenges not present in either task alone.
How to automatically evaluate speech-to-speech translation is an open question
which has not previously been explored. Translating to speech rather than to
text is often motivated by unwritten languages or languages without
standardized orthographies. However, we show that the previously used automatic
metric for this task is best equipped for standardized high-resource languages
only. In this work, we first evaluate current metrics for speech-to-speech
translation, and second assess how translation to dialectal variants rather
than to standardized languages impacts various evaluation methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Interlocking Dynamics of Cooperative Rationalization. (arXiv:2110.13880v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13880">
<div class="article-summary-box-inner">
<span><p>Selective rationalization explains the prediction of complex neural networks
by finding a small subset of the input that is sufficient to predict the neural
model output. The selection mechanism is commonly integrated into the model
itself by specifying a two-component cascaded system consisting of a rationale
generator, which makes a binary selection of the input features (which is the
rationale), and a predictor, which predicts the output based only on the
selected features. The components are trained jointly to optimize prediction
performance. In this paper, we reveal a major problem with such cooperative
rationalization paradigm -- model interlocking. Interlocking arises when the
predictor overfits to the features selected by the generator thus reinforcing
the generator's selection even if the selected rationales are sub-optimal. The
fundamental cause of the interlocking problem is that the rationalization
objective to be minimized is concave with respect to the generator's selection
policy. We propose a new rationalization framework, called A2R, which
introduces a third component into the architecture, a predictor driven by soft
attention as opposed to selection. The generator now realizes both soft and
hard attention over the features and these are fed into the two different
predictors. While the generator still seeks to support the original predictor
performance, it also minimizes a gap between the two predictors. As we will
show theoretically, since the attention-based predictor exhibits a better
convexity property, A2R can overcome the concavity barrier. Our experiments on
two synthetic benchmarks and two real datasets demonstrate that A2R can
significantly alleviate the interlock problem and find explanations that better
align with human judgments. We release our code at
https://github.com/Gorov/Understanding_Interlocking.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing. (arXiv:2110.13900v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13900">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) achieves great success in speech recognition,
while limited exploration has been attempted for other speech processing tasks.
As speech signal contains multi-faceted information including speaker identity,
paralinguistics, spoken content, etc., learning universal representations for
all speech tasks is challenging. In this paper, we propose a new pre-trained
model, WavLM, to solve full-stack downstream speech tasks. WavLM is built based
on the HuBERT framework, with an emphasis on both spoken content modeling and
speaker identity preservation. We first equip the Transformer structure with
gated relative position bias to improve its capability on recognition tasks.
For better speaker discrimination, we propose an utterance mixing training
strategy, where additional overlapped utterances are created unsupervisely and
incorporated during model training. Lastly, we scale up the training dataset
from 60k hours to 94k hours of public audio data, and optimize its training
procedure for better representation extraction. WavLM Large achieves
state-of-the-art performance on the SUPERB benchmark, and brings significant
improvements for various speech processing tasks on their representative
benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Variance of the Adaptive Learning Rate and Beyond. (arXiv:1908.03265v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.03265">
<div class="article-summary-box-inner">
<span><p>The learning rate warmup heuristic achieves remarkable success in stabilizing
training, accelerating convergence and improving generalization for adaptive
stochastic optimization algorithms like RMSprop and Adam. Here, we study its
mechanism in details. Pursuing the theory behind warmup, we identify a problem
of the adaptive learning rate (i.e., it has problematically large variance in
the early stage), suggest warmup works as a variance reduction technique, and
provide both empirical and theoretical evidence to verify our hypothesis. We
further propose RAdam, a new variant of Adam, by introducing a term to rectify
the variance of the adaptive learning rate. Extensive experimental results on
image classification, language modeling, and neural machine translation verify
our intuition and demonstrate the effectiveness and robustness of our proposed
method. All implementations are available at:
https://github.com/LiyuanLucasLiu/RAdam.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Global-aware Beam Search for Neural Abstractive Summarization. (arXiv:2009.06891v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06891">
<div class="article-summary-box-inner">
<span><p>This study develops a calibrated beam-based algorithm with awareness of the
global attention distribution for neural abstractive summarization, aiming to
improve the local optimality problem of the original beam search in a rigorous
way. Specifically, a novel global protocol is proposed based on the attention
distribution to stipulate how a global optimal hypothesis should attend to the
source. A global scoring mechanism is then developed to regulate beam search to
generate summaries in a near-global optimal fashion. This novel design enjoys a
distinctive property, i.e., the global attention distribution could be
predicted before inference, enabling step-wise improvements on the beam search
through the global scoring mechanism. Extensive experiments on nine datasets
show that the global (attention)-aware inference significantly improves
state-of-the-art summarization models even using empirical hyper-parameters.
The algorithm is also proven robust as it remains to generate meaningful texts
with corrupted attention distributions. The codes and a comprehensive set of
examples are available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention over learned object embeddings enables complex visual reasoning. (arXiv:2012.08508v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08508">
<div class="article-summary-box-inner">
<span><p>Neural networks have achieved success in a wide array of perceptual tasks but
often fail at tasks involving both perception and higher-level reasoning. On
these more challenging tasks, bespoke approaches (such as modular symbolic
components, independent dynamics models or semantic parsers) targeted towards
that specific type of task have typically performed better. The downside to
these targeted approaches, however, is that they can be more brittle than
general-purpose neural networks, requiring significant modification or even
redesign according to the particular task at hand. Here, we propose a more
general neural-network-based approach to dynamic visual reasoning problems that
obtains state-of-the-art performance on three different domains, in each case
outperforming bespoke modular approaches tailored specifically to the task. Our
method relies on learned object-centric representations, self-attention and
self-supervised dynamics learning, and all three elements together are required
for strong performance to emerge. The success of this combination suggests that
there may be no need to trade off flexibility for performance on problems
involving spatio-temporal or causal-style reasoning. With the right soft biases
and learning objectives in a neural network we may be able to attain the best
of both worlds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning From Human Correction For Data-Centric Deep Learning. (arXiv:2102.00225v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00225">
<div class="article-summary-box-inner">
<span><p>In industry NLP application, our manually labeled data has a certain number
of noisy data. We present a simple method to find the noisy data and relabel
them manually, meanwhile we collect the correction information. Then we present
novel method to incorporate the human correction information into deep learning
model. Human know how to correct noisy data. So the correction information can
be inject into deep learning model. We do the experiment on our own text
classification dataset, which is manually labeled, because we relabel the noisy
data in our dataset for our industry application. The experiment result shows
that our method improve the classification accuracy from 91.7% to 92.5%. The
91.7% baseline is based on BERT training on the corrected dataset, which is
hard to surpass.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mind the Gap: Assessing Temporal Generalization in Neural Language Models. (arXiv:2102.01951v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01951">
<div class="article-summary-box-inner">
<span><p>Our world is open-ended, non-stationary, and constantly evolving; thus what
we talk about and how we talk about it change over time. This inherent dynamic
nature of language contrasts with the current static language modelling
paradigm, which trains and evaluates models on utterances from overlapping time
periods. Despite impressive recent progress, we demonstrate that Transformer-XL
language models perform worse in the realistic setup of predicting future
utterances from beyond their training period, and that model performance
becomes increasingly worse with time. We find that, while increasing model size
alone -- a key driver behind recent progress -- does not solve this problem,
having models that continually update their knowledge with new information can
indeed mitigate this performance degradation over time. Hence, given the
compilation of ever-larger language modelling datasets, combined with the
growing list of language-model-based NLP applications that require up-to-date
factual knowledge about the world, we argue that now is the right time to
rethink the static way in which we currently train and evaluate our language
models, and develop adaptive language models that can remain up-to-date with
respect to our ever-changing and non-stationary world. We publicly release our
dynamic, streaming language modelling benchmarks for WMT and arXiv to
facilitate language model evaluation that takes temporal dynamics into account.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Augmentation with Hierarchical SQL-to-Question Generation for Cross-domain Text-to-SQL Parsing. (arXiv:2103.02227v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02227">
<div class="article-summary-box-inner">
<span><p>Data augmentation has attracted a lot of research attention in the deep
learning era for its ability in alleviating data sparseness. The lack of
labeled data for unseen evaluation databases is exactly the major challenge for
cross-domain text-to-SQL parsing. Previous works either require human
intervention to guarantee the quality of generated data, or fail to handle
complex SQL queries. This paper presents a simple yet effective data
augmentation framework. First, given a database, we automatically produce a
large number of SQL queries based on an abstract syntax tree grammar. For
better distribution matching, we require that at least 80% of SQL patterns in
the training data are covered by generated queries. Second, we propose a
hierarchical SQL-to-question generation model to obtain high-quality natural
language questions, which is the major contribution of this work. Finally, we
design a simple sampling strategy that can greatly improve training efficiency
given large amounts of generated data. Experiments on three cross-domain
datasets, i.e., WikiSQL and Spider in English, and DuSQL in Chinese, show that
our proposed data augmentation framework can consistently improve performance
over strong baselines, and the hierarchical generation component is the key for
the improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does the Magic of BERT Apply to Medical Code Assignment? A Quantitative Study. (arXiv:2103.06511v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06511">
<div class="article-summary-box-inner">
<span><p>Unsupervised pretraining is an integral part of many natural language
processing systems, and transfer learning with language models has achieved
remarkable results in many downstream tasks. In the clinical application of
medical code assignment, diagnosis and procedure codes are inferred from
lengthy clinical notes such as hospital discharge summaries. However, it is not
clear if pretrained models are useful for medical code prediction without
further architecture engineering. This paper conducts a comprehensive
quantitative analysis of various contextualized language models' performance,
pretrained in different domains, for medical code assignment from clinical
notes. We propose a hierarchical fine-tuning architecture to capture
interactions between distant words and adopt label-wise attention to exploit
label information. Contrary to current trends, we demonstrate that a carefully
trained classical CNN outperforms attention-based models on a MIMIC-III subset
with frequent codes. Our empirical findings suggest directions for improving
the medical code assignment application.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets. (arXiv:2103.12028v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12028">
<div class="article-summary-box-inner">
<span><p>With the success of large-scale pre-training and multilingual modeling in
Natural Language Processing (NLP), recent years have seen a proliferation of
large, web-mined text datasets covering hundreds of languages. We manually
audit the quality of 205 language-specific corpora released with five major
public datasets (CCAligned, ParaCrawl, WikiMatrix, OSCAR, mC4). Lower-resource
corpora have systematic issues: At least 15 corpora have no usable text, and a
significant fraction contains less than 50% sentences of acceptable quality. In
addition, many are mislabeled or use nonstandard/ambiguous language codes. We
demonstrate that these issues are easy to detect even for non-proficient
speakers, and supplement the human audit with automatic analyses. Finally, we
recommend techniques to evaluate and improve multilingual corpora and discuss
potential risks that come with low-quality data releases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fabula Entropy Indexing: Objective Measures of Story Coherence. (arXiv:2104.07472v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07472">
<div class="article-summary-box-inner">
<span><p>Automated story generation remains a difficult area of research because it
lacks strong objective measures. Generated stories may be linguistically sound,
but in many cases suffer poor narrative coherence required for a compelling,
logically-sound story. To address this, we present Fabula Entropy Indexing
(FEI), an evaluation method to assess story coherence by measuring the degree
to which human participants agree with each other when answering true/false
questions about stories. We devise two theoretically grounded measures of
reader question-answering entropy, the entropy of world coherence (EWC), and
the entropy of transitional coherence (ETC), focusing on global and local
coherence, respectively. We evaluate these metrics by testing them on
human-written stories and comparing against the same stories that have been
corrupted to introduce incoherencies. We show that in these controlled studies,
our entropy indices provide a reliable objective measure of story coherence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Customized determination of stop words using Random Matrix Theory approach. (arXiv:2104.08642v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08642">
<div class="article-summary-box-inner">
<span><p>The distances between words calculated in word units are studied and compared
with the distributions of the Random Matrix Theory (RMT). It is found that the
distribution of distance between the same words can be well described by the
single-parameter Brody distribution. Using the Brody distribution fit, we found
that the distance between given words in a set of texts can show mixed
dynamics, coexisting regular and chaotic regimes. It is found that
distributions correctly fitted by the Brody distribution with a certain
goodness of the fit threshold can be identifid as stop words, usually
considered as the uninformative part of the text. By applying various threshold
values for the goodness of fit, we can extract uninformative words from the
texts under analysis to the desired extent. On this basis we formulate a fully
agnostic recipe that can be used in the creation of a customized set of stop
words for texts in any language based on words.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Estimating Redundancy in Clinical Text. (arXiv:2105.11832v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11832">
<div class="article-summary-box-inner">
<span><p>The current mode of use of Electronic Health Record (EHR) elicits text
redundancy. Clinicians often populate new documents by duplicating existing
notes, then updating accordingly. Data duplication can lead to a propagation of
errors, inconsistencies and misreporting of care. Therefore, quantifying
information redundancy can play an essential role in evaluating innovations
that operate on clinical narratives.
</p>
<p>This work is a quantitative examination of information redundancy in EHR
notes. We present and evaluate two strategies to measure redundancy: an
information-theoretic approach and a lexicosyntactic and semantic model. We
evaluate the measures by training large Transformer-based language models using
clinical text from a large openly available US-based ICU dataset and a large
multi-site UK based Trust. By comparing the information-theoretic content of
the trained models with open-domain language models, the language models
trained using clinical text have shown ~1.5x to ~3x less efficient than
open-domain corpora. Manual evaluation shows a high correlation with
lexicosyntactic and semantic redundancy, with averages ~43 to ~65%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tail-to-Tail Non-Autoregressive Sequence Prediction for Chinese Grammatical Error Correction. (arXiv:2106.01609v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01609">
<div class="article-summary-box-inner">
<span><p>We investigate the problem of Chinese Grammatical Error Correction (CGEC) and
present a new framework named Tail-to-Tail (\textbf{TtT}) non-autoregressive
sequence prediction to address the deep issues hidden in CGEC. Considering that
most tokens are correct and can be conveyed directly from source to target, and
the error positions can be estimated and corrected based on the bidirectional
context information, thus we employ a BERT-initialized Transformer Encoder as
the backbone model to conduct information modeling and conveying. Considering
that only relying on the same position substitution cannot handle the
variable-length correction cases, various operations such substitution,
deletion, insertion, and local paraphrasing are required jointly. Therefore, a
Conditional Random Fields (CRF) layer is stacked on the up tail to conduct
non-autoregressive sequence prediction by modeling the token dependencies.
Since most tokens are correct and easily to be predicted/conveyed to the
target, then the models may suffer from a severe class imbalance issue. To
alleviate this problem, focal loss penalty strategies are integrated into the
loss functions. Moreover, besides the typical fix-length error correction
datasets, we also construct a variable-length corpus to conduct experiments.
Experimental results on standard datasets, especially on the variable-length
datasets, demonstrate the effectiveness of TtT in terms of sentence-level
Accuracy, Precision, Recall, and F1-Measure on tasks of error Detection and
Correction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counterfactual Maximum Likelihood Estimation for Training Deep Networks. (arXiv:2106.03831v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03831">
<div class="article-summary-box-inner">
<span><p>Although deep learning models have driven state-of-the-art performance on a
wide array of tasks, they are prone to spurious correlations that should not be
learned as predictive clues. To mitigate this problem, we propose a
causality-based training framework to reduce the spurious correlations caused
by observed confounders. We give theoretical analysis on the underlying general
Structural Causal Model (SCM) and propose to perform Maximum Likelihood
Estimation (MLE) on the interventional distribution instead of the
observational distribution, namely Counterfactual Maximum Likelihood Estimation
(CMLE). As the interventional distribution, in general, is hidden from the
observational data, we then derive two different upper bounds of the expected
negative log-likelihood and propose two general algorithms, Implicit CMLE and
Explicit CMLE, for causal predictions of deep learning models using
observational data. We conduct experiments on both simulated data and two
real-world tasks: Natural Language Inference (NLI) and Image Captioning. The
results show that CMLE methods outperform the regular MLE method in terms of
out-of-domain generalization performance and reducing spurious correlations,
while maintaining comparable performance on the regular evaluations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition. (arXiv:2106.05933v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05933">
<div class="article-summary-box-inner">
<span><p>Self-supervised speech representation learning (speech SSL) has demonstrated
the benefit of scale in learning rich representations for Automatic Speech
Recognition (ASR) with limited paired data, such as wav2vec 2.0. We investigate
the existence of sparse subnetworks in pre-trained speech SSL models that
achieve even better low-resource ASR results. However, directly applying widely
adopted pruning methods such as the Lottery Ticket Hypothesis (LTH) is
suboptimal in the computational cost needed. Moreover, we show that the
discovered subnetworks yield minimal performance gain compared to the original
dense network. We present Prune-Adjust-Re-Prune (PARP), which discovers and
finetunes subnetworks for much better performance, while only requiring a
single downstream ASR finetuning run. PARP is inspired by our surprising
observation that subnetworks pruned for pre-training tasks need merely a slight
adjustment to achieve a sizeable performance boost in downstream ASR tasks.
Extensive experiments on low-resource ASR verify (1) sparse subnetworks exist
in mono-lingual/multi-lingual pre-trained speech SSL, and (2) the computational
advantage and performance gain of PARP over baseline pruning methods. In
particular, on the 10min Librispeech split without LM decoding, PARP discovers
subnetworks from wav2vec 2.0 with an absolute 10.9%/12.6% WER decrease compared
to the full model. We further demonstrate the effectiveness of PARP via:
cross-lingual pruning without any phone recognition degradation, the discovery
of a multi-lingual subnetwork for 10 spoken languages in 1 finetuning run, and
its applicability to pre-trained BERT/XLNet for natural language tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling morphology with Linear Discriminative Learning: considerations and design choices. (arXiv:2106.07936v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07936">
<div class="article-summary-box-inner">
<span><p>This study addresses a series of methodological questions that arise when
modeling inflectional morphology with Linear Discriminative Learning. Taking
the semi-productive German noun system as example, we illustrate how decisions
made about the representation of form and meaning influence model performance.
We clarify that for modeling frequency effects in learning, it is essential to
make use of incremental learning rather than the endstate of learning. We also
discuss how the model can be set up to approximate the learning of inflected
words in context. In addition, we illustrate how in this approach the wug task
can be modeled in considerable detail. In general, the model provides an
excellent memory for known words, but appropriately shows more limited
performance for unseen data, in line with the semi-productivity of German noun
inflection and generalization performance of native German speakers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Transformer-based Cross-modal Fusion Model with Adversarial Training for VQA Challenge 2021. (arXiv:2106.13033v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13033">
<div class="article-summary-box-inner">
<span><p>In this paper, inspired by the successes of visionlanguage pre-trained models
and the benefits from training with adversarial attacks, we present a novel
transformerbased cross-modal fusion modeling by incorporating the both notions
for VQA challenge 2021. Specifically, the proposed model is on top of the
architecture of VinVL model [19], and the adversarial training strategy [4] is
applied to make the model robust and generalized. Moreover, two implementation
tricks are also used in our system to obtain better results. The experiments
demonstrate that the novel framework can achieve 76.72% on VQAv2 test-std set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Extrapolation for Attribute-Enhanced Generation. (arXiv:2107.02968v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02968">
<div class="article-summary-box-inner">
<span><p>Attribute extrapolation in sample generation is challenging for deep neural
networks operating beyond the training distribution. We formulate a new task
for extrapolation in sequence generation, focusing on natural language and
proteins, and propose GENhance, a generative framework that enhances attributes
through a learned latent space. Trained on movie reviews and a computed protein
stability dataset, GENhance can generate strongly-positive text reviews and
highly stable protein sequences without being exposed to similar data during
training. We release our benchmark tasks and models to contribute to the study
of generative modeling extrapolation and data-driven design in biology and
chemistry.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EviDR: Evidence-Emphasized Discrete Reasoning for Reasoning Machine Reading Comprehension. (arXiv:2108.07994v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07994">
<div class="article-summary-box-inner">
<span><p>Reasoning machine reading comprehension (R-MRC) aims to answer complex
questions that require discrete reasoning based on text. To support discrete
reasoning, evidence, typically the concise textual fragments that describe
question-related facts, including topic entities and attribute values, are
crucial clues from question to answer. However, previous end-to-end methods
that achieve state-of-the-art performance rarely solve the problem by paying
enough emphasis on the modeling of evidence, missing the opportunity to further
improve the model's reasoning ability for R-MRC. To alleviate the above issue,
in this paper, we propose an evidence-emphasized discrete reasoning approach
(EviDR), in which sentence and clause level evidence is first detected based on
distant supervision, and then used to drive a reasoning module implemented with
a relational heterogeneous graph convolutional network to derive answers.
Extensive experiments are conducted on DROP (discrete reasoning over
paragraphs) dataset, and the results demonstrate the effectiveness of our
proposed approach. In addition, qualitative analysis verifies the capability of
the proposed evidence-emphasized discrete reasoning for R-MRC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond NED: Fast and Effective Search Space Reduction for Complex Question Answering over Knowledge Bases. (arXiv:2108.08597v5 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08597">
<div class="article-summary-box-inner">
<span><p>Answering complex questions over knowledge bases (KB-QA) faces huge input
data with billions of facts, involving millions of entities and thousands of
predicates. For efficiency, QA systems first reduce the answer search space by
identifying a set of facts that is likely to contain all answers and relevant
cues. The most common technique or doing this is to apply named entity
disambiguation (NED) systems to the question, and retrieve KB facts for the
disambiguated entities. This work presents CLOCQ, an efficient method that
prunes irrelevant parts of the search space using KB-aware signals. CLOCQ uses
a top-k query processor over score-ordered lists of KB items that combine
signals about lexical matching, relevance to the question, coherence among
candidate items, and connectivity in the KB graph. Experiments with two recent
QA benchmarks for complex questions demonstrate the superiority of CLOCQ over
state-of-the-art baselines with respect to answer presence, size of the search
space, and runtimes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robustness and Sensitivity of BERT Models Predicting Alzheimer's Disease from Text. (arXiv:2109.11888v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.11888">
<div class="article-summary-box-inner">
<span><p>Understanding robustness and sensitivity of BERT models predicting
Alzheimer's disease from text is important for both developing better
classification models and for understanding their capabilities and limitations.
In this paper, we analyze how a controlled amount of desired and undesired text
alterations impacts performance of BERT. We show that BERT is robust to natural
linguistic variations in text. On the other hand, we show that BERT is not
sensitive to removing clinically important information from text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cut the CARP: Fishing for zero-shot story evaluation. (arXiv:2110.03111v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03111">
<div class="article-summary-box-inner">
<span><p>Recent advances in large-scale language models (Raffel et al., 2019; Brown et
al., 2020) have brought significant qualitative and quantitative improvements
in machine-driven text generation. Despite this, generation and evaluation of
machine-generated narrative text remains a challenging problem. Objective
evaluation of computationally-generated stories may be prohibitively expensive,
require meticulously annotated datasets, or may not adequately measure the
logical coherence of a generated story's narratological structure.
</p>
<p>Informed by recent advances in contrastive learning (Radford et al., 2021),
we present Contrastive Authoring and Reviewing Pairing (CARP): a scalable,
efficient method for performing qualitatively superior, zero-shot evaluation of
stories. We show a strong correlation between human evaluation of stories and
those of CARP. Model outputs more significantly correlate with corresponding
human input than those language-model based methods which utilize finetuning or
prompt engineering approaches. We also present and analyze the Story-Critique
Dataset, a new corpora composed of 1.3 million aligned story-critique pairs
derived from over 80,000 stories. We expect this corpus to be of interest to
NLP researchers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transliteration of Foreign Words in Burmese. (arXiv:2110.03163v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03163">
<div class="article-summary-box-inner">
<span><p>This manuscript provides general descriptions on transliteration of foreign
words in the Burmese language. Phenomena caused by phonetic and orthographic
issues are discussed. Based on this work, we expect to gradually establish
prescriptive guidelines to normalize the transliteration on modern words in
Burmese.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Continual Knowledge Learning of Language Models. (arXiv:2110.03215v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03215">
<div class="article-summary-box-inner">
<span><p>Large Language Models (LMs) are known to encode world knowledge in their
parameters as they pretrain on a vast amount of web corpus, which is often
utilized for performing knowledge-dependent downstream tasks such as question
answering, fact-checking, and open dialogue. In real-world scenarios, the world
knowledge stored in the LMs can quickly become outdated as the world changes,
but it is non-trivial to avoid catastrophic forgetting and reliably acquire new
knowledge while preserving invariant knowledge. To push the community towards
better maintenance of ever-changing LMs, we formulate a new continual learning
(CL) problem called Continual Knowledge Learning (CKL). We construct a new
benchmark and metric to quantify the retention of time-invariant world
knowledge, the update of outdated knowledge, and the acquisition of new
knowledge. We adopt applicable recent methods from literature to create several
strong baselines. Through extensive experiments, we find that CKL exhibits
unique challenges that are not addressed in previous CL setups, where parameter
expansion is necessary to reliably retain and learn knowledge simultaneously.
By highlighting the critical causes of knowledge forgetting, we show that CKL
is a challenging and important problem that helps us better understand and
train ever-changing LMs. The benchmark datasets, evaluation script, and
baseline code to reproduce our results are available at
https://github.com/joeljang/continual-knowledge-learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VarArray: Array-Geometry-Agnostic Continuous Speech Separation. (arXiv:2110.05745v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.05745">
<div class="article-summary-box-inner">
<span><p>Continuous speech separation using a microphone array was shown to be
promising in dealing with the speech overlap problem in natural conversation
transcription. This paper proposes VarArray, an array-geometry-agnostic speech
separation neural network model. The proposed model is applicable to any number
of microphones without retraining while leveraging the nonlinear correlation
between the input channels. The proposed method adapts different elements that
were proposed before separately, including transform-average-concatenate,
conformer speech separation, and inter-channel phase differences, and combines
them in an efficient and cohesive way. Large-scale evaluation was performed
with two real meeting transcription tasks by using a fully developed
transcription system requiring no prior knowledge such as reference
segmentations, which allowed us to measure the impact that the continuous
speech separation system could have in realistic settings. The proposed model
outperformed a previous approach to array-geometry-agnostic modeling for all of
the geometry configurations considered, achieving asclite-based
speaker-agnostic word error rates of 17.5% and 20.4% for the AMI development
and evaluation sets, respectively, in the end-to-end setting using no
ground-truth segmentations.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Light-Field Microscopy for optical imaging of neuronal activity: when model-based methods meet data-driven approaches. (arXiv:2110.13142v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13142">
<div class="article-summary-box-inner">
<span><p>Understanding how networks of neurons process information is one of the key
challenges in modern neuroscience. A necessary step to achieve this goal is to
be able to observe the dynamics of large populations of neurons over a large
area of the brain. Light-field microscopy (LFM), a type of scanless microscope,
is a particularly attractive candidate for high-speed three-dimensional (3D)
imaging. It captures volumetric information in a single snapshot, allowing
volumetric imaging at video frame-rates. Specific features of imaging neuronal
activity using LFM call for the development of novel machine learning
approaches that fully exploit priors embedded in physics and optics models.
Signal processing theory and wave-optics theory could play a key role in
filling this gap, and contribute to novel computational methods with enhanced
interpretability and generalization by integrating model-driven and data-driven
approaches. This paper is devoted to a comprehensive survey to state-of-the-art
of computational methods for LFM, with a focus on model-based and data-driven
approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Embedded System for Image-based Crack Detection by using Fine-Tuning model of Adaptive Structural Learning of Deep Belief Network. (arXiv:2110.13145v1 [cs.NE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13145">
<div class="article-summary-box-inner">
<span><p>Deep learning has been a successful model which can effectively represent
several features of input space and remarkably improve image recognition
performance on the deep architectures. In our research, an adaptive structural
learning method of Restricted Boltzmann Machine (Adaptive RBM) and Deep Belief
Network (Adaptive DBN) have been developed as a deep learning model. The models
have a self-organize function which can discover an optimal number of hidden
neurons for given input data in a RBM by neuron generation-annihilation
algorithm, and can obtain an appropriate number of RBM as hidden layers in the
trained DBN. The proposed method was applied to a concrete image benchmark data
set SDNET 2018 for crack detection. The dataset contains about 56,000 crack
images for three types of concrete structures: bridge decks, walls, and paved
roads. The fine-tuning method of the Adaptive DBN can show 99.7%, 99.7%, and
99.4% classification accuracy for test dataset of three types of structures. In
this paper, our developed Adaptive DBN was embedded to a tiny PC with GPU for
real-time inference on a drone. For fast inference, the fine tuning algorithm
also removed some inactivated hidden neurons to make a small model and then the
model was able to improve not only classification accuracy but also inference
speed simultaneously. The inference speed and running time of portable battery
charger were evaluated on three kinds of Nvidia embedded systems; Jetson Nano,
AGX Xavier, and Xavier NX.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">As if by magic: self-supervised training of deep despeckling networks with MERLIN. (arXiv:2110.13148v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13148">
<div class="article-summary-box-inner">
<span><p>Speckle fluctuations seriously limit the interpretability of synthetic
aperture radar (SAR) images. Speckle reduction has thus been the subject of
numerous works spanning at least four decades. Techniques based on deep neural
networks have recently achieved a new level of performance in terms of SAR
image restoration quality. Beyond the design of suitable network architectures
or the selection of adequate loss functions, the construction of training sets
is of uttermost importance. So far, most approaches have considered a
supervised training strategy: the networks are trained to produce outputs as
close as possible to speckle-free reference images. Speckle-free images are
generally not available, which requires resorting to natural or optical images
or the selection of stable areas in long time series to circumvent the lack of
ground truth. Self-supervision, on the other hand, avoids the use of
speckle-free images. We introduce a self-supervised strategy based on the
separation of the real and imaginary parts of single-look complex SAR images,
called MERLIN (coMplex sElf-supeRvised despeckLINg), and show that it offers a
straightforward way to train all kinds of deep despeckling networks. Networks
trained with MERLIN take into account the spatial correlations due to the SAR
transfer function specific to a given sensor and imaging mode. By requiring
only a single image, and possibly exploiting large archives, MERLIN opens the
door to hassle-free as well as large-scale training of despeckling networks.
The code of the trained models is made freely available at
https://gitlab.telecom-paris.fr/RING/MERLIN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised similarity search for large scientific datasets. (arXiv:2110.13151v1 [astro-ph.IM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13151">
<div class="article-summary-box-inner">
<span><p>We present the use of self-supervised learning to explore and exploit large
unlabeled datasets. Focusing on 42 million galaxy images from the latest data
release of the Dark Energy Spectroscopic Instrument (DESI) Legacy Imaging
Surveys, we first train a self-supervised model to distil low-dimensional
representations that are robust to symmetries, uncertainties, and noise in each
image. We then use the representations to construct and publicly release an
interactive semantic similarity search tool. We demonstrate how our tool can be
used to rapidly discover rare objects given only a single example, increase the
speed of crowd-sourcing campaigns, and construct and improve training sets for
supervised applications. While we focus on images from sky surveys, the
technique is straightforward to apply to any scientific dataset of any
dimensionality. The similarity search web app can be found at
https://github.com/georgestein/galaxy_search
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generalized Multi-Task Learning from Substantially Unlabeled Multi-Source Medical Image Data. (arXiv:2110.13185v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13185">
<div class="article-summary-box-inner">
<span><p>Deep learning-based models, when trained in a fully-supervised manner, can be
effective in performing complex image analysis tasks, although contingent upon
the availability of large labeled datasets. Especially in the medical imaging
domain, however, expert image annotation is expensive, time-consuming, and
prone to variability. Semi-supervised learning from limited quantities of
labeled data has shown promise as an alternative. Maximizing knowledge gains
from copious unlabeled data benefits semi-supervised learning models. Moreover,
learning multiple tasks within the same model further improves its
generalizability. We propose MultiMix, a new multi-task learning model that
jointly learns disease classification and anatomical segmentation in a
semi-supervised manner, while preserving explainability through a novel
saliency bridge between the two tasks. Our experiments with varying quantities
of multi-source labeled data in the training sets confirm the effectiveness of
MultiMix in the simultaneous classification of pneumonia and segmentation of
the lungs in chest X-ray images. Moreover, both in-domain and cross-domain
evaluations across these tasks further showcase the potential of our model to
adapt to challenging generalization scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Task Meta-Learning Modification with Stochastic Approximation. (arXiv:2110.13188v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13188">
<div class="article-summary-box-inner">
<span><p>Meta-learning methods aim to build learning algorithms capable of quickly
adapting to new tasks in low-data regime. One of the main benchmarks of such an
algorithms is a few-shot learning problem. In this paper we investigate the
modification of standard meta-learning pipeline that takes a multi-task
approach during training. The proposed method simultaneously utilizes
information from several meta-training tasks in a common loss function. The
impact of each of these tasks in the loss function is controlled by the
corresponding weight. Proper optimization of these weights can have a big
influence on training of the entire model and might improve the quality on test
time tasks. In this work we propose and investigate the use of methods from the
family of simultaneous perturbation stochastic approximation (SPSA) approaches
for meta-train tasks weights optimization. We have also compared the proposed
algorithms with gradient-based methods and found that stochastic approximation
demonstrates the largest quality boost in test time. Proposed multi-task
modification can be applied to almost all methods that use meta-learning
pipeline. In this paper we study applications of this modification on
Prototypical Networks and Model-Agnostic Meta-Learning algorithms on CIFAR-FS,
FC100, tieredImageNet and miniImageNet few-shot learning benchmarks. During
these experiments, multi-task modification has demonstrated improvement over
original methods. The proposed SPSA-Tracking algorithm shows the largest
accuracy boost. Our code is available online.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spectral unmixing of Raman microscopic images of single human cells using Independent Component Analysis. (arXiv:2110.13189v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13189">
<div class="article-summary-box-inner">
<span><p>Application of independent component analysis (ICA) as an unmixing and image
clustering technique for high spatial resolution Raman maps is reported. A
hyperspectral map of a fixed human cell was collected by a Raman micro
spectrometer in a raster pattern on a 0.5um grid. Unlike previously used
unsupervised machine learning techniques such as principal component analysis,
ICA is based on non-Gaussianity and statistical independence of data which is
the case for mixture Raman spectra. Hence, ICA is a great candidate for
assembling pseudo-colour maps from the spectral hypercube of Raman spectra. Our
experimental results revealed that ICA is capable of reconstructing false
colour maps of Raman hyperspectral data of human cells, showing the nuclear
region constituents as well as subcellular organelle in the cytoplasm and
distribution of mitochondria in the perinuclear region. Minimum preprocessing
requirements and label-free nature of the ICA method make it a great unmixed
method for extraction of endmembers in Raman hyperspectral maps of living
cells.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IconQA: A New Benchmark for Abstract Diagram Understanding and Visual Language Reasoning. (arXiv:2110.13214v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13214">
<div class="article-summary-box-inner">
<span><p>Current visual question answering (VQA) tasks mainly consider answering
human-annotated questions for natural images. However, aside from natural
images, abstract diagrams with semantic richness are still understudied in
visual understanding and reasoning research. In this work, we introduce a new
challenge of Icon Question Answering (IconQA) with the goal of answering a
question in an icon image context. We release IconQA, a large-scale dataset
that consists of 107,439 questions and three sub-tasks: multi-image-choice,
multi-text-choice, and filling-in-the-blank. The IconQA dataset is inspired by
real-world diagram word problems that highlight the importance of abstract
diagram understanding and comprehensive cognitive reasoning. Thus, IconQA
requires not only perception skills like object recognition and text
understanding, but also diverse cognitive reasoning skills, such as geometric
reasoning, commonsense reasoning, and arithmetic reasoning. To facilitate
potential IconQA models to learn semantic representations for icon images, we
further release an icon dataset Icon645 which contains 645,687 colored icons on
377 classes. We conduct extensive user studies and blind experiments and
reproduce a wide range of advanced VQA methods to benchmark the IconQA task.
Also, we develop a strong IconQA baseline Patch-TRM that applies a pyramid
cross-modal Transformer with input diagram embeddings pre-trained on the icon
dataset. IconQA and Icon645 are available at https://iconqa.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RBSRICNN: Raw Burst Super-Resolution through Iterative Convolutional Neural Network. (arXiv:2110.13217v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13217">
<div class="article-summary-box-inner">
<span><p>Modern digital cameras and smartphones mostly rely on image signal processing
(ISP) pipelines to produce realistic colored RGB images. However, compared to
DSLR cameras, low-quality images are usually obtained in many portable mobile
devices with compact camera sensors due to their physical limitations. The
low-quality images have multiple degradations i.e., sub-pixel shift due to
camera motion, mosaick patterns due to camera color filter array,
low-resolution due to smaller camera sensors, and the rest information are
corrupted by the noise. Such degradations limit the performance of current
Single Image Super-resolution (SISR) methods in recovering high-resolution (HR)
image details from a single low-resolution (LR) image. In this work, we propose
a Raw Burst Super-Resolution Iterative Convolutional Neural Network (RBSRICNN)
that follows the burst photography pipeline as a whole by a forward (physical)
model. The proposed Burst SR scheme solves the problem with classical image
regularization, convex optimization, and deep learning techniques, compared to
existing black-box data-driven methods. The proposed network produces the final
output by an iterative refinement of the intermediate SR estimates. We
demonstrate the effectiveness of our proposed approach in quantitative and
qualitative experiments that generalize robustly to real LR burst inputs with
onl synthetic burst data available for training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identifying and Benchmarking Natural Out-of-Context Prediction Problems. (arXiv:2110.13223v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13223">
<div class="article-summary-box-inner">
<span><p>Deep learning systems frequently fail at out-of-context (OOC) prediction, the
problem of making reliable predictions on uncommon or unusual inputs or
subgroups of the training distribution. To this end, a number of benchmarks for
measuring OOC performance have recently been introduced. In this work, we
introduce a framework unifying the literature on OOC performance measurement,
and demonstrate how rich auxiliary information can be leveraged to identify
candidate sets of OOC examples in existing datasets. We present NOOCh: a suite
of naturally-occurring "challenge sets", and show how varying notions of
context can be used to probe specific OOC failure modes. Experimentally, we
explore the tradeoffs between various learning approaches on these challenge
sets and demonstrate how the choices made in designing OOC benchmarks can yield
varying conclusions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pediatric Otoscopy Video Screening with Shift Contrastive Anomaly Detection. (arXiv:2110.13254v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13254">
<div class="article-summary-box-inner">
<span><p>Ear related concerns and symptoms represents the leading indication for
seeking pediatric healthcare attention. Despite the high incidence of such
encounters, the diagnostic process of commonly encountered disease of the
middle and external presents significant challenge. Much of this challenge
stems from the lack of cost effective diagnostic testing, which necessitating
the presence or absence of ear pathology to be determined clinically. Research
has however demonstrated considerable variation among clinicians in their
ability to accurately diagnose and consequently manage ear pathology. With
recent advances in computer vision and machine learning, there is an increasing
interest in helping clinicians to accurately diagnose middle and external ear
pathology with computer-aided systems. It has been shown that AI has the
capacity to analyse a single clinical image captured during examination of the
ear canal and eardrum from which it can determine the likelihood of a
pathognomonic pattern for a specific diagnosis being present. The capture of
such an image can however be challenging especially to inexperienced
clinicians. To help mitigate this technical challenge we have developed and
tested a method using video sequences. We present a two stage method that
first, identifies valid frames by detecting and extracting ear drum patches
from the video sequence, and second, performs the proposed shift contrastive
anomaly detection to flag the otoscopy video sequences as normal or abnormal.
Our method achieves an AUROC of 88.0% on the patient-level and also outperforms
the average of a group of 25 clinicians in a comparative study, which is the
largest of such published to date. We conclude that the presented method
achieves a promising first step towards automated analysis of otoscopy video.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Learning for Deep Visual Tracking. (arXiv:2110.13259v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13259">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks (CNNs) have been successfully applied to the
single target tracking task in recent years. Generally, training a deep CNN
model requires numerous labeled training samples, and the number and quality of
these samples directly affect the representational capability of the trained
model. However, this approach is restrictive in practice, because manually
labeling such a large number of training samples is time-consuming and
prohibitively expensive. In this paper, we propose an active learning method
for deep visual tracking, which selects and annotates the unlabeled samples to
train the deep CNNs model. Under the guidance of active learning, the tracker
based on the trained deep CNNs model can achieve competitive tracking
performance while reducing the labeling cost. More specifically, to ensure the
diversity of selected samples, we propose an active learning method based on
multi-frame collaboration to select those training samples that should be and
need to be annotated. Meanwhile, considering the representativeness of these
selected samples, we adopt a nearest neighbor discrimination method based on
the average nearest neighbor distance to screen isolated samples and
low-quality samples. Therefore, the training samples subset selected based on
our method requires only a given budget to maintain the diversity and
representativeness of the entire sample set. Furthermore, we adopt a Tversky
loss to improve the bounding box estimation of our tracker, which can ensure
that the tracker achieves more accurate target states. Extensive experimental
results confirm that our active learning-based tracker (ALT) achieves
competitive tracking accuracy and speed compared with state-of-the-art trackers
on the seven most challenging evaluation benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Quality Assessment using Contrastive Learning. (arXiv:2110.13266v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13266">
<div class="article-summary-box-inner">
<span><p>We consider the problem of obtaining image quality representations in a
self-supervised manner. We use prediction of distortion type and degree as an
auxiliary task to learn features from an unlabeled image dataset containing a
mixture of synthetic and realistic distortions. We then train a deep
Convolutional Neural Network (CNN) using a contrastive pairwise objective to
solve the auxiliary problem. We refer to the proposed training framework and
resulting deep IQA model as the CONTRastive Image QUality Evaluator
(CONTRIQUE). During evaluation, the CNN weights are frozen and a linear
regressor maps the learned representations to quality scores in a No-Reference
(NR) setting. We show through extensive experiments that CONTRIQUE achieves
competitive performance when compared to state-of-the-art NR image quality
models, even without any additional fine-tuning of the CNN backbone. The
learned representations are highly robust and generalize well across images
afflicted by either synthetic or authentic distortions. Our results suggest
that powerful quality representations with perceptual relevance can be obtained
without requiring large labeled subjective image quality datasets. The
implementations used in this paper are available at
\url{https://github.com/pavancm/CONTRIQUE}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Facial Recognition in Collaborative Learning Videos. (arXiv:2110.13269v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13269">
<div class="article-summary-box-inner">
<span><p>Face recognition in collaborative learning videos presents many challenges.
In collaborative learning videos, students sit around a typical table at
different positions to the recording camera, come and go, move around, get
partially or fully occluded. Furthermore, the videos tend to be very long,
requiring the development of fast and accurate methods. We develop a dynamic
system of recognizing participants in collaborative learning systems. We
address occlusion and recognition failures by using past information about the
face detection history. We address the need for detecting faces from different
poses and the need for speed by associating each participant with a collection
of prototype faces computed through sampling or K-means clustering. Our results
show that the proposed system is proven to be very fast and accurate. We also
compare our system against a baseline system that uses InsightFace [2] and the
original training video segments. We achieved an average accuracy of 86.2%
compared to 70.8% for the baseline system. On average, our recognition rate was
28.1 times faster than the baseline system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Neural Transmittance for Efficient Rendering of Reflectance Fields. (arXiv:2110.13272v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13272">
<div class="article-summary-box-inner">
<span><p>Recently neural volumetric representations such as neural reflectance fields
have been widely applied to faithfully reproduce the appearance of real-world
objects and scenes under novel viewpoints and lighting conditions. However, it
remains challenging and time-consuming to render such representations under
complex lighting such as environment maps, which requires individual ray
marching towards each single light to calculate the transmittance at every
sampled point. In this paper, we propose a novel method based on precomputed
Neural Transmittance Functions to accelerate the rendering of neural
reflectance fields. Our neural transmittance functions enable us to efficiently
query the transmittance at an arbitrary point in space along an arbitrary ray
without tedious ray marching, which effectively reduces the time-complexity of
the rendering. We propose a novel formulation for the neural transmittance
function, and train it jointly with the neural reflectance fields on images
captured under collocated camera and light, while enforcing monotonicity.
Results on real and synthetic scenes demonstrate almost two order of magnitude
speedup for renderings under environment maps with minimal accuracy loss.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Variational Graph Autoencoder for Manipulation Action Recognition and Prediction. (arXiv:2110.13280v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13280">
<div class="article-summary-box-inner">
<span><p>Despite decades of research, understanding human manipulation activities is,
and has always been, one of the most attractive and challenging research topics
in computer vision and robotics. Recognition and prediction of observed human
manipulation actions have their roots in the applications related to, for
instance, human-robot interaction and robot learning from demonstration. The
current research trend heavily relies on advanced convolutional neural networks
to process the structured Euclidean data, such as RGB camera images. These
networks, however, come with immense computational complexity to be able to
process high dimensional raw data.
</p>
<p>Different from the related works, we here introduce a deep graph autoencoder
to jointly learn recognition and prediction of manipulation tasks from symbolic
scene graphs, instead of relying on the structured Euclidean data. Our network
has a variational autoencoder structure with two branches: one for identifying
the input graph type and one for predicting the future graphs. The input of the
proposed network is a set of semantic graphs which store the spatial relations
between subjects and objects in the scene. The network output is a label set
representing the detected and predicted class types. We benchmark our new model
against different state-of-the-art methods on two different datasets, MANIAC
and MSRC-9, and show that our proposed model can achieve better performance. We
also release our source code https://github.com/gamzeakyol/GNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generative Flows as a General Purpose Solution for Inverse Problems. (arXiv:2110.13285v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13285">
<div class="article-summary-box-inner">
<span><p>Due to the success of generative flows to model data distributions, they have
been explored in inverse problems. Given a pre-trained generative flow,
previous work proposed to minimize the 2-norm of the latent variables as a
regularization term in the main objective. The intuition behind it was to
ensure high likelihood latent variables, however this does not ensure the
generation of realistic samples as we show in our experiments. We therefore
propose a regularization term to directly produce high likelihood
reconstructions. Our hypothesis is that our method could make generative flows
a general-purpose solver for inverse problems. We evaluate our method in image
denoising, image deblurring, image inpainting, and image colorization. We
observe a compelling improvement of our method over prior works in the PSNR and
SSIM metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty quantification in non-rigid image registration via stochastic gradient Markov chain Monte Carlo. (arXiv:2110.13289v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13289">
<div class="article-summary-box-inner">
<span><p>We develop a new Bayesian model for non-rigid registration of
three-dimensional medical images, with a focus on uncertainty quantification.
Probabilistic registration of large images with calibrated uncertainty
estimates is difficult for both computational and modelling reasons. To address
the computational issues, we explore connections between the Markov chain Monte
Carlo by backpropagation and the variational inference by backpropagation
frameworks, in order to efficiently draw samples from the posterior
distribution of transformation parameters. To address the modelling issues, we
formulate a Bayesian model for image registration that overcomes the existing
barriers when using a dense, high-dimensional, and diffeomorphic transformation
parametrisation. This results in improved calibration of uncertainty estimates.
We compare the model in terms of both image registration accuracy and
uncertainty quantification to VoxelMorph, a state-of-the-art image registration
model based on deep learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">History Aware Multimodal Transformer for Vision-and-Language Navigation. (arXiv:2110.13309v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13309">
<div class="article-summary-box-inner">
<span><p>Vision-and-language navigation (VLN) aims to build autonomous visual agents
that follow instructions and navigate in real scenes. To remember previously
visited locations and actions taken, most approaches to VLN implement memory
using recurrent states. Instead, we introduce a History Aware Multimodal
Transformer (HAMT) to incorporate a long-horizon history into multimodal
decision making. HAMT efficiently encodes all the past panoramic observations
via a hierarchical vision transformer (ViT), which first encodes individual
images with ViT, then models spatial relation between images in a panoramic
observation and finally takes into account temporal relation between panoramas
in the history. It, then, jointly combines text, history and current
observation to predict the next action. We first train HAMT end-to-end using
several proxy tasks including single step action prediction and spatial
relation prediction, and then use reinforcement learning to further improve the
navigation policy. HAMT achieves new state of the art on a broad range of VLN
tasks, including VLN with fine-grained instructions (R2R, RxR), high-level
instructions (R2R-Last, REVERIE), dialogs (CVDN) as well as long-horizon VLN
(R4R, R2R-Back). We demonstrate HAMT to be particularly effective for
navigation tasks with longer trajectories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Ellipsoid-specific Fitting via Expectation Maximization. (arXiv:2110.13337v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13337">
<div class="article-summary-box-inner">
<span><p>Ellipsoid fitting is of general interest in machine vision, such as object
detection and shape approximation. Most existing approaches rely on the
least-squares fitting of quadrics, minimizing the algebraic or geometric
distances, with additional constraints to enforce the quadric as an ellipsoid.
However, they are susceptible to outliers and non-ellipsoid or biased results
when the axis ratio exceeds certain thresholds. To address these problems, we
propose a novel and robust method for ellipsoid fitting in a noisy,
outlier-contaminated 3D environment. We explicitly model the ellipsoid by
kernel density estimation (KDE) of the input data. The ellipsoid fitting is
cast as a maximum likelihood estimation (MLE) problem without extra
constraints, where a weighting term is added to depress outliers, and then
effectively solved via the Expectation-Maximization (EM) framework.
Furthermore, we introduce the vector {\epsilon} technique to accelerate the
convergence of the original EM. The proposed method is compared with
representative state-of-the-art approaches by extensive experiments, and
results show that our method is ellipsoid-specific, parameter free, and more
robust against noise, outliers, and the large axis ratio. Our implementation is
available at https://zikai1.github.io/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Camera-Based Physiological Sensing: Challenges and Future Directions. (arXiv:2110.13362v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13362">
<div class="article-summary-box-inner">
<span><p>Numerous real-world applications have been driven by the recent algorithmic
advancement of artificial intelligence (AI). Healthcare is no exception and AI
technologies have great potential to revolutionize the industry. Non-contact
camera-based physiological sensing, including remote photoplethysmography
(rPPG), is a set of imaging methods that leverages ordinary RGB cameras (e.g.,
webcam or smartphone camera) to capture subtle changes in electromagnetic
radiation (e.g., light) reflected by the body caused by physiological
processes. Because of the relative ubiquity of cameras, these methods not only
have the ability to measure the signals without contact with the body but also
have the opportunity to capture multimodal information (e.g., facial
expressions, activities and other context) from the same sensor. However,
developing accessible, equitable and useful camera-based physiological sensing
systems comes with various challenges. In this article, we identify four
research challenges for the field of camera-based physiological sensing and
broader AI driven healthcare communities and suggest future directions to
tackle these. We believe solving these challenges will help deliver accurate,
equitable and generalizable AI systems for healthcare that are practical in
real-world and clinical contexts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Automatic Detection Method Of Cerebral Aneurysms In Time-Of-Flight Magnetic Resonance Angiography Images Based On Attention 3D U-Net. (arXiv:2110.13367v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13367">
<div class="article-summary-box-inner">
<span><p>Background:Subarachnoid hemorrhage caused by ruptured cerebral aneurysm often
leads to fatal consequences.However,if the aneurysm can be found and treated
during asymptomatic periods,the probability of rupture can be greatly
reduced.At present,time-of-flight magnetic resonance angiography is one of the
most commonly used non-invasive screening techniques for cerebral aneurysm,and
the application of deep learning technology in aneurysm detection can
effectively improve the screening effect of aneurysm.Existing studies have
found that three-dimensional features play an important role in aneurysm
detection,but they require a large amount of training data and have problems
such as a high false positive rate. Methods:This paper proposed a novel method
for aneurysm detection.First,a fully automatic cerebral artery segmentation
algorithm without training data was used to extract the volume of interest,and
then the 3D U-Net was improved by the 3D SENet module to establish an aneurysm
detection model.Eventually a set of fully automated,end-to-end aneurysm
detection methods have been formed. Results:A total of 231 magnetic resonance
angiography image data were used in this study,among which 132 were training
sets,34 were internal test sets and 65 were external test sets.The presented
method obtained 97.89% sensitivity in the five-fold cross-validation and
obtained 91.0% sensitivity with 2.48 false positives/case in the detection of
the external test sets. Conclusions:Compared with the results of our previous
studies and other studies,the method in this paper achieves a very competitive
sensitivity with less training data and maintains a low false positive rate.As
the only method currently using 3D U-Net for aneurysm detection,it proves the
feasibility and superior performance of this network in aneurysm detection,and
also explores the potential of the channel attention mechanism in this task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Plug-and-Play Few-shot Object Detection with Meta Strategy and Explicit Localization Inference. (arXiv:2110.13377v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13377">
<div class="article-summary-box-inner">
<span><p>Aiming at recognizing and localizing the object of novel categories by a few
reference samples, few-shot object detection is a quite challenging task.
Previous works often depend on the fine-tuning process to transfer their model
to the novel category and rarely consider the defect of fine-tuning, resulting
in many drawbacks. For example, these methods are far from satisfying in the
low-shot or episode-based scenarios since the fine-tuning process in object
detection requires much time and high-shot support data. To this end, this
paper proposes a plug-and-play few-shot object detection (PnP-FSOD) framework
that can accurately and directly detect the objects of novel categories without
the fine-tuning process. To accomplish the objective, the PnP-FSOD framework
contains two parallel techniques to address the core challenges in the few-shot
learning, i.e., across-category task and few-annotation support. Concretely, we
first propose two simple but effective meta strategies for the box classifier
and RPN module to enable the across-category object detection without
fine-tuning. Then, we introduce two explicit inferences into the localization
process to reduce its dependence on the annotated data, including explicit
localization score and semi-explicit box regression. In addition to the
PnP-FSOD framework, we propose a novel one-step tuning method that can avoid
the defects in fine-tuning. It is noteworthy that the proposed techniques and
tuning method are based on the general object detector without other prior
methods, so they are easily compatible with the existing FSOD methods.
Extensive experiments show that the PnP-FSOD framework has achieved the
state-of-the-art few-shot object detection performance without any tuning
method. After applying the one-step tuning method, it further shows a
significant lead in both efficiency, precision, and recall, under varied
evaluation protocols.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ViDA-MAN: Visual Dialog with Digital Humans. (arXiv:2110.13384v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13384">
<div class="article-summary-box-inner">
<span><p>We demonstrate ViDA-MAN, a digital-human agent for multi-modal interaction,
which offers realtime audio-visual responses to instant speech inquiries.
Compared to traditional text or voice-based system, ViDA-MAN offers human-like
interactions (e.g, vivid voice, natural facial expression and body gestures).
Given a speech request, the demonstration is able to response with high quality
videos in sub-second latency. To deliver immersive user experience, ViDA-MAN
seamlessly integrates multi-modal techniques including Acoustic Speech
Recognition (ASR), multi-turn dialog, Text To Speech (TTS), talking heads video
generation. Backed with large knowledge base, ViDA-MAN is able to chat with
users on a number of topics including chit-chat, weather, device control, News
recommendations, booking hotels, as well as answering questions via structured
knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">IIP-Transformer: Intra-Inter-Part Transformer for Skeleton-Based Action Recognition. (arXiv:2110.13385v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13385">
<div class="article-summary-box-inner">
<span><p>Recently, Transformer-based networks have shown great promise on
skeleton-based action recognition tasks. The ability to capture global and
local dependencies is the key to success while it also brings quadratic
computation and memory cost. Another problem is that previous studies mainly
focus on the relationships among individual joints, which often suffers from
the noisy skeleton joints introduced by the noisy inputs of sensors or
inaccurate estimations. To address the above issues, we propose a novel
Transformer-based network (IIP-Transformer). Instead of exploiting interactions
among individual joints, our IIP-Transformer incorporates body joints and parts
interactions simultaneously and thus can capture both joint-level (intra-part)
and part-level (inter-part) dependencies efficiently and effectively. From the
data aspect, we introduce a part-level skeleton data encoding that
significantly reduces the computational complexity and is more robust to
joint-level skeleton noise. Besides, a new part-level data augmentation is
proposed to improve the performance of the model. On two large-scale datasets,
NTU-RGB+D 60 and NTU RGB+D 120, the proposed IIP-Transformer achieves
the-state-of-art performance with more than 8x less computational complexity
than DSTA-Net, which is the SOTA Transformer-based method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Denoising Neural Networks for Few Shot Learning. (arXiv:2110.13386v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13386">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce a new architecture for few shot learning, the
task of teaching a neural network from as few as one or five labeled examples.
Inspired by the theoretical results of Alaine et al that Denoising Autoencoders
refine features to lie closer to the true data manifold, we present a new
training scheme that adds noise at multiple stages of an existing neural
architecture while simultaneously learning to be robust to this added noise.
This architecture, which we call a Self-Denoising Neural Network (SDNN), can be
applied easily to most modern convolutional neural architectures, and can be
used as a supplement to many existing few-shot learning techniques. We
empirically show that SDNNs out-perform previous state-of-the-art methods for
few shot image recognition using the Wide-ResNet architecture on the
\textit{mini}ImageNet, tiered-ImageNet, and CIFAR-FS few shot learning
datasets. We also perform a series of ablation experiments to empirically
justify the construction of the SDNN architecture. Finally, we show that SDNNs
even improve few shot performance on the task of human action detection in
video using experiments on the ActEV SDL Surprise Activities challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Normalized Gaussian Wasserstein Distance for Tiny Object Detection. (arXiv:2110.13389v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13389">
<div class="article-summary-box-inner">
<span><p>Detecting tiny objects is a very challenging problem since a tiny object only
contains a few pixels in size. We demonstrate that state-of-the-art detectors
do not produce satisfactory results on tiny objects due to the lack of
appearance information. Our key observation is that Intersection over Union
(IoU) based metrics such as IoU itself and its extensions are very sensitive to
the location deviation of the tiny objects, and drastically deteriorate the
detection performance when used in anchor-based detectors. To alleviate this,
we propose a new evaluation metric using Wasserstein distance for tiny object
detection. Specifically, we first model the bounding boxes as 2D Gaussian
distributions and then propose a new metric dubbed Normalized Wasserstein
Distance (NWD) to compute the similarity between them by their corresponding
Gaussian distributions. The proposed NWD metric can be easily embedded into the
assignment, non-maximum suppression, and loss function of any anchor-based
detector to replace the commonly used IoU metric. We evaluate our metric on a
new dataset for tiny object detection (AI-TOD) in which the average object size
is much smaller than existing object detection datasets. Extensive experiments
show that, when equipped with NWD metric, our approach yields performance that
is 6.7 AP points higher than a standard fine-tuning baseline, and 6.0 AP points
higher than state-of-the-art competitors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transferring Domain-Agnostic Knowledge in Video Question Answering. (arXiv:2110.13395v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13395">
<div class="article-summary-box-inner">
<span><p>Video question answering (VideoQA) is designed to answer a given question
based on a relevant video clip. The current available large-scale datasets have
made it possible to formulate VideoQA as the joint understanding of visual and
language information. However, this training procedure is costly and still less
competent with human performance. In this paper, we investigate a transfer
learning method by the introduction of domain-agnostic knowledge and
domain-specific knowledge. First, we develop a novel transfer learning
framework, which finetunes the pre-trained model by applying domain-agnostic
knowledge as the medium. Second, we construct a new VideoQA dataset with 21,412
human-generated question-answer samples for comparable transfer of knowledge.
Our experiments show that: (i) domain-agnostic knowledge is transferable and
(ii) our proposed transfer learning framework can boost VideoQA performance
effectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Rich Features for Gait Recognition by Integrating Skeletons and Silhouettes. (arXiv:2110.13408v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13408">
<div class="article-summary-box-inner">
<span><p>Gait recognition captures gait patterns from the walking sequence of an
individual for identification. Most existing gait recognition methods learn
features from silhouettes or skeletons for the robustness to clothing,
carrying, and other exterior factors. The combination of the two data
modalities, however, is not fully exploited. This paper proposes a simple yet
effective bimodal fusion (BiFusion) network, which mines the complementary
clues of skeletons and silhouettes, to learn rich features for gait
identification. Particularly, the inherent hierarchical semantics of body
joints in a skeleton is leveraged to design a novel Multi-scale Gait Graph
(MSGG) network for the feature extraction of skeletons. Extensive experiments
on CASIA-B and OUMVLP demonstrate both the superiority of the proposed MSGG
network in modeling skeletons and the effectiveness of the bimodal fusion for
gait recognition. Under the most challenging condition of walking in different
clothes on CASIA-B, our method achieves the rank-1 accuracy of 92.1%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TriBERT: Full-body Human-centric Audio-visual Representation Learning for Visual Sound Separation. (arXiv:2110.13412v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13412">
<div class="article-summary-box-inner">
<span><p>The recent success of transformer models in language, such as BERT, has
motivated the use of such architectures for multi-modal feature learning and
tasks. However, most multi-modal variants (e.g., ViLBERT) have limited
themselves to visual-linguistic data. Relatively few have explored its use in
audio-visual modalities, and none, to our knowledge, illustrate them in the
context of granular audio-visual detection or segmentation tasks such as sound
source separation and localization. In this work, we introduce TriBERT -- a
transformer-based architecture, inspired by ViLBERT, which enables contextual
feature learning across three modalities: vision, pose, and audio, with the use
of flexible co-attention. The use of pose keypoints is inspired by recent works
that illustrate that such representations can significantly boost performance
in many audio-visual scenarios where often one or more persons are responsible
for the sound explicitly (e.g., talking) or implicitly (e.g., sound produced as
a function of human manipulating an object). From a technical perspective, as
part of the TriBERT architecture, we introduce a learned visual tokenization
scheme based on spatial attention and leverage weak-supervision to allow
granular cross-modal interactions for visual and pose modalities. Further, we
supplement learning with sound-source separation loss formulated across all
three streams. We pre-train our model on the large MUSIC21 dataset and
demonstrate improved performance in audio-visual sound source separation on
that dataset as well as other datasets through fine-tuning. In addition, we
show that the learned TriBERT representations are generic and significantly
improve performance on other audio-visual tasks such as cross-modal
audio-visual-pose retrieval by as much as 66.7% in top-1 accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Host-free Trojan Attack. (arXiv:2110.13414v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13414">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel host-free Trojan attack with triggers that
are fixed in the semantic space but not necessarily in the pixel space. In
contrast to existing Trojan attacks which use clean input images as hosts to
carry small, meaningless trigger patterns, our attack considers triggers as
full-sized images belonging to a semantically meaningful object class. Since in
our attack, the backdoored classifier is encouraged to memorize the abstract
semantics of the trigger images than any specific fixed pattern, it can be
later triggered by semantically similar but different looking images. This
makes our attack more practical to be applied in the real-world and harder to
defend against. Extensive experimental results demonstrate that with only a
small number of Trojan patterns for training, our attack can generalize well to
new patterns of the same Trojan class and can bypass state-of-the-art defense
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Magnification Network for Vessel Segmentation in OCTA Images. (arXiv:2110.13428v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13428">
<div class="article-summary-box-inner">
<span><p>Optical coherence tomography angiography (OCTA) is a novel non-invasive
imaging modality that allows micron-level resolution to visualize the retinal
microvasculature. The retinal vessel segmentation in OCTA images is still an
open problem, and especially the thin and dense structure of the capillary
plexus is an important challenge of this problem. In this work, we propose a
novel image magnification network (IMN) for vessel segmentation in OCTA images.
Contrary to the U-Net structure with a down-sampling encoder and up-sampling
decoder, the proposed IMN adopts the design of up-sampling encoding and then
down-sampling decoding. This design is to capture more image details and reduce
the omission of thin-and-small structures. The experimental results on three
open OCTA datasets show that the proposed IMN with an average dice score of
90.2% achieves the best performance in vessel segmentation of OCTA images.
Besides, we also demonstrate the superior performance of IMN in cross-field
image vessel segmentation and vessel skeleton extraction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextual Similarity Aggregation with Self-attention for Visual Re-ranking. (arXiv:2110.13430v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13430">
<div class="article-summary-box-inner">
<span><p>In content-based image retrieval, the first-round retrieval result by simple
visual feature comparison may be unsatisfactory, which can be refined by visual
re-ranking techniques. In image retrieval, it is observed that the contextual
similarity among the top-ranked images is an important clue to distinguish the
semantic relevance. Inspired by this observation, in this paper, we propose a
visual re-ranking method by contextual similarity aggregation with
self-attention. In our approach, for each image in the top-K ranking list, we
represent it into an affinity feature vector by comparing it with a set of
anchor images. Then, the affinity features of the top-K images are refined by
aggregating the contextual information with a transformer encoder. Finally, the
affinity features are used to recalculate the similarity scores between the
query and the top-K images for re-ranking of the latter. To further improve the
robustness of our re-ranking model and enhance the performance of our method, a
new data augmentation scheme is designed. Since our re-ranking model is not
directly involved with the visual feature used in the initial retrieval, it is
ready to be applied to retrieval result lists obtained from various retrieval
algorithms. We conduct comprehensive experiments on four benchmark datasets to
demonstrate the generality and effectiveness of our proposed visual re-ranking
method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning-based Segmentation of Cerebral Aneurysms in 3D TOF-MRA using Coarse-to-Fine Framework. (arXiv:2110.13432v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13432">
<div class="article-summary-box-inner">
<span><p>BACKGROUND AND PURPOSE: Cerebral aneurysm is one of the most common
cerebrovascular diseases, and SAH caused by its rupture has a very high
mortality and disability rate. Existing automatic segmentation methods based on
DLMs with TOF-MRA modality could not segment edge voxels very well, so that our
goal is to realize more accurate segmentation of cerebral aneurysms in 3D
TOF-MRA with the help of DLMs. MATERIALS AND METHODS: In this research, we
proposed an automatic segmentation framework of cerebral aneurysm in 3D
TOF-MRA. The framework was composed of two segmentation networks ranging from
coarse to fine. The coarse segmentation network, namely DeepMedic, completed
the coarse segmentation of cerebral aneurysms, and the processed results were
fed into the fine segmentation network, namely dual-channel SE_3D U-Net trained
with weighted loss function, for fine segmentation. Images from ADAM2020
(n=113) were used for training and validation and images from another center
(n=45) were used for testing. The segmentation metrics we used include DSC, HD,
and VS. RESULTS: The trained cerebral aneurysm segmentation model achieved DSC
of 0.75, HD of 1.52, and VS of 0.91 on validation cohort. On the totally
independent test cohort, our method achieved the highest DSC of 0.12, the
lowest HD of 11.61, and the highest VS of 0.16 in comparison with
state-of-the-art segmentation networks. CONCLUSIONS: The coarse-to-fine
framework, which composed of DeepMedic and dual-channel SE_3D U-Net can segment
cerebral aneurysms in 3D TOF-MRA with a superior accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding the Role of Self-Supervised Learning in Out-of-Distribution Detection Task. (arXiv:2110.13435v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13435">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning (SSL) has achieved great success in a variety of
computer vision tasks. However, the mechanism of how SSL works in these tasks
remains a mystery. In this paper, we study how SSL can enhance the performance
of the out-of-distribution (OOD) detection task. We first point out two general
properties that a good OOD detector should have: 1) the overall feature space
should be large and 2) the inlier feature space should be small. Then we
demonstrate that SSL can indeed increase the intrinsic dimension of the overall
feature space. In the meantime, SSL even has the potential to shrink the inlier
feature space. As a result, there will be more space spared for the outliers,
making OOD detection much easier. The conditions when SSL can shrink the inlier
feature space is also discussed and validated. By understanding the role of SSL
in the OOD detection task, our study can provide a guideline for designing
better OOD detection algorithms. Moreover, this work can also shed light to
other tasks where SSL can improve the performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A time-weighted metric for sets of trajectories to assess multi-object tracking algorithms. (arXiv:2110.13444v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13444">
<div class="article-summary-box-inner">
<span><p>This paper proposes a metric for sets of trajectories to evaluate
multi-object tracking algorithms that includes time-weighted costs for
localisation errors of properly detected targets, for false targets, missed
targets and track switches. The proposed metric extends the metric in [1] by
including weights to the costs associated to different time steps. The
time-weighted costs increase the flexibility of the metric [1] to fit more
applications and user preferences. We first introduce a metric based on
multi-dimensional assignments, and then its linear programming relaxation,
which is computable in polynomial time and is also a metric. The metrics can
also be extended to metrics on random finite sets of trajectories to evaluate
and rank algorithms across different scenarios, each with a ground truth set of
trajectories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Subject Adaptive EEG-based Visual Recognition. (arXiv:2110.13470v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13470">
<div class="article-summary-box-inner">
<span><p>This paper focuses on EEG-based visual recognition, aiming to predict the
visual object class observed by a subject based on his/her EEG signals. One of
the main challenges is the large variation between signals from different
subjects. It limits recognition systems to work only for the subjects involved
in model training, which is undesirable for real-world scenarios where new
subjects are frequently added. This limitation can be alleviated by collecting
a large amount of data for each new user, yet it is costly and sometimes
infeasible. To make the task more practical, we introduce a novel problem
setting, namely subject adaptive EEG-based visual recognition. In this setting,
a bunch of pre-recorded data of existing users (source) is available, while
only a little training data from a new user (target) are provided. At inference
time, the model is evaluated solely on the signals from the target user. This
setting is challenging, especially because training samples from source
subjects may not be helpful when evaluating the model on the data from the
target subject. To tackle the new problem, we design a simple yet effective
baseline that minimizes the discrepancy between feature distributions from
different subjects, which allows the model to extract subject-independent
features. Consequently, our model can learn the common knowledge shared among
subjects, thereby significantly improving the recognition performance for the
target subject. In the experiments, we demonstrate the effectiveness of our
method under various settings. Our code is available at
https://github.com/DeepBCI/Deep-BCI/tree/master/1_Intelligent_BCI/Subject_Adaptive_EEG_based_Visual_Recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Response-based Distillation for Incremental Object Detection. (arXiv:2110.13471v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13471">
<div class="article-summary-box-inner">
<span><p>Traditional object detection are ill-equipped for incremental learning.
However, fine-tuning directly on a well-trained detection model with only new
data will leads to catastrophic forgetting. Knowledge distillation is a
straightforward way to mitigate catastrophic forgetting. In Incremental Object
Detection (IOD), previous work mainly focuses on feature-level knowledge
distillation, but the different response of detector has not been fully
explored yet. In this paper, we propose a fully response-based incremental
distillation method focusing on learning response from detection bounding boxes
and classification predictions. Firstly, our method transferring category
knowledge while equipping student model with the ability to retain localization
knowledge during incremental learning. In addition, we further evaluate the
qualities of all locations and provides valuable response by adaptive
pseudo-label selection (APS) strategies. Finally, we elucidate that knowledge
from different responses should be assigned with different importance during
incremental distillation. Extensive experiments conducted on MS COCO
demonstrate significant advantages of our method, which substantially narrow
the performance gap towards full training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CTRN: Class-Temporal Relational Network for Action Detection. (arXiv:2110.13473v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13473">
<div class="article-summary-box-inner">
<span><p>Action detection is an essential and challenging task, especially for densely
labelled datasets of untrimmed videos. There are many real-world challenges in
those datasets, such as composite action, co-occurring action, and high
temporal variation of instance duration. For handling these challenges, we
propose to explore both the class and temporal relations of detected actions.
In this work, we introduce an end-to-end network: Class-Temporal Relational
Network (CTRN). It contains three key components: (1) The Representation
Transform Module filters the class-specific features from the mixed
representations to build graph-structured data. (2) The Class-Temporal Module
models the class and temporal relations in a sequential manner. (3)
G-classifier leverages the privileged knowledge of the snippet-wise
co-occurring action pairs to further improve the co-occurring action detection.
We evaluate CTRN on three challenging densely labelled datasets and achieve
state-of-the-art performance, reflecting the effectiveness and robustness of
our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-Shot Action Recognition from Diverse Object-Scene Compositions. (arXiv:2110.13479v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13479">
<div class="article-summary-box-inner">
<span><p>This paper investigates the problem of zero-shot action recognition, in the
setting where no training videos with seen actions are available. For this
challenging scenario, the current leading approach is to transfer knowledge
from the image domain by recognizing objects in videos using pre-trained
networks, followed by a semantic matching between objects and actions. Where
objects provide a local view on the content in videos, in this work we also
seek to include a global view of the scene in which actions occur. We find that
scenes on their own are also capable of recognizing unseen actions, albeit more
marginally than objects, and a direct combination of object-based and
scene-based scores degrades the action recognition performance. To get the best
out of objects and scenes, we propose to construct them as a Cartesian product
of all possible compositions. We outline how to determine the likelihood of
object-scene compositions in videos, as well as a semantic matching from
object-scene compositions to actions that enforces diversity among the most
relevant compositions for each action. While simple, our composition-based
approach outperforms object-based approaches and even state-of-the-art
zero-shot approaches that rely on large-scale video datasets with hundreds of
seen actions for training and knowledge transfer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-Learning for Multi-Label Few-Shot Classification. (arXiv:2110.13494v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13494">
<div class="article-summary-box-inner">
<span><p>Even with the luxury of having abundant data, multi-label classification is
widely known to be a challenging task to address. This work targets the problem
of multi-label meta-learning, where a model learns to predict multiple labels
within a query (e.g., an image) by just observing a few supporting examples. In
doing so, we first propose a benchmark for Few-Shot Learning (FSL) with
multiple labels per sample. Next, we discuss and extend several solutions
specifically designed to address the conventional and single-label FSL, to work
in the multi-label regime. Lastly, we introduce a neural module to estimate the
label count of a given sample by exploiting the relational inference. We will
show empirically the benefit of the label count module, the label propagation
algorithm, and the extensions of conventional FSL methods on three challenging
datasets, namely MS-COCO, iMaterialist, and Open MIC. Overall, our thorough
experiments suggest that the proposed label-propagation algorithm in
conjunction with the neural label count module (NLC) shall be considered as the
method of choice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Single Morphing Attack Detection using Feature Selection and Visualisation based on Mutual Information. (arXiv:2110.13552v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13552">
<div class="article-summary-box-inner">
<span><p>Face morphing attack detection is a challenging task. Automatic
classification methods and manual inspection are realised in automatic border
control gates to detect morphing attacks. Understanding how a machine learning
system can detect morphed faces and the most relevant facial areas is crucial.
Those relevant areas contain texture signals that allow us to separate the bona
fide and the morph images. Also, it helps in the manual examination to detect a
passport generated with morphed images. This paper explores features extracted
from intensity, shape, texture, and proposes a feature selection stage based on
the Mutual Information filter to select the most relevant and less redundant
features. This selection allows us to reduce the workload and know the exact
localisation of such areas to understand the morphing impact and create a
robust classifier. The best results were obtained for the method based on
Conditional Mutual Information and Shape features using only 500 features for
FERET images and 800 features for FRGCv2 images from 1,048 features available.
The eyes and nose are identified as the most critical areas to be analysed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Directional Self-supervised Learning for Risky Image Augmentations. (arXiv:2110.13555v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13555">
<div class="article-summary-box-inner">
<span><p>Only a few cherry-picked robust augmentation policies are beneficial to
standard self-supervised image representation learning, despite the large
augmentation family. In this paper, we propose a directional self-supervised
learning paradigm (DSSL), which is compatible with significantly more
augmentations. Specifically, we adapt risky augmentation policies after
standard views augmented by robust augmentations, to generate harder risky view
(RV). The risky view usually has a higher deviation from the original image
than the standard robust view (SV). Unlike previous methods equally pairing all
augmented views for symmetrical self-supervised training to maximize their
similarities, DSSL treats augmented views of the same instance as a partially
ordered set (SV$\leftrightarrow $SV, SV$\leftarrow$RV), and then equips
directional objective functions respecting to the derived relationships among
views. DSSL can be easily implemented with a few lines of Pseudocode and is
highly flexible to popular self-supervised learning frameworks, including
SimCLR, SimSiam, BYOL. The extensive experimental results on CIFAR and ImageNet
demonstrated that DSSL can stably improve these frameworks with compatibility
to a wider range of augmentations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Region Building Counting in Satellite Imagery using Counting Consistency. (arXiv:2110.13558v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13558">
<div class="article-summary-box-inner">
<span><p>Estimating the number of buildings in any geographical region is a vital
component of urban analysis, disaster management, and public policy decision.
Deep learning methods for building localization and counting in satellite
imagery, can serve as a viable and cheap alternative. However, these algorithms
suffer performance degradation when applied to the regions on which they have
not been trained. Current large datasets mostly cover the developed regions and
collecting such datasets for every region is a costly, time-consuming, and
difficult endeavor. In this paper, we propose an unsupervised domain adaptation
method for counting buildings where we use a labeled source domain (developed
regions) and adapt the trained model on an unlabeled target domain (developing
regions). We initially align distribution maps across domains by aligning the
output space distribution through adversarial loss. We then exploit counting
consistency constraints, within-image count consistency, and across-image count
consistency, to decrease the domain shift. Within-image consistency enforces
that building count in the whole image should be greater than or equal to count
in any of its sub-image. Across-image consistency constraint enforces that if
an image contains considerably more buildings than the other image, then their
sub-images shall also have the same order. These two constraints encourage the
behavior to be consistent across and within the images, regardless of the
scale. To evaluate the performance of our proposed approach, we collected and
annotated a large-scale dataset consisting of challenging South Asian regions
having higher building densities and irregular structures as compared to
existing datasets. We perform extensive experiments to verify the efficacy of
our approach and report improvements of approximately 7% to 20% over the
competitive baseline methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Graph Representation of Person-specific Cognitive Processes from Audio-visual Behaviours for Automatic Personality Recognition. (arXiv:2110.13570v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13570">
<div class="article-summary-box-inner">
<span><p>This approach builds on two following findings in cognitive science: (i)
human cognition partially determines expressed behaviour and is directly linked
to true personality traits; and (ii) in dyadic interactions individuals'
nonverbal behaviours are influenced by their conversational partner behaviours.
In this context, we hypothesise that during a dyadic interaction, a target
subject's facial reactions are driven by two main factors, i.e. their internal
(person-specific) cognitive process, and the externalised nonverbal behaviours
of their conversational partner. Consequently, we propose to represent the
target subjects (defined as the listener) person-specific cognition in the form
of a person-specific CNN architecture that has unique architectural parameters
and depth, which takes audio-visual non-verbal cues displayed by the
conversational partner (defined as the speaker) as input, and is able to
reproduce the target subject's facial reactions. Each person-specific CNN is
explored by the Neural Architecture Search (NAS) and a novel adaptive loss
function, which is then represented as a graph representation for recognising
the target subject's true personality. Experimental results not only show that
the produced graph representations are well associated with target subjects'
personality traits in both human-human and human-machine interaction scenarios,
and outperform the existing approaches with significant advantages, but also
demonstrate that the proposed novel strategies such as adaptive loss, and the
end-to-end vertices/edges feature learning, help the proposed approach in
learning more reliable personality representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emotion recognition in talking-face videos using persistent entropy and neural networks. (arXiv:2110.13571v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13571">
<div class="article-summary-box-inner">
<span><p>The automatic recognition of a person's emotional state has become a very
active research field that involves scientists specialized in different areas
such as artificial intelligence, computer vision or psychology, among others.
Our main objective in this work is to develop a novel approach, using
persistent entropy and neural networks as main tools, to recognise and classify
emotions from talking-face videos. Specifically, we combine audio-signal and
image-sequence information to compute a topology signature(a 9-dimensional
vector) for each video. We prove that small changes in the video produce small
changes in the signature. These topological signatures are used to feed a
neural network to distinguish between the following emotions: neutral, calm,
happy, sad, angry, fearful, disgust, and surprised. The results reached are
promising and competitive, beating the performance reached in other
state-of-the-art works found in the literature.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incremental Learning for Animal Pose Estimation using RBF k-DPP. (arXiv:2110.13598v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13598">
<div class="article-summary-box-inner">
<span><p>Pose estimation is the task of locating keypoints for an object of interest
in an image. Animal Pose estimation is more challenging than estimating human
pose due to high inter and intra class variability in animals. Existing works
solve this problem for a fixed set of predefined animal categories. Models
trained on such sets usually do not work well with new animal categories.
Retraining the model on new categories makes the model overfit and leads to
catastrophic forgetting. Thus, in this work, we propose a novel problem of
"Incremental Learning for Animal Pose Estimation". Our method uses an exemplar
memory, sampled using Determinantal Point Processes (DPP) to continually adapt
to new animal categories without forgetting the old ones. We further propose a
new variant of k-DPP that uses RBF kernel (termed as "RBF k-DPP") which gives
more gain in performance over traditional k-DPP. Due to memory constraints, the
limited number of exemplars along with new class data can lead to class
imbalance. We mitigate it by performing image warping as an augmentation
technique. This helps in crafting diverse poses, which reduces overfitting and
yields further improvement in performance. The efficacy of our proposed
approach is demonstrated via extensive experiments and ablations where we
obtain significant improvements over state-of-the-art baseline methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dendritic Self-Organizing Maps for Continual Learning. (arXiv:2110.13611v1 [cs.NE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13611">
<div class="article-summary-box-inner">
<span><p>Current deep learning architectures show remarkable performance when trained
in large-scale, controlled datasets. However, the predictive ability of these
architectures significantly decreases when learning new classes incrementally.
This is due to their inclination to forget the knowledge acquired from
previously seen data, a phenomenon termed catastrophic-forgetting. On the other
hand, Self-Organizing Maps (SOMs) can model the input space utilizing
constrained k-means and thus maintain past knowledge. Here, we propose a novel
algorithm inspired by biological neurons, termed Dendritic-Self-Organizing Map
(DendSOM). DendSOM consists of a single layer of SOMs, which extract patterns
from specific regions of the input space accompanied by a set of hit matrices,
one per SOM, which estimate the association between units and labels. The
best-matching unit of an input pattern is selected using the maximum cosine
similarity rule, while the point-wise mutual information is employed for class
inference. DendSOM performs unsupervised feature extraction as it does not use
labels for targeted updating of the weights. It outperforms classical SOMs and
several state-of-the-art continual learning algorithms on benchmark datasets,
such as the Split-MNIST and Split-CIFAR-10. We propose that the incorporation
of neuronal properties in SOMs may help remedy catastrophic forgetting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bayesian Optimization and Deep Learning forsteering wheel angle prediction. (arXiv:2110.13629v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13629">
<div class="article-summary-box-inner">
<span><p>Automated driving systems (ADS) have undergone a significant improvement in
the last years. ADS and more precisely self-driving cars technologies will
change the way we perceive and know the world of transportation systems in
terms of user experience, mode choices and business models. The emerging field
of Deep Learning (DL) has been successfully applied for the development of
innovative ADS solutions. However, the attempt to single out the best deep
neural network architecture and tuning its hyperparameters are all expensive
processes, both in terms of time and computational resources. In this work,
Bayesian Optimization (BO) is used to optimize the hyperparameters of a
Spatiotemporal-Long Short Term Memory (ST-LSTM) network with the aim to obtain
an accurate model for the prediction of the steering angle in a ADS. BO was
able to identify, within a limited number of trials, a model -- namely
BOST-LSTM -- which resulted, on a public dataset, the most accurate when
compared to classical end-to-end driving models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Precision Diagnostic Framework of Renal Cell Carcinoma on Whole-Slide Images using Deep Learning. (arXiv:2110.13652v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13652">
<div class="article-summary-box-inner">
<span><p>Diagnostic pathology, which is the basis and gold standard of cancer
diagnosis, provides essential information on the prognosis of the disease and
vital evidence for clinical treatment. Tumor region detection, subtype and
grade classification are the fundamental diagnostic indicators for renal cell
carcinoma (RCC) in whole-slide images (WSIs). However, pathological diagnosis
is subjective, differences in observation and diagnosis between pathologists is
common in hospitals with inadequate diagnostic capacity. The main challenge for
developing deep learning based RCC diagnostic system is the lack of large-scale
datasets with precise annotations. In this work, we proposed a deep
learning-based framework for analyzing histopathological images of patients
with renal cell carcinoma, which has the potential to achieve pathologist-level
accuracy in diagnosis. A deep convolutional neural network (InceptionV3) was
trained on the high-quality annotated dataset of The Cancer Genome Atlas (TCGA)
whole-slide histopathological image for accurate tumor area detection,
classification of RCC subtypes, and ISUP grades classification of clear cell
carcinoma subtypes. These results suggest that our framework can help
pathologists in the detection of cancer region and classification of subtypes
and grades, which could be applied to any cancer type, providing auxiliary
diagnosis and promoting clinical consensus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">W-Net: A Two-Stage Convolutional Network for Nucleus Detection in Histopathology Image. (arXiv:2110.13670v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13670">
<div class="article-summary-box-inner">
<span><p>Pathological diagnosis is the gold standard for cancer diagnosis, but it is
labor-intensive, in which tasks such as cell detection, classification, and
counting are particularly prominent. A common solution for automating these
tasks is using nucleus segmentation technology. However, it is hard to train a
robust nucleus segmentation model, due to several challenging problems, the
nucleus adhesion, stacking, and excessive fusion with the background. Recently,
some researchers proposed a series of automatic nucleus segmentation methods
based on point annotation, which can significant improve the model performance.
Nevertheless, the point annotation needs to be marked by experienced
pathologists. In order to take advantage of segmentation methods based on point
annotation, further alleviate the manual workload, and make cancer diagnosis
more efficient and accurate, it is necessary to develop an automatic nucleus
detection algorithm, which can automatically and efficiently locate the
position of the nucleus in the pathological image and extract valuable
information for pathologists. In this paper, we propose a W-shaped network for
automatic nucleus detection. Different from the traditional U-Net based method,
mapping the original pathology image to the target mask directly, our proposed
method split the detection task into two sub-tasks. The first sub-task maps the
original pathology image to the binary mask, then the binary mask is mapped to
the density mask in the second sub-task. After the task is split, the task's
difficulty is significantly reduced, and the network's overall performance is
improved.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Alpha-IoU: A Family of Power Intersection over Union Losses for Bounding Box Regression. (arXiv:2110.13675v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13675">
<div class="article-summary-box-inner">
<span><p>Bounding box (bbox) regression is a fundamental task in computer vision. So
far, the most commonly used loss functions for bbox regression are the
Intersection over Union (IoU) loss and its variants. In this paper, we
generalize existing IoU-based losses to a new family of power IoU losses that
have a power IoU term and an additional power regularization term with a single
power parameter $\alpha$. We call this new family of losses the $\alpha$-IoU
losses and analyze properties such as order preservingness and loss/gradient
reweighting. Experiments on multiple object detection benchmarks and models
demonstrate that $\alpha$-IoU losses, 1) can surpass existing IoU-based losses
by a noticeable performance margin; 2) offer detectors more flexibility in
achieving different levels of bbox regression accuracy by modulating $\alpha$;
and 3) are more robust to small datasets and noisy bboxes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Personalized Diagnostic Generation Framework Based on Multi-source Heterogeneous Data. (arXiv:2110.13677v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13677">
<div class="article-summary-box-inner">
<span><p>Personalized diagnoses have not been possible due to sear amount of data
pathologists have to bear during the day-to-day routine. This lead to the
current generalized standards that are being continuously updated as new
findings are reported. It is noticeable that these effective standards are
developed based on a multi-source heterogeneous data, including whole-slide
images and pathology and clinical reports. In this study, we propose a
framework that combines pathological images and medical reports to generate a
personalized diagnosis result for individual patient. We use nuclei-level image
feature similarity and content-based deep learning method to search for a
personalized group of population with similar pathological characteristics,
extract structured prognostic information from descriptive pathology reports of
the similar patient population, and assign importance of different prognostic
factors to generate a personalized pathological diagnosis result. We use
multi-source heterogeneous data from TCGA (The Cancer Genome Atlas) database.
The result demonstrate that our framework matches the performance of
pathologists in the diagnosis of renal cell carcinoma. This framework is
designed to be generic, thus could be applied for other types of cancer. The
weights could provide insights to the known prognostic factors and further
guide more precise clinical treatment protocols.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BioIE: Biomedical Information Extraction with Multi-head Attention Enhanced Graph Convolutional Network. (arXiv:2110.13683v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13683">
<div class="article-summary-box-inner">
<span><p>Constructing large-scaled medical knowledge graphs can significantly boost
healthcare applications for medical surveillance, bring much attention from
recent research. An essential step in constructing large-scale MKG is
extracting information from medical reports. Recently, information extraction
techniques have been proposed and show promising performance in biomedical
information extraction. However, these methods only consider limited types of
entity and relation due to the noisy biomedical text data with complex entity
correlations. Thus, they fail to provide enough information for constructing
MKGs and restrict the downstream applications. To address this issue, we
propose Biomedical Information Extraction, a hybrid neural network to extract
relations from biomedical text and unstructured medical reports. Our model
utilizes a multi-head attention enhanced graph convolutional network to capture
the complex relations and context information while resisting the noise from
the data. We evaluate our model on two major biomedical relationship extraction
tasks, chemical-disease relation and chemical-protein interaction, and a
cross-hospital pan-cancer pathology report corpus. The results show that our
method achieves superior performance than baselines. Furthermore, we evaluate
the applicability of our method under a transfer learning setting and show that
BioIE achieves promising performance in processing medical text from different
formats and writing styles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Closer Look at Reference Learning for Fourier Phase Retrieval. (arXiv:2110.13688v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13688">
<div class="article-summary-box-inner">
<span><p>Reconstructing images from their Fourier magnitude measurements is a problem
that often arises in different research areas. This process is also referred to
as phase retrieval. In this work, we consider a modified version of the phase
retrieval problem, which allows for a reference image to be added onto the
image before the Fourier magnitudes are measured. We analyze an unrolled
Gerchberg-Saxton (GS) algorithm that can be used to learn a good reference
image from a dataset. Furthermore, we take a closer look at the learned
reference images and propose a simple and efficient heuristic to construct
reference images that, in some cases, yields reconstructions of comparable
quality as approaches that learn references. Our code is available at
https://github.com/tuelwer/reference-learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Horizon Detection Algorithm for Maritime Surveillance. (arXiv:2110.13694v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13694">
<div class="article-summary-box-inner">
<span><p>The horizon line is a valuable feature in the maritime environment as it has
a high persistence when compared to other features (e.g., shore corners,
waves). It is used in several applications, especially in maritime
surveillance. The task of horizon detection may be easy for humans, but it is
hard on computers due to the high change of color and texture on maritime
scenes. Moreover, the computational complexity is an important constraint to
take into account while developing the algorithm. In this paper, we propose a
new method that we expect to enhance the state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Addressing out-of-distribution label noise in webly-labelled data. (arXiv:2110.13699v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13699">
<div class="article-summary-box-inner">
<span><p>A recurring focus of the deep learning community is towards reducing the
labeling effort. Data gathering and annotation using a search engine is a
simple alternative to generating a fully human-annotated and human-gathered
dataset. Although web crawling is very time efficient, some of the retrieved
images are unavoidably noisy, i.e. incorrectly labeled. Designing robust
algorithms for training on noisy data gathered from the web is an important
research perspective that would render the building of datasets easier. In this
paper we conduct a study to understand the type of label noise to expect when
building a dataset using a search engine. We review the current limitations of
state-of-the-art methods for dealing with noisy labels for image classification
tasks in the case of web noise distribution. We propose a simple solution to
bridge the gap with a fully clean dataset using Dynamic Softening of
Out-of-distribution Samples (DSOS), which we design on corrupted versions of
the CIFAR-100 dataset, and compare against state-of-the-art algorithms on the
web noise perturbated MiniImageNet and Stanford datasets and on real label
noise datasets: WebVision 1.0 and Clothing1M. Our work is fully reproducible
https://git.io/JKGcj
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TNTC: two-stream network with transformer-based complementarity for gait-based emotion recognition. (arXiv:2110.13708v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13708">
<div class="article-summary-box-inner">
<span><p>Recognizing the human emotion automatically from visual characteristics plays
a vital role in many intelligent applications. Recently, gait-based emotion
recognition, especially gait skeletons-based characteristic, has attracted much
attention, while many available methods have been proposed gradually. The
popular pipeline is to first extract affective features from joint skeletons,
and then aggregate the skeleton joint and affective features as the feature
vector for classifying the emotion. However, the aggregation procedure of these
emerged methods might be rigid, resulting in insufficiently exploiting the
complementary relationship between skeleton joint and affective features.
Meanwhile, the long range dependencies in both spatial and temporal domains of
the gait sequence are scarcely considered. To address these issues, we propose
a novel two-stream network with transformer-based complementarity, termed as
TNTC. Skeleton joint and affective features are encoded into two individual
images as the inputs of two streams, respectively. A new transformer-based
complementarity module (TCM) is proposed to bridge the complementarity between
two streams hierarchically via capturing long range dependencies. Experimental
results demonstrate TNTC outperforms state-of-the-art methods on the latest
dataset in terms of accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">YOLO-ReT: Towards High Accuracy Real-time Object Detection on Edge GPUs. (arXiv:2110.13713v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13713">
<div class="article-summary-box-inner">
<span><p>Performance of object detection models has been growing rapidly on two major
fronts, model accuracy and efficiency. However, in order to map deep neural
network (DNN) based object detection models to edge devices, one typically
needs to compress such models significantly, thus compromising the model
accuracy. In this paper, we propose a novel edge GPU friendly module for
multi-scale feature interaction by exploiting missing combinatorial connections
between various feature scales in existing state-of-the-art methods.
Additionally, we propose a novel transfer learning backbone adoption inspired
by the changing translational information flow across various tasks, designed
to complement our feature interaction module and together improve both accuracy
as well as execution speed on various edge GPU devices available in the market.
For instance, YOLO-ReT with MobileNetV2x0.75 backbone runs real-time on Jetson
Nano, and achieves 68.75 mAP on Pascal VOC and 34.91 mAP on COCO, beating its
peers by 3.05 mAP and 0.91 mAP respectively, while executing faster by 3.05
FPS. Furthermore, introducing our multi-scale feature interaction module in
YOLOv4-tiny and YOLOv4-tiny (3l) improves their performance to 41.5 and 48.1
mAP respectively on COCO, outperforming the original versions by 1.3 and 0.9
mAP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-supervised dry herbage mass estimation using automatic data and synthetic images. (arXiv:2110.13719v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13719">
<div class="article-summary-box-inner">
<span><p>Monitoring species-specific dry herbage biomass is an important aspect of
pasture-based milk production systems. Being aware of the herbage biomass in
the field enables farmers to manage surpluses and deficits in herbage supply,
as well as using targeted nitrogen fertilization when necessary. Deep learning
for computer vision is a powerful tool in this context as it can accurately
estimate the dry biomass of a herbage parcel using images of the grass canopy
taken using a portable device. However, the performance of deep learning comes
at the cost of an extensive, and in this case destructive, data gathering
process. Since accurate species-specific biomass estimation is labor intensive
and destructive for the herbage parcel, we propose in this paper to study low
supervision approaches to dry biomass estimation using computer vision. Our
contributions include: a synthetic data generation algorithm to generate data
for a herbage height aware semantic segmentation task, an automatic process to
label data using semantic segmentation maps, and a robust regression network
trained to predict dry biomass using approximate biomass labels and a small
trusted dataset with gold standard labels. We design our approach on a herbage
mass estimation dataset collected in Ireland and also report state-of-the-art
results on the publicly released Grass-Clover biomass estimation dataset from
Denmark. Our code is available at https://git.io/J0L2a
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep DIC: Deep Learning-Based Digital Image Correlation for End-to-End Displacement and Strain Measurement. (arXiv:2110.13720v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13720">
<div class="article-summary-box-inner">
<span><p>Digital image correlation (DIC) has become an industry standard to retrieve
accurate displacement and strain measurement in tensile testing and other
material characterization. Though traditional DIC offers a high precision
estimation of deformation for general tensile testing cases, the prediction
becomes unstable at large deformation or when the speckle patterns start to
tear. In addition, traditional DIC requires a long computation time and often
produces a low spatial resolution output affected by filtering and speckle
pattern quality. To address these challenges, we propose a new deep
learning-based DIC approach -- Deep DIC, in which two convolutional neural
networks, DisplacementNet and StrainNet, are designed to work together for
end-to-end prediction of displacements and strains. DisplacementNet predicts
the displacement field and adaptively tracks the change of a region of
interest. StrainNet predicts the strain field directly from the image input
without relying on the displacement prediction, which significantly improves
the strain prediction accuracy. A new dataset generation method is proposed to
synthesize a realistic and comprehensive dataset including artificial speckle
patterns, randomly generated displacement and strain fields, and deformed
images based on the given deformation. Proposed Deep DIC is trained purely on a
synthetic dataset, but designed to perform both on simulated and experimental
data. Its performance is systematically evaluated and compared with commercial
DIC software. Deep DIC gives highly consistent and comparable predictions of
displacement and strain with those obtained from commercial DIC software, while
it outperforms commercial software with very robust strain prediction even with
large and localized deformation and varied pattern qualities.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DP-SSL: Towards Robust Semi-supervised Learning with A Few Labeled Samples. (arXiv:2110.13740v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13740">
<div class="article-summary-box-inner">
<span><p>The scarcity of labeled data is a critical obstacle to deep learning.
Semi-supervised learning (SSL) provides a promising way to leverage unlabeled
data by pseudo labels. However, when the size of labeled data is very small
(say a few labeled samples per class), SSL performs poorly and unstably,
possibly due to the low quality of learned pseudo labels. In this paper, we
propose a new SSL method called DP-SSL that adopts an innovative data
programming (DP) scheme to generate probabilistic labels for unlabeled data.
Different from existing DP methods that rely on human experts to provide
initial labeling functions (LFs), we develop a multiple-choice learning~(MCL)
based approach to automatically generate LFs from scratch in SSL style. With
the noisy labels produced by the LFs, we design a label model to resolve the
conflict and overlap among the noisy labels, and finally infer probabilistic
labels for unlabeled samples. Extensive experiments on four standard SSL
benchmarks show that DP-SSL can provide reliable labels for unlabeled data and
achieve better classification performance on test sets than existing SSL
methods, especially when only a small number of labeled samples are available.
Concretely, for CIFAR-10 with only 40 labeled samples, DP-SSL achieves 93.82%
annotation accuracy on unlabeled data and 93.46% classification accuracy on
test data, which are higher than the SOTA results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Multi-view Registration of Point Sets with Laplacian Mixture Model. (arXiv:2110.13744v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13744">
<div class="article-summary-box-inner">
<span><p>Point set registration is an essential step in many computer vision
applications, such as 3D reconstruction and SLAM. Although there exist many
registration algorithms for different purposes, however, this topic is still
challenging due to the increasing complexity of various real-world scenarios,
such as heavy noise and outlier contamination. In this paper, we propose a
novel probabilistic generative method to simultaneously align multiple point
sets based on the heavy-tailed Laplacian distribution. The proposed method
assumes each data point is generated by a Laplacian Mixture Model (LMM), where
its centers are determined by the corresponding points in other point sets.
Different from the previous Gaussian Mixture Model (GMM) based method, which
minimizes the quadratic distance between points and centers of Gaussian
probability density, LMM minimizes the sparsity-induced L1 distance, thereby it
is more robust against noise and outliers. We adopt Expectation-Maximization
(EM) framework to solve LMM parameters and rigid transformations. We
approximate the L1 optimization as a linear programming problem by exponential
mapping in Lie algebra, which can be effectively solved through the interior
point method. To improve efficiency, we also solve the L1 optimization by
Alternating Direction Multiplier Method (ADMM). We demonstrate the advantages
of our method by comparing it with representative state-of-the-art approaches
on benchmark challenging data sets, in terms of robustness and accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">H-NeRF: Neural Radiance Fields for Rendering and Temporal Reconstruction of Humans in Motion. (arXiv:2110.13746v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13746">
<div class="article-summary-box-inner">
<span><p>We present H-NeRF, neural radiance fields for rendering and temporal (4D)
reconstruction of a human in motion as captured by a sparse set of cameras or
even from a monocular video. Our NeRF-inspired approach combines ideas from
neural scene representation, novel-view synthesis, and implicit statistical
geometric human representations. H-NeRF allows to accurately synthesize images
of the observed subject under novel camera views and human poses. Instead of
learning a radiance field in empty space, we attach it to a structured implicit
human body model, represented using signed distance functions. This allows us
to robustly fuse information from sparse views and, at test time, to
extrapolate beyond the observed poses or views. Moreover, we apply geometric
constraints to co-learn the structure of the observed subject (including both
body and clothing) and to regularize the radiance field to geometrical
plausible solutions. Extensive experiments on multiple datasets demonstrate the
robustness and accuracy of our approach and its generalization capabilities
beyond the sparse training set of poses and views.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DPCOVID: Privacy-Preserving Federated Covid-19 Detection. (arXiv:2110.13760v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13760">
<div class="article-summary-box-inner">
<span><p>Coronavirus (COVID-19) has shown an unprecedented global crisis by the
detrimental effect on the global economy and health. The number of COVID-19
cases has been rapidly increasing, and there is no sign of stopping. It leads
to a severe shortage of test kits and accurate detection models. A recent study
demonstrated that the chest X-ray radiography outperformed laboratory testing
in COVID-19 detection. Therefore, using chest X-ray radiography analysis can
help to screen suspected COVID-19 cases at an early stage. Moreover, the
patient data is sensitive, and it must be protected to avoid revealing through
model updates and reconstruction from the malicious attacker. In this paper, we
present a privacy-preserving Federated Learning system for COVID-19 detection
based on chest X-ray images. First, a Federated Learning system is constructed
from chest X-ray images. The main idea is to build a decentralized model across
multiple hospitals without sharing data among hospitals. Second, we first show
that the accuracy of Federated Learning for COVID-19 identification reduces
significantly for Non-IID data. We then propose a strategy to improve model's
accuracy on Non-IID COVID-19 data by increasing the total number of clients,
parallelism (client fraction), and computation per client. Finally, we apply a
Differential Privacy Stochastic Gradient Descent (DP-SGD) to enhance the
preserving of patient data privacy for our Federated Learning model. A strategy
is also proposed to keep the robustness of Federated Learning to ensure the
security and accuracy of the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AugMax: Adversarial Composition of Random Augmentations for Robust Training. (arXiv:2110.13771v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13771">
<div class="article-summary-box-inner">
<span><p>Data augmentation is a simple yet effective way to improve the robustness of
deep neural networks (DNNs). Diversity and hardness are two complementary
dimensions of data augmentation to achieve robustness. For example, AugMix
explores random compositions of a diverse set of augmentations to enhance
broader coverage, while adversarial training generates adversarially hard
samples to spot the weakness. Motivated by this, we propose a data augmentation
framework, termed AugMax, to unify the two aspects of diversity and hardness.
AugMax first randomly samples multiple augmentation operators and then learns
an adversarial mixture of the selected operators. Being a stronger form of data
augmentation, AugMax leads to a significantly augmented input distribution
which makes model training more challenging. To solve this problem, we further
design a disentangled normalization module, termed DuBIN
(Dual-Batch-and-Instance Normalization), that disentangles the instance-wise
feature heterogeneity arising from AugMax. Experiments show that AugMax-DuBIN
leads to significantly improved out-of-distribution robustness, outperforming
prior arts by 3.03%, 3.49%, 1.82% and 0.71% on CIFAR10-C, CIFAR100-C, Tiny
ImageNet-C and ImageNet-C. Codes and pretrained models are available:
https://github.com/VITA-Group/AugMax.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pyramidal Blur Aware X-Corner Chessboard Detector. (arXiv:2110.13793v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13793">
<div class="article-summary-box-inner">
<span><p>With camera resolution ever increasing and the need to rapidly recalibrate
robotic platforms in less than ideal environments, there is a need for faster
and more robust chessboard fiducial marker detectors. A new chessboard detector
is proposed that is specifically designed for: high resolution images,
focus/motion blur, harsh lighting conditions, and background clutter. This is
accomplished using a new x-corner detector, where for the first time blur is
estimated and used in a novel way to enhance corner localization, edge
validation, and connectivity. Performance is measured and compared against
other libraries using a diverse set of images created by combining multiple
third party datasets and including new specially crafted scenarios designed to
stress the state-of-the-art. The proposed detector has the best F1- Score of
0.97, runs 1.9x faster than next fastest, and is a top performer for corner
accuracy, while being the only detector to have consistent good performance in
all scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting speaking persons in video. (arXiv:2110.13806v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13806">
<div class="article-summary-box-inner">
<span><p>We present a novel method for detecting speaking persons in video, by
extracting facial landmarks with a neural network and analysing these landmarks
statistically over time
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Segmentation for Urban-Scene Images. (arXiv:2110.13813v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13813">
<div class="article-summary-box-inner">
<span><p>Urban-scene Image segmentation is an important and trending topic in computer
vision with wide use cases like autonomous driving [1]. Starting with the
breakthrough work of Long et al. [2] that introduces Fully Convolutional
Networks (FCNs), the development of novel architectures and practical uses of
neural networks in semantic segmentation has been expedited in the recent 5
years. Aside from seeking solutions in general model design for information
shrinkage due to pooling, urban-scene image itself has intrinsic features like
positional patterns [3]. Our project seeks an advanced and integrated solution
that specifically targets urban-scene image semantic segmentation among the
most novel approaches in the current field. We re-implement the cutting edge
model DeepLabv3+ [4] with ResNet-101 [5] backbone as our strong baseline model.
Based upon DeepLabv3+, we incorporate HANet [3] to account for the vertical
spatial priors in urban-scene image tasks. To boost up model efficiency and
performance, we further explore the Atrous Spatial Pooling (ASP) layer in
DeepLabv3+ and infuse a computational efficient variation called "Waterfall"
Atrous Spatial Pooling (WASP) [6] architecture in our model. We find that our
two-step integrated model improves the mean Intersection-Over-Union (mIoU)
score gradually from the baseline model. In particular, HANet successfully
identifies height-driven patterns and improves per-class IoU of common class
labels in urban scenario like fence and bus. We also demonstrate the
improvement of model efficiency with help of WASP in terms of computational
times during training and parameter reduction from the original ASPP module.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CloudFindr: A Deep Learning Cloud Artifact Masker for Satellite DEM Data. (arXiv:2110.13819v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13819">
<div class="article-summary-box-inner">
<span><p>Artifact removal is an integral component of cinematic scientific
visualization, and is especially challenging with big datasets in which
artifacts are difficult to define. In this paper, we describe a method for
creating cloud artifact masks which can be used to remove artifacts from
satellite imagery using a combination of traditional image processing together
with deep learning based on U-Net. Compared to previous methods, our approach
does not require multi-channel spectral imagery but performs successfully on
single-channel Digital Elevation Models (DEMs). DEMs are a representation of
the topography of the Earth and have a variety applications including planetary
science, geology, flood modeling, and city planning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-time division-of-focal-plane polarization imaging system with progressive networks. (arXiv:2110.13823v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13823">
<div class="article-summary-box-inner">
<span><p>Division-of-focal-plane (DoFP) polarization imaging technical recently has
been applied in many fields. However, the images captured by such sensors
cannot be used directly because they suffer from instantaneous field-of-view
errors and low resolution problem. This paper builds a fast DoFP demosaicing
system with proposed progressive polarization demosaicing convolutional neural
network (PPDN), which is specifically designed for edge-side GPU devices like
Navidia Jetson TX2. The proposed network consists of two parts: reconstruction
stage and refining stage. The former recovers four polarization channels from a
single DoFP image. The latter fine-tune the four channels to obtain more
accurate polarization information. PPDN can be implemented in another version:
PPDN-L (large), for the platforms of high computing resources. Experiments show
that PPDN can compete with the best existing methods with fewer parameters and
faster inference speed and meet the real-time demands of imaging system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Light-weight Interpretable CompositionalNetwork for Nuclei Detection and Weakly-supervised Segmentation. (arXiv:2110.13846v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13846">
<div class="article-summary-box-inner">
<span><p>The field of computational pathology has witnessed great advancements since
deep neural networks have been widely applied. These deep neural networks
usually require large numbers of annotated data to train vast parameters.
However, it takes significant effort to annotate a large histopathology
dataset. We propose to build a data-efficient model, which only requires
partial annotation, specifically on isolated nucleus, rather than on the whole
slide image. It exploits shallow features as its backbone and is light-weight,
therefore a small number of data is sufficient for training. What's more, it is
a generative compositional model, which enjoys interpretability in its
prediction. The proposed method could be an alternative solution for the
data-hungry problem of deep learning methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Defensive Tensorization. (arXiv:2110.13859v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13859">
<div class="article-summary-box-inner">
<span><p>We propose defensive tensorization, an adversarial defence technique that
leverages a latent high-order factorization of the network. The layers of a
network are first expressed as factorized tensor layers. Tensor dropout is then
applied in the latent subspace, therefore resulting in dense reconstructed
weights, without the sparsity or perturbations typically induced by the
randomization.Our approach can be readily integrated with any arbitrary neural
architecture and combined with techniques like adversarial training. We
empirically demonstrate the effectiveness of our approach on standard image
classification benchmarks. We validate the versatility of our approach across
domains and low-precision architectures by considering an audio classification
task and binary networks. In all cases, we demonstrate improved performance
compared to prior works.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FL-WBC: Enhancing Robustness against Model Poisoning Attacks in Federated Learning from a Client Perspective. (arXiv:2110.13864v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13864">
<div class="article-summary-box-inner">
<span><p>Federated learning (FL) is a popular distributed learning framework that
trains a global model through iterative communications between a central server
and edge devices. Recent works have demonstrated that FL is vulnerable to model
poisoning attacks. Several server-based defense approaches (e.g. robust
aggregation), have been proposed to mitigate such attacks. However, we
empirically show that under extremely strong attacks, these defensive methods
fail to guarantee the robustness of FL. More importantly, we observe that as
long as the global model is polluted, the impact of attacks on the global model
will remain in subsequent rounds even if there are no subsequent attacks. In
this work, we propose a client-based defense, named White Blood Cell for
Federated Learning (FL-WBC), which can mitigate model poisoning attacks that
have already polluted the global model. The key idea of FL-WBC is to identify
the parameter space where long-lasting attack effect on parameters resides and
perturb that space during local training. Furthermore, we derive a certified
robustness guarantee against model poisoning attacks and a convergence
guarantee to FedAvg after applying our FL-WBC. We conduct experiments on
FasionMNIST and CIFAR10 to evaluate the defense against state-of-the-art model
poisoning attacks. The results demonstrate that our method can effectively
mitigate model poisoning attack impact on the global model within 5
communication rounds with nearly no accuracy drop under both IID and Non-IID
settings. Our defense is also complementary to existing server-based robust
aggregation approaches and can further improve the robustness of FL under
extremely strong attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HR-RCNN: Hierarchical Relational Reasoning for Object Detection. (arXiv:2110.13892v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13892">
<div class="article-summary-box-inner">
<span><p>Incorporating relational reasoning in neural networks for object recognition
remains an open problem. Although many attempts have been made for relational
reasoning, they generally only consider a single type of relationship. For
example, pixel relations through self-attention (e.g., non-local networks),
scale relations through feature fusion (e.g., feature pyramid networks), or
object relations through graph convolutions (e.g., reasoning-RCNN). Little
attention has been given to more generalized frameworks that can reason across
these relationships. In this paper, we propose a hierarchical relational
reasoning framework (HR-RCNN) for object detection, which utilizes a novel
graph attention module (GAM). This GAM is a concise module that enables
reasoning across heterogeneous nodes by operating on the graph edges directly.
Leveraging heterogeneous relationships, our HR-RCNN shows great improvement on
COCO dataset, for both object detection and instance segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeRV: Neural Representations for Videos. (arXiv:2110.13903v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.13903">
<div class="article-summary-box-inner">
<span><p>We propose a novel neural representation for videos (NeRV) which encodes
videos in neural networks. Unlike conventional representations that treat
videos as frame sequences, we represent videos as neural networks taking frame
index as input. Given a frame index, NeRV outputs the corresponding RGB image.
Video encoding in NeRV is simply fitting a neural network to video frames and
decoding process is a simple feedforward operation. As an image-wise implicit
representation, NeRV output the whole image and shows great efficiency compared
to pixel-wise implicit representation, improving the encoding speed by 25x to
70x, the decoding speed by 38x to 132x, while achieving better video quality.
With such a representation, we can treat videos as neural networks, simplifying
several video-related tasks. For example, conventional video compression
methods are restricted by a long and complex pipeline, specifically designed
for the task. In contrast, with NeRV, we can use any neural network compression
method as a proxy for video compression, and achieve comparable performance to
traditional frame-based video compression approaches (H.264, HEVC \etc).
Besides compression, we demonstrate the generalization of NeRV for video
denoising. The source code and pre-trained model can be found at
https://github.com/haochen-rye/NeRV.git.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Overinterpretation reveals image classification model pathologies. (arXiv:2003.08907v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.08907">
<div class="article-summary-box-inner">
<span><p>Image classifiers are typically scored on their test set accuracy, but high
accuracy can mask a subtle type of model failure. We find that high scoring
convolutional neural networks (CNNs) on popular benchmarks exhibit troubling
pathologies that allow them to display high accuracy even in the absence of
semantically salient features. When a model provides a high-confidence decision
without salient supporting input features, we say the classifier has
overinterpreted its input, finding too much class-evidence in patterns that
appear nonsensical to humans. Here, we demonstrate that neural networks trained
on CIFAR-10 and ImageNet suffer from overinterpretation, and we find models on
CIFAR-10 make confident predictions even when 95% of input images are masked
and humans cannot discern salient features in the remaining pixel-subsets. We
introduce Batched Gradient SIS, a new method for discovering sufficient input
subsets for complex datasets, and use this method to show the sufficiency of
border pixels in ImageNet for training and testing. Although these patterns
portend potential model fragility in real-world deployment, they are in fact
valid statistical patterns of the benchmark that alone suffice to attain high
test accuracy. Unlike adversarial examples, overinterpretation relies upon
unmodified image pixels. We find ensembling and input dropout can each help
mitigate overinterpretation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">360-Degree Gaze Estimation in the Wild Using Multiple Zoom Scales. (arXiv:2009.06924v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06924">
<div class="article-summary-box-inner">
<span><p>Gaze estimation involves predicting where the person is looking at within an
image or video. Technically, the gaze information can be inferred from two
different magnification levels: face orientation and eye orientation. The
inference is not always feasible for gaze estimation in the wild, given the
lack of clear eye patches in conditions like extreme left/right gazes or
occlusions. In this work, we design a model that mimics humans' ability to
estimate the gaze by aggregating from focused looks, each at a different
magnification level of the face area. The model avoids the need to extract
clear eye patches and at the same time addresses another important issue of
face-scale variation for gaze estimation in the wild. We further extend the
model to handle the challenging task of 360-degree gaze estimation by encoding
the backward gazes in the polar representation along with a robust averaging
scheme. Experiment results on the ETH-XGaze dataset, which does not contain
scale-varying faces, demonstrate the model's effectiveness to assimilate
information from multiple scales. For other benchmark datasets with many
scale-varying faces (Gaze360 and RT-GENE), the proposed model achieves
state-of-the-art performance for gaze estimation when using either images or
videos. Our code and pretrained models can be accessed at
https://github.com/ashesh-0/MultiZoomGaze.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Geography-Aware Self-Supervised Learning. (arXiv:2011.09980v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09980">
<div class="article-summary-box-inner">
<span><p>Contrastive learning methods have significantly narrowed the gap between
supervised and unsupervised learning on computer vision tasks. In this paper,
we explore their application to geo-located datasets, e.g. remote sensing,
where unlabeled data is often abundant but labeled data is scarce. We first
show that due to their different characteristics, a non-trivial gap persists
between contrastive and supervised learning on standard benchmarks. To close
the gap, we propose novel training methods that exploit the spatio-temporal
structure of remote sensing data. We leverage spatially aligned images over
time to construct temporal positive pairs in contrastive learning and
geo-location to design pre-text tasks. Our experiments show that our proposed
method closes the gap between contrastive and supervised learning on image
classification, object detection and semantic segmentation for remote sensing.
Moreover, we demonstrate that the proposed method can also be applied to
geo-tagged ImageNet images, improving downstream performance on various tasks.
Project Webpage can be found at this link geography-aware-ssl.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Robust Partially Supervised Multi-Structure Medical Image Segmentation on Small-Scale Data. (arXiv:2011.14164v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14164">
<div class="article-summary-box-inner">
<span><p>The data-driven nature of deep learning (DL) models for semantic segmentation
requires a large number of pixel-level annotations. However, large-scale and
fully labeled medical datasets are often unavailable for practical tasks.
Recently, partially supervised methods have been proposed to utilize images
with incomplete labels in the medical domain. To bridge the methodological gaps
in partially supervised learning (PSL) under data scarcity, we propose Vicinal
Labels Under Uncertainty (VLUU), a simple yet efficient framework utilizing the
human structure similarity for partially supervised medical image segmentation.
Motivated by multi-task learning and vicinal risk minimization, VLUU transforms
the partially supervised problem into a fully supervised problem by generating
vicinal labels. We systematically evaluate VLUU under the challenges of
small-scale data, dataset shift, and class imbalance on two commonly used
segmentation datasets for the tasks of chest organ segmentation and optic
disc-and-cup segmentation. The experimental results show that VLUU can
consistently outperform previous partially supervised models in these settings.
Our research suggests a new research direction in label-efficient deep learning
with partial supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Capturing implicit hierarchical structure in 3D biomedical images with self-supervised hyperbolic representations. (arXiv:2012.01644v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01644">
<div class="article-summary-box-inner">
<span><p>We consider the task of representation learning for unsupervised segmentation
of 3D voxel-grid biomedical images. We show that models that capture implicit
hierarchical relationships between subvolumes are better suited for this task.
To that end, we consider encoder-decoder architectures with a hyperbolic latent
space, to explicitly capture hierarchical relationships present in subvolumes
of the data. We propose utilizing a 3D hyperbolic variational autoencoder with
a novel gyroplane convolutional layer to map from the embedding space back to
3D images. To capture these relationships, we introduce an essential
self-supervised loss -- in addition to the standard VAE loss -- which infers
approximate hierarchies and encourages implicitly related subvolumes to be
mapped closer in the embedding space. We present experiments on both synthetic
data and biomedical data to validate our hypothesis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention over learned object embeddings enables complex visual reasoning. (arXiv:2012.08508v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08508">
<div class="article-summary-box-inner">
<span><p>Neural networks have achieved success in a wide array of perceptual tasks but
often fail at tasks involving both perception and higher-level reasoning. On
these more challenging tasks, bespoke approaches (such as modular symbolic
components, independent dynamics models or semantic parsers) targeted towards
that specific type of task have typically performed better. The downside to
these targeted approaches, however, is that they can be more brittle than
general-purpose neural networks, requiring significant modification or even
redesign according to the particular task at hand. Here, we propose a more
general neural-network-based approach to dynamic visual reasoning problems that
obtains state-of-the-art performance on three different domains, in each case
outperforming bespoke modular approaches tailored specifically to the task. Our
method relies on learned object-centric representations, self-attention and
self-supervised dynamics learning, and all three elements together are required
for strong performance to emerge. The success of this combination suggests that
there may be no need to trade off flexibility for performance on problems
involving spatio-temporal or causal-style reasoning. With the right soft biases
and learning objectives in a neural network we may be able to attain the best
of both worlds.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AQuA: Analytical Quality Assessment for Optimizing Video Analytics Systems. (arXiv:2101.09752v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09752">
<div class="article-summary-box-inner">
<span><p>Millions of cameras at edge are being deployed to power a variety of
different deep learning applications. However, the frames captured by these
cameras are not always pristine - they can be distorted due to lighting issues,
sensor noise, compression etc. Such distortions not only deteriorate visual
quality, they impact the accuracy of deep learning applications that process
such video streams. In this work, we introduce AQuA, to protect application
accuracy against such distorted frames by scoring the level of distortion in
the frames. It takes into account the analytical quality of frames, not the
visual quality, by learning a novel metric, classifier opinion score, and uses
a lightweight, CNN-based, object-independent feature extractor. AQuA accurately
scores distortion levels of frames and generalizes to multiple different deep
learning applications. When used for filtering poor quality frames at edge, it
reduces high-confidence errors for analytics applications by 17%. Through
filtering, and due to its low overhead (14ms), AQuA can also reduce computation
time and average bandwidth usage by 25%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A-NeRF: Articulated Neural Radiance Fields for Learning Human Shape, Appearance, and Pose. (arXiv:2102.06199v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06199">
<div class="article-summary-box-inner">
<span><p>While deep learning reshaped the classical motion capture pipeline with
feed-forward networks, generative models are required to recover fine alignment
via iterative refinement. Unfortunately, the existing models are usually
hand-crafted or learned in controlled conditions, only applicable to limited
domains. We propose a method to learn a generative neural body model from
unlabelled monocular videos by extending Neural Radiance Fields (NeRFs). We
equip them with a skeleton to apply to time-varying and articulated motion. A
key insight is that implicit models require the inverse of the forward
kinematics used in explicit surface models. Our reparameterization defines
spatial latent variables relative to the pose of body parts and thereby
overcomes ill-posed inverse operations with an overparameterization. This
enables learning volumetric body shape and appearance from scratch while
jointly refining the articulated pose; all without ground truth labels for
appearance, pose, or 3D shape on the input videos. When used for
novel-view-synthesis and motion capture, our neural model improves accuracy on
diverse datasets. Project website: https://lemonatsu.github.io/anerf/ .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust Lane Detection via Expanded Self Attention. (arXiv:2102.07037v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07037">
<div class="article-summary-box-inner">
<span><p>The image-based lane detection algorithm is one of the key technologies in
autonomous vehicles. Modern deep learning methods achieve high performance in
lane detection, but it is still difficult to accurately detect lanes in
challenging situations such as congested roads and extreme lighting conditions.
To be robust on these challenging situations, it is important to extract global
contextual information even from limited visual cues. In this paper, we propose
a simple but powerful self-attention mechanism optimized for lane detection
called the Expanded Self Attention (ESA) module. Inspired by the simple
geometric structure of lanes, the proposed method predicts the confidence of a
lane along the vertical and horizontal directions in an image. The prediction
of the confidence enables estimating occluded locations by extracting global
contextual information. ESA module can be easily implemented and applied to any
encoder-decoder-based model without increasing the inference time. The
performance of our method is evaluated on three popular lane detection
benchmarks (TuSimple, CULane and BDD100K). We achieve state-of-the-art
performance in CULane and BDD100K and distinct improvement on TuSimple dataset.
The experimental results show that our approach is robust to occlusion and
extreme lighting conditions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SWAD: Domain Generalization by Seeking Flat Minima. (arXiv:2102.08604v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08604">
<div class="article-summary-box-inner">
<span><p>Domain generalization (DG) methods aim to achieve generalizability to an
unseen target domain by using only training data from the source domains.
Although a variety of DG methods have been proposed, a recent study shows that
under a fair evaluation protocol, called DomainBed, the simple empirical risk
minimization (ERM) approach works comparable to or even outperforms previous
methods. Unfortunately, simply solving ERM on a complex, non-convex loss
function can easily lead to sub-optimal generalizability by seeking sharp
minima. In this paper, we theoretically show that finding flat minima results
in a smaller domain generalization gap. We also propose a simple yet effective
method, named Stochastic Weight Averaging Densely (SWAD), to find flat minima.
SWAD finds flatter minima and suffers less from overfitting than does the
vanilla SWA by a dense and overfit-aware stochastic weight sampling strategy.
SWAD shows state-of-the-art performances on five DG benchmarks, namely PACS,
VLCS, OfficeHome, TerraIncognita, and DomainNet, with consistent and large
margins of +1.6% averagely on out-of-domain accuracy. We also compare SWAD with
conventional generalization methods, such as data augmentation and consistency
regularization methods, to verify that the remarkable performance improvements
are originated from by seeking flat minima, not from better in-domain
generalizability. Last but not least, SWAD is readily adaptable to existing DG
methods without modification; the combination of SWAD and an existing DG method
further improves DG performances. Source code is available at
https://github.com/khanrc/swad.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Input Gradients Highlight Discriminative Features?. (arXiv:2102.12781v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12781">
<div class="article-summary-box-inner">
<span><p>Post-hoc gradient-based interpretability methods [Simonyan et al., 2013,
Smilkov et al., 2017] that provide instance-specific explanations of model
predictions are often based on assumption (A): magnitude of input gradients --
gradients of logits with respect to input -- noisily highlight discriminative
task-relevant features. In this work, we test the validity of assumption (A)
using a three-pronged approach. First, we develop an evaluation framework,
DiffROAR, to test assumption (A) on four image classification benchmarks. Our
results suggest that (i) input gradients of standard models (i.e., trained on
original data) may grossly violate (A), whereas (ii) input gradients of
adversarially robust models satisfy (A). Second, we introduce BlockMNIST, an
MNIST-based semi-real dataset, that by design encodes a priori knowledge of
discriminative features. Our analysis on BlockMNIST leverages this information
to validate as well as characterize differences between input gradient
attributions of standard and robust models. Finally, we theoretically prove
that our empirical findings hold on a simplified version of the BlockMNIST
dataset. Specifically, we prove that input gradients of standard
one-hidden-layer MLPs trained on this dataset do not highlight
instance-specific signal coordinates, thus grossly violating assumption (A).
Our findings motivate the need to formalize and test common assumptions in
interpretability in a falsifiable manner [Leavitt and Morcos, 2020]. We believe
that the DiffROAR evaluation framework and BlockMNIST-based datasets can serve
as sanity checks to audit instance-specific interpretability methods; code and
data available at https://github.com/harshays/inputgradients.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer in Transformer. (arXiv:2103.00112v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00112">
<div class="article-summary-box-inner">
<span><p>Transformer is a new kind of neural architecture which encodes the input data
as powerful features via the attention mechanism. Basically, the visual
transformers first divide the input images into several local patches and then
calculate both representations and their relationship. Since natural images are
of high complexity with abundant detail and color information, the granularity
of the patch dividing is not fine enough for excavating features of objects in
different scales and locations. In this paper, we point out that the attention
inside these local patches are also essential for building visual transformers
with high performance and we explore a new architecture, namely, Transformer iN
Transformer (TNT). Specifically, we regard the local patches (e.g.,
16$\times$16) as "visual sentences" and present to further divide them into
smaller patches (e.g., 4$\times$4) as "visual words". The attention of each
word will be calculated with other words in the given visual sentence with
negligible computational costs. Features of both words and sentences will be
aggregated to enhance the representation ability. Experiments on several
benchmarks demonstrate the effectiveness of the proposed TNT architecture,
e.g., we achieve an 81.5% top-1 accuracy on the ImageNet, which is about 1.7%
higher than that of the state-of-the-art visual transformer with similar
computational cost. The PyTorch code is available at
https://github.com/huawei-noah/CV-Backbones, and the MindSpore code is
available at https://gitee.com/mindspore/models/tree/master/research/cv/TNT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scalable Scene Flow from Point Clouds in the Real World. (arXiv:2103.01306v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01306">
<div class="article-summary-box-inner">
<span><p>Autonomous vehicles operate in highly dynamic environments necessitating an
accurate assessment of which aspects of a scene are moving and where they are
moving to. A popular approach to 3D motion estimation, termed scene flow, is to
employ 3D point cloud data from consecutive LiDAR scans, although such
approaches have been limited by the small size of real-world, annotated LiDAR
data. In this work, we introduce a new large-scale dataset for scene flow
estimation derived from corresponding tracked 3D objects, which is
$\sim$1,000$\times$ larger than previous real-world datasets in terms of the
number of annotated frames. We demonstrate how previous works were bounded
based on the amount of real LiDAR data available, suggesting that larger
datasets are required to achieve state-of-the-art predictive performance.
Furthermore, we show how previous heuristics for operating on point clouds such
as down-sampling heavily degrade performance, motivating a new class of models
that are tractable on the full point cloud. To address this issue, we introduce
the FastFlow3D architecture which provides real time inference on the full
point cloud. Additionally, we design human-interpretable metrics that better
capture real world aspects by accounting for ego-motion and providing
breakdowns per object type. We hope that this dataset may provide new
opportunities for developing real world scene flow systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cut-Thumbnail: A Novel Data Augmentation for Convolutional Neural Network. (arXiv:2103.05342v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05342">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel data augmentation strategy named
Cut-Thumbnail, that aims to improve the shape bias of the network. We reduce an
image to a certain size and replace the random region of the original image
with the reduced image. The generated image not only retains most of the
original image information but also has global information in the reduced
image. We call the reduced image as thumbnail. Furthermore, we find that the
idea of thumbnail can be perfectly integrated with Mixed Sample Data
Augmentation, so we put one image's thumbnail on another image while the ground
truth labels are also mixed, making great achievements on various computer
vision tasks. Extensive experiments show that Cut-Thumbnail works better than
state-of-the-art augmentation strategies across classification, fine-grained
image classification, and object detection. On ImageNet classification,
ResNet-50 architecture with our method achieves 79.21\% accuracy, which is more
than 2.8\% improvement on the baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating and Evaluating Explanations of Attended and Error-Inducing Input Regions for VQA Models. (arXiv:2103.14712v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14712">
<div class="article-summary-box-inner">
<span><p>Attention maps, a popular heatmap-based explanation method for Visual
Question Answering (VQA), are supposed to help users understand the model by
highlighting portions of the image/question used by the model to infer answers.
However, we see that users are often misled by current attention map
visualizations that point to relevant regions despite the model producing an
incorrect answer. Hence, we propose Error Maps that clarify the error by
highlighting image regions where the model is prone to err. Error maps can
indicate when a correctly attended region may be processed incorrectly leading
to an incorrect answer, and hence, improve users' understanding of those cases.
To evaluate our new explanations, we further introduce a metric that simulates
users' interpretation of explanations to evaluate their potential helpfulness
to understand model correctness. We finally conduct user studies to see that
our new explanations help users understand model correctness better than
baselines by an expected 30\% and that our proxy helpfulness metrics correlate
strongly ($\rho&gt;0.97$) with how well users can predict model correctness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RTIC: Residual Learning for Text and Image Composition using Graph Convolutional Network. (arXiv:2104.03015v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03015">
<div class="article-summary-box-inner">
<span><p>In this paper, we study the compositional learning of images and texts for
image retrieval. The query is given in the form of an image and text that
describes the desired modifications to the image; the goal is to retrieve the
target image that satisfies the given modifications and resembles the query by
composing information in both the text and image modalities. To remedy this, we
propose a novel architecture designed for the image-text composition task and
show that the proposed structure can effectively encode the differences between
the source and target images conditioned on the text. Furthermore, we introduce
a new joint training technique based on the graph convolutional network that is
generally applicable for any existing composition methods in a plug-and-play
manner. We found that the proposed technique consistently improves performance
and achieves state-of-the-art scores on various benchmarks. To avoid misleading
experimental results caused by trivial training hyper-parameters, we reproduce
all individual baselines and train models with a unified training environment.
We expect this approach to suppress undesirable effects from irrelevant
components and emphasize the image-text composition module's ability. Also, we
achieve the state-of-the-art score without restricting the training
environment, which implies the superiority of our method considering the gains
from hyper-parameter tuning. The code, including all the baseline methods, are
released https://github.com/nashory/rtic-gcn-pytorch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Enabling Meta-Learning from Target Models. (arXiv:2104.03736v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03736">
<div class="article-summary-box-inner">
<span><p>Meta-learning can extract an inductive bias from previous learning experience
and assist the training of new tasks. It is often realized through optimizing a
meta-model with the evaluation loss of task-specific solvers. Most existing
algorithms sample non-overlapping $\mathit{support}$ sets and $\mathit{query}$
sets to train and evaluate the solvers respectively due to simplicity
($\mathcal{S}$/$\mathcal{Q}$ protocol). Different from
$\mathcal{S}$/$\mathcal{Q}$ protocol, we can also evaluate a task-specific
solver by comparing it to a target model $\mathcal{T}$, which is the optimal
model for this task or a model that behaves well enough on this task
($\mathcal{S}$/$\mathcal{T}$ protocol). Although being short of research,
$\mathcal{S}$/$\mathcal{T}$ protocol has unique advantages such as offering
more informative supervision, but it is computationally expensive. This paper
looks into this special evaluation method and takes a step towards putting it
into practice. We find that with a small ratio of tasks armed with target
models, classic meta-learning algorithms can be improved a lot without
consuming many resources. We empirically verify the effectiveness of
$\mathcal{S}$/$\mathcal{T}$ protocol in a typical application of meta-learning,
$\mathit{i.e.}$, few-shot learning. In detail, after constructing target models
by fine-tuning the pre-trained network on those hard tasks, we match the
task-specific solvers and target models via knowledge distillation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RaidaR: A Rich Annotated Image Dataset of Rainy Street Scenes. (arXiv:2104.04606v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04606">
<div class="article-summary-box-inner">
<span><p>We introduce RaidaR, a rich annotated image dataset of rainy street scenes,
to support autonomous driving research. The new dataset contains the largest
number of rainy images (58,542) to date, 5,000 of which provide semantic
segmentations and 3,658 provide object instance segmentations. The RaidaR
images cover a wide range of realistic rain-induced artifacts, including fog,
droplets, and road reflections, which can effectively augment existing street
scene datasets to improve data-driven machine perception during rainy weather.
To facilitate efficient annotation of a large volume of images, we develop a
semi-automatic scheme combining manual segmentation and an automated processing
akin to cross validation, resulting in 10-20 fold reduction on annotation time.
We demonstrate the utility of our new dataset by showing how data augmentation
with RaidaR can elevate the accuracy of existing segmentation algorithms. We
also present a novel unpaired image-to-image translation algorithm for
adding/removing rain artifacts, which directly benefits from RaidaR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Inexact Projected Gradient Method with Rounding and Lifting by Nonlinear Programming for Solving Rank-One Semidefinite Relaxation of Polynomial Optimization. (arXiv:2105.14033v2 [math.OC] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14033">
<div class="article-summary-box-inner">
<span><p>We consider solving high-order semidefinite programming (SDP) relaxations of
nonconvex polynomial optimization problems (POPs) that often admit degenerate
rank-one optimal solutions. Instead of solving the SDP alone, we propose a new
algorithmic framework that blends local search using the nonconvex POP into
global descent using the convex SDP. In particular, we first design a globally
convergent inexact projected gradient method (iPGM) for solving the SDP that
serves as the backbone of our framework. We then accelerate iPGM by taking
long, but safeguarded, rank-one steps generated by fast nonlinear programming
algorithms. We prove that the new framework is still globally convergent for
solving the SDP. To solve the iPGM subproblem of projecting a given point onto
the feasible set of the SDP, we design a two-phase algorithm with phase one
using a symmetric Gauss-Seidel based accelerated proximal gradient method
(sGS-APG) to generate a good initial point, and phase two using a modified
limited-memory BFGS (L-BFGS) method to obtain an accurate solution. We analyze
the convergence for both phases and establish a novel global convergence result
for the modified L-BFGS that does not require the objective function to be
twice continuously differentiable. We conduct numerical experiments for solving
second-order SDP relaxations arising from a diverse set of POPs. Our framework
demonstrates state-of-the-art efficiency, scalability, and robustness in
solving degenerate rank-one SDPs to high accuracy, even in the presence of
millions of equality constraints.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Not All Images are Worth 16x16 Words: Dynamic Transformers for Efficient Image Recognition. (arXiv:2105.15075v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15075">
<div class="article-summary-box-inner">
<span><p>Vision Transformers (ViT) have achieved remarkable success in large-scale
image recognition. They split every 2D image into a fixed number of patches,
each of which is treated as a token. Generally, representing an image with more
tokens would lead to higher prediction accuracy, while it also results in
drastically increased computational cost. To achieve a decent trade-off between
accuracy and speed, the number of tokens is empirically set to 16x16 or 14x14.
In this paper, we argue that every image has its own characteristics, and
ideally the token number should be conditioned on each individual input. In
fact, we have observed that there exist a considerable number of "easy" images
which can be accurately predicted with a mere number of 4x4 tokens, while only
a small fraction of "hard" ones need a finer representation. Inspired by this
phenomenon, we propose a Dynamic Transformer to automatically configure a
proper number of tokens for each input image. This is achieved by cascading
multiple Transformers with increasing numbers of tokens, which are sequentially
activated in an adaptive fashion at test time, i.e., the inference is
terminated once a sufficiently confident prediction is produced. We further
design efficient feature reuse and relationship reuse mechanisms across
different components of the Dynamic Transformer to reduce redundant
computations. Extensive empirical results on ImageNet, CIFAR-10, and CIFAR-100
demonstrate that our method significantly outperforms the competitive baselines
in terms of both theoretical computational efficiency and practical inference
speed. Code and pre-trained models (based on PyTorch and MindSpore) are
available at https://github.com/blackfeather-wang/Dynamic-Vision-Transformer
and https://github.com/blackfeather-wang/Dynamic-Vision-Transformer-MindSpore.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification. (arXiv:2106.02034v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02034">
<div class="article-summary-box-inner">
<span><p>Attention is sparse in vision transformers. We observe the final prediction
in vision transformers is only based on a subset of most informative tokens,
which is sufficient for accurate image recognition. Based on this observation,
we propose a dynamic token sparsification framework to prune redundant tokens
progressively and dynamically based on the input. Specifically, we devise a
lightweight prediction module to estimate the importance score of each token
given the current features. The module is added to different layers to prune
redundant tokens hierarchically. To optimize the prediction module in an
end-to-end manner, we propose an attention masking strategy to differentiably
prune a token by blocking its interactions with other tokens. Benefiting from
the nature of self-attention, the unstructured sparse tokens are still hardware
friendly, which makes our framework easy to achieve actual speed-up. By
hierarchically pruning 66% of the input tokens, our method greatly reduces
31%~37% FLOPs and improves the throughput by over 40% while the drop of
accuracy is within 0.5% for various vision transformers. Equipped with the
dynamic token sparsification framework, DynamicViT models can achieve very
competitive complexity/accuracy trade-offs compared to state-of-the-art CNNs
and vision transformers on ImageNet. Code is available at
https://github.com/raoyongming/DynamicViT
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CATs: Cost Aggregation Transformers for Visual Correspondence. (arXiv:2106.02520v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02520">
<div class="article-summary-box-inner">
<span><p>We propose a novel cost aggregation network, called Cost Aggregation
Transformers (CATs), to find dense correspondences between semantically similar
images with additional challenges posed by large intra-class appearance and
geometric variations. Cost aggregation is a highly important process in
matching tasks, which the matching accuracy depends on the quality of its
output. Compared to hand-crafted or CNN-based methods addressing the cost
aggregation, in that either lacks robustness to severe deformations or inherit
the limitation of CNNs that fail to discriminate incorrect matches due to
limited receptive fields, CATs explore global consensus among initial
correlation map with the help of some architectural designs that allow us to
fully leverage self-attention mechanism. Specifically, we include appearance
affinity modeling to aid the cost aggregation process in order to disambiguate
the noisy initial correlation maps and propose multi-level aggregation to
efficiently capture different semantics from hierarchical feature
representations. We then combine with swapping self-attention technique and
residual connections not only to enforce consistent matching but also to ease
the learning process, which we find that these result in an apparent
performance boost. We conduct experiments to demonstrate the effectiveness of
the proposed model over the latest methods and provide extensive ablation
studies. Code and trained models are available
at~\url{https://github.com/SunghwanHong/CATs}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recovery Analysis for Plug-and-Play Priors using the Restricted Eigenvalue Condition. (arXiv:2106.03668v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03668">
<div class="article-summary-box-inner">
<span><p>The plug-and-play priors (PnP) and regularization by denoising (RED) methods
have become widely used for solving inverse problems by leveraging pre-trained
deep denoisers as image priors. While the empirical imaging performance and the
theoretical convergence properties of these algorithms have been widely
investigated, their recovery properties have not previously been theoretically
analyzed. We address this gap by showing how to establish theoretical recovery
guarantees for PnP/RED by assuming that the solution of these methods lies near
the fixed-points of a deep neural network. We also present numerical results
comparing the recovery performance of PnP/RED in compressive sensing against
that of recent compressive sensing algorithms based on generative models. Our
numerical results suggest that PnP with a pre-trained artifact removal network
provides significantly better results compared to the existing state-of-the-art
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Semantic Hallucination for Domain Generalized Semantic Segmentation. (arXiv:2106.04144v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04144">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks typically perform poorly when the test (target
domain) and training (source domain) data have significantly different
distributions. While this problem can be mitigated by using the target domain
data to align the source and target domain feature representations, the target
domain data may be unavailable due to privacy concerns. Consequently, there is
a need for methods that generalize well despite restricted access to target
domain data during training. In this work, we propose an adversarial semantic
hallucination approach (ASH), which combines a class-conditioned hallucination
module and a semantic segmentation module. Since the segmentation performance
varies across different classes, we design a semantic-conditioned style
hallucination module to generate affine transformation parameters from semantic
information in the segmentation probability maps of the source domain image.
Unlike previous adaptation approaches, which treat all classes equally, ASH
considers the class-wise differences. The segmentation module and the
hallucination module compete adversarially, with the hallucination module
generating increasingly "difficult" stylized images to challenge the
segmentation module. In response, the segmentation module improves as it is
trained with generated samples at an appropriate class-wise difficulty level.
Our results on the Cityscapes and Mapillary benchmark datasets show that our
method is competitive with state of the art work. Code is made available at
https://github.com/gabriel-tjio/ASH.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond BatchNorm: Towards a Unified Understanding of Normalization in Deep Learning. (arXiv:2106.05956v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05956">
<div class="article-summary-box-inner">
<span><p>Inspired by BatchNorm, there has been an explosion of normalization layers in
deep learning. Recent works have identified a multitude of beneficial
properties in BatchNorm to explain its success. However, given the pursuit of
alternative normalization layers, these properties need to be generalized so
that any given layer's success/failure can be accurately predicted. In this
work, we take a first step towards this goal by extending known properties of
BatchNorm in randomly initialized deep neural networks (DNNs) to several
recently proposed normalization layers. Our primary findings follow: (i)
similar to BatchNorm, activations-based normalization layers can prevent
exponential growth of activations in ResNets, but parametric techniques require
explicit remedies; (ii) use of GroupNorm can ensure an informative forward
propagation, with different samples being assigned dissimilar activations, but
increasing group size results in increasingly indistinguishable activations for
different samples, explaining slow convergence speed in models with LayerNorm;
and (iii) small group sizes result in large gradient norm in earlier layers,
hence explaining training instability issues in Instance Normalization and
illustrating a speed-stability tradeoff in GroupNorm. Overall, our analysis
reveals a unified set of mechanisms that underpin the success of normalization
methods in deep learning, providing us with a compass to systematically explore
the vast design space of DNN normalization layers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dynamic Distillation Network for Cross-Domain Few-Shot Recognition with Unlabeled Data. (arXiv:2106.07807v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07807">
<div class="article-summary-box-inner">
<span><p>Most existing works in few-shot learning rely on meta-learning the network on
a large base dataset which is typically from the same domain as the target
dataset. We tackle the problem of cross-domain few-shot learning where there is
a large shift between the base and target domain. The problem of cross-domain
few-shot recognition with unlabeled target data is largely unaddressed in the
literature. STARTUP was the first method that tackles this problem using
self-training. However, it uses a fixed teacher pretrained on a labeled base
dataset to create soft labels for the unlabeled target samples. As the base
dataset and unlabeled dataset are from different domains, projecting the target
images in the class-domain of the base dataset with a fixed pretrained model
might be sub-optimal. We propose a simple dynamic distillation-based approach
to facilitate unlabeled images from the novel/base dataset. We impose
consistency regularization by calculating predictions from the weakly-augmented
versions of the unlabeled images from a teacher network and matching it with
the strongly augmented versions of the same images from a student network. The
parameters of the teacher network are updated as exponential moving average of
the parameters of the student network. We show that the proposed network learns
representation that can be easily adapted to the target domain even though it
has not been trained with target-specific classes during the pretraining phase.
Our model outperforms the current state-of-the art method by 4.4% for 1-shot
and 3.6% for 5-shot classification in the BSCD-FSL benchmark, and also shows
competitive performance on traditional in-domain few-shot learning task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting the Calibration of Modern Neural Networks. (arXiv:2106.07998v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07998">
<div class="article-summary-box-inner">
<span><p>Accurate estimation of predictive uncertainty (model calibration) is
essential for the safe application of neural networks. Many instances of
miscalibration in modern neural networks have been reported, suggesting a trend
that newer, more accurate models produce poorly calibrated predictions. Here,
we revisit this question for recent state-of-the-art image classification
models. We systematically relate model calibration and accuracy, and find that
the most recent models, notably those not using convolutions, are among the
best calibrated. Trends observed in prior model generations, such as decay of
calibration with distribution shift or model size, are less pronounced in
recent architectures. We also show that model size and amount of pretraining do
not fully explain these differences, suggesting that architecture is a major
determinant of calibration properties.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spot the Difference: Detection of Topological Changes via Geometric Alignment. (arXiv:2106.08233v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08233">
<div class="article-summary-box-inner">
<span><p>Geometric alignment appears in a variety of applications, ranging from domain
adaptation, optimal transport, and normalizing flows in machine learning;
optical flow and learned augmentation in computer vision and deformable
registration within biomedical imaging. A recurring challenge is the alignment
of domains whose topology is not the same; a problem that is routinely ignored,
potentially introducing bias in downstream analysis. As a first step towards
solving such alignment problems, we propose an unsupervised algorithm for the
detection of changes in image topology. The model is based on a conditional
variational auto-encoder and detects topological changes between two images
during the registration step. We account for both topological changes in the
image under spatial variation and unexpected transformations. Our approach is
validated on two tasks and datasets: detection of topological changes in
microscopy images of cells, and unsupervised anomaly detection brain imaging.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EdgeConv with Attention Module for Monocular Depth Estimation. (arXiv:2106.08615v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08615">
<div class="article-summary-box-inner">
<span><p>Monocular depth estimation is an especially important task in robotics and
autonomous driving, where 3D structural information is essential. However,
extreme lighting conditions and complex surface objects make it difficult to
predict depth in a single image. Therefore, to generate accurate depth maps, it
is important for the model to learn structural information about the scene. We
propose a novel Patch-Wise EdgeConv Module (PEM) and EdgeConv Attention Module
(EAM) to solve the difficulty of monocular depth estimation. The proposed
modules extract structural information by learning the relationship between
image patches close to each other in space using edge convolution. Our method
is evaluated on two popular datasets, the NYU Depth V2 and the KITTI Eigen
split, achieving state-of-the-art performance. We prove that the proposed model
predicts depth robustly in challenging scenes through various comparative
experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shape from Blur: Recovering Textured 3D Shape and Motion of Fast Moving Objects. (arXiv:2106.08762v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08762">
<div class="article-summary-box-inner">
<span><p>We address the novel task of jointly reconstructing the 3D shape, texture,
and motion of an object from a single motion-blurred image. While previous
approaches address the deblurring problem only in the 2D image domain, our
proposed rigorous modeling of all object properties in the 3D domain enables
the correct description of arbitrary object motion. This leads to significantly
better image decomposition and sharper deblurring results. We model the
observed appearance of a motion-blurred object as a combination of the
background and a 3D object with constant translation and rotation. Our method
minimizes a loss on reconstructing the input image via differentiable rendering
with suitable regularizers. This enables estimating the textured 3D mesh of the
blurred object with high fidelity. Our method substantially outperforms
competing approaches on several benchmarks for fast moving objects deblurring.
Qualitative results show that the reconstructed 3D mesh generates high-quality
temporal super-resolution and novel views of the deblurred object.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accumulative Poisoning Attacks on Real-time Data. (arXiv:2106.09993v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09993">
<div class="article-summary-box-inner">
<span><p>Collecting training data from untrusted sources exposes machine learning
services to poisoning adversaries, who maliciously manipulate training data to
degrade the model accuracy. When trained on offline datasets, poisoning
adversaries have to inject the poisoned data in advance before training, and
the order of feeding these poisoned batches into the model is stochastic. In
contrast, practical systems are more usually trained/fine-tuned on sequentially
captured real-time data, in which case poisoning adversaries could dynamically
poison each data batch according to the current model state. In this paper, we
focus on the real-time settings and propose a new attacking strategy, which
affiliates an accumulative phase with poisoning attacks to secretly (i.e.,
without affecting accuracy) magnify the destructive effect of a (poisoned)
trigger batch. By mimicking online learning and federated learning on MNIST and
CIFAR-10, we show that model accuracy significantly drops by a single update
step on the trigger batch after the accumulative phase. Our work validates that
a well-designed but straightforward attacking strategy can dramatically amplify
the poisoning effects, with no need to explore complex techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ToAlign: Task-oriented Alignment for Unsupervised Domain Adaptation. (arXiv:2106.10812v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10812">
<div class="article-summary-box-inner">
<span><p>Unsupervised domain adaptive classifcation intends to improve the
classifcation performance on unlabeled target domain. To alleviate the adverse
effect of domain shift, many approaches align the source and target domains in
the feature space. However, a feature is usually taken as a whole for alignment
without explicitly making domain alignment proactively serve the classifcation
task, leading to sub-optimal solution. In this paper, we propose an effective
Task-oriented Alignment (ToAlign) for unsupervised domain adaptation (UDA). We
study what features should be aligned across domains and propose to make the
domain alignment proactively serve classifcation by performing feature
decomposition and alignment under the guidance of the prior knowledge induced
from the classifcation task itself. Particularly, we explicitly decompose a
feature in the source domain into a task-related/discriminative feature that
should be aligned, and a task-irrelevant feature that should be
avoided/ignored, based on the classifcation meta-knowledge. Extensive
experimental results on various benchmarks (e.g., Offce-Home, Visda-2017, and
DomainNet) under different domain adaptation settings demonstrate the
effectiveness of ToAlign which helps achieve the state-of-the-art performance.
The code is publicly available at https://github.com/microsoft/UDA
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Transformer-based Cross-modal Fusion Model with Adversarial Training for VQA Challenge 2021. (arXiv:2106.13033v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13033">
<div class="article-summary-box-inner">
<span><p>In this paper, inspired by the successes of visionlanguage pre-trained models
and the benefits from training with adversarial attacks, we present a novel
transformerbased cross-modal fusion modeling by incorporating the both notions
for VQA challenge 2021. Specifically, the proposed model is on top of the
architecture of VinVL model [19], and the adversarial training strategy [4] is
applied to make the model robust and generalized. Moreover, two implementation
tricks are also used in our system to obtain better results. The experiments
demonstrate that the novel framework can achieve 76.72% on VQAv2 test-std set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Early Convolutions Help Transformers See Better. (arXiv:2106.14881v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14881">
<div class="article-summary-box-inner">
<span><p>Vision transformer (ViT) models exhibit substandard optimizability. In
particular, they are sensitive to the choice of optimizer (AdamW vs. SGD),
optimizer hyperparameters, and training schedule length. In comparison, modern
convolutional neural networks are easier to optimize. Why is this the case? In
this work, we conjecture that the issue lies with the patchify stem of ViT
models, which is implemented by a stride-p p*p convolution (p=16 by default)
applied to the input image. This large-kernel plus large-stride convolution
runs counter to typical design choices of convolutional layers in neural
networks. To test whether this atypical design choice causes an issue, we
analyze the optimization behavior of ViT models with their original patchify
stem versus a simple counterpart where we replace the ViT stem by a small
number of stacked stride-two 3*3 convolutions. While the vast majority of
computation in the two ViT designs is identical, we find that this small change
in early visual processing results in markedly different training behavior in
terms of the sensitivity to optimization settings as well as the final model
accuracy. Using a convolutional stem in ViT dramatically increases optimization
stability and also improves peak performance (by ~1-2% top-1 accuracy on
ImageNet-1k), while maintaining flops and runtime. The improvement can be
observed across the wide spectrum of model complexities (from 1G to 36G flops)
and dataset scales (from ImageNet-1k to ImageNet-21k). These findings lead us
to recommend using a standard, lightweight convolutional stem for ViT models in
this regime as a more robust architectural choice compared to the original ViT
model design.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">O2O-Afford: Annotation-Free Large-Scale Object-Object Affordance Learning. (arXiv:2106.15087v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15087">
<div class="article-summary-box-inner">
<span><p>Contrary to the vast literature in modeling, perceiving, and understanding
agent-object (e.g., human-object, hand-object, robot-object) interaction in
computer vision and robotics, very few past works have studied the task of
object-object interaction, which also plays an important role in robotic
manipulation and planning tasks. There is a rich space of object-object
interaction scenarios in our daily life, such as placing an object on a messy
tabletop, fitting an object inside a drawer, pushing an object using a tool,
etc. In this paper, we propose a unified affordance learning framework to learn
object-object interaction for various tasks. By constructing four object-object
interaction task environments using physical simulation (SAPIEN) and thousands
of ShapeNet models with rich geometric diversity, we are able to conduct
large-scale object-object affordance learning without the need for human
annotations or demonstrations. At the core of technical contribution, we
propose an object-kernel point convolution network to reason about detailed
interaction between two objects. Experiments on large-scale synthetic data and
real-world data prove the effectiveness of the proposed approach. Please refer
to the project webpage for code, data, video, and more materials:
https://cs.stanford.edu/~kaichun/o2oafford
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Global Filter Networks for Image Classification. (arXiv:2107.00645v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00645">
<div class="article-summary-box-inner">
<span><p>Recent advances in self-attention and pure multi-layer perceptrons (MLP)
models for vision have shown great potential in achieving promising performance
with fewer inductive biases. These models are generally based on learning
interaction among spatial locations from raw data. The complexity of
self-attention and MLP grows quadratically as the image size increases, which
makes these models hard to scale up when high-resolution features are required.
In this paper, we present the Global Filter Network (GFNet), a conceptually
simple yet computationally efficient architecture, that learns long-term
spatial dependencies in the frequency domain with log-linear complexity. Our
architecture replaces the self-attention layer in vision transformers with
three key operations: a 2D discrete Fourier transform, an element-wise
multiplication between frequency-domain features and learnable global filters,
and a 2D inverse Fourier transform. We exhibit favorable accuracy/complexity
trade-offs of our models on both ImageNet and downstream tasks. Our results
demonstrate that GFNet can be a very competitive alternative to
transformer-style models and CNNs in efficiency, generalization ability and
robustness. Code is available at https://github.com/raoyongming/GFNet
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CHASE: Robust Visual Tracking via Cell-Level Differentiable Neural Architecture Search. (arXiv:2107.03463v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03463">
<div class="article-summary-box-inner">
<span><p>A strong visual object tracker nowadays relies on its well-crafted modules,
which typically consist of manually-designed network architectures to deliver
high-quality tracking results. Not surprisingly, the manual design process
becomes a particularly challenging barrier, as it demands sufficient prior
experience, enormous effort, intuition, and perhaps some good luck. Meanwhile,
neural architecture search has gaining grounds in practical applications as a
promising method in tackling the issue of automated search of feasible network
structures. In this work, we propose a novel cell-level differentiable
architecture search mechanism with early stopping to automate the network
design of the tracking module, aiming to adapt backbone features to the
objective of Siamese tracking networks during offline training. Besides, the
proposed early stopping strategy avoids over-fitting and performance collapse
problems leading to generalization improvement. The proposed approach is
simple, efficient, and with no need to stack a series of modules to construct a
network. Our approach is easy to be incorporated into existing trackers, which
is empirically validated using different differentiable architecture
search-based methods and tracking objectives. Extensive experimental
evaluations demonstrate the superior performance of our approach over five
commonly-used benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Object Behavioral Feature Extraction for Potential Risk Analysis based on Video Sensor. (arXiv:2107.03554v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03554">
<div class="article-summary-box-inner">
<span><p>Pedestrians are exposed to risk of death or serious injuries on roads,
especially unsignalized crosswalks, for a variety of reasons. To date, an
extensive variety of studies have reported on vision based traffic safety
system. However, many studies required manual inspection of the volumes of
traffic video to reliably obtain traffic related objects behavioral factors. In
this paper, we propose an automated and simpler system for effectively
extracting object behavioral features from video sensors deployed on the road.
We conduct basic statistical analysis on these features, and show how they can
be useful for monitoring the traffic behavior on the road. We confirm the
feasibility of the proposed system by applying our prototype to two
unsignalized crosswalks in Osan city, South Korea. To conclude, we compare
behaviors of vehicles and pedestrians in those two areas by simple statistical
analysis. This study demonstrates the potential for a network of connected
video sensors to provide actionable data for smart cities to improve pedestrian
safety in dangerous road environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CamTuner: Reinforcement-Learning based System for Camera Parameter Tuning to enhance Analytics. (arXiv:2107.03964v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03964">
<div class="article-summary-box-inner">
<span><p>Video analytics systems critically rely on video cameras, which capture
high-quality video frames, to achieve high analytics accuracy. Although modern
video cameras often expose tens of configurable parameter settings that can be
set by end-users, deployment of surveillance cameras today often uses a fixed
set of parameter settings because the end-users lack the skill or understanding
to reconfigure these parameters.
</p>
<p>In this paper, we first show that in a typical surveillance camera
deployment, environmental condition changes can significantly affect the
accuracy of analytics units such as person detection, face detection and face
recognition, and how such adverse impact can be mitigated by dynamically
adjusting camera settings. We then propose CAMTUNER, a framework that can be
easily applied to an existing video analytics pipeline (VAP) to enable
automatic and dynamic adaptation of complex camera settings to changing
environmental conditions, and autonomously optimize the accuracy of analytics
units (AUs) in the VAP. CAMTUNER is based on SARSA reinforcement learning (RL)
and it incorporates two novel components: a light-weight analytics quality
estimator and a virtual camera. CAMTUNER is implemented in a system with AXIS
surveillance cameras and several VAPs (with various AUs) that processed
day-long customer videos captured at airport entrances. Our evaluations show
that CAMTUNER can adapt quickly to changing environments. We compared CAMTUNER
with two alternative approaches where either static camera settings were used,
or a strawman approach where camera settings were manually changed every hour
(based on human perception of quality). We observed that for the face detection
and person detection AUs, CAMTUNER is able to achieve up to 13.8% and 9.2%
higher accuracy, respectively, compared to the best of the two approaches
(average improvement of 8% for both AUs).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CentripetalText: An Efficient Text Instance Representation for Scene Text Detection. (arXiv:2107.05945v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05945">
<div class="article-summary-box-inner">
<span><p>Scene text detection remains a grand challenge due to the variation in text
curvatures, orientations, and aspect ratios. One of the hardest problems in
this task is how to represent text instances of arbitrary shapes. Although many
methods have been proposed to model irregular texts in a flexible manner, most
of them lose simplicity and robustness. Their complicated post-processings and
the regression under Dirac delta distribution undermine the detection
performance and the generalization ability. In this paper, we propose an
efficient text instance representation named CentripetalText (CT), which
decomposes text instances into the combination of text kernels and centripetal
shifts. Specifically, we utilize the centripetal shifts to implement pixel
aggregation, guiding the external text pixels to the internal text kernels. The
relaxation operation is integrated into the dense regression for centripetal
shifts, allowing the correct prediction in a range instead of a specific value.
The convenient reconstruction of text contours and the tolerance of prediction
errors in our method guarantee the high detection accuracy and the fast
inference speed, respectively. Besides, we shrink our text detector into a
proposal generation module, namely CentripetalText Proposal Network, replacing
Segmentation Proposal Network in Mask TextSpotter v3 and producing more
accurate proposals. To validate the effectiveness of our method, we conduct
experiments on several commonly used scene text benchmarks, including both
curved and multi-oriented text datasets. For the task of scene text detection,
our approach achieves superior or competitive performance compared to other
existing methods, e.g., F-measure of 86.3% at 40.0 FPS on Total-Text, F-measure
of 86.1% at 34.8 FPS on MSRA-TD500, etc. For the task of end-to-end scene text
recognition, our method outperforms Mask TextSpotter v3 by 1.1% on Total-Text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CCVS: Context-aware Controllable Video Synthesis. (arXiv:2107.08037v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08037">
<div class="article-summary-box-inner">
<span><p>This presentation introduces a self-supervised learning approach to the
synthesis of new video clips from old ones, with several new key elements for
improved spatial resolution and realism: It conditions the synthesis process on
contextual information for temporal continuity and ancillary information for
fine control. The prediction model is doubly autoregressive, in the latent
space of an autoencoder for forecasting, and in image space for updating
contextual information, which is also used to enforce spatio-temporal
consistency through a learnable optical flow module. Adversarial training of
the autoencoder in the appearance and temporal domains is used to further
improve the realism of its output. A quantizer inserted between the encoder and
the transformer in charge of forecasting future frames in latent space (and its
inverse inserted between the transformer and the decoder) adds even more
flexibility by affording simple mechanisms for handling multimodal ancillary
information for controlling the synthesis process (eg, a few sample frames, an
audio track, a trajectory in image space) and taking into account the
intrinsically uncertain nature of the future by allowing multiple predictions.
Experiments with an implementation of the proposed approach give very good
qualitative and quantitative results on multiple tasks and standard benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active 3D Shape Reconstruction from Vision and Touch. (arXiv:2107.09584v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.09584">
<div class="article-summary-box-inner">
<span><p>Humans build 3D understandings of the world through active object
exploration, using jointly their senses of vision and touch. However, in 3D
shape reconstruction, most recent progress has relied on static datasets of
limited sensory data such as RGB images, depth maps or haptic readings, leaving
the active exploration of the shape largely unexplored. Inactive touch sensing
for 3D reconstruction, the goal is to actively select the tactile readings that
maximize the improvement in shape reconstruction accuracy. However, the
development of deep learning-based active touch models is largely limited by
the lack of frameworks for shape exploration. In this paper, we focus on this
problem and introduce a system composed of: 1) a haptic simulator leveraging
high spatial resolution vision-based tactile sensors for active touching of 3D
objects; 2)a mesh-based 3D shape reconstruction model that relies on tactile or
visuotactile signals; and 3) a set of data-driven solutions with either tactile
or visuotactile priors to guide the shape exploration. Our framework enables
the development of the first fully data-driven solutions to active touch on top
of learned models for object understanding. Our experiments show the benefits
of such solutions in the task of 3D shape understanding where our models
consistently outperform natural baselines. We provide our framework as a tool
to foster future research in this direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Modal Graph with Meta Concepts for Video Captioning. (arXiv:2108.06458v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06458">
<div class="article-summary-box-inner">
<span><p>Video captioning targets interpreting the complex visual contents as text
descriptions, which requires the model to fully understand video scenes
including objects and their interactions. Prevailing methods adopt
off-the-shelf object detection networks to give object proposals and use the
attention mechanism to model the relations between objects. They often miss
some undefined semantic concepts of the pretrained model and fail to identify
exact predicate relationships between objects. In this paper, we investigate an
open research task of generating text descriptions for the given videos, and
propose Cross-Modal Graph (CMG) with meta concepts for video captioning.
Specifically, to cover the useful semantic concepts in video captions, we
weakly learn the corresponding visual regions for text descriptions, where the
associated visual regions and textual words are named cross-modal meta
concepts. We further build meta concept graphs dynamically with the learned
cross-modal meta concepts. We also construct holistic video-level and local
frame-level video graphs with the predicted predicates to model video sequence
structures. We validate the efficacy of our proposed techniques with extensive
experiments and achieve state-of-the-art results on two public datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counterfactual Attention Learning for Fine-Grained Visual Categorization and Re-identification. (arXiv:2108.08728v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08728">
<div class="article-summary-box-inner">
<span><p>Attention mechanism has demonstrated great potential in fine-grained visual
recognition tasks. In this paper, we present a counterfactual attention
learning method to learn more effective attention based on causal inference.
Unlike most existing methods that learn visual attention based on conventional
likelihood, we propose to learn the attention with counterfactual causality,
which provides a tool to measure the attention quality and a powerful
supervisory signal to guide the learning process. Specifically, we analyze the
effect of the learned visual attention on network prediction through
counterfactual intervention and maximize the effect to encourage the network to
learn more useful attention for fine-grained image recognition. Empirically, we
evaluate our method on a wide range of fine-grained recognition tasks where
attention plays a crucial role, including fine-grained image categorization,
person re-identification, and vehicle re-identification. The consistent
improvement on all benchmarks demonstrates the effectiveness of our method.
Code is available at https://github.com/raoyongming/CAL
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shifted Chunk Transformer for Spatio-Temporal Representational Learning. (arXiv:2108.11575v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11575">
<div class="article-summary-box-inner">
<span><p>Spatio-temporal representational learning has been widely adopted in various
fields such as action recognition, video object segmentation, and action
anticipation. Previous spatio-temporal representational learning approaches
primarily employ ConvNets or sequential models,e.g., LSTM, to learn the
intra-frame and inter-frame features. Recently, Transformer models have
successfully dominated the study of natural language processing (NLP), image
classification, etc. However, the pure-Transformer based spatio-temporal
learning can be prohibitively costly on memory and computation to extract
fine-grained features from a tiny patch. To tackle the training difficulty and
enhance the spatio-temporal learning, we construct a shifted chunk Transformer
with pure self-attention blocks. Leveraging the recent efficient Transformer
design in NLP, this shifted chunk Transformer can learn hierarchical
spatio-temporal features from a local tiny patch to a global video clip. Our
shifted self-attention can also effectively model complicated inter-frame
variances. Furthermore, we build a clip encoder based on Transformer to model
long-term temporal dependencies. We conduct thorough ablation studies to
validate each component and hyper-parameters in our shifted chunk Transformer,
and it outperforms previous state-of-the-art approaches on Kinetics-400,
Kinetics-600, UCF101, and HMDB51. Code and trained models will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual Transfer Learning for Event-based End-task Prediction via Pluggable Event to Image Translation. (arXiv:2109.01801v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01801">
<div class="article-summary-box-inner">
<span><p>Event cameras are novel sensors that perceive the per-pixel intensity changes
and output asynchronous event streams with high dynamic range and less motion
blur. It has been shown that events alone can be used for end-task learning,
e.g., semantic segmentation, based on encoder-decoder-like networks. However,
as events are sparse and mostly reflect edge information, it is difficult to
recover original details merely relying on the decoder. Moreover, most methods
resort to pixel-wise loss alone for supervision, which might be insufficient to
fully exploit the visual details from sparse events, thus leading to less
optimal performance. In this paper, we propose a simple yet flexible two-stream
framework named Dual Transfer Learning (DTL) to effectively enhance the
performance on the end-tasks without adding extra inference cost. The proposed
approach consists of three parts: event to end-task learning (EEL) branch,
event to image translation (EIT) branch, and transfer learning (TL) module that
simultaneously explores the feature-level affinity information and pixel-level
knowledge from the EIT branch to improve the EEL branch. This simple yet novel
method leads to strong representation learning from events and is evidenced by
the significant performance boost on the end-tasks such as semantic
segmentation and depth estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Local Domains for Image-to-Image Translation. (arXiv:2109.04468v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04468">
<div class="article-summary-box-inner">
<span><p>Image-to-image (i2i) networks struggle to capture local changes because they
do not affect the global scene structure. For example, translating from highway
scenes to offroad, i2i networks easily focus on global color features but
ignore obvious traits for humans like the absence of lane markings. In this
paper, we leverage human knowledge about spatial domain characteristics which
we refer to as 'local domains' and demonstrate its benefit for image-to-image
translation. Relying on a simple geometrical guidance, we train a patch-based
GAN on few source data and hallucinate a new unseen domain which subsequently
eases transfer learning to target. We experiment on three tasks ranging from
unstructured environments to adverse weather. Our comprehensive evaluation
setting shows we are able to generate realistic translations, with minimal
priors, and training only on a few images. Furthermore, when trained on our
translations images we show that all tested proxy tasks are significantly
improved, without ever seeing target domain at training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficiently Identifying Task Groupings for Multi-Task Learning. (arXiv:2109.04617v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04617">
<div class="article-summary-box-inner">
<span><p>Multi-task learning can leverage information learned by one task to benefit
the training of other tasks. Despite this capacity, naively training all tasks
together in one model often degrades performance, and exhaustively searching
through combinations of task groupings can be prohibitively expensive. As a
result, efficiently identifying the tasks that would benefit from training
together remains a challenging design question without a clear solution. In
this paper, we suggest an approach to select which tasks should train together
in multi-task learning models. Our method determines task groupings in a single
run by training all tasks together and quantifying the effect to which one
task's gradient would affect another task's loss. On the large-scale Taskonomy
computer vision dataset, we find this method can decrease test loss by 10.0%
compared to simply training all tasks together while operating 11.6 times
faster than a state-of-the-art task grouping method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Domain Adaptive Learning via Synthetic Data for Person Re-identification. (arXiv:2109.05542v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05542">
<div class="article-summary-box-inner">
<span><p>Person re-identification (re-ID) has gained more and more attention due to
its widespread applications in intelligent video surveillance. Unfortunately,
the mainstream deep learning methods still need a large quantity of labeled
data to train models, and annotating data is an expensive work in real-world
scenarios. In addition, due to domain gaps between different datasets, the
performance is dramatically decreased when re-ID models pre-trained on
label-rich datasets (source domain) are directly applied to other unlabeled
datasets (target domain). In this paper, we attempt to remedy these problems
from two aspects, namely data and methodology. Firstly, we develop a data
collector to automatically generate synthetic re-ID samples in a computer game,
and construct a data labeler to simultaneously annotate them, which free humans
from heavy data collections and annotations. Based on them, we build two
synthetic person re-ID datasets with different scales, "GSPR" and "mini-GSPR"
datasets. Secondly, we propose a synthesis-based multi-domain collaborative
refinement (SMCR) network, which contains a synthetic pretraining module and
two collaborative-refinement modules to implement sufficient learning for the
valuable knowledge from multiple domains. Extensive experiments show that our
proposed framework obtains significant performance improvements over the
state-of-the-art methods on multiple unsupervised domain adaptation tasks of
person re-ID.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EdgeFlow: Achieving Practical Interactive Segmentation with Edge-Guided Flow. (arXiv:2109.09406v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.09406">
<div class="article-summary-box-inner">
<span><p>High-quality training data play a key role in image segmentation tasks.
Usually, pixel-level annotations are expensive, laborious and time-consuming
for the large volume of training data. To reduce labelling cost and improve
segmentation quality, interactive segmentation methods have been proposed,
which provide the result with just a few clicks. However, their performance
does not meet the requirements of practical segmentation tasks in terms of
speed and accuracy. In this work, we propose EdgeFlow, a novel architecture
that fully utilizes interactive information of user clicks with edge-guided
flow. Our method achieves state-of-the-art performance without any
post-processing or iterative optimization scheme. Comprehensive experiments on
benchmarks also demonstrate the superiority of our method. In addition, with
the proposed method, we develop an efficient interactive segmentation tool for
practical data annotation tasks. The source code and tool is avaliable at
https://github.com/PaddlePaddle/PaddleSeg.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Well Googled is Half Done: Multimodal Forecasting of New Fashion Product Sales with Image-based Google Trends. (arXiv:2109.09824v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.09824">
<div class="article-summary-box-inner">
<span><p>This paper investigates the effectiveness of systematically probing Google
Trends against textual translations of visual aspects as exogenous knowledge to
predict the sales of brand-new fashion items, where past sales data is not
available, but only an image and few metadata are available. In particular, we
propose GTM-Transformer, standing for Google Trends Multimodal Transformer,
whose encoder works on the representation of the exogenous time series, while
the decoder forecasts the sales using the Google Trends encoding, and the
available visual and metadata information. Our model works in a
non-autoregressive manner, avoiding the compounding effect of the first-step
errors. As a second contribution, we present the VISUELLE dataset, which is the
first publicly available dataset for the task of new fashion product sales
forecasting, containing the sales of 5577 new products sold between 2016-2019,
derived from genuine historical data of Nunalie, an Italian fast-fashion
company. Our dataset is equipped with images of products, metadata, related
sales, and associated Google Trends. We use VISUELLE to compare our approach
against state-of-the-art alternatives and numerous baselines, showing that
GTM-Transformer is the most accurate in terms of both percentage and absolute
error. It is worth noting that the addition of exogenous knowledge boosts the
forecasting accuracy by 1.5% WAPE wise, showing the importance of exploiting
Google Trends. The code and dataset are both available at
https://github.com/HumaticsLAB/GTM-Transformer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-loss ensemble deep learning for chest X-ray classification. (arXiv:2109.14433v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.14433">
<div class="article-summary-box-inner">
<span><p>Medical images commonly exhibit multiple abnormalities. Predicting them
requires multi-class classifiers whose training and desired reliable
performance can be affected by a combination of factors, such as, dataset size,
data source, distribution, and the loss function used to train the deep neural
networks. Currently, the cross-entropy loss remains the de-facto loss function
for training deep learning classifiers. This loss function, however, asserts
equal learning from all classes, leading to a bias toward the majority class.
In this work, we benchmark various state-of-the-art loss functions that are
suitable for multi-class classification, critically analyze model performance,
and propose improved loss functions. We select a pediatric chest X-ray (CXR)
dataset that includes images with no abnormality (normal), and those exhibiting
manifestations consistent with bacterial and viral pneumonia. We construct
prediction-level and model-level ensembles, respectively, to improve
classification performance. Our results show that compared to the individual
models and the state-of-the-art literature, the weighted averaging of the
predictions for top-3 and top-5 model-level ensembles delivered significantly
superior classification performance (p &lt; 0.05) in terms of MCC (0.9068, 95%
confidence interval (0.8839, 0.9297)) metric. Finally, we performed
localization studies to interpret model behaviors to visualize and confirm that
the individual models and ensembles learned meaningful features and highlighted
disease manifestations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D Pose Transfer with Correspondence Learning and Mesh Refinement. (arXiv:2109.15025v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.15025">
<div class="article-summary-box-inner">
<span><p>3D pose transfer is one of the most challenging 3D generation tasks. It aims
to transfer the pose of a source mesh to a target mesh and keep the identity
(e.g., body shape) of the target mesh. Some previous works require key point
annotations to build reliable correspondence between the source and target
meshes, while other methods do not consider any shape correspondence between
sources and targets, which leads to limited generation quality. In this work,
we propose a correspondence-refinement network to help the 3D pose transfer for
both human and animal meshes. The correspondence between source and target
meshes is first established by solving an optimal transport problem. Then, we
warp the source mesh according to the dense correspondence and obtain a coarse
warped mesh. The warped mesh will be better refined with our proposed Elastic
Instance Normalization, which is a conditional normalization layer and can help
to generate high-quality meshes. Extensive experimental results show that the
proposed architecture can effectively transfer the poses from source to target
meshes and produce better results with satisfied visual performance than
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causal Representation Learning for Fine-Grained Face Transfer. (arXiv:2110.01571v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01571">
<div class="article-summary-box-inner">
<span><p>Identity transfer often faces the challenge of generalizing to new situations
where large pose and expression or background gaps exist between source and
target face images. To improve generalization in such situations, biases take a
key role \cite{mitchell_1980_bias}. This paper proposes an Errors-in-Variables
Adapter (EVA) model to induce learning of proper generalizations by explicitly
employing biases to identity estimation based on prior knowledge about the
target situation. To better match the source face with the target situation in
terms of pose, expression, and background factors, we model the bias as a
causal effect of the target situation on source identity and estimate this
effect through a controlled intervention trial. To achieve smoother transfer
for the target face across the identity gap, we eliminate the target face
specificity through multiple kernel regressions. The kernels are used to
constrain the regressions to operate only on identity information in the
internal representations of the target image, while leaving other perceptual
information invariant. Combining these post-regression representations with the
biased estimation for identity, EVA shows impressive performance even in the
presence of large gaps, providing empirical evidence supporting the utility of
the inductive biases in identity estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Top 3 in FG 2021 Families In the Wild Kinship Verification Challenge. (arXiv:2110.07020v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07020">
<div class="article-summary-box-inner">
<span><p>Kinship verification is the task of determining whether a parent-child,
sibling, or grandparent-grandchild relationship exists between two people and
is important in social media applications, forensic investigations, finding
missing children, and reuniting families. We demonstrate high quality kinship
verification by participating in the FG 2021 Recognizing Families in the Wild
challenge which provides the largest publicly available dataset in the field.
Our approach is among the top 3 winning entries in the competition. We ensemble
models written by both human experts and OpenAI Codex. We make our models and
code publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Capacity of Group-invariant Linear Readouts from Equivariant Representations: How Many Objects can be Linearly Classified Under All Possible Views?. (arXiv:2110.07472v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07472">
<div class="article-summary-box-inner">
<span><p>Equivariance has emerged as a desirable property of representations of
objects subject to identity-preserving transformations that constitute a group,
such as translations and rotations. However, the expressivity of a
representation constrained by group equivariance is still not fully understood.
We address this gap by providing a generalization of Cover's Function Counting
Theorem that quantifies the number of linearly separable and group-invariant
binary dichotomies that can be assigned to equivariant representations of
objects. We find that the fraction of separable dichotomies is determined by
the dimension of the space that is fixed by the group action. We show how this
relation extends to operations such as convolutions, element-wise
nonlinearities, and global and local pooling. While other operations do not
change the fraction of separable dichotomies, local pooling decreases the
fraction, despite being a highly nonlinear operation. Finally, we test our
theory on intermediate representations of randomly initialized and fully
trained convolutional neural networks and find perfect agreement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unrestricted Adversarial Attacks on ImageNet Competition. (arXiv:2110.09903v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.09903">
<div class="article-summary-box-inner">
<span><p>Many works have investigated the adversarial attacks or defenses under the
settings where a bounded and imperceptible perturbation can be added to the
input. However in the real-world, the attacker does not need to comply with
this restriction. In fact, more threats to the deep model come from
unrestricted adversarial examples, that is, the attacker makes large and
visible modifications on the image, which causes the model classifying
mistakenly, but does not affect the normal observation in human perspective.
Unrestricted adversarial attack is a popular and practical direction but has
not been studied thoroughly. We organize this competition with the purpose of
exploring more effective unrestricted adversarial attack algorithm, so as to
accelerate the academical research on the model robustness under stronger
unbounded attacks. The competition is held on the TianChi platform
(\url{https://tianchi.aliyun.com/competition/entrance/531853/introduction}) as
one of the series of AI Security Challengers Program.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised denoising for massive noisy images. (arXiv:2110.11911v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.11911">
<div class="article-summary-box-inner">
<span><p>We propose an effective deep learning model for signal reconstruction, which
requires no signal prior, no noise model calibration, and no clean samples.
This model only assumes that the noise is independent of the measurement and
that the true signals share the same structured information. We demonstrate its
performance on a variety of real-world applications, from sub-\r{A}ngstr\"{o}m
resolution atomic images to sub-arcsecond resolution astronomy images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image-Based CLIP-Guided Essence Transfer. (arXiv:2110.12427v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.12427">
<div class="article-summary-box-inner">
<span><p>The conceptual blending of two signals is a semantic task that may underline
both creativity and intelligence. We propose to perform such blending in a way
that incorporates two latent spaces: that of the generator network and that of
the semantic network. For the first network, we employ the powerful StyleGAN
generator, and for the second, the powerful image-language matching network of
CLIP. The new method creates a blending operator that is optimized to be
simultaneously additive in both latent spaces. Our results demonstrate that
this leads to blending that is much more natural than what can be obtained in
each space separately.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">hSDB-instrument: Instrument Localization Database for Laparoscopic and Robotic Surgeries. (arXiv:2110.12555v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.12555">
<div class="article-summary-box-inner">
<span><p>Automated surgical instrument localization is an important technology to
understand the surgical process and in order to analyze them to provide
meaningful guidance during surgery or surgical index after surgery to the
surgeon. We introduce a new dataset that reflects the kinematic characteristics
of surgical instruments for automated surgical instrument localization of
surgical videos. The hSDB(hutom Surgery DataBase)-instrument dataset consists
of instrument localization information from 24 cases of laparoscopic
cholecystecomy and 24 cases of robotic gastrectomy. Localization information
for all instruments is provided in the form of a bounding box for object
detection. To handle class imbalance problem between instruments, synthesized
instruments modeled in Unity for 3D models are included as training data.
Besides, for 3D instrument data, a polygon annotation is provided to enable
instance segmentation of the tool. To reflect the kinematic characteristics of
all instruments, they are annotated with head and body parts for laparoscopic
instruments, and with head, wrist, and body parts for robotic instruments
separately. Annotation data of assistive tools (specimen bag, needle, etc.)
that are frequently used for surgery are also included. Moreover, we provide
statistical information on the hSDB-instrument dataset and the baseline
localization performances of the object detection networks trained by the
MMDetection library and resulting analyses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Local plasticity rules can learn deep representations using self-supervised contrastive predictions. (arXiv:2010.08262v5 [cs.NE] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08262">
<div class="article-summary-box-inner">
<span><p>Learning in the brain is poorly understood and learning rules that respect
biological constraints, yet yield deep hierarchical representations, are still
unknown. Here, we propose a learning rule that takes inspiration from
neuroscience and recent advances in self-supervised deep learning. Learning
minimizes a simple layer-specific loss function and does not need to
back-propagate error signals within or between layers. Instead, weight updates
follow a local, Hebbian, learning rule that only depends on pre- and
post-synaptic neuronal activity, predictive dendritic input and widely
broadcasted modulation factors which are identical for large groups of neurons.
The learning rule applies contrastive predictive learning to a causal,
biological setting using saccades (i.e. rapid shifts in gaze direction). We
find that networks trained with this self-supervised and local rule build deep
hierarchical representations of images, speech and video.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Learning of Event-Based Optical Flow with Spiking Neural Networks. (arXiv:2106.01862v2 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01862">
<div class="article-summary-box-inner">
<span><p>The field of neuromorphic computing promises extremely low-power and
low-latency sensing and processing. Challenges in transferring learning
algorithms from traditional artificial neural networks (ANNs) to spiking neural
networks (SNNs) have so far prevented their application to large-scale, complex
regression tasks. Furthermore, realizing a truly asynchronous and fully
neuromorphic pipeline that maximally attains the abovementioned benefits
involves rethinking the way in which this pipeline takes in and accumulates
information. In the case of perception, spikes would be passed as-is and
one-by-one between an event camera and an SNN, meaning all temporal integration
of information must happen inside the network. In this article, we tackle these
two problems. We focus on the complex task of learning to estimate optical flow
from event-based camera inputs in a self-supervised manner, and modify the
state-of-the-art ANN training pipeline to encode minimal temporal information
in its inputs. Moreover, we reformulate the self-supervised loss function for
event-based optical flow to improve its convexity. We perform experiments with
various types of recurrent ANNs and SNNs using the proposed pipeline.
Concerning SNNs, we investigate the effects of elements such as parameter
initialization and optimization, surrogate gradient shape, and adaptive
neuronal mechanisms. We find that initialization and surrogate gradient width
play a crucial part in enabling learning with sparse inputs, while the
inclusion of adaptivity and learnable neuronal parameters can improve
performance. We show that the performance of the proposed ANNs and SNNs are on
par with that of the current state-of-the-art ANNs trained in a self-supervised
manner.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-10-27 23:02:57.016776833 UTC">2021-10-27 23:02:57 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.6</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>