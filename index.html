<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-07-01T01:30:00Z">07-01</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Solving Quantitative Reasoning Problems with Language Models. (arXiv:2206.14858v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14858">
<div class="article-summary-box-inner">
<span><p>Language models have achieved remarkable performance on a wide range of tasks
that require natural language understanding. Nevertheless, state-of-the-art
models have generally struggled with tasks that require quantitative reasoning,
such as solving mathematics, science, and engineering problems at the college
level. To help close this gap, we introduce Minerva, a large language model
pretrained on general natural language data and further trained on technical
content. The model achieves state-of-the-art performance on technical
benchmarks without the use of external tools. We also evaluate our model on
over two hundred undergraduate-level problems in physics, biology, chemistry,
economics, and other sciences that require quantitative reasoning, and find
that the model can correctly answer nearly a third of them.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Space-Efficient Representation of Entity-centric Query Language Models. (arXiv:2206.14885v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14885">
<div class="article-summary-box-inner">
<span><p>Virtual assistants make use of automatic speech recognition (ASR) to help
users answer entity-centric queries. However, spoken entity recognition is a
difficult problem, due to the large number of frequently-changing named
entities. In addition, resources available for recognition are constrained when
ASR is performed on-device.
</p>
<p>In this work, we investigate the use of probabilistic grammars as language
models within the finite-state transducer (FST) framework. We introduce a
deterministic approximation to probabilistic grammars that avoids the explicit
expansion of non-terminals at model creation time, integrates directly with the
FST framework, and is complementary to n-gram models.
</p>
<p>We obtain a 10% relative word error rate improvement on long tail entity
queries compared to when a similarly-sized n-gram model is used without our
method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GPTs at Factify 2022: Prompt Aided Fact-Verification. (arXiv:2206.14913v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14913">
<div class="article-summary-box-inner">
<span><p>One of the most pressing societal issues is the fight against false news. The
false claims, as difficult as they are to expose, create a lot of damage. To
tackle the problem, fact verification becomes crucial and thus has been a topic
of interest among diverse research communities. Using only the textual form of
data we propose our solution to the problem and achieve competitive results
with other approaches. We present our solution based on two approaches - PLM
(pre-trained language model) based method and Prompt based method. The
PLM-based approach uses the traditional supervised learning, where the model is
trained to take 'x' as input and output prediction 'y' as P(y|x). Whereas,
Prompt-based learning reflects the idea to design input to fit the model such
that the original objective may be re-framed as a problem of (masked) language
modeling. We may further stimulate the rich knowledge provided by PLMs to
better serve downstream tasks by employing extra prompts to fine-tune PLMs. Our
experiments showed that the proposed method performs better than just
fine-tuning PLMs. We achieved an F1 score of 0.6946 on the FACTIFY dataset and
a 7th position on the competition leader-board.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Masked Part-Of-Speech Model: Does Modeling Long Context Help Unsupervised POS-tagging?. (arXiv:2206.14969v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14969">
<div class="article-summary-box-inner">
<span><p>Previous Part-Of-Speech (POS) induction models usually assume certain
independence assumptions (e.g., Markov, unidirectional, local dependency) that
do not hold in real languages. For example, the subject-verb agreement can be
both long-term and bidirectional. To facilitate flexible dependency modeling,
we propose a Masked Part-of-Speech Model (MPoSM), inspired by the recent
success of Masked Language Models (MLM). MPoSM can model arbitrary tag
dependency and perform POS induction through the objective of masked POS
reconstruction. We achieve competitive results on both the English Penn WSJ
dataset as well as the universal treebank containing 10 diverse languages.
Though modeling the long-term dependency should ideally help this task, our
ablation study shows mixed trends in different languages. To better understand
this phenomenon, we design a novel synthetic experiment that can specifically
diagnose the model's ability to learn tag agreement. Surprisingly, we find that
even strong baselines fail to solve this problem consistently in a very
simplified setting: the agreement between adjacent words. Nonetheless, MPoSM
achieves overall better performance. Lastly, we conduct a detailed error
analysis to shed light on other remaining challenges. Our code is available at
https://github.com/owenzx/MPoSM
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Building Multilingual Machine Translation Systems That Serve Arbitrary X-Y Translations. (arXiv:2206.14982v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14982">
<div class="article-summary-box-inner">
<span><p>Multilingual Neural Machine Translation (MNMT) enables one system to
translate sentences from multiple source languages to multiple target
languages, greatly reducing deployment costs compared with conventional
bilingual systems. The MNMT training benefit, however, is often limited to
many-to-one directions. The model suffers from poor performance in one-to-many
and many-to-many with zero-shot setup. To address this issue, this paper
discusses how to practically build MNMT systems that serve arbitrary X-Y
translation directions while leveraging multilinguality with a two-stage
training strategy of pretraining and finetuning. Experimenting with the WMT'21
multilingual translation task, we demonstrate that our systems outperform the
conventional baselines of direct bilingual models and pivot translation models
for most directions, averagely giving +6.0 and +4.1 BLEU, without the need for
architecture change or extra data collection. Moreover, we also examine our
proposed approach in an extremely large-scale data setting to accommodate
practical deployment scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GSCLIP : A Framework for Explaining Distribution Shifts in Natural Language. (arXiv:2206.15007v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15007">
<div class="article-summary-box-inner">
<span><p>Helping end users comprehend the abstract distribution shifts can greatly
facilitate AI deployment. Motivated by this, we propose a novel task, dataset
explanation. Given two image data sets, dataset explanation aims to
automatically point out their dataset-level distribution shifts with natural
language. Current techniques for monitoring distribution shifts provide
inadequate information to understand datasets with the goal of improving data
quality. Therefore, we introduce GSCLIP, a training-free framework to solve the
dataset explanation task. In GSCLIP, we propose the selector as the first
quantitative evaluation method to identify explanations that are proper to
summarize dataset shifts. Furthermore, we leverage this selector to demonstrate
the superiority of a generator based on language model generation. Systematic
evaluation on natural data shift verifies that GSCLIP, a combined system of a
hybrid generator group and an efficient selector is not only easy-to-use but
also powerful for dataset explanation at scale.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"Diversity and Uncertainty in Moderation" are the Key to Data Selection for Multilingual Few-shot Transfer. (arXiv:2206.15010v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15010">
<div class="article-summary-box-inner">
<span><p>Few-shot transfer often shows substantial gain over zero-shot
transfer~\cite{lauscher2020zero}, which is a practically useful trade-off
between fully supervised and unsupervised learning approaches for multilingual
pretrained model-based systems. This paper explores various strategies for
selecting data for annotation that can result in a better few-shot transfer.
The proposed approaches rely on multiple measures such as data entropy using
$n$-gram language model, predictive entropy, and gradient embedding. We propose
a loss embedding method for sequence labeling tasks, which induces diversity
and uncertainty sampling similar to gradient embedding. The proposed data
selection strategies are evaluated and compared for POS tagging, NER, and NLI
tasks for up to 20 languages. Our experiments show that the gradient and loss
embedding-based strategies consistently outperform random data selection
baselines, with gains varying with the initial performance of the zero-shot
transfer. Furthermore, the proposed method shows similar trends in improvement
even when the model is fine-tuned using a lower proportion of the original
task-specific labeled training data for zero-shot transfer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Compressing Pre-trained Transformers via Low-Bit NxM Sparsity for Natural Language Understanding. (arXiv:2206.15014v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15014">
<div class="article-summary-box-inner">
<span><p>In recent years, large pre-trained Transformer networks have demonstrated
dramatic improvements in many natural language understanding tasks. However,
the huge size of these models brings significant challenges to their
fine-tuning and online deployment due to latency and cost constraints. New
hardware supporting both N:M semi-structured sparsity and low-precision integer
computation is a promising solution to boost DNN model serving efficiency.
However, there have been very few studies that systematically investigate to
what extent pre-trained Transformer networks benefit from the combination of
these techniques, as well as how to best compress each component of the
Transformer. We propose a flexible compression framework NxMiFormer that
performs simultaneous sparsification and quantization using ADMM and STE-based
QAT. Furthermore, we present and inexpensive, heuristic-driven search algorithm
that identifies promising heterogeneous compression configurations that meet a
compression ratio constraint. When evaluated across the GLUE suite of NLU
benchmarks, our approach can achieve up to 93% compression of the encoders of a
BERT model while retaining 98.2% of the original model accuracy and taking full
advantage of the hardware's capabilities. Heterogeneous configurations found
the by the search heuristic maintain 99.5% of the baseline accuracy while still
compressing the model by 87.5%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modern Question Answering Datasets and Benchmarks: A Survey. (arXiv:2206.15030v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15030">
<div class="article-summary-box-inner">
<span><p>Question Answering (QA) is one of the most important natural language
processing (NLP) tasks. It aims using NLP technologies to generate a
corresponding answer to a given question based on the massive unstructured
corpus. With the development of deep learning, more and more challenging QA
datasets are being proposed, and lots of new methods for solving them are also
emerging. In this paper, we investigate influential QA datasets that have been
released in the era of deep learning. Specifically, we begin with introducing
two of the most common QA tasks - textual question answer and visual question
answering - separately, covering the most representative datasets, and then
give some current challenges of QA research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Story-thinking, computational-thinking, programming and software engineering. (arXiv:2206.15066v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15066">
<div class="article-summary-box-inner">
<span><p>Working with stories and working with computations require very different
modes of thought. We call the first mode "story-thinking" and the second
"computational-thinking". The aim of this curiosity-driven paper is to explore
the nature of these two modes of thinking, and to do so in relation to
programming, including software engineering as programming-in-the-large. We
suggest that story-thinking and computational-thinking may be understood as two
ways of attending to the world, and that each both contributes and neglects the
world, though in different ways and for different ends. We formulate two
fundamental problems, i.e., the problem of "neglectful representations" and the
problem of oppositional ways of thinking. We briefly suggest two ways in which
these problems might be tackled and identify candidate hypotheses about the
current state of the world, one assertion about a possible future state, and
several research questions for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BigBIO: A Framework for Data-Centric Biomedical Natural Language Processing. (arXiv:2206.15076v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15076">
<div class="article-summary-box-inner">
<span><p>Training and evaluating language models increasingly requires the
construction of meta-datasets --diverse collections of curated data with clear
provenance. Natural language prompting has recently lead to improved zero-shot
generalization by transforming existing, supervised datasets into a diversity
of novel pretraining tasks, highlighting the benefits of meta-dataset curation.
While successful in general-domain text, translating these data-centric
approaches to biomedical language modeling remains challenging, as labeled
biomedical datasets are significantly underrepresented in popular data hubs. To
address this challenge, we introduce BigBIO a community library of 126+
biomedical NLP datasets, currently covering 12 task categories and 10+
languages. BigBIO facilitates reproducible meta-dataset curation via
programmatic access to datasets and their metadata, and is compatible with
current platforms for prompt engineering and end-to-end few/zero shot language
model evaluation. We discuss our process for task schema harmonization, data
auditing, contribution guidelines, and outline two illustrative use cases:
zero-shot evaluation of biomedical prompts and large-scale, multi-task
learning. BigBIO is an ongoing community effort and is available at
https://github.com/bigscience-workshop/biomedical
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">esCorpius: A Massive Spanish Crawling Corpus. (arXiv:2206.15147v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15147">
<div class="article-summary-box-inner">
<span><p>In the recent years, transformer-based models have lead to significant
advances in language modelling for natural language processing. However, they
require a vast amount of data to be (pre-)trained and there is a lack of
corpora in languages other than English. Recently, several initiatives have
presented multilingual datasets obtained from automatic web crawling. However,
the results in Spanish present important shortcomings, as they are either too
small in comparison with other languages, or present a low quality derived from
sub-optimal cleaning and deduplication. In this paper, we introduce
\textsc{esCorpius}, a Spanish crawling corpus obtained from near 1 Pb of Common
Crawl data. It is the most extensive corpus in Spanish with this level of
quality in the extraction, purification and deduplication of web textual
content. Our data curation process involves a novel highly parallel cleaning
pipeline and encompasses a series of deduplication mechanisms that together
ensure the integrity of both document and paragraph boundaries. Additionally,
we maintain both the source web page URL and the WARC shard origin URL in order
to complain with EU regulations. \textsc{esCorpius} has been released under CC
BY-NC-ND 4.0 license and is available on HuggingFace.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Entity Candidate Generation for Low-Resource Languages. (arXiv:2206.15163v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15163">
<div class="article-summary-box-inner">
<span><p>Candidate generation is a crucial module in entity linking. It also plays a
key role in multiple NLP tasks that have been proven to beneficially leverage
knowledge bases. Nevertheless, it has often been overlooked in the monolingual
English entity linking literature, as naive approaches obtain very good
performance. Unfortunately, the existing approaches for English cannot be
successfully transferred to poorly resourced languages. This paper constitutes
an in-depth analysis of the candidate generation problem in the context of
cross-lingual entity linking with a focus on low-resource languages. Among
other contributions, we point out limitations in the evaluation conducted in
previous works. We introduce a characterization of queries into types based on
their difficulty, which improves the interpretability of the performance of
different methods. We also propose a light-weight and simple solution based on
the construction of indexes whose design is motivated by more complex transfer
learning based neural approaches. A thorough empirical analysis on 9 real-world
datasets under 2 evaluation settings shows that our simple solution outperforms
the state-of-the-art approach in terms of both quality and efficiency for
almost all datasets and query types.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Topological BERT: Transforming Attention into Topology for Natural Language Processing. (arXiv:2206.15195v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15195">
<div class="article-summary-box-inner">
<span><p>In recent years, the introduction of the Transformer models sparked a
revolution in natural language processing (NLP). BERT was one of the first text
encoders using only the attention mechanism without any recurrent parts to
achieve state-of-the-art results on many NLP tasks.
</p>
<p>This paper introduces a text classifier using topological data analysis. We
use BERT's attention maps transformed into attention graphs as the only input
to that classifier. The model can solve tasks such as distinguishing spam from
ham messages, recognizing whether a sentence is grammatically correct, or
evaluating a movie review as negative or positive. It performs comparably to
the BERT baseline and outperforms it on some tasks.
</p>
<p>Additionally, we propose a new method to reduce the number of BERT's
attention heads considered by the topological classifier, which allows us to
prune the number of heads from 144 down to as few as ten with no reduction in
performance. Our work also shows that the topological model displays higher
robustness against adversarial attacks than the original BERT model, which is
maintained during the pruning process. To the best of our knowledge, this work
is the first to confront topological-based models with adversarial attacks in
the context of NLP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Adaptive Pretraining for Multilingual Acronym Extraction. (arXiv:2206.15221v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15221">
<div class="article-summary-box-inner">
<span><p>This paper presents our findings from participating in the multilingual
acronym extraction shared task SDU@AAAI-22. The task consists of acronym
extraction from documents in 6 languages within scientific and legal domains.
To address multilingual acronym extraction we employed BiLSTM-CRF with
multilingual XLM-RoBERTa embeddings. We pretrained the XLM-RoBERTa model on the
shared task corpus to further adapt XLM-RoBERTa embeddings to the shared task
domain(s). Our system (team: SMR-NLP) achieved competitive performance for
acronym extraction across all the languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FL-Tuning: Layer Tuning for Feed-Forward Network in Transformer. (arXiv:2206.15312v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15312">
<div class="article-summary-box-inner">
<span><p>Prompt tuning is an emerging way of adapting pre-trained language models to
downstream tasks. However, the existing studies are mainly to add prompts to
the input sequence. This way would not work as expected due to the intermediate
multi-head self-attention and feed-forward network computation, making model
optimization not very smooth. Hence, we propose a novel tuning way called layer
tuning, aiming to add learnable parameters in Transformer layers. Specifically,
we focus on layer tuning for feed-forward network in the Transformer, namely
FL-tuning. It introduces additional units into the hidden layer of each
feed-forward network. We conduct extensive experiments on the public CLUE
benchmark. The results show that: 1) Our FL-tuning outperforms prompt tuning
methods under both full-data and few-shot settings in almost all cases. In
particular, it improves accuracy by 17.93% (full-data setting) on WSC 1.0 and
F1 by 16.142% (few-shot setting) on CLUENER over P-tuning v2. 2) Our FL-tuning
is more stable and converges about 1.17 times faster than P-tuning v2. 3) With
only about 3% of Transformer's parameters to be trained, FL-tuning is
comparable with fine-tuning on most datasets, and significantly outperforms
fine-tuning (e.g., accuracy improved by 12.9% on WSC 1.1) on several datasets.
The source codes are available at https://github.com/genggui001/FL-Tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Two-Stage Classifier for COVID-19 Misinformation Detection Using BERT: a Study on Indonesian Tweets. (arXiv:2206.15359v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15359">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic has caused globally significant impacts since the
beginning of 2020. This brought a lot of confusion to society, especially due
to the spread of misinformation through social media. Although there were
already several studies related to the detection of misinformation in social
media data, most studies focused on the English dataset. Research on COVID-19
misinformation detection in Indonesia is still scarce. Therefore, through this
research, we collect and annotate datasets for Indonesian and build prediction
models for detecting COVID-19 misinformation by considering the tweet's
relevance. The dataset construction is carried out by a team of annotators who
labeled the relevance and misinformation of the tweet data. In this study, we
propose the two-stage classifier model using IndoBERT pre-trained language
model for the Tweet misinformation detection task. We also experiment with
several other baseline models for text classification. The experimental results
show that the combination of the BERT sequence classifier for relevance
prediction and Bi-LSTM for misinformation detection outperformed other machine
learning models with an accuracy of 87.02%. Overall, the BERT utilization
contributes to the higher performance of most prediction models. We release a
high-quality COVID-19 misinformation Tweet corpus in the Indonesian language,
indicated by the high inter-annotator agreement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Visual grounding of abstract and concrete words: A response to G\"unther et al. (2020). (arXiv:2206.15381v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15381">
<div class="article-summary-box-inner">
<span><p>Current computational models capturing words' meaning mostly rely on textual
corpora. While these approaches have been successful over the last decades,
their lack of grounding in the real world is still an ongoing problem. In this
paper, we focus on visual grounding of word embeddings and target two important
questions. First, how can language benefit from vision in the process of visual
grounding? And second, is there a link between visual grounding and abstract
concepts? We investigate these questions by proposing a simple yet effective
approach where language benefits from vision specifically with respect to the
modeling of both concrete and abstract words. Our model aligns word embeddings
with their corresponding visual representation without deteriorating the
knowledge captured by textual distributional information. We apply our model to
a behavioral experiment reported by G\"unther et al. (2020), which addresses
the plausibility of having visual mental representations for abstract words.
Our evaluation results show that: (1) It is possible to predict human behaviour
to a large degree using purely textual embeddings. (2) Our grounded embeddings
model human behavior better compared to their textual counterparts. (3)
Abstract concepts benefit from visual grounding implicitly through their
connections to concrete concepts, rather than from having corresponding visual
representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hate Speech Criteria: A Modular Approach to Task-Specific Hate Speech Definitions. (arXiv:2206.15455v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15455">
<div class="article-summary-box-inner">
<span><p>\textbf{Offensive Content Warning}: This paper contains offensive language
only for providing examples that clarify this research and do not reflect the
authors' opinions. Please be aware that these examples are offensive and may
cause you distress.
</p>
<p>The subjectivity of recognizing \textit{hate speech} makes it a complex task.
This is also reflected by different and incomplete definitions in NLP. We
present \textit{hate speech} criteria, developed with perspectives from law and
social science, with the aim of helping researchers create more precise
definitions and annotation guidelines on five aspects: (1) target groups, (2)
dominance, (3) perpetrator characteristics, (4) type of negative group
reference, and the (5) type of potential consequences/effects. Definitions can
be structured so that they cover a more broad or more narrow phenomenon. As
such, conscious choices can be made on specifying criteria or leaving them
open. We argue that the goal and exact task developers have in mind should
determine how the scope of \textit{hate speech} is defined. We provide an
overview of the properties of English datasets from \url{hatespeechdata.com}
that may help select the most suitable dataset for a specific scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Visual Grounding by Encouraging Consistent Gradient-based Explanations. (arXiv:2206.15462v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15462">
<div class="article-summary-box-inner">
<span><p>We propose a margin-based loss for vision-language model pretraining that
encourages gradient-based explanations that are consistent with region-level
annotations. We refer to this objective as Attention Mask Consistency (AMC) and
demonstrate that it produces superior visual grounding performance compared to
models that rely instead on region-level annotations for explicitly training an
object detector such as Faster R-CNN. AMC works by encouraging gradient-based
explanation masks that focus their attention scores mostly within annotated
regions of interest for images that contain such annotations. Particularly, a
model trained with AMC on top of standard vision-language modeling objectives
obtains a state-of-the-art accuracy of 86.59% in the Flickr30k visual grounding
benchmark, an absolute improvement of 5.48% when compared to the best previous
model. Our approach also performs exceedingly well on established benchmarks
for referring expression comprehension and offers the added benefit by design
of gradient-based explanations that better align with human annotations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Forecasting Future World Events with Neural Networks. (arXiv:2206.15474v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15474">
<div class="article-summary-box-inner">
<span><p>Forecasting future world events is a challenging but valuable task. Forecasts
of climate, geopolitical conflict, pandemics and economic indicators help shape
policy and decision making. In these domains, the judgment of expert humans
contributes to the best forecasts. Given advances in language modeling, can
these forecasts be automated? To this end, we introduce Autocast, a dataset
containing thousands of forecasting questions and an accompanying news corpus.
Questions are taken from forecasting tournaments, ensuring high quality,
real-world importance, and diversity. The news corpus is organized by date,
allowing us to precisely simulate the conditions under which humans made past
forecasts (avoiding leakage from the future). Motivated by the difficulty of
forecasting numbers across orders of magnitude (e.g. global cases of COVID-19
in 2022), we also curate IntervalQA, a dataset of numerical questions and
metrics for calibration. We test language models on our forecasting task and
find that performance is far below a human expert baseline. However,
performance improves with increased model size and incorporation of relevant
information from the news corpus. In sum, Autocast poses a novel challenge for
large language models and improved performance could bring large practical
benefits.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NewsEdits: A Dataset of Revision Histories for News Articles (Technical Report: Data Processing). (arXiv:2104.09647v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09647">
<div class="article-summary-box-inner">
<span><p>News article revision histories have the potential to give us novel insights
across varied fields of linguistics and social sciences. In this work, we
present, to our knowledge, the first publicly available dataset of news article
revision histories, or NewsEdits.
</p>
<p>Our dataset is multilingual; it contains 1,278,804 articles with 4,609,430
versions from over 22 English- and French-language newspaper sources based in
three countries. Across version pairs, we count 10.9 million added sentences;
8.9 million changed sentences and 6.8 million removed sentences. Within the
changed sentences, we derive 72 million atomic edits. NewsEdits is, to our
knowledge, the largest corpus of revision histories of any domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StateCensusLaws.org: A Web Application for Consuming and Annotating Legal Discourse Learning. (arXiv:2104.10263v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10263">
<div class="article-summary-box-inner">
<span><p>In this work, we create a web application to highlight the output of NLP
models trained to parse and label discourse segments in law text. Our system is
built primarily with journalists and legal interpreters in mind, and we focus
on state-level law that uses U.S. Census population numbers to allocate
resources and organize government.
</p>
<p>Our system exposes a corpus we collect of 6,000 state-level laws that pertain
to the U.S. census, using 25 scrapers we built to crawl state law websites,
which we release. We also build a novel, flexible annotation framework that can
handle span-tagging and relation tagging on an arbitrary input text document
and be embedded simply into any webpage. This framework allows journalists and
researchers to add to our annotation database by correcting and tagging new
data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Auto Response Generation in Online Medical Chat Services. (arXiv:2104.12755v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12755">
<div class="article-summary-box-inner">
<span><p>Telehealth helps to facilitate access to medical professionals by enabling
remote medical services for the patients. These services have become gradually
popular over the years with the advent of necessary technological
infrastructure. The benefits of telehealth have been even more apparent since
the beginning of the COVID-19 crisis, as people have become less inclined to
visit doctors in person during the pandemic. In this paper, we focus on
facilitating the chat sessions between a doctor and a patient. We note that the
quality and efficiency of the chat experience can be critical as the demand for
telehealth services increases. Accordingly, we develop a smart auto-response
generation mechanism for medical conversations that helps doctors respond to
consultation requests efficiently, particularly during busy sessions. We
explore over 900,000 anonymous, historical online messages between doctors and
patients collected over nine months. We implement clustering algorithms to
identify the most frequent responses by doctors and manually label the data
accordingly. We then train machine learning algorithms using this preprocessed
data to generate the responses. The considered algorithm has two steps: a
filtering (i.e., triggering) model to filter out infeasible patient messages
and a response generator to suggest the top-3 doctor responses for the ones
that successfully pass the triggering phase. The method provides an accuracy of
83.28\% for precision@3 and shows robustness to its parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-Grounded Self-Rationalization via Extractive and Natural Language Explanations. (arXiv:2106.13876v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13876">
<div class="article-summary-box-inner">
<span><p>Models that generate extractive rationales (i.e., subsets of features) or
natural language explanations (NLEs) for their predictions are important for
explainable AI. While an extractive rationale provides a quick view of the
features most responsible for a prediction, an NLE allows for a comprehensive
description of the decision-making process behind a prediction. However,
current models that generate the best extractive rationales or NLEs often fall
behind the state-of-the-art (SOTA) in terms of task performance. In this work,
we bridge this gap by introducing RExC, a self-rationalizing framework that
grounds its predictions and two complementary types of explanations (NLEs and
extractive rationales) in background knowledge. Our framework improves over
previous methods by: (i) reaching SOTA task performance while also providing
explanations, (ii) providing two types of explanations, while existing models
usually provide only one type, and (iii) beating by a large margin the previous
SOTA in terms of quality of both types of explanations. Furthermore, a
perturbation analysis in RExC shows a high degree of association between
explanations and predictions, a necessary property of faithful explanations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Neural Machine Translation with Dependency-Scaled Self-Attention Network. (arXiv:2111.11707v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.11707">
<div class="article-summary-box-inner">
<span><p>Syntax knowledge contributes its powerful strength in Neural machine
translation (NMT) tasks. Early NMT works supposed that syntax details can be
automatically learned from numerous texts via attention networks. However,
succeeding researches pointed out that limited by the uncontrolled nature of
attention computation, the NMT model requires an external syntax to capture the
deep syntactic awareness. Although existing syntax-aware NMT methods have bored
great fruits in combining syntax, the additional workloads they introduced
render the model heavy and slow. Particularly, these efforts scarcely involve
the Transformer-based NMT and modify its core self-attention network (SAN). To
this end, we propose a parameter-free, dependency-scaled self-attention network
(Deps-SAN) for syntax-aware Transformer-based NMT. A quantified matrix of
dependency closeness between tokens is constructed to impose explicit syntactic
constraints into the SAN for learning syntactic details and dispelling the
dispersion of attention distributions. Two knowledge sparsing techniques are
further integrated to avoid the model overfitting the dependency noises
introduce by the external parser. Experiments and analyses on IWSLT14
German-to-English and WMT16 German-to-English benchmark NMT tasks verify the
effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Supervised Visual Attention for Simultaneous Multimodal Machine Translation. (arXiv:2201.09324v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.09324">
<div class="article-summary-box-inner">
<span><p>Recently, there has been a surge in research in multimodal machine
translation (MMT), where additional modalities such as images are used to
improve translation quality of textual systems. A particular use for such
multimodal systems is the task of simultaneous machine translation, where
visual context has been shown to complement the partial information provided by
the source sentence, especially in the early phases of translation. In this
paper, we propose the first Transformer-based simultaneous MMT architecture,
which has not been previously explored in the field. Additionally, we extend
this model with an auxiliary supervision signal that guides its visual
attention mechanism using labelled phrase-region alignments. We perform
comprehensive experiments on three language directions and conduct thorough
quantitative and qualitative analyses using both automatic metrics and manual
inspection. Our results show that (i) supervised visual attention consistently
improves the translation quality of the MMT models, and (ii) fine-tuning the
MMT with supervision loss enabled leads to better performance than training the
MMT from scratch. Compared to the state-of-the-art, our proposed model achieves
improvements of up to 2.3 BLEU and 3.5 METEOR points.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Learning with Random-projection Quantizer for Speech Recognition. (arXiv:2202.01855v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.01855">
<div class="article-summary-box-inner">
<span><p>We present a simple and effective self-supervised learning approach for
speech recognition. The approach learns a model to predict the masked speech
signals, in the form of discrete labels generated with a random-projection
quantizer. In particular the quantizer projects speech inputs with a randomly
initialized matrix, and does a nearest-neighbor lookup in a
randomly-initialized codebook. Neither the matrix nor the codebook is updated
during self-supervised learning. Since the random-projection quantizer is not
trained and is separated from the speech recognition model, the design makes
the approach flexible and is compatible with universal speech recognition
architecture. On LibriSpeech our approach achieves similar word-error-rates as
previous work using self-supervised learning with non-streaming models, and
provides lower word-error-rates and latency than wav2vec 2.0 and w2v-BERT with
streaming models. On multilingual tasks the approach also provides significant
improvement over wav2vec 2.0 and w2v-BERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is Neuro-Symbolic AI Meeting its Promise in Natural Language Processing? A Structured Review. (arXiv:2202.12205v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.12205">
<div class="article-summary-box-inner">
<span><p>Advocates for Neuro-Symbolic Artificial Intelligence (NeSy) assert that
combining deep learning with symbolic reasoning will lead to stronger AI than
either paradigm on its own. As successful as deep learning has been, it is
generally accepted that even our best deep learning systems are not very good
at abstract reasoning. And since reasoning is inextricably linked to language,
it makes intuitive sense that Natural Language Processing (NLP), would be a
particularly well-suited candidate for NeSy. We conduct a structured review of
studies implementing NeSy for NLP, with the aim of answering the question of
whether NeSy is indeed meeting its promises: reasoning, out-of-distribution
generalization, interpretability, learning and reasoning from small data, and
transferability to new domains. We examine the impact of knowledge
representation, such as rules and semantic networks, language structure and
relational structure, and whether implicit or explicit reasoning contributes to
higher promise scores. We find that systems where logic is compiled into the
neural network lead to the most NeSy goals being satisfied, while other factors
such as knowledge representation, or type of neural architecture do not exhibit
a clear correlation with goals being met. We find many discrepancies in how
reasoning is defined, specifically in relation to human level reasoning, which
impact decisions about model architectures and drive conclusions which are not
always consistent across studies. Hence we advocate for a more methodical
approach to the application of theories of human reasoning as well as the
development of appropriate benchmarks, which we hope can lead to a better
understanding of progress in the field. We make our data and code available on
github for further analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mapping global dynamics of benchmark creation and saturation in artificial intelligence. (arXiv:2203.04592v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.04592">
<div class="article-summary-box-inner">
<span><p>Benchmarks are crucial to measuring and steering progress in artificial
intelligence (AI). However, recent studies raised concerns over the state of AI
benchmarking, reporting issues such as benchmark overfitting, benchmark
saturation and increasing centralization of benchmark dataset creation. To
facilitate monitoring of the health of the AI benchmarking ecosystem, we
introduce methodologies for creating condensed maps of the global dynamics of
benchmark creation and saturation. We curated data for 1688 benchmarks covering
the entire domains of computer vision and natural language processing, and show
that a large fraction of benchmarks quickly trended towards near-saturation,
that many benchmarks fail to find widespread utilization, and that benchmark
performance gains for different AI tasks were prone to unforeseen bursts. We
analyze attributes associated with benchmark popularity, and conclude that
future benchmarks should emphasize versatility, breadth and real-world utility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Speech recognition for Speech Assessment of Persian Preschool Children. (arXiv:2203.12886v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.12886">
<div class="article-summary-box-inner">
<span><p>Preschool evaluation is crucial because it gives teachers and parents crucial
knowledge about a children's growth and development. The coronavirus pandemic
has highlighted the necessity for preschool children to be assessed online.
This online testing requires a variety of technologies, from web application
development to various artificial intelligence models in diverse criteria such
as speech recognition. Because of the acoustic fluctuations and differences in
voice frequencies between children and adults, employing Automatic Speech
Recognition(ASR) systems is difficult because they are pre-trained on adults'
voices. In addition, training a new model requires a large amount of data. To
solve this issue, we constructed an ASR for our cognitive test system using the
Wav2Vec 2.0 model with a new pre-training objective, called Random Frequency
Pitch(RFP), and our new dataset, which was tested on Meaningless Words(MW) and
Rapid Automatic Naming(RAN) tests. Due to the peculiarities of these two tests,
we explored numerous models, including Convolutional Neural Network(CNN) and
Wav2Vec 2.0 models. Our new approach, reaches Word Error Rate(WER) of 6.45 on
the Persian section of CommonVoice dataset. Furthermore our novel methodology
produces positive outcomes in zero- and few-shot scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rainbow Keywords: Efficient Incremental Learning for Online Spoken Keyword Spotting. (arXiv:2203.16361v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.16361">
<div class="article-summary-box-inner">
<span><p>Catastrophic forgetting is a thorny challenge when updating keyword spotting
(KWS) models after deployment. This problem will be more challenging if KWS
models are further required for edge devices due to their limited memory. To
alleviate such an issue, we propose a novel diversity-aware incremental
learning method named Rainbow Keywords (RK). Specifically, the proposed RK
approach introduces a diversity-aware sampler to select a diverse set from
historical and incoming keywords by calculating classification uncertainty. As
a result, the RK approach can incrementally learn new tasks without forgetting
prior knowledge. Besides, the RK approach also proposes data augmentation and
knowledge distillation loss function for efficient memory management on the
edge device. Experimental results show that the proposed RK approach achieves
4.2% absolute improvement in terms of average accuracy over the best baseline
on Google Speech Command dataset with less required memory. The scripts are
available on GitHub.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mixed-Phoneme BERT: Improving BERT with Mixed Phoneme and Sup-Phoneme Representations for Text to Speech. (arXiv:2203.17190v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.17190">
<div class="article-summary-box-inner">
<span><p>Recently, leveraging BERT pre-training to improve the phoneme encoder in text
to speech (TTS) has drawn increasing attention. However, the works apply
pre-training with character-based units to enhance the TTS phoneme encoder,
which is inconsistent with the TTS fine-tuning that takes phonemes as input.
Pre-training only with phonemes as input can alleviate the input mismatch but
lack the ability to model rich representations and semantic information due to
limited phoneme vocabulary. In this paper, we propose MixedPhoneme BERT, a
novel variant of the BERT model that uses mixed phoneme and sup-phoneme
representations to enhance the learning capability. Specifically, we merge the
adjacent phonemes into sup-phonemes and combine the phoneme sequence and the
merged sup-phoneme sequence as the model input, which can enhance the model
capacity to learn rich contextual representations. Experiment results
demonstrate that our proposed Mixed-Phoneme BERT significantly improves the TTS
performance with 0.30 CMOS gain compared with the FastSpeech 2 baseline. The
Mixed-Phoneme BERT achieves 3x inference speedup and similar voice quality to
the previous TTS pre-trained model PnG BERT
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CL-XABSA: Contrastive Learning for Cross-lingual Aspect-based Sentiment Analysis. (arXiv:2204.00791v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.00791">
<div class="article-summary-box-inner">
<span><p>As an extensive research in the field of natural language processing (NLP),
aspect-based sentiment analysis (ABSA) is the task of predicting the sentiment
expressed in a text relative to the corresponding aspect. Unfortunately, most
languages lack sufficient annotation resources, thus more and more recent
researchers focus on cross-lingual aspect-based sentiment analysis (XABSA).
However, most recent researches only concentrate on cross-lingual data
alignment instead of model alignment. To this end, we propose a novel
framework, CL-XABSA: Contrastive Learning for Cross-lingual Aspect-Based
Sentiment Analysis. Based on contrastive learning, we close the distance
between samples with the same label in different semantic spaces, thus
achieving a convergence of semantic spaces of different languages.
Specifically, we design two contrastive strategies, token level contrastive
learning of token embeddings (TL-CTE) and sentiment level contrastive learning
of token embeddings (SL-CTE), to regularize the semantic space of source and
target language to be more uniform. Since our framework can receive datasets in
multiple languages during training, our framework can be adapted not only for
XABSA task but also for multilingual aspect-based sentiment analysis (MABSA).
To further improve the performance of our model, we perform knowledge
distillation technology leveraging data from unlabeled target language. In the
distillation XABSA task, we further explore the comparative effectiveness of
different data (source dataset, translated dataset, and code-switched dataset).
The results demonstrate that the proposed method has a certain improvement in
the three tasks of XABSA, distillation XABSA and MABSA. For reproducibility,
our code for this paper is available at https://github.com/GKLMIP/CL-XABSA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhanced Direct Speech-to-Speech Translation Using Self-supervised Pre-training and Data Augmentation. (arXiv:2204.02967v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.02967">
<div class="article-summary-box-inner">
<span><p>Direct speech-to-speech translation (S2ST) models suffer from data scarcity
issues as there exists little parallel S2ST data, compared to the amount of
data available for conventional cascaded systems that consist of automatic
speech recognition (ASR), machine translation (MT), and text-to-speech (TTS)
synthesis. In this work, we explore self-supervised pre-training with unlabeled
speech data and data augmentation to tackle this issue. We take advantage of a
recently proposed speech-to-unit translation (S2UT) framework that encodes
target speech into discrete representations, and transfer pre-training and
efficient partial finetuning techniques that work well for speech-to-text
translation (S2T) to the S2UT domain by studying both speech encoder and
discrete unit decoder pre-training. Our experiments on Spanish-English
translation show that self-supervised pre-training consistently improves model
performance compared with multitask learning with an average 6.6-12.1 BLEU
gain, and it can be further combined with data augmentation techniques that
apply MT to create weakly supervised training data. Audio samples are available
at:
https://facebookresearch.github.io/speech_translation/enhanced_direct_s2st_units/index.html .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Production federated keyword spotting via distillation, filtering, and joint federated-centralized training. (arXiv:2204.06322v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.06322">
<div class="article-summary-box-inner">
<span><p>We trained a keyword spotting model using federated learning on real user
devices and observed significant improvements when the model was deployed for
inference on phones. To compensate for data domains that are missing from
on-device training caches, we employed joint federated-centralized training.
And to learn in the absence of curated labels on-device, we formulated a
confidence filtering strategy based on user-feedback signals for federated
distillation. These techniques created models that significantly improved
quality metrics in offline evaluations and user-experience metrics in live A/B
experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Event Linking to Wikidata. (arXiv:2204.06535v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.06535">
<div class="article-summary-box-inner">
<span><p>We present a task of multilingual linking of events to a knowledge base. We
automatically compile a large-scale dataset for this task, comprising of 1.8M
mentions across 44 languages referring to over 10.9K events from Wikidata. We
propose two variants of the event linking task: 1) multilingual, where event
descriptions are from the same language as the mention, and 2) crosslingual,
where all event descriptions are in English. On the two proposed tasks, we
compare multiple event linking systems including BM25+ (Lv and Zhai, 2011) and
multilingual adaptations of the biencoder and crossencoder architectures from
BLINK (Wu et al., 2020). In our experiments on the two task variants, we find
both biencoder and crossencoder models significantly outperform the BM25+
baseline. Our results also indicate that the crosslingual task is in general
more challenging than the multilingual task. To test the out-of-domain
generalization of the proposed linking systems, we additionally create a
Wikinews-based evaluation set. We present qualitative analysis highlighting
various aspects captured by the proposed dataset, including the need for
temporal reasoning over context and tackling diverse event descriptions across
languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploration strategies for articulatory synthesis of complex syllable onsets. (arXiv:2204.09381v2 [cs.SD] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.09381">
<div class="article-summary-box-inner">
<span><p>High-quality articulatory speech synthesis has many potential applications in
speech science and technology. However, developing appropriate mappings from
linguistic specification to articulatory gestures is difficult and time
consuming. In this paper we construct an optimisation-based framework as a
first step towards learning these mappings without manual intervention. We
demonstrate the production of syllables with complex onsets and discuss the
quality of the articulatory gestures with reference to coarticulation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Review on Multiple Plagiarism: A Performance Comparison Study. (arXiv:2206.02983v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.02983">
<div class="article-summary-box-inner">
<span><p>Plagiarism is the practice of claiming to be someone else content, thoughts
or ideas as one own without any proper credit and citations. This paper is a
survey paper that, represent the some of the great research paper and its
comparison that is work done on plagiarism. Now a days, plagiarism became one
of the most interesting and crucial research points in Natural Language
Processing area. We review some old research paper based on different types of
plagiarism detection and their models and algorithm, and comparison of the
accuracy of those papers. There are many several ways which are available for
plagiarism detection in different language. There are a few algorithms to
detecting plagiarism. Like, corpus, CL-CNG, LSI, Levenshtein Distance etc. We
analysis those papers, and learn that they used different types of algorithms
for detecting plagiarism. After experiment those papers, we got that some of
the algorithms give a better output and accuracy for detecting plagiarism. We
are going to give a review on some papers about Plagiarism and will discuss
about the pros and cons of their models. And we also show a propose method for
plagiarism detection method which based on sentience separation, word
separation and make sentence based on synonym and compare with any sources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting Corporate Risk by Jointly Modeling Company Networks and Dialogues in Earnings Conference Calls. (arXiv:2206.06174v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.06174">
<div class="article-summary-box-inner">
<span><p>Earnings conference calls are attracting an increasing number of researchers
due to their free form and rich information. Existing studies, however, do not
take speaker role information into account. Furthermore, current research does
not fully account for the impact of inter-company relationships on company
risk. The only study that integrates company networks and earnings conference
calls constructs an undirected graph for companies holding earnings conference
calls at different dates, failing to meet the requirement of no temporal
information leakage for prediction tasks. To address the aforementioned issues,
we propose a new model called Temporal Virtual Graph Neural Network (TVGNN),
which incorporates earnings conference calls and company networks to predict
company risk. For the first time, our model incorporates participant role
information in dialogue modeling. Moreover, we develop a new approach to
construct company networks that ensures no temporal information leakage in the
graph. In experiments, our proposed model outperforms all baselines. The
supplementary analyses demonstrate the model's effectiveness and
interpretability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Implementing a Chatbot Solution for Learning Management System. (arXiv:2206.13187v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13187">
<div class="article-summary-box-inner">
<span><p>Innovation is a key component in trying new solutions for the students to
learn efficiently and in ways that correspond to their own experience, where
chatbots are one of these new solutions. One of the main problem that chatbots
face today is to mimic human language, where they try to find the best answer
to an input, which is not how a human conversation usually works, rather taking
into account the previous messages and building onto them. Extreme programming
methodology was chosen to use integrate ChatterBot, Pyside2, web scraping and
Tampermonkey into Blackboard as a test case. Problems occurred with the bot and
more training was needed for the bot to work perfectly, but the integration and
web scraping worked, giving us a chatbot that was able to talk with. We showed
the plausibility of integrating an AI bot in an educational setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Long Range Language Modeling via Gated State Spaces. (arXiv:2206.13947v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13947">
<div class="article-summary-box-inner">
<span><p>State space models have shown to be effective at modeling long range
dependencies, specially on sequence classification tasks. In this work we focus
on autoregressive sequence modeling over English books, Github source code and
ArXiv mathematics articles. Based on recent developments around the
effectiveness of gated activation functions, we propose a new layer named Gated
State Space (GSS) and show that it trains significantly faster than the
diagonal version of S4 (i.e. DSS) on TPUs, is fairly competitive with several
well-tuned Transformer-based baselines and exhibits zero-shot generalization to
longer inputs while being straightforward to implement. Finally, we show that
leveraging self-attention to model local dependencies improves the performance
of GSS even further.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Distillation of Transformer-based Language Models Revisited. (arXiv:2206.14366v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14366">
<div class="article-summary-box-inner">
<span><p>In the past few years, transformer-based pre-trained language models have
achieved astounding success in both industry and academia. However, the large
model size and high run-time latency are serious impediments to applying them
in practice, especially on mobile phones and Internet of Things (IoT) devices.
To compress the model, considerable literature has grown up around the theme of
knowledge distillation (KD) recently. Nevertheless, how KD works in
transformer-based models is still unclear. We tease apart the components of KD
and propose a unified KD framework. Through the framework, systematic and
extensive experiments that spent over 23,000 GPU hours render a comprehensive
analysis from the perspectives of knowledge types, matching strategies,
width-depth trade-off, initialization, model size, etc. Our empirical results
shed light on the distillation in the pre-train language model and with
relative significant improvement over previous state-of-the-arts(SOTA).
Finally, we provide a best-practice guideline for the KD in transformer-based
models.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Strong Lensing Source Reconstruction Using Continuous Neural Fields. (arXiv:2206.14820v1 [astro-ph.CO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14820">
<div class="article-summary-box-inner">
<span><p>From the nature of dark matter to the rate of expansion of our Universe,
observations of distant galaxies distorted through strong gravitational lensing
have the potential to answer some of the major open questions in astrophysics.
Modeling galaxy-galaxy strong lensing observations presents a number of
challenges as the exact configuration of both the background source and
foreground lens galaxy is unknown. A timely call, prompted by a number of
upcoming surveys anticipating high-resolution lensing images, demands methods
that can efficiently model lenses at their full complexity. In this work, we
introduce a method that uses continuous neural fields to non-parametrically
reconstruct the complex morphology of a source galaxy while simultaneously
inferring a distribution over foreground lens galaxy configurations. We
demonstrate the efficacy of our method through experiments on simulated data
targeting high-resolution lensing images similar to those anticipated in
near-future astrophysical surveys.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causality for Inherently Explainable Transformers: CAT-XPLAIN. (arXiv:2206.14841v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14841">
<div class="article-summary-box-inner">
<span><p>There have been several post-hoc explanation approaches developed to explain
pre-trained black-box neural networks. However, there is still a gap in
research efforts toward designing neural networks that are inherently
explainable. In this paper, we utilize a recently proposed instance-wise
post-hoc causal explanation method to make an existing transformer architecture
inherently explainable. Once trained, our model provides an explanation in the
form of top-$k$ regions in the input space of the given instance contributing
to its decision. We evaluate our method on binary classification tasks using
three image datasets: MNIST, FMNIST, and CIFAR. Our results demonstrate that
compared to the causality-based post-hoc explainer model, our inherently
explainable model achieves better explainability results while eliminating the
need of training a separate explainer model. Our code is available at
https://github.com/mvrl/CAT-XPLAIN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Reinforcement Learning for Small Bowel Path Tracking using Different Types of Annotations. (arXiv:2206.14847v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14847">
<div class="article-summary-box-inner">
<span><p>Small bowel path tracking is a challenging problem considering its many folds
and contact along its course. For the same reason, it is very costly to achieve
the ground-truth (GT) path of the small bowel in 3D. In this work, we propose
to train a deep reinforcement learning tracker using datasets with different
types of annotations. Specifically, we utilize CT scans that have only GT small
bowel segmentation as well as ones with the GT path. It is enabled by designing
a unique environment that is compatible for both, including a reward definable
even without the GT path. The performed experiments proved the validity of the
proposed method. The proposed method holds a high degree of usability in this
problem by being able to utilize the scans with weak annotations, and thus by
possibly reducing the required annotation cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Motion Fields: Encoding Grasp Trajectories as Implicit Value Functions. (arXiv:2206.14854v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14854">
<div class="article-summary-box-inner">
<span><p>The pipeline of current robotic pick-and-place methods typically consists of
several stages: grasp pose detection, finding inverse kinematic solutions for
the detected poses, planning a collision-free trajectory, and then executing
the open-loop trajectory to the grasp pose with a low-level tracking
controller. While these grasping methods have shown good performance on
grasping static objects on a table-top, the problem of grasping dynamic objects
in constrained environments remains an open problem. We present Neural Motion
Fields, a novel object representation which encodes both object point clouds
and the relative task trajectories as an implicit value function parameterized
by a neural network. This object-centric representation models a continuous
distribution over the SE(3) space and allows us to perform grasping reactively
by leveraging sampling-based MPC to optimize this value function.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Two-Stage COVID19 Classification Using BERT Features. (arXiv:2206.14861v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14861">
<div class="article-summary-box-inner">
<span><p>We propose an automatic COVID1-19 diagnosis framework from lung CT-scan slice
images using double BERT feature extraction. In the first BERT feature
extraction, A 3D-CNN is first used to extract CNN internal feature maps.
Instead of using the global average pooling, a late BERT temporal pooing is
used to aggregate the temporal information in these feature maps, followed by a
classification layer. This 3D-CNN-BERT classification network is first trained
on sampled fixed number of slice images from every original CT scan volume. In
the second stage, the 3D-CNN-BERT embedding features are extracted on all slice
images of every CT scan volume, and these features are averaged into a fixed
number of segments. Then another BERT network is used to aggregate these
multiple features into a single feature followed by another classification
layer. The classification results of both stages are combined to generate final
outputs. On the validation dataset, we achieve macro F1 score of 0.9164.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teach me how to Interpolate a Myriad of Embeddings. (arXiv:2206.14868v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14868">
<div class="article-summary-box-inner">
<span><p>Mixup refers to interpolation-based data augmentation, originally motivated
as a way to go beyond empirical risk minimization (ERM). Yet, its extensions
focus on the definition of interpolation and the space where it takes place,
while the augmentation itself is less studied: For a mini-batch of size $m$,
most methods interpolate between $m$ pairs with a single scalar interpolation
factor $\lambda$.
</p>
<p>In this work, we make progress in this direction by introducing MultiMix,
which interpolates an arbitrary number $n$ of tuples, each of length $m$, with
one vector $\lambda$ per tuple. On sequence data, we further extend to dense
interpolation and loss computation over all spatial positions. Overall, we
increase the number of tuples per mini-batch by orders of magnitude at little
additional cost. This is possible by interpolating at the very last layer
before the classifier. Finally, to address inconsistencies due to linear target
interpolation, we introduce a self-distillation approach to generate and
interpolate synthetic targets.
</p>
<p>We empirically show that our contributions result in significant improvement
over state-of-the-art mixup methods on four benchmarks. By analyzing the
embedding space, we observe that the classes are more tightly clustered and
uniformly spread over the embedding space, thereby explaining the improved
behavior.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Unfolding of StyleGAN Latent Space. (arXiv:2206.14892v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14892">
<div class="article-summary-box-inner">
<span><p>Generative adversarial networks (GANs) have proven to be surprisingly
efficient for image editing by inverting and manipulating the latent code
corresponding to an input real image. This editing property emerges from the
disentangled nature of the latent space. In this paper, we identify that the
facial attribute disentanglement is not optimal, thus facial editing relying on
linear attribute separation is flawed. We thus propose to improve semantic
disentanglement with supervision. Our method consists in learning a proxy
latent representation using normalizing flows, and we show that this leads to a
more efficient space for face image editing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CIRDataset: A large-scale Dataset for Clinically-Interpretable lung nodule Radiomics and malignancy prediction. (arXiv:2206.14903v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14903">
<div class="article-summary-box-inner">
<span><p>Spiculations/lobulations, sharp/curved spikes on the surface of lung nodules,
are good predictors of lung cancer malignancy and hence, are routinely assessed
and reported by radiologists as part of the standardized Lung-RADS clinical
scoring criteria. Given the 3D geometry of the nodule and 2D slice-by-slice
assessment by radiologists, manual spiculation/lobulation annotation is a
tedious task and thus no public datasets exist to date for probing the
importance of these clinically-reported features in the SOTA malignancy
prediction algorithms. As part of this paper, we release a large-scale
Clinically-Interpretable Radiomics Dataset, CIRDataset, containing 956
radiologist QA/QC'ed spiculation/lobulation annotations on segmented lung
nodules from two public datasets, LIDC-IDRI (N=883) and LUNGx (N=73). We also
present an end-to-end deep learning model based on multi-class Voxel2Mesh
extension to segment nodules (while preserving spikes), classify spikes
(sharp/spiculation and curved/lobulation), and perform malignancy prediction.
Previous methods have performed malignancy prediction for LIDC and LUNGx
datasets but without robust attribution to any clinically reported/actionable
features (due to known hyperparameter sensitivity issues with general
attribution schemes). With the release of this comprehensively-annotated
CIRDataset and end-to-end deep learning baseline, we hope that malignancy
prediction methods can validate their explanations, benchmark against our
baseline, and provide clinically-actionable insights. Dataset, code, pretrained
models, and docker containers are available at
https://github.com/nadeemlab/CIR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identifying and Combating Bias in Segmentation Networks by leveraging multiple resolutions. (arXiv:2206.14919v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14919">
<div class="article-summary-box-inner">
<span><p>Exploration of bias has significant impact on the transparency and
applicability of deep learning pipelines in medical settings, yet is so far
woefully understudied. In this paper, we consider two separate groups for which
training data is only available at differing image resolutions. For group H,
available images and labels are at the preferred high resolution while for
group L only deprecated lower resolution data exist. We analyse how this
resolution-bias in the data distribution propagates to systematically biased
predictions for group L at higher resolutions. Our results demonstrate that
single-resolution training settings result in significant loss of volumetric
group differences that translate to erroneous segmentations as measured by DSC
and subsequent classification failures on the low resolution group. We further
explore how training data across resolutions can be used to combat this
systematic bias. Specifically, we investigate the effect of image resampling,
scale augmentation and resolution independence and demonstrate that biases can
effectively be reduced with multi-resolution approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Non-Random Missing Labels in Semi-Supervised Learning. (arXiv:2206.14923v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14923">
<div class="article-summary-box-inner">
<span><p>Semi-Supervised Learning (SSL) is fundamentally a missing label problem, in
which the label Missing Not At Random (MNAR) problem is more realistic and
challenging, compared to the widely-adopted yet naive Missing Completely At
Random assumption where both labeled and unlabeled data share the same class
distribution. Different from existing SSL solutions that overlook the role of
"class" in causing the non-randomness, e.g., users are more likely to label
popular classes, we explicitly incorporate "class" into SSL. Our method is
three-fold: 1) We propose Class-Aware Propensity (CAP) that exploits the
unlabeled data to train an improved classifier using the biased labeled data.
2) To encourage rare class training, whose model is low-recall but
high-precision that discards too many pseudo-labeled data, we propose
Class-Aware Imputation (CAI) that dynamically decreases (or increases) the
pseudo-label assignment threshold for rare (or frequent) classes. 3) Overall,
we integrate CAP and CAI into a Class-Aware Doubly Robust (CADR) estimator for
training an unbiased SSL model. Under various MNAR settings and ablations, our
method not only significantly outperforms existing baselines but also surpasses
other label bias removal SSL methods. Please check our code at:
https://github.com/JoyHuYY1412/CADR-FixMatch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeRF, meet differential geometry!. (arXiv:2206.14938v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14938">
<div class="article-summary-box-inner">
<span><p>Neural radiance fields, or NeRF, represent a breakthrough in the field of
novel view synthesis and 3D modeling of complex scenes from multi-view image
collections. Numerous recent works have been focusing on making the models more
robust, by means of regularization, so as to be able to train with possibly
inconsistent and/or very sparse data. In this work, we scratch the surface of
how differential geometry can provide regularization tools for robustly
training NeRF-like models, which are modified so as to represent continuous and
infinitely differentiable functions. In particular, we show how these tools
yield a direct mathematical formalism of previously proposed NeRF variants
aimed at improving the performance in challenging conditions (i.e. RegNeRF).
Based on this, we show how the same formalism can be used to natively encourage
the regularity of surfaces (by means of Gaussian and Mean Curvatures) making it
possible, for example, to learn surfaces from a very limited number of views.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLTS-GAN: Color-Lighting-Texture-Specular Reflection Augmentation for Colonoscopy. (arXiv:2206.14951v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14951">
<div class="article-summary-box-inner">
<span><p>Automated analysis of optical colonoscopy (OC) video frames (to assist
endoscopists during OC) is challenging due to variations in color, lighting,
texture, and specular reflections. Previous methods either remove some of these
variations via preprocessing (making pipelines cumbersome) or add diverse
training data with annotations (but expensive and time-consuming). We present
CLTS-GAN, a new deep learning model that gives fine control over color,
lighting, texture, and specular reflection synthesis for OC video frames. We
show that adding these colonoscopy-specific augmentations to the training data
can improve state-of-the-art polyp detection/segmentation methods as well as
drive next generation of OC simulators for training medical students. The code
and pre-trained models for CLTS-GAN are available on Computational Endoscopy
Platform GitHub (https://github.com/nadeemlab/CEP).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting 3D Object Detection by Simulating Multimodality on Point Clouds. (arXiv:2206.14971v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14971">
<div class="article-summary-box-inner">
<span><p>This paper presents a new approach to boost a single-modality (LiDAR) 3D
object detector by teaching it to simulate features and responses that follow a
multi-modality (LiDAR-image) detector. The approach needs LiDAR-image data only
when training the single-modality detector, and once well-trained, it only
needs LiDAR data at inference. We design a novel framework to realize the
approach: response distillation to focus on the crucial response samples and
avoid the background samples; sparse-voxel distillation to learn voxel
semantics and relations from the estimated crucial voxels; a fine-grained
voxel-to-point distillation to better attend to features of small and distant
objects; and instance distillation to further enhance the deep-feature
consistency. Experimental results on the nuScenes dataset show that our
approach outperforms all SOTA LiDAR-only 3D detectors and even surpasses the
baseline LiDAR-image detector on the key NDS metric, filling 72% mAP gap
between the single- and multi-modality detectors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Benchmarking the Robustness of Deep Neural Networks to Common Corruptions in Digital Pathology. (arXiv:2206.14973v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14973">
<div class="article-summary-box-inner">
<span><p>When designing a diagnostic model for a clinical application, it is crucial
to guarantee the robustness of the model with respect to a wide range of image
corruptions. Herein, an easy-to-use benchmark is established to evaluate how
deep neural networks perform on corrupted pathology images. Specifically,
corrupted images are generated by injecting nine types of common corruptions
into validation images. Besides, two classification and one ranking metrics are
designed to evaluate the prediction and confidence performance under
corruption. Evaluated on two resulting benchmark datasets, we find that (1) a
variety of deep neural network models suffer from a significant accuracy
decrease (double the error on clean images) and the unreliable confidence
estimation on corrupted images; (2) A low correlation between the validation
and test errors while replacing the validation set with our benchmark can
increase the correlation. Our codes are available on
https://github.com/superjamessyx/robustness_benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Unified End-to-End Retriever-Reader Framework for Knowledge-based VQA. (arXiv:2206.14989v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14989">
<div class="article-summary-box-inner">
<span><p>Knowledge-based Visual Question Answering (VQA) expects models to rely on
external knowledge for robust answer prediction. Though significant it is, this
paper discovers several leading factors impeding the advancement of current
state-of-the-art methods. On the one hand, methods which exploit the explicit
knowledge take the knowledge as a complement for the coarsely trained VQA
model. Despite their effectiveness, these approaches often suffer from noise
incorporation and error propagation. On the other hand, pertaining to the
implicit knowledge, the multi-modal implicit knowledge for knowledge-based VQA
still remains largely unexplored. This work presents a unified end-to-end
retriever-reader framework towards knowledge-based VQA. In particular, we shed
light on the multi-modal implicit knowledge from vision-language pre-training
models to mine its potential in knowledge reasoning. As for the noise problem
encountered by the retrieval operation on explicit knowledge, we design a novel
scheme to create pseudo labels for effective knowledge supervision. This scheme
is able to not only provide guidance for knowledge retrieval, but also drop
these instances potentially error-prone towards question answering. To validate
the effectiveness of the proposed method, we conduct extensive experiments on
the benchmark dataset. The experimental results reveal that our method
outperforms existing baselines by a noticeable margin. Beyond the reported
numbers, this paper further spawns several insights on knowledge utilization
for future research with some empirical findings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-domain Federated Object Detection. (arXiv:2206.14996v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.14996">
<div class="article-summary-box-inner">
<span><p>Detection models trained by one party (server) may face severe performance
degradation when distributed to other users (clients). For example, in
autonomous driving scenarios, different driving environments may bring obvious
domain shifts, which lead to biases in model predictions. Federated learning
that has emerged in recent years can enable multi-party collaborative training
without leaking client data. In this paper, we focus on a special cross-domain
scenario where the server contains large-scale data and multiple clients only
contain a small amount of data; meanwhile, there exist differences in data
distributions among the clients. In this case, traditional federated learning
techniques cannot take into account the learning of both the global knowledge
of all participants and the personalized knowledge of a specific client. To
make up for this limitation, we propose a cross-domain federated object
detection framework, named FedOD. In order to learn both the global knowledge
and the personalized knowledge in different domains, the proposed framework
first performs the federated training to obtain a public global aggregated
model through multi-teacher distillation, and sends the aggregated model back
to each client for finetuning its personalized local model. After very few
rounds of communication, on each client we can perform weighted ensemble
inference on the public global model and the personalized local model. With the
ensemble, the generalization performance of the client-side model can
outperform a single model with the same parameter scale. We establish a
federated object detection dataset which has significant background differences
and instance differences based on multiple public autonomous driving datasets,
and then conduct extensive experiments on the dataset. The experimental results
validate the effectiveness of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatial Transformer Network with Transfer Learning for Small-scale Fine-grained Skeleton-based Tai Chi Action Recognition. (arXiv:2206.15002v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15002">
<div class="article-summary-box-inner">
<span><p>Human action recognition is a quite hugely investigated area where most
remarkable action recognition networks usually use large-scale coarse-grained
action datasets of daily human actions as inputs to state the superiority of
their networks. We intend to recognize our small-scale fine-grained Tai Chi
action dataset using neural networks and propose a transfer-learning method
using NTU RGB+D dataset to pre-train our network. More specifically, the
proposed method first uses a large-scale NTU RGB+D dataset to pre-train the
Transformer-based network for action recognition to extract common features
among human motion. Then we freeze the network weights except for the fully
connected (FC) layer and take our Tai Chi actions as inputs only to train the
initialized FC weights. Experimental results show that our general model
pipeline can reach a high accuracy of small-scale fine-grained Tai Chi action
recognition with even few inputs and demonstrate that our method achieves the
state-of-the-art performance compared with previous Tai Chi action recognition
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GSCLIP : A Framework for Explaining Distribution Shifts in Natural Language. (arXiv:2206.15007v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15007">
<div class="article-summary-box-inner">
<span><p>Helping end users comprehend the abstract distribution shifts can greatly
facilitate AI deployment. Motivated by this, we propose a novel task, dataset
explanation. Given two image data sets, dataset explanation aims to
automatically point out their dataset-level distribution shifts with natural
language. Current techniques for monitoring distribution shifts provide
inadequate information to understand datasets with the goal of improving data
quality. Therefore, we introduce GSCLIP, a training-free framework to solve the
dataset explanation task. In GSCLIP, we propose the selector as the first
quantitative evaluation method to identify explanations that are proper to
summarize dataset shifts. Furthermore, we leverage this selector to demonstrate
the superiority of a generator based on language model generation. Systematic
evaluation on natural data shift verifies that GSCLIP, a combined system of a
hybrid generator group and an efficient selector is not only easy-to-use but
also powerful for dataset explanation at scale.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Temporally Dynamic Data Augmentation for Video Recognition. (arXiv:2206.15015v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15015">
<div class="article-summary-box-inner">
<span><p>Data augmentation has recently emerged as an essential component of modern
training recipes for visual recognition tasks. However, data augmentation for
video recognition has been rarely explored despite its effectiveness. Few
existing augmentation recipes for video recognition naively extend the image
augmentation methods by applying the same operations to the whole video frames.
Our main idea is that the magnitude of augmentation operations for each frame
needs to be changed over time to capture the real-world video's temporal
variations. These variations should be generated as diverse as possible using
fewer additional hyper-parameters during training. Through this motivation, we
propose a simple yet effective video data augmentation framework, DynaAugment.
The magnitude of augmentation operations on each frame is changed by an
effective mechanism, Fourier Sampling that parameterizes diverse, smooth, and
realistic temporal variations. DynaAugment also includes an extended search
space suitable for video for automatic data augmentation methods. DynaAugment
experimentally demonstrates that there are additional performance rooms to be
improved from static augmentations on diverse video models. Specifically, we
show the effectiveness of DynaAugment on various video datasets and tasks:
large-scale video recognition (Kinetics-400 and Something-Something-v2),
small-scale video recognition (UCF- 101 and HMDB-51), fine-grained video
recognition (Diving-48 and FineGym), video action segmentation on Breakfast,
video action localization on THUMOS'14, and video object detection on MOT17Det.
DynaAugment also enables video models to learn more generalized representation
to improve the model robustness on the corrupted videos.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Timestamp-Supervised Action Segmentation with Graph Convolutional Networks. (arXiv:2206.15031v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15031">
<div class="article-summary-box-inner">
<span><p>We introduce a novel approach for temporal activity segmentation with
timestamp supervision. Our main contribution is a graph convolutional network,
which is learned in an end-to-end manner to exploit both frame features and
connections between neighboring frames to generate dense framewise labels from
sparse timestamp labels. The generated dense framewise labels can then be used
to train the segmentation model. In addition, we propose a framework for
alternating learning of both the segmentation model and the graph convolutional
model, which first initializes and then iteratively refines the learned models.
Detailed experiments on four public datasets, including 50 Salads, GTEA,
Breakfast, and Desktop Assembly, show that our method is superior to the
multi-layer perceptron baseline, while performing on par with or better than
the state of the art in temporal activity segmentation with timestamp
supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PVT-COV19D: Pyramid Vision Transformer for COVID-19 Diagnosis. (arXiv:2206.15069v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15069">
<div class="article-summary-box-inner">
<span><p>With the outbreak of COVID-19, a large number of relevant studies have
emerged in recent years. We propose an automatic COVID-19 diagnosis framework
based on lung CT scan images, the PVT-COV19D. In order to accommodate the
different dimensions of the image input, we first classified the images using
Transformer models, then sampled the images in the dataset according to normal
distribution, and fed the sampling results into the modified PVTv2 model for
training. A large number of experiments on the COV19-CT-DB dataset demonstrate
the effectiveness of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Custom Pretrainings and Adapted 3D-ConvNeXt Architecture for COVID Detection and Severity Prediction. (arXiv:2206.15073v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15073">
<div class="article-summary-box-inner">
<span><p>Since COVID strongly affects the respiratory system, lung CT scans can be
used for the analysis of a patients health. We introduce an neural network for
the prediction of the severity of lung damage and the detection of infection
using three-dimensional CT-scans. Therefore, we adapt the recent ConvNeXt model
to process three-dimensional data. Furthermore, we introduce different
pretraining methods specifically adjusted to improve the models ability to
handle three-dimensional CT-data. In order to test the performance of our
model, we participate in the 2nd COV19D Competition for severity prediction and
infection detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Mask Calibration for Unified Domain Adaptive Panoptic Segmentation. (arXiv:2206.15083v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15083">
<div class="article-summary-box-inner">
<span><p>Domain adaptive panoptic segmentation aims to mitigate data annotation
challenge by leveraging off-the-shelf annotated data in one or multiple related
source domains. However, existing studies employ two networks for instance
segmentation and semantic segmentation separately which lead to a large amount
of network parameters with complicated and computationally intensive training
and inference processes. We design UniDAPS, a Unified Domain Adaptive Panoptic
Segmentation network that is simple but capable of achieving domain adaptive
instance segmentation and semantic segmentation simultaneously within a single
network. UniDAPS introduces Hierarchical Mask Calibration (HMC) that rectifies
the predicted pseudo masks, pseudo superpixels and pseudo pixels and performs
network re-training via an online self-training process on the fly. It has
three unique features: 1) it enables unified domain adaptive panoptic
adaptation; 2) it mitigates false predictions and improves domain adaptive
panoptic segmentation effectively; 3) it is end-to-end trainable with much less
parameters and simpler training and inference pipeline. Extensive experiments
over multiple public benchmarks show that UniDAPS achieves superior domain
adaptive panoptic segmentation as compared with the state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Skeleton-based Action Recognition via Adaptive Cross-Form Learning. (arXiv:2206.15085v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15085">
<div class="article-summary-box-inner">
<span><p>Skeleton-based action recognition aims to project skeleton sequences to
action categories, where skeleton sequences are derived from multiple forms of
pre-detected points. Compared with earlier methods that focus on exploring
single-form skeletons via Graph Convolutional Networks (GCNs), existing methods
tend to improve GCNs by leveraging multi-form skeletons due to their
complementary cues. However, these methods (either adapting structure of GCNs
or model ensemble) require the co-existence of all forms of skeletons during
both training and inference stages, while a typical situation in real life is
the existence of only partial forms for inference. To tackle this issue, we
present Adaptive Cross-Form Learning (ACFL), which empowers well-designed GCNs
to generate complementary representation from single-form skeletons without
changing model capacity. Specifically, each GCN model in ACFL not only learns
action representation from the single-form skeletons, but also adaptively
mimics useful representations derived from other forms of skeletons. In this
way, each GCN can learn how to strengthen what has been learned, thus
exploiting model potential and facilitating action recognition as well.
Extensive experiments conducted on three challenging benchmarks, i.e.,
NTU-RGB+D 120, NTU-RGB+D 60 and UAV-Human, demonstrate the effectiveness and
generalizability of the proposed method. Specifically, the ACFL significantly
improves various GCN models (i.e., CTR-GCN, MS-G3D, and Shift-GCN), achieving a
new record for skeleton-based action recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MKIoU Loss: Towards Accurate Oriented Object Detection in Aerial Images. (arXiv:2206.15109v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15109">
<div class="article-summary-box-inner">
<span><p>Oriented bounding box regression is crucial for oriented object detection.
However, regression-based methods often suffer from boundary problems and the
inconsistency between loss and evaluation metrics. In this paper, a modulated
Kalman IoU loss of approximate SkewIoU is proposed, named MKIoU. To avoid
boundary problems, we convert the oriented bounding box to Gaussian
distribution, then use the Kalman filter to approximate the intersection area.
However, there exists significant difference between the calculated and actual
intersection areas. Thus, we propose a modulation factor to adjust the
sensitivity of angle deviation and width-height offset to loss variation,
making the loss more consistent with the evaluation metric. Furthermore, the
Gaussian modeling method avoids the boundary problem but causes the angle
confusion of square objects simultaneously. Thus, the Gaussian Angle Loss (GA
Loss) is presented to solve this problem by adding a corrected loss for square
targets. The proposed GA Loss can be easily extended to other Gaussian-based
methods. Experiments on three publicly available aerial image datasets, DOTA,
UCAS-AOD, and HRSC2016, show the effectiveness of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting and Recovering Adversarial Examples from Extracting Non-robust and Highly Predictive Adversarial Perturbations. (arXiv:2206.15128v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15128">
<div class="article-summary-box-inner">
<span><p>Deep neural networks (DNNs) have been shown to be vulnerable against
adversarial examples (AEs) which are maliciously designed to fool target
models. The normal examples (NEs) added with imperceptible adversarial
perturbation, can be a security threat to DNNs. Although the existing AEs
detection methods have achieved a high accuracy, they failed to exploit the
information of the AEs detected. Thus, based on high-dimension perturbation
extraction, we propose a model-free AEs detection method, the whole process of
which is free from querying the victim model. Research shows that DNNs are
sensitive to the high-dimension features. The adversarial perturbation hiding
in the adversarial example belongs to the high-dimension feature which is
highly predictive and non-robust. DNNs learn more details from high-dimension
data than others. In our method, the perturbation extractor can extract the
adversarial perturbation from AEs as high-dimension feature, then the trained
AEs discriminator determines whether the input is an AE. Experimental results
show that the proposed method can not only detect the adversarial examples with
high accuracy, but also detect the specific category of the AEs. Meanwhile, the
extracted perturbation can be used to recover the AEs to NEs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InsMix: Towards Realistic Generative Data Augmentation for Nuclei Instance Segmentation. (arXiv:2206.15134v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15134">
<div class="article-summary-box-inner">
<span><p>Nuclei Segmentation from histology images is a fundamental task in digital
pathology analysis. However, deep-learning-based nuclei segmentation methods
often suffer from limited annotations. This paper proposes a realistic data
augmentation method for nuclei segmentation, named InsMix, that follows a
Copy-Paste-Smooth principle and performs morphology-constrained generative
instance augmentation. Specifically, we propose morphology constraints that
enable the augmented images to acquire luxuriant information about nuclei while
maintaining their morphology characteristics (e.g., geometry and location). To
fully exploit the pixel redundancy of the background and improve the model's
robustness, we further propose a background perturbation method, which randomly
shuffles the background patches without disordering the original nuclei
distribution. To achieve contextual consistency between original and template
instances, a smooth-GAN is designed with a foreground similarity encoder (FSE)
and a triplet loss. We validated the proposed method on two datasets, i.e.,
Kumar and CPS datasets. Experimental results demonstrate the effectiveness of
each component and the superior performance achieved by our method to the
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DFGC 2022: The Second DeepFake Game Competition. (arXiv:2206.15138v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15138">
<div class="article-summary-box-inner">
<span><p>This paper presents the summary report on our DFGC 2022 competition. The
DeepFake is rapidly evolving, and realistic face-swaps are becoming more
deceptive and difficult to detect. On the contrary, methods for detecting
DeepFakes are also improving. There is a two-party game between DeepFake
creators and defenders. This competition provides a common platform for
benchmarking the game between the current state-of-the-arts in DeepFake
creation and detection methods. The main research question to be answered by
this competition is the current state of the two adversaries when competed with
each other. This is the second edition after the last year's DFGC 2021, with a
new, more diverse video dataset, a more realistic game setting, and more
reasonable evaluation metrics. With this competition, we aim to stimulate
research ideas for building better defenses against the DeepFake threats. We
also release our DFGC 2022 dataset contributed by both our participants and
ourselves to enrich the DeepFake data resources for the research community
(https://github.com/NiCE-X/DFGC-2022).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BoxGraph: Semantic Place Recognition and Pose Estimation from 3D LiDAR. (arXiv:2206.15154v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15154">
<div class="article-summary-box-inner">
<span><p>This paper is about extremely robust and lightweight localisation using LiDAR
point clouds based on instance segmentation and graph matching. We model 3D
point clouds as fully-connected graphs of semantically identified components
where each vertex corresponds to an object instance and encodes its shape.
Optimal vertex association across graphs allows for full 6-Degree-of-Freedom
(DoF) pose estimation and place recognition by measuring similarity. This
representation is very concise, condensing the size of maps by a factor of 25
against the state-of-the-art, requiring only 3kB to represent a 1.4MB laser
scan. We verify the efficacy of our system on the SemanticKITTI dataset, where
we achieve a new state-of-the-art in place recognition, with an average of
88.4% recall at 100% precision where the next closest competitor follows with
64.9%. We also show accurate metric pose estimation performance - estimating
6-DoF pose with median errors of 10 cm and 0.33 deg.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HRFuser: A Multi-resolution Sensor Fusion Architecture for 2D Object Detection. (arXiv:2206.15157v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15157">
<div class="article-summary-box-inner">
<span><p>Besides standard cameras, autonomous vehicles typically include multiple
additional sensors, such as lidars and radars, which help acquire richer
information for perceiving the content of the driving scene. While several
recent works focus on fusing certain pairs of sensors - such as camera and
lidar or camera and radar - by using architectural components specific to the
examined setting, a generic and modular sensor fusion architecture is missing
from the literature. In this work, we focus on 2D object detection, a
fundamental high-level task which is defined on the 2D image domain, and
propose HRFuser, a multi-resolution sensor fusion architecture that scales
straightforwardly to an arbitrary number of input modalities. The design of
HRFuser is based on state-of-the-art high-resolution networks for image-only
dense prediction and incorporates a novel multi-window cross-attention block as
the means to perform fusion of multiple modalities at multiple resolutions.
Even though cameras alone provide very informative features for 2D detection,
we demonstrate via extensive experiments on the nuScenes and Seeing Through Fog
datasets that our model effectively leverages complementary features from
additional modalities, substantially improving upon camera-only performance and
consistently outperforming state-of-the-art fusion methods for 2D detection
both in normal and adverse conditions. The source code will be made publicly
available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LiDAR-as-Camera for End-to-End Driving. (arXiv:2206.15170v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15170">
<div class="article-summary-box-inner">
<span><p>The core task of any autonomous driving system is to transform sensory inputs
into driving commands. In end-to-end driving, this is achieved via a neural
network, with one or multiple cameras as the most commonly used input and
low-level driving command, e.g. steering angle, as output. However,
depth-sensing has been shown in simulation to make the end-to-end driving task
easier. On a real car, combining depth and visual information can be
challenging, due to the difficulty of obtaining good spatial and temporal
alignment of the sensors. To alleviate alignment problems, Ouster LiDARs can
output surround-view LiDAR-images with depth, intensity, and ambient radiation
channels. These measurements originate from the same sensor, rendering them
perfectly aligned in time and space. We demonstrate that such LiDAR-images are
sufficient for the real-car road-following task and perform at least equally to
camera-based models in the tested conditions, with the difference increasing
when needing to generalize to new weather conditions. In the second direction
of study, we reveal that the temporal smoothness of off-policy prediction
sequences correlates equally well with actual on-policy driving ability as the
commonly used mean absolute error.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Medical Image Fusion Method based on MDLatLRRv2. (arXiv:2206.15179v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15179">
<div class="article-summary-box-inner">
<span><p>Since MDLatLRR only considers detailed parts (salient features) of input
images extracted by latent low-rank representation (LatLRR), it doesn't use
base parts (principal features) extracted by LatLRR effectively. Therefore, we
proposed an improved multi-level decomposition method called MDLatLRRv2 which
effectively analyzes and utilizes all the image features obtained by LatLRR.
Then we apply MDLatLRRv2 to medical image fusion. The base parts are fused by
average strategy and the detail parts are fused by nuclear-norm operation. The
comparison with the existing methods demonstrates that the proposed method can
achieve state-of-the-art fusion performance in objective and subjective
assessment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The (de)biasing effect of GAN-based augmentation methods on skin lesion images. (arXiv:2206.15182v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15182">
<div class="article-summary-box-inner">
<span><p>New medical datasets are now more open to the public, allowing for better and
more extensive research. Although prepared with the utmost care, new datasets
might still be a source of spurious correlations that affect the learning
process. Moreover, data collections are usually not large enough and are often
unbalanced. One approach to alleviate the data imbalance is using data
augmentation with Generative Adversarial Networks (GANs) to extend the dataset
with high-quality images. GANs are usually trained on the same biased datasets
as the target data, resulting in more biased instances. This work explored
unconditional and conditional GANs to compare their bias inheritance and how
the synthetic data influenced the models. We provided extensive manual data
annotation of possibly biasing artifacts on the well-known ISIC dataset with
skin lesions. In addition, we examined classification models trained on both
real and synthetic data with counterfactual bias explanations. Our experiments
showed that GANs inherited biases and sometimes even amplified them, leading to
even stronger spurious correlations. Manual data annotation and synthetic
images are publicly available for reproducible scientific research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Out-of-Distribution Detection for Long-tailed and Fine-grained Skin Lesion Images. (arXiv:2206.15186v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15186">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed a rapid development of automated methods for skin
lesion diagnosis and classification. Due to an increasing deployment of such
systems in clinics, it has become important to develop a more robust system
towards various Out-of-Distribution(OOD) samples (unknown skin lesions and
conditions). However, the current deep learning models trained for skin lesion
classification tend to classify these OOD samples incorrectly into one of their
learned skin lesion categories. To address this issue, we propose a simple yet
strategic approach that improves the OOD detection performance while
maintaining the multi-class classification accuracy for the known categories of
skin lesion. To specify, this approach is built upon a realistic scenario of a
long-tailed and fine-grained OOD detection task for skin lesion images. Through
this approach, 1) First, we target the mixup amongst middle and tail classes to
address the long-tail problem. 2) Later, we combine the above mixup strategy
with prototype learning to address the fine-grained nature of the dataset. The
unique contribution of this paper is two-fold, justified by extensive
experiments. First, we present a realistic problem setting of OOD task for skin
lesion. Second, we propose an approach to target the long-tailed and
fine-grained aspects of the problem setting simultaneously to increase the OOD
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Granularity Regularized Re-Balancing for Class Incremental Learning. (arXiv:2206.15189v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15189">
<div class="article-summary-box-inner">
<span><p>Deep learning models suffer from catastrophic forgetting when learning new
tasks incrementally. Incremental learning has been proposed to retain the
knowledge of old classes while learning to identify new classes. A typical
approach is to use a few exemplars to avoid forgetting old knowledge. In such a
scenario, data imbalance between old and new classes is a key issue that leads
to performance degradation of the model. Several strategies have been designed
to rectify the bias towards the new classes due to data imbalance. However,
they heavily rely on the assumptions of the bias relation between old and new
classes. Therefore, they are not suitable for complex real-world applications.
In this study, we propose an assumption-agnostic method, Multi-Granularity
Regularized re-Balancing (MGRB), to address this problem. Re-balancing methods
are used to alleviate the influence of data imbalance; however, we empirically
discover that they would under-fit new classes. To this end, we further design
a novel multi-granularity regularization term that enables the model to
consider the correlations of classes in addition to re-balancing the data. A
class hierarchy is first constructed by grouping the semantically or visually
similar classes. The multi-granularity regularization then transforms the
one-hot label vector into a continuous label distribution, which reflects the
relations between the target class and other classes based on the constructed
class hierarchy. Thus, the model can learn the inter-class relational
information, which helps enhance the learning of both old and new classes.
Experimental results on both public datasets and a real-world fault diagnosis
dataset verify the effectiveness of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Implicit U-Net for volumetric medical image segmentation. (arXiv:2206.15217v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15217">
<div class="article-summary-box-inner">
<span><p>U-Net has been the go-to architecture for medical image segmentation tasks,
however computational challenges arise when extending the U-Net architecture to
3D images. We propose the Implicit U-Net architecture that adapts the efficient
Implicit Representation paradigm to supervised image segmentation tasks. By
combining a convolutional feature extractor with an implicit localization
network, our implicit U-Net has 40% less parameters than the equivalent U-Net.
Moreover, we propose training and inference procedures to capitalize sparse
predictions. When comparing to an equivalent fully convolutional U-Net,
Implicit U-Net reduces by approximately 30% inference and training time as well
as training memory footprint while achieving comparable results in our
experiments with two different abdominal CT scan datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CTrGAN: Cycle Transformers GAN for Gait Transfer. (arXiv:2206.15248v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15248">
<div class="article-summary-box-inner">
<span><p>We attempt for the first time to address the problem of gait transfer. In
contrast to motion transfer, the objective here is not to imitate the source's
normal motions, but rather to transform the source's motion into a typical gait
pattern for the target. Using gait recognition models, we demonstrate that
existing techniques yield a discrepancy that can be easily detected. We
introduce a novel model, Cycle Transformers GAN (CTrGAN), that can successfully
generate the target's natural gait. CTrGAN's generators consist of a decoder
and encoder, both Transformers, where the attention is on the temporal domain
between complete images rather than the spatial domain between patches. While
recent Transformer studies in computer vision mainly focused on discriminative
tasks, we introduce an architecture that can be applied to synthesis tasks.
Using a widely-used gait recognition dataset, we demonstrate that our approach
is capable of producing over an order of magnitude more realistic personalized
gaits than existing methods, even when used with sources that were not
available during training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Localizing the Recurrent Laryngeal Nerve via Ultrasound with a Bayesian Shape Framework. (arXiv:2206.15254v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15254">
<div class="article-summary-box-inner">
<span><p>Tumor infiltration of the recurrent laryngeal nerve (RLN) is a
contraindication for robotic thyroidectomy and can be difficult to detect via
standard laryngoscopy. Ultrasound (US) is a viable alternative for RLN
detection due to its safety and ability to provide real-time feedback. However,
the tininess of the RLN, with a diameter typically less than 3mm, poses
significant challenges to the accurate localization of the RLN. In this work,
we propose a knowledge-driven framework for RLN localization, mimicking the
standard approach surgeons take to identify the RLN according to its
surrounding organs. We construct a prior anatomical model based on the inherent
relative spatial relationships between organs. Through Bayesian shape alignment
(BSA), we obtain the candidate coordinates of the center of a region of
interest (ROI) that encloses the RLN. The ROI allows a decreased field of view
for determining the refined centroid of the RLN using a dual-path
identification network, based on multi-scale semantic information. Experimental
results indicate that the proposed method achieves superior hit rates and
substantially smaller distance errors compared with state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Rendering for Stereo 3D Reconstruction of Deformable Tissues in Robotic Surgery. (arXiv:2206.15255v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15255">
<div class="article-summary-box-inner">
<span><p>Reconstruction of the soft tissues in robotic surgery from endoscopic stereo
videos is important for many applications such as intra-operative navigation
and image-guided robotic surgery automation. Previous works on this task mainly
rely on SLAM-based approaches, which struggle to handle complex surgical
scenes. Inspired by recent progress in neural rendering, we present a novel
framework for deformable tissue reconstruction from binocular captures in
robotic surgery under the single-viewpoint setting. Our framework adopts
dynamic neural radiance fields to represent deformable surgical scenes in MLPs
and optimize shapes and deformations in a learning-based manner. In addition to
non-rigid deformations, tool occlusion and poor 3D clues from a single
viewpoint are also particular challenges in soft tissue reconstruction. To
overcome these difficulties, we present a series of strategies of tool
mask-guided ray casting, stereo depth-cueing ray marching and stereo
depth-supervised optimization. With experiments on DaVinci robotic surgery
videos, our method significantly outperforms the current state-of-the-art
reconstruction method for handling various complex non-rigid deformations. To
our best knowledge, this is the first work leveraging neural rendering for
surgical scene 3D reconstruction with remarkable potential demonstrated. Code
is available at: https://github.com/med-air/EndoNeRF.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D Camera. (arXiv:2206.15258v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15258">
<div class="article-summary-box-inner">
<span><p>We propose Neural-DynamicReconstruction (NDR), a template-free method to
recover high-fidelity geometry and motions of a dynamic scene from a monocular
RGB-D camera. In NDR, we adopt the neural implicit function for surface
representation and rendering such that the captured color and depth can be
fully utilized to jointly optimize the surface and deformations. To represent
and constrain the non-rigid deformations, we propose a novel neural invertible
deforming network such that the cycle consistency between arbitrary two frames
is automatically satisfied. Considering that the surface topology of dynamic
scene might change over time, we employ a topology-aware strategy to construct
the topology-variant correspondence for the fused frames. NDR also further
refines the camera poses in a global optimization manner. Experiments on public
datasets and our collected dataset demonstrate that NDR outperforms existing
monocular dynamic reconstruction methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Submission to Generic Event Boundary Detection Challenge@CVPR 2022: Local Context Modeling and Global Boundary Decoding Approach. (arXiv:2206.15268v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15268">
<div class="article-summary-box-inner">
<span><p>Generic event boundary detection (GEBD) is an important yet challenging task
in video understanding, which aims at detecting the moments where humans
naturally perceive event boundaries. In this paper, we present a local context
modeling and global boundary decoding approach for GEBD task. Local context
modeling sub-network is proposed to perceive diverse patterns of generic event
boundaries, and it generates powerful video representations and reliable
boundary confidence. Based on them, global boundary decoding sub-network is
exploited to decode event boundaries from a global view. Our proposed method
achieves 85.13% F1-score on Kinetics-GEBD testing set, which achieves a more
than 22% F1-score boost compared to the baseline method. The code is available
at https://github.com/JackyTown/GEBD_Challenge_CVPR2022.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exposing and addressing the fragility of neural networks in digital pathology. (arXiv:2206.15274v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15274">
<div class="article-summary-box-inner">
<span><p>Neural networks have achieved impressive results in many medical imaging
tasks but often perform substantially worse on out-of-distribution datasets
originating from different medical centres or patient cohorts. Evaluating this
lack of ability to generalise and address the underlying problem are the two
main challenges in developing neural networks intended for clinical practice.
</p>
<p>In this study, we develop a new method for evaluating neural network models'
ability to generalise by generating a large number of distribution-shifted
datasets, which can be used to thoroughly investigate their robustness to
variability encountered in clinical practice. Compared to external validation,
\textit{shifted evaluation} can provide explanations for why neural networks
fail on a given dataset, thus offering guidance on how to improve model
robustness. With shifted evaluation, we demonstrate that neural networks,
trained with state-of-the-art methods, are highly fragile to even small
distribution shifts from training data, and in some cases lose all
discrimination ability.
</p>
<p>To address this fragility, we develop an augmentation strategy, explicitly
designed to increase neural networks' robustness to distribution shifts.
\texttt{StrongAugment} is evaluated with large-scale, heterogeneous
histopathology data including five training datasets from two tissue types, 274
distribution-shifted datasets and 20 external datasets from four countries.
Neural networks trained with \texttt{StrongAugment} retain similar performance
on all datasets, even with distribution shifts where networks trained with
current state-of-the-art methods lose all discrimination ability. We recommend
using strong augmentation and shifted evaluation to train and evaluate all
neural networks intended for clinical practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multiclass-SGCN: Sparse Graph-based Trajectory Prediction with Agent Class Embedding. (arXiv:2206.15275v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15275">
<div class="article-summary-box-inner">
<span><p>Trajectory prediction of road users in real-world scenarios is challenging
because their movement patterns are stochastic and complex. Previous
pedestrian-oriented works have been successful in modelling the complex
interactions among pedestrians, but fail in predicting trajectories when other
types of road users are involved (e.g., cars, cyclists, etc.), because they
ignore user types. Although a few recent works construct densely connected
graphs with user label information, they suffer from superfluous spatial
interactions and temporal dependencies. To address these issues, we propose
Multiclass-SGCN, a sparse graph convolution network based approach for
multi-class trajectory prediction that takes into consideration velocity and
agent label information and uses a novel interaction mask to adaptively decide
the spatial and temporal connections of agents based on their interaction
scores. The proposed approach significantly outperformed state-of-the-art
approaches on the Stanford Drone Dataset, providing more realistic and
plausible trajectory predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TINC: Temporally Informed Non-Contrastive Learning for Disease Progression Modeling in Retinal OCT Volumes. (arXiv:2206.15282v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15282">
<div class="article-summary-box-inner">
<span><p>Recent contrastive learning methods achieved state-of-the-art in low label
regimes. However, the training requires large batch sizes and heavy
augmentations to create multiple views of an image. With non-contrastive
methods, the negatives are implicitly incorporated in the loss, allowing
different images and modalities as pairs. Although the meta-information (i.e.,
age, sex) in medical imaging is abundant, the annotations are noisy and prone
to class imbalance. In this work, we exploited already existing temporal
information (different visits from a patient) in a longitudinal optical
coherence tomography (OCT) dataset using temporally informed non-contrastive
loss (TINC) without increasing complexity and need for negative pairs.
Moreover, our novel pair-forming scheme can avoid heavy augmentations and
implicitly incorporates the temporal information in the pairs. Finally, these
representations learned from the pretraining are more successful in predicting
disease progression where the temporal information is crucial for the
downstream task. More specifically, our model outperforms existing models in
predicting the risk of conversion within a time frame from intermediate
age-related macular degeneration (AMD) to the late wet-AMD stage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-SuperFlow: Self-supervised Scene Flow Prediction in Stereo Sequences. (arXiv:2206.15296v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15296">
<div class="article-summary-box-inner">
<span><p>In recent years, deep neural networks showed their exceeding capabilities in
addressing many computer vision tasks including scene flow prediction. However,
most of the advances are dependent on the availability of a vast amount of
dense per pixel ground truth annotations, which are very difficult to obtain
for real life scenarios. Therefore, synthetic data is often relied upon for
supervision, resulting in a representation gap between the training and test
data. Even though a great quantity of unlabeled real world data is available,
there is a huge lack in self-supervised methods for scene flow prediction.
Hence, we explore the extension of a self-supervised loss based on the Census
transform and occlusion-aware bidirectional displacements for the problem of
scene flow prediction. Regarding the KITTI scene flow benchmark, our method
outperforms the corresponding supervised pre-training of the same network and
shows improved generalization capabilities while achieving much faster
convergence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpretable Anomaly Detection in Echocardiograms with Dynamic Variational Trajectory Models. (arXiv:2206.15316v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15316">
<div class="article-summary-box-inner">
<span><p>We propose a novel anomaly detection method for echocardiogram videos. The
introduced method takes advantage of the periodic nature of the heart cycle to
learn different variants of a variational latent trajectory model (TVAE). The
models are trained on the healthy samples of an in-house dataset of infant
echocardiogram videos consisting of multiple chamber views to learn a normative
prior of the healthy population. During inference, maximum a posteriori (MAP)
based anomaly detection is performed to detect out-of-distribution samples in
our dataset. The proposed method reliably identifies severe congenital heart
defects, such as Ebstein's Anomaly or Shonecomplex. Moreover, it achieves
superior performance over MAP-based anomaly detection with standard variational
autoencoders on the task of detecting pulmonary hypertension and right
ventricular dilation. Finally, we demonstrate that the proposed method provides
interpretable explanations of its output through heatmaps which highlight the
regions corresponding to anomalous heart structures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Annotation Refinement: Development of a New 3D Dataset for Adrenal Gland Analysis. (arXiv:2206.15328v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15328">
<div class="article-summary-box-inner">
<span><p>The human annotations are imperfect, especially when produced by junior
practitioners. Multi-expert consensus is usually regarded as golden standard,
while this annotation protocol is too expensive to implement in many real-world
projects. In this study, we propose a method to refine human annotation, named
Neural Annotation Refinement (NeAR). It is based on a learnable implicit
function, which decodes a latent vector into represented shape. By integrating
the appearance as an input of implicit functions, the appearance-aware NeAR
fixes the annotation artefacts. Our method is demonstrated on the application
of adrenal gland analysis. We first show that the NeAR can repair distorted
golden standards on a public adrenal gland segmentation dataset. Besides, we
develop a new Adrenal gLand ANalysis (ALAN) dataset with the proposed NeAR,
where each case consists of a 3D shape of adrenal gland and its diagnosis label
(normal vs. abnormal) assigned by experts. We show that models trained on the
shapes repaired by the NeAR can diagnose adrenal glands better than the
original ones. The ALAN dataset will be open-source, with 1,594 shapes for
adrenal gland diagnosis, which serves as a new benchmark for medical shape
analysis. Code and dataset are available at https://github.com/M3DV/NeAR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Competitive Coding Approach for Palmprint Recognition: A Linear Discriminant Analysis Perspective. (arXiv:2206.15349v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15349">
<div class="article-summary-box-inner">
<span><p>The competitive Coding approach (CompCode) is one of the most promising
methods for palmprint recognition. Due to its high performance and simple
formulation, it has been continuously studied for many years. However, although
numerous variations of CompCode have been proposed, a detailed analysis of the
method is still absent. In this paper, we provide a detailed analysis of
CompCode from the perspective of linear discriminant analysis (LDA) for the
first time. A non-trivial sufficient condition under which the CompCode is
optimal in the sense of Fisher's criterion is presented. Based on our analysis,
we examined the statistics of palmprints and concluded that CompCode deviates
from the optimal condition. To mitigate the deviation, we propose a new method
called Class-Specific CompCode that improves CompCode by excluding
non-palm-line areas from matching. A nonlinear mapping of the competitive code
is also applied in this method to further enhance accuracy. Experiments on two
public databases demonstrate the effectiveness of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning to See: Towards New Foundations of Computer Vision. (arXiv:2206.15351v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15351">
<div class="article-summary-box-inner">
<span><p>The remarkable progress in computer vision over the last few years is, by and
large, attributed to deep learning, fueled by the availability of huge sets of
labeled data, and paired with the explosive growth of the GPU paradigm. While
subscribing to this view, this book criticizes the supposed scientific progress
in the field and proposes the investigation of vision within the framework of
information-based laws of nature. Specifically, the present work poses
fundamental questions about vision that remain far from understood, leading the
reader on a journey populated by novel challenges resonating with the
foundations of machine learning. The central thesis is that for a deeper
understanding of visual computational processes, it is necessary to look beyond
the applications of general purpose machine learning algorithms and focus
instead on appropriate learning theories that take into account the
spatiotemporal nature of the visual signal.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Underrepresented Classes from Decentralized Partially Labeled Medical Images. (arXiv:2206.15353v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15353">
<div class="article-summary-box-inner">
<span><p>Using decentralized data for federated training is one promising emerging
research direction for alleviating data scarcity in the medical domain.
However, in contrast to large-scale fully labeled data commonly seen in general
object recognition tasks, the local medical datasets are more likely to only
have images annotated for a subset of classes of interest due to high
annotation costs. In this paper, we consider a practical yet under-explored
problem, where underrepresented classes only have few labeled instances
available and only exist in a few clients of the federated system. We show that
standard federated learning approaches fail to learn robust multi-label
classifiers with extreme class imbalance and address it by proposing a novel
federated learning framework, FedFew. FedFew consists of three stages, where
the first stage leverages federated self-supervised learning to learn
class-agnostic representations. In the second stage, the decentralized
partially labeled data are exploited to learn an energy-based multi-label
classifier for the common classes. Finally, the underrepresented classes are
detected based on the energy and a prototype-based nearest-neighbor model is
proposed for few-shot matching. We evaluate FedFew on multi-label thoracic
disease classification tasks and demonstrate that it outperforms the federated
baselines by a large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving the Generalization of Supervised Models. (arXiv:2206.15369v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15369">
<div class="article-summary-box-inner">
<span><p>We consider the problem of training a deep neural network on a given
classification task, e.g., ImageNet-1K (IN1K), so that it excels at that task
as well as at other (future) transfer tasks. These two seemingly contradictory
properties impose a trade-off between improving the model's generalization
while maintaining its performance on the original task. Models trained with
self-supervised learning (SSL) tend to generalize better than their supervised
counterparts for transfer learning; yet, they still lag behind supervised
models on IN1K. In this paper, we propose a supervised learning setup that
leverages the best of both worlds. We enrich the common supervised training
framework using two key components of recent SSL models: multi-scale crops for
data augmentation and the use of an expendable projector head. We replace the
last layer of class weights with class prototypes computed on the fly using a
memory bank. We show that these three improvements lead to a more favorable
trade-off between the IN1K training task and 13 transfer tasks. Over all the
explored configurations, we single out two models: t-ReX that achieves a new
state of the art for transfer learning and outperforms top methods such as DINO
and PAWS on IN1K, and t-ReX* that matches the highly optimized RSB-A1 model on
IN1K while performing better on transfer tasks. Project page and pretrained
models: https://europe.naverlabs.com/t-rex
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PolarFormer: Multi-camera 3D Object Detection with Polar Transformer. (arXiv:2206.15398v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15398">
<div class="article-summary-box-inner">
<span><p>3D object detection in autonomous driving aims to reason "what" and "where"
the objects of interest present in a 3D world. Following the conventional
wisdom of previous 2D object detection, existing methods often adopt the
canonical Cartesian coordinate system with perpendicular axis. However, we
conjugate that this does not fit the nature of the ego car's perspective, as
each onboard camera perceives the world in shape of wedge intrinsic to the
imaging geometry with radical (non-perpendicular) axis. Hence, in this paper we
advocate the exploitation of the Polar coordinate system and propose a new
Polar Transformer (PolarFormer) for more accurate 3D object detection in the
bird's-eye-view (BEV) taking as input only multi-camera 2D images.
Specifically, we design a cross attention based Polar detection head without
restriction to the shape of input structure to deal with irregular Polar grids.
For tackling the unconstrained object scale variations along Polar's distance
dimension, we further introduce a multi-scalePolar representation learning
strategy. As a result, our model can make best use of the Polar representation
rasterized via attending to the corresponding image observation in a
sequence-to-sequence fashion subject to the geometric constraints. Thorough
experiments on the nuScenes dataset demonstrate that our PolarFormer
outperforms significantly state-of-the-art 3D object detection alternatives, as
well as yielding competitive performance on BEV semantic segmentation task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MEAD: A Multi-Armed Approach for Evaluation of Adversarial Examples Detectors. (arXiv:2206.15415v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15415">
<div class="article-summary-box-inner">
<span><p>Detection of adversarial examples has been a hot topic in the last years due
to its importance for safely deploying machine learning algorithms in critical
applications. However, the detection methods are generally validated by
assuming a single implicitly known attack strategy, which does not necessarily
account for real-life threats. Indeed, this can lead to an overoptimistic
assessment of the detectors' performance and may induce some bias in the
comparison between competing detection schemes. We propose a novel multi-armed
framework, called MEAD, for evaluating detectors based on several attack
strategies to overcome this limitation. Among them, we make use of three new
objectives to generate attacks. The proposed performance metric is based on the
worst-case scenario: detection is successful if and only if all different
attacks are correctly recognized. Empirically, we show the effectiveness of our
approach. Moreover, the poor performance obtained for state-of-the-art
detectors opens a new exciting line of research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ensemble CNN models for Covid-19 Recognition and Severity Perdition From 3D CT-scan. (arXiv:2206.15431v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15431">
<div class="article-summary-box-inner">
<span><p>Since the appearance of Covid-19 in late 2019, Covid-19 has become an active
research topic for the artificial intelligence (AI) community. One of the most
interesting AI topics is Covid-19 analysis of medical imaging. CT-scan imaging
is the most informative tool about this disease. This work is part of the 2nd
COV19D competition, where two challenges are set: Covid-19 Detection and
Covid-19 Severity Detection from the CT-scans. For Covid-19 detection from
CT-scans, we proposed an ensemble of 2D Convolution blocks with Densenet-161
models. Here, each 2D convolutional block with Densenet-161 architecture is
trained separately and in testing phase, the ensemble model is based on the
average of their probabilities. On the other hand, we proposed an ensemble of
Convolutional Layers with Inception models for Covid-19 severity detection. In
addition to the Convolutional Layers, three Inception variants were used,
namely Inception-v3, Inception-v4 and Inception-Resnet. Our proposed approaches
outperformed the baseline approach in the validation data of the 2nd COV19D
competition by 11% and 16% for Covid-19 detection and Covid-19 severity
detection, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Category-Level 6D Object Pose Estimation in the Wild: A Semi-Supervised Learning Approach and A New Dataset. (arXiv:2206.15436v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15436">
<div class="article-summary-box-inner">
<span><p>6D object pose estimation is one of the fundamental problems in computer
vision and robotics research. While a lot of recent efforts have been made on
generalizing pose estimation to novel object instances within the same
category, namely category-level 6D pose estimation, it is still restricted in
constrained environments given the limited number of annotated data. In this
paper, we collect Wild6D, a new unlabeled RGBD object video dataset with
diverse instances and backgrounds. We utilize this data to generalize
category-level 6D object pose estimation in the wild with semi-supervised
learning. We propose a new model, called Rendering for Pose estimation network
RePoNet, that is jointly trained using the free ground-truths with the
synthetic data, and a silhouette matching objective function on the real-world
data. Without using any 3D annotations on real data, our method outperforms
state-of-the-art methods on the previous dataset and our Wild6D test set (with
manual annotations for evaluation) by a large margin. Project page with Wild6D
data: https://oasisyang.github.io/semi-pose .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Asymmetry Disentanglement Network for Interpretable Acute Ischemic Stroke Infarct Segmentation in Non-Contrast CT Scans. (arXiv:2206.15445v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15445">
<div class="article-summary-box-inner">
<span><p>Accurate infarct segmentation in non-contrast CT (NCCT) images is a crucial
step toward computer-aided acute ischemic stroke (AIS) assessment. In clinical
practice, bilateral symmetric comparison of brain hemispheres is usually used
to locate pathological abnormalities. Recent research has explored asymmetries
to assist with AIS segmentation. However, most previous symmetry-based work
mixed different types of asymmetries when evaluating their contribution to AIS.
In this paper, we propose a novel Asymmetry Disentanglement Network (ADN) to
automatically separate pathological asymmetries and intrinsic anatomical
asymmetries in NCCTs for more effective and interpretable AIS segmentation. ADN
first performs asymmetry disentanglement based on input NCCTs, which produces
different types of 3D asymmetry maps. Then a synthetic,
intrinsic-asymmetry-compensated and pathology-asymmetry-salient NCCT volume is
generated and later used as input to a segmentation network. The training of
ADN incorporates domain knowledge and adopts a tissue-type aware regularization
loss function to encourage clinically-meaningful pathological asymmetry
extraction. Coupled with an unsupervised 3D transformation network, ADN
achieves state-of-the-art AIS segmentation performance on a public NCCT
dataset. In addition to the superior performance, we believe the learned
clinically-interpretable asymmetry maps can also provide insights towards a
better understanding of AIS assessment. Our code is available at
https://github.com/nihaomiao/MICCAI22_ADN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Visual Grounding by Encouraging Consistent Gradient-based Explanations. (arXiv:2206.15462v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15462">
<div class="article-summary-box-inner">
<span><p>We propose a margin-based loss for vision-language model pretraining that
encourages gradient-based explanations that are consistent with region-level
annotations. We refer to this objective as Attention Mask Consistency (AMC) and
demonstrate that it produces superior visual grounding performance compared to
models that rely instead on region-level annotations for explicitly training an
object detector such as Faster R-CNN. AMC works by encouraging gradient-based
explanation masks that focus their attention scores mostly within annotated
regions of interest for images that contain such annotations. Particularly, a
model trained with AMC on top of standard vision-language modeling objectives
obtains a state-of-the-art accuracy of 86.59% in the Flickr30k visual grounding
benchmark, an absolute improvement of 5.48% when compared to the best previous
model. Our approach also performs exceedingly well on established benchmarks
for referring expression comprehension and offers the added benefit by design
of gradient-based explanations that better align with human annotations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Watch and Match: Supercharging Imitation with Regularized Optimal Transport. (arXiv:2206.15469v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15469">
<div class="article-summary-box-inner">
<span><p>Imitation learning holds tremendous promise in learning policies efficiently
for complex decision making problems. Current state-of-the-art algorithms often
use inverse reinforcement learning (IRL), where given a set of expert
demonstrations, an agent alternatively infers a reward function and the
associated optimal policy. However, such IRL approaches often require
substantial online interactions for complex control problems. In this work, we
present Regularized Optimal Transport (ROT), a new imitation learning algorithm
that builds on recent advances in optimal transport based trajectory-matching.
Our key technical insight is that adaptively combining trajectory-matching
rewards with behavior cloning can significantly accelerate imitation even with
only a few demonstrations. Our experiments on 20 visual control tasks across
the DeepMind Control Suite, the OpenAI Robotics Suite, and the Meta-World
Benchmark demonstrate an average of 7.8X faster imitation to reach 90% of
expert performance compared to prior state-of-the-art methods. On real-world
robotic manipulation, with just one demonstration and an hour of online
training, ROT achieves an average success rate of 90.1% across 14 tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dressing Avatars: Deep Photorealistic Appearance for Physically Simulated Clothing. (arXiv:2206.15470v1 [cs.GR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15470">
<div class="article-summary-box-inner">
<span><p>Despite recent progress in developing animatable full-body avatars, realistic
modeling of clothing - one of the core aspects of human self-expression -
remains an open challenge. State-of-the-art physical simulation methods can
generate realistically behaving clothing geometry at interactive rate. Modeling
photorealistic appearance, however, usually requires physically-based rendering
which is too expensive for interactive applications. On the other hand,
data-driven deep appearance models are capable of efficiently producing
realistic appearance, but struggle at synthesizing geometry of highly dynamic
clothing and handling challenging body-clothing configurations. To this end, we
introduce pose-driven avatars with explicit modeling of clothing that exhibit
both realistic clothing dynamics and photorealistic appearance learned from
real-world data. The key idea is to introduce a neural clothing appearance
model that operates on top of explicit geometry: at train time we use
high-fidelity tracking, whereas at animation time we rely on physically
simulated geometry. Our key contribution is a physically-inspired appearance
network, capable of generating photorealistic appearance with view-dependent
and dynamic shadowing effects even for unseen body-clothing configurations. We
conduct a thorough evaluation of our model and demonstrate diverse animation
results on several subjects and different types of clothing. Unlike previous
work on photorealistic full-body avatars, our approach can produce much richer
dynamics and more realistic deformations even for loose clothing. We also
demonstrate that our formulation naturally allows clothing to be used with
avatars of different people while staying fully animatable, thus enabling, for
the first time, photorealistic avatars with novel clothing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On-Device Training Under 256KB Memory. (arXiv:2206.15472v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.15472">
<div class="article-summary-box-inner">
<span><p>On-device training enables the model to adapt to new data collected from the
sensors by fine-tuning a pre-trained model. However, the training memory
consumption is prohibitive for IoT devices that have tiny memory resources. We
propose an algorithm-system co-design framework to make on-device training
possible with only 256KB of memory. On-device training faces two unique
challenges: (1) the quantized graphs of neural networks are hard to optimize
due to mixed bit-precision and the lack of normalization; (2) the limited
hardware resource (memory and computation) does not allow full backward
computation. To cope with the optimization difficulty, we propose
Quantization-Aware Scaling to calibrate the gradient scales and stabilize
quantized training. To reduce the memory footprint, we propose Sparse Update to
skip the gradient computation of less important layers and sub-tensors. The
algorithm innovation is implemented by a lightweight training system, Tiny
Training Engine, which prunes the backward computation graph to support sparse
updates and offloads the runtime auto-differentiation to compile time. Our
framework is the first practical solution for on-device transfer learning of
visual recognition on tiny IoT devices (e.g., a microcontroller with only 256KB
SRAM), using less than 1/100 of the memory of existing frameworks while
matching the accuracy of cloud training+edge deployment for the tinyML
application VWW. Our study enables IoT devices to not only perform inference
but also continuously adapt to new data for on-device lifelong learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A DCNN-based Arbitrarily-Oriented Object Detector for Quality Control and Inspection Application. (arXiv:2101.07383v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07383">
<div class="article-summary-box-inner">
<span><p>Following the success of machine vision systems for on-line automated quality
control and inspection processes, an object recognition solution is presented
in this work for two different specific applications, i.e., the detection of
quality control items in surgery toolboxes prepared for sterilizing in a
hospital, as well as the detection of defects in vessel hulls to prevent
potential structural failures. The solution has two stages. First, a feature
pyramid architecture based on Single Shot MultiBox Detector (SSD) is used to
improve the detection performance, and a statistical analysis based on ground
truth is employed to select parameters of a range of default boxes. Second, a
lightweight neural network is exploited to achieve oriented detection results
using a regression method. The first stage of the proposed method is capable of
detecting the small targets considered in the two scenarios. In the second
stage, despite the simplicity, it is efficient to detect elongated targets
while maintaining high running efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SimPLE: Similar Pseudo Label Exploitation for Semi-Supervised Classification. (arXiv:2103.16725v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16725">
<div class="article-summary-box-inner">
<span><p>A common classification task situation is where one has a large amount of
data available for training, but only a small portion is annotated with class
labels. The goal of semi-supervised training, in this context, is to improve
classification accuracy by leverage information not only from labeled data but
also from a large amount of unlabeled data. Recent works have developed
significant improvements by exploring the consistency constrain between
differently augmented labeled and unlabeled data. Following this path, we
propose a novel unsupervised objective that focuses on the less studied
relationship between the high confidence unlabeled data that are similar to
each other. The new proposed Pair Loss minimizes the statistical distance
between high confidence pseudo labels with similarity above a certain
threshold. Combining the Pair Loss with the techniques developed by the
MixMatch family, our proposed SimPLE algorithm shows significant performance
gains over previous algorithms on CIFAR-100 and Mini-ImageNet, and is on par
with the state-of-the-art methods on CIFAR-10 and SVHN. Furthermore, SimPLE
also outperforms the state-of-the-art methods in the transfer learning setting,
where models are initialized by the weights pre-trained on ImageNet or
DomainNet-Real. The code is available at github.com/zijian-hu/SimPLE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PVT v2: Improved Baselines with Pyramid Vision Transformer. (arXiv:2106.13797v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13797">
<div class="article-summary-box-inner">
<span><p>Transformer recently has presented encouraging progress in computer vision.
In this work, we present new baselines by improving the original Pyramid Vision
Transformer (PVT v1) by adding three designs, including (1) linear complexity
attention layer, (2) overlapping patch embedding, and (3) convolutional
feed-forward network. With these modifications, PVT v2 reduces the
computational complexity of PVT v1 to linear and achieves significant
improvements on fundamental vision tasks such as classification, detection, and
segmentation. Notably, the proposed PVT v2 achieves comparable or better
performances than recent works such as Swin Transformer. We hope this work will
facilitate state-of-the-art Transformer researches in computer vision. Code is
available at https://github.com/whai362/PVT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised domain adaptation for clinician pose estimation and instance segmentation in the operating room. (arXiv:2108.11801v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11801">
<div class="article-summary-box-inner">
<span><p>The fine-grained localization of clinicians in the operating room (OR) is a
key component to design the new generation of OR support systems. Computer
vision models for person pixel-based segmentation and body-keypoints detection
are needed to better understand the clinical activities and the spatial layout
of the OR. This is challenging, not only because OR images are very different
from traditional vision datasets, but also because data and annotations are
hard to collect and generate in the OR due to privacy concerns. To address
these concerns, we first study how joint person pose estimation and instance
segmentation can be performed on low resolutions images with downsampling
factors from 1x to 12x. Second, to address the domain shift and the lack of
annotations, we propose a novel unsupervised domain adaptation method, called
AdaptOR, to adapt a model from an in-the-wild labeled source domain to a
statistically different unlabeled target domain. We propose to exploit explicit
geometric constraints on the different augmentations of the unlabeled target
domain image to generate accurate pseudo labels and use these pseudo labels to
train the model on high- and low-resolution OR images in a self-training
framework. Furthermore, we propose disentangled feature normalization to handle
the statistically different source and target domain data. Extensive
experimental results with detailed ablation studies on the two OR datasets
MVOR+ and TUM-OR-test show the effectiveness of our approach against strongly
constructed baselines, especially on the low-resolution privacy-preserving OR
images. Finally, we show the generality of our method as a semi-supervised
learning (SSL) method on the large-scale COCO dataset, where we achieve
comparable results with as few as 1% of labeled supervision against a model
trained with 100% labeled supervision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DAReN: A Collaborative Approach Towards Reasoning And Disentangling. (arXiv:2109.13156v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13156">
<div class="article-summary-box-inner">
<span><p>Computational learning approaches to solving visual reasoning tests, such as
Raven's Progressive Matrices (RPM), critically depend on the ability to
identify the visual concepts used in the test (i.e., the representation) as
well as the latent rules based on those concepts (i.e., the reasoning).
However, learning of representation and reasoning is a challenging and
ill-posed task, often approached in a stage-wise manner (first representation,
then reasoning). In this work, we propose an end-to-end joint
representation-reasoning learning framework, which leverages a weak form of
inductive bias to improve both tasks together. Specifically, we introduce a
general generative graphical model for RPMs, GM-RPM, and apply it to solve the
reasoning test. We accomplish this using a novel learning framework
Disentangling based Abstract Reasoning Network (DAReN) based on the principles
of GM-RPM. We perform an empirical evaluation of DAReN over several benchmark
datasets. DAReN shows consistent improvement over state-of-the-art (SOTA)
models on both the reasoning and the disentanglement tasks. This demonstrates
the strong correlation between disentangled latent representation and the
ability to solve abstract visual reasoning tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Fusion Prior for Multi-Focus Image Super Resolution Fusion. (arXiv:2110.05706v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.05706">
<div class="article-summary-box-inner">
<span><p>Multi-focus image fusion (MFIF) and super-resolution (SR) are the inverse
problem of imaging model, purposes of MFIF and SR are obtaining all-in-focus
and high-resolution 2D mapping of targets. Though various MFIF and SR methods
have been designed; almost all the them deal with MFIF and SR separately. This
paper unifies MFIF and SR problems in the physical perspective as the
multi-focus image super resolution fusion (MFISRF), and we propose a novel
unified dataset-free unsupervised framework named deep fusion prior (DFP)
based-on deep image prior (DIP) to address such MFISRF with single model.
Experiments have proved that our proposed DFP approaches or even outperforms
those state-of-art MFIF and SR method combinations. To our best knowledge, our
proposed work is a dataset-free unsupervised method to simultaneously implement
the multi-focus fusion and super-resolution task for the first time.
Additionally, DFP is a general framework, thus its networks and focus
measurement tactics can be continuously updated to further improve the MFISRF
performance. DFP codes are open source available at
<a href="http://github.com/GuYuanjie/DeepFusionPrior.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SOSP: Efficiently Capturing Global Correlations by Second-Order Structured Pruning. (arXiv:2110.11395v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.11395">
<div class="article-summary-box-inner">
<span><p>Pruning neural networks reduces inference time and memory costs. On standard
hardware, these benefits will be especially prominent if coarse-grained
structures, like feature maps, are pruned. We devise two novel saliency-based
methods for second-order structured pruning (SOSP) which include correlations
among all structures and layers. Our main method SOSP-H employs an innovative
second-order approximation, which enables saliency evaluations by fast
Hessian-vector products. SOSP-H thereby scales like a first-order method
despite taking into account the full Hessian. We validate SOSP-H by comparing
it to our second method SOSP-I that uses a well-established Hessian
approximation, and to numerous state-of-the-art methods. While SOSP-H performs
on par or better in terms of accuracy, it has clear advantages in terms of
scalability and efficiency. This allowed us to scale SOSP-H to large-scale
vision tasks, even though it captures correlations across all layers of the
network. To underscore the global nature of our pruning methods, we evaluate
their performance not only by removing structures from a pretrained network,
but also by detecting architectural bottlenecks. We show that our algorithms
allow to systematically reveal architectural bottlenecks, which we then remove
to further increase the accuracy of the networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">fMRI Neurofeedback Learning Patterns are Predictive of Personal and Clinical Traits. (arXiv:2112.11014v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11014">
<div class="article-summary-box-inner">
<span><p>We obtain a personal signature of a person's learning progress in a
self-neuromodulation task, guided by functional MRI (fMRI). The signature is
based on predicting the activity of the Amygdala in a second neurofeedback
session, given a similar fMRI-derived brain state in the first session. The
prediction is made by a deep neural network, which is trained on the entire
training cohort of patients. This signal, which is indicative of a person's
progress in performing the task of Amygdala modulation, is aggregated across
multiple prototypical brain states and then classified by a linear classifier
to various personal and clinical indications. The predictive power of the
obtained signature is stronger than previous approaches for obtaining a
personal signature from fMRI neurofeedback and provides an indication that a
person's learning pattern may be used as a diagnostic tool. Our code has been
made available, and data would be shared, subject to ethical approvals.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Equalized Focal Loss for Dense Long-Tailed Object Detection. (arXiv:2201.02593v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.02593">
<div class="article-summary-box-inner">
<span><p>Despite the recent success of long-tailed object detection, almost all
long-tailed object detectors are developed based on the two-stage paradigm. In
practice, one-stage detectors are more prevalent in the industry because they
have a simple and fast pipeline that is easy to deploy. However, in the
long-tailed scenario, this line of work has not been explored so far. In this
paper, we investigate whether one-stage detectors can perform well in this
case. We discover the primary obstacle that prevents one-stage detectors from
achieving excellent performance is: categories suffer from different degrees of
positive-negative imbalance problems under the long-tailed data distribution.
The conventional focal loss balances the training process with the same
modulating factor for all categories, thus failing to handle the long-tailed
problem. To address this issue, we propose the Equalized Focal Loss (EFL) that
rebalances the loss contribution of positive and negative samples of different
categories independently according to their imbalance degrees. Specifically,
EFL adopts a category-relevant modulating factor which can be adjusted
dynamically by the training status of different categories. Extensive
experiments conducted on the challenging LVIS v1 benchmark demonstrate the
effectiveness of our proposed method. With an end-to-end training pipeline, EFL
achieves 29.2% in terms of overall AP and obtains significant performance
improvements on rare categories, surpassing all existing state-of-the-art
methods. The code is available at https://github.com/ModelTC/EOD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Pretraining for Echocardiography Segmentation with Limited Data. (arXiv:2201.07219v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.07219">
<div class="article-summary-box-inner">
<span><p>Contrastive learning has proven useful in many applications where access to
labelled data is limited. The lack of annotated data is particularly
problematic in medical image segmentation as it is difficult to have clinical
experts manually annotate large volumes of data such as cardiac structures in
ultrasound images of the heart. In this paper, we argue whether or not
contrastive pretraining is helpful for the segmentation of the left ventricle
in echocardiography images. Furthermore, we study the effect of contrastive
pretraining on two well-known segmentation networks, UNet and DeepLabV3. Our
results show that contrastive pretraining helps improve the performance on left
ventricle segmentation, particularly when annotated data is scarce. We show how
to achieve comparable results to state-of-the-art fully supervised algorithms
when we train our models in a self-supervised fashion followed by fine-tuning
on just 5\% of the data. We show that our solution outperforms what is
currently published on a large public dataset (EchoNet-Dynamic) achieving a
Dice score of 0.9211. We also compare the performance of our solution on
another smaller dataset (CAMUS) to demonstrate the generalizability of our
proposed solution. The code is available at
(https://github.com/BioMedIA-MBZUAI/contrastive-echo).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin Lesion Classification. (arXiv:2202.02832v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.02832">
<div class="article-summary-box-inner">
<span><p>Convolutional Neural Networks have demonstrated human-level performance in
the classification of melanoma and other skin lesions, but evident performance
disparities between differing skin tones should be addressed before widespread
deployment. In this work, we propose an efficient yet effective algorithm for
automatically labelling the skin tone of lesion images, and use this to
annotate the benchmark ISIC dataset. We subsequently use these automated labels
as the target for two leading bias unlearning techniques towards mitigating
skin tone bias. Our experimental results provide evidence that our skin tone
detection algorithm outperforms existing solutions and that unlearning skin
tone improves generalisation and can reduce the performance disparity between
melanoma detection in lighter and darker skin tones.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ab-initio Contrast Estimation and Denoising of Cryo-EM Images. (arXiv:2202.07737v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.07737">
<div class="article-summary-box-inner">
<span><p>Background and Objective: The contrast of cryo-EM images varies from one to
another, primarily due to the uneven thickness of the ice layer. This contrast
variation can affect the quality of 2-D class averaging, 3-D ab-initio
modeling, and 3-D heterogeneity analysis. Contrast estimation is currently
performed during 3-D iterative refinement. As a result, the estimates are not
available at the earlier computational stages of class averaging and ab-initio
modeling. This paper aims to solve the contrast estimation problem directly
from the picked particle images in the ab-initio stage, without estimating the
3-D volume, image rotations, or class averages.
</p>
<p>Methods: The key observation underlying our analysis is that the 2-D
covariance matrix of the raw images is related to the covariance of the
underlying clean images, the noise variance, and the contrast variability
between images. We show that the contrast variability can be derived from the
2-D covariance matrix and we apply the existing Covariance Wiener Filtering
(CWF) framework to estimate it. We also demonstrate a modification of CWF to
estimate the contrast of individual images.
</p>
<p>Results: Our method improves the contrast estimation by a large margin,
compared to the previous CWF method. Its estimation accuracy is often
comparable to that of an oracle that knows the ground truth covariance of the
clean images. The more accurate contrast estimation also improves the quality
of image restoration as demonstrated in both synthetic and experimental
datasets.
</p>
<p>Conclusions: This paper proposes an effective method for contrast estimation
directly from noisy images without using any 3-D volume information. It enables
contrast correction in the earlier stage of single particle analysis, and may
improve the accuracy of downstream processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">U-Attention to Textures: Hierarchical Hourglass Vision Transformer for Universal Texture Synthesis. (arXiv:2202.11703v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11703">
<div class="article-summary-box-inner">
<span><p>We present a novel U-Attention vision Transformer for universal texture
synthesis. We exploit the natural long-range dependencies enabled by the
attention mechanism to allow our approach to synthesize diverse textures while
preserving their structures in a single inference. We propose a hierarchical
hourglass backbone that attends to the global structure and performs patch
mapping at varying scales in a coarse-to-fine-to-coarse stream. Completed by
skip connection and convolution designs that propagate and fuse information at
different scales, our hierarchical U-Attention architecture unifies attention
to features from macro structures to micro details, and progressively refines
synthesis results at successive stages. Our method achieves stronger 2$\times$
synthesis than previous work on both stochastic and structured textures while
generalizing to unseen textures without fine-tuning. Ablation studies
demonstrate the effectiveness of each component of our architecture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Disentangled Generative Adversarial Network for Zero-Shot Sketch-Based 3D Shape Retrieval. (arXiv:2202.11948v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11948">
<div class="article-summary-box-inner">
<span><p>Sketch-based 3D shape retrieval is a challenging task due to the large domain
discrepancy between sketches and 3D shapes. Since existing methods are trained
and evaluated on the same categories, they cannot effectively recognize the
categories that have not been used during training. In this paper, we propose a
novel domain disentangled generative adversarial network (DD-GAN) for zero-shot
sketch-based 3D retrieval, which can retrieve the unseen categories that are
not accessed during training. Specifically, we first generate domain-invariant
features and domain-specific features by disentangling the learned features of
sketches and 3D shapes, where the domain-invariant features are used to align
with the corresponding word embeddings. Then, we develop a generative
adversarial network that combines the domain-specific features of the seen
categories with the aligned domain-invariant features to synthesize samples,
where the synthesized samples of the unseen categories are generated by using
the corresponding word embeddings. Finally, we use the synthesized samples of
the unseen categories combined with the real samples of the seen categories to
train the network for retrieval, so that the unseen categories can be
recognized. In order to reduce the domain shift problem, we utilized unlabeled
unseen samples to enhance the discrimination ability of the discriminator. With
the discriminator distinguishing the generated samples from the unlabeled
unseen samples, the generator can generate more realistic unseen samples.
Extensive experiments on the SHREC'13 and SHREC'14 datasets show that our
method significantly improves the retrieval performance of the unseen
categories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Capturing Shape Information with Multi-Scale Topological Loss Terms for 3D Reconstruction. (arXiv:2203.01703v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.01703">
<div class="article-summary-box-inner">
<span><p>Reconstructing 3D objects from 2D images is both challenging for our brains
and machine learning algorithms. To support this spatial reasoning task,
contextual information about the overall shape of an object is critical.
However, such information is not captured by established loss terms (e.g. Dice
loss). We propose to complement geometrical shape information by including
multi-scale topological features, such as connected components, cycles, and
voids, in the reconstruction loss. Our method uses cubical complexes to
calculate topological features of 3D volume data and employs an optimal
transport distance to guide the reconstruction process. This topology-aware
loss is fully differentiable, computationally efficient, and can be added to
any neural network. We demonstrate the utility of our loss by incorporating it
into SHAPR, a model for predicting the 3D cell shape of individual cells based
on 2D microscopy images. Using a hybrid loss that leverages both geometrical
and topological information of single objects to assess their shape, we find
that topological information substantially improves the quality of
reconstructions, thus highlighting its ability to extract more relevant
features from image datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mapping global dynamics of benchmark creation and saturation in artificial intelligence. (arXiv:2203.04592v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.04592">
<div class="article-summary-box-inner">
<span><p>Benchmarks are crucial to measuring and steering progress in artificial
intelligence (AI). However, recent studies raised concerns over the state of AI
benchmarking, reporting issues such as benchmark overfitting, benchmark
saturation and increasing centralization of benchmark dataset creation. To
facilitate monitoring of the health of the AI benchmarking ecosystem, we
introduce methodologies for creating condensed maps of the global dynamics of
benchmark creation and saturation. We curated data for 1688 benchmarks covering
the entire domains of computer vision and natural language processing, and show
that a large fraction of benchmarks quickly trended towards near-saturation,
that many benchmarks fail to find widespread utilization, and that benchmark
performance gains for different AI tasks were prone to unforeseen bursts. We
analyze attributes associated with benchmark popularity, and conclude that
future benchmarks should emphasize versatility, breadth and real-world utility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MotionSC: Data Set and Network for Real-Time Semantic Mapping in Dynamic Environments. (arXiv:2203.07060v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07060">
<div class="article-summary-box-inner">
<span><p>This work addresses a gap in semantic scene completion (SSC) data by creating
a novel outdoor data set with accurate and complete dynamic scenes. Our data
set is formed from randomly sampled views of the world at each time step, which
supervises generalizability to complete scenes without occlusions or traces. We
create SSC baselines from state-of-the-art open source networks and construct a
benchmark real-time dense local semantic mapping algorithm, MotionSC, by
leveraging recent 3D deep learning architectures to enhance SSC with temporal
information. Our network shows that the proposed data set can quantify and
supervise accurate scene completion in the presence of dynamic objects, which
can lead to the development of improved dynamic mapping algorithms. All
software is available at https://github.com/UMich-CURLY/3DMapping.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel End-To-End Network for Reconstruction of Non-Regularly Sampled Image Data Using Locally Fully Connected Layers. (arXiv:2203.09180v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.09180">
<div class="article-summary-box-inner">
<span><p>Quarter sampling and three-quarter sampling are novel sensor concepts that
enable the acquisition of higher resolution images without increasing the
number of pixels. This is achieved by non-regularly covering parts of each
pixel of a low-resolution sensor such that only one quadrant or three quadrants
of the sensor area of each pixel is sensitive to light. Combining a properly
designed mask and a high-quality reconstruction algorithm, a higher image
quality can be achieved than using a low-resolution sensor and subsequent
upsampling. For the latter case, the image quality can be further enhanced
using super resolution algorithms such as the very deep super resolution
network (VDSR). In this paper, we propose a novel end-to-end neural network to
reconstruct high resolution images from non-regularly sampled sensor data. The
network is a concatenation of a locally fully connected reconstruction network
(LFCR) and a standard VDSR network. Altogether, using a three-quarter sampling
sensor with our novel neural network layout, the image quality in terms of PSNR
for the Urban100 dataset can be increased by 2.96 dB compared to the
state-of-the-art approach. Compared to a low-resolution sensor with VDSR, a
gain of 1.11 dB is achieved.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Intermediate-level Attack Framework on The Basis of Linear Regression. (arXiv:2203.10723v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.10723">
<div class="article-summary-box-inner">
<span><p>This paper substantially extends our work published at ECCV, in which an
intermediate-level attack was proposed to improve the transferability of some
baseline adversarial examples. Specifically, we advocate a framework in which a
direct linear mapping from the intermediate-level discrepancies (between
adversarial features and benign features) to prediction loss of the adversarial
example is established. By delving deep into the core components of such a
framework, we show that 1) a variety of linear regression models can all be
considered in order to establish the mapping, 2) the magnitude of the finally
obtained intermediate-level adversarial discrepancy is correlated with the
transferability, 3) further boost of the performance can be achieved by
performing multiple runs of the baseline attack with random initialization. In
addition, by leveraging these findings, we achieve new state-of-the-arts on
transfer-based $\ell_\infty$ and $\ell_2$ attacks. Our code is publicly
available at https://github.com/qizhangli/ila-plus-plus-lr.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Privileged Attribution Constrained Deep Networks for Facial Expression Recognition. (arXiv:2203.12905v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.12905">
<div class="article-summary-box-inner">
<span><p>Facial Expression Recognition (FER) is crucial in many research domains
because it enables machines to better understand human behaviours. FER methods
face the problems of relatively small datasets and noisy data that don't allow
classical networks to generalize well. To alleviate these issues, we guide the
model to concentrate on specific facial areas like the eyes, the mouth or the
eyebrows, which we argue are decisive to recognise facial expressions. We
propose the Privileged Attribution Loss (PAL), a method that directs the
attention of the model towards the most salient facial regions by encouraging
its attribution maps to correspond to a heatmap formed by facial landmarks.
Furthermore, we introduce several channel strategies that allow the model to
have more degrees of freedom. The proposed method is independent of the
backbone architecture and doesn't need additional semantic information at test
time. Finally, experimental results show that the proposed PAL method
outperforms current state-of-the-art methods on both RAF-DB and AffectNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VocaLiST: An Audio-Visual Synchronisation Model for Lips and Voices. (arXiv:2204.02090v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.02090">
<div class="article-summary-box-inner">
<span><p>In this paper, we address the problem of lip-voice synchronisation in videos
containing human face and voice. Our approach is based on determining if the
lips motion and the voice in a video are synchronised or not, depending on
their audio-visual correspondence score. We propose an audio-visual cross-modal
transformer-based model that outperforms several baseline models in the
audio-visual synchronisation task on the standard lip-reading speech benchmark
dataset LRS2. While the existing methods focus mainly on lip synchronisation in
speech videos, we also consider the special case of the singing voice. The
singing voice is a more challenging use case for synchronisation due to
sustained vowel sounds. We also investigate the relevance of lip
synchronisation models trained on speech datasets in the context of singing
voice. Finally, we use the frozen visual features learned by our lip
synchronisation model in the singing voice separation task to outperform a
baseline audio-visual model which was trained end-to-end. The demos, source
code, and the pre-trained models are available on
https://ipcv.github.io/VocaLiST/
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Pneumatic Non-Prehensile Manipulation with a Mobile Blower. (arXiv:2204.02390v2 [cs.RO] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.02390">
<div class="article-summary-box-inner">
<span><p>We investigate pneumatic non-prehensile manipulation (i.e., blowing) as a
means of efficiently moving scattered objects into a target receptacle. Due to
the chaotic nature of aerodynamic forces, a blowing controller must (i)
continually adapt to unexpected changes from its actions, (ii) maintain
fine-grained control, since the slightest misstep can result in large
unintended consequences (e.g., scatter objects already in a pile), and (iii)
infer long-range plans (e.g., move the robot to strategic blowing locations).
We tackle these challenges in the context of deep reinforcement learning,
introducing a multi-frequency version of the spatial action maps framework.
This allows for efficient learning of vision-based policies that effectively
combine high-level planning and low-level closed-loop control for dynamic
mobile manipulation. Experiments show that our system learns efficient
behaviors for the task, demonstrating in particular that blowing achieves
better downstream performance than pushing, and that our policies improve
performance over baselines. Moreover, we show that our system naturally
encourages emergent specialization between the different subpolicies spanning
low-level fine-grained control and high-level planning. On a real mobile robot
equipped with a miniature air blower, we show that our simulation-trained
policies transfer well to a real environment and can generalize to novel
objects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LifeLonger: A Benchmark for Continual Disease Classification. (arXiv:2204.05737v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.05737">
<div class="article-summary-box-inner">
<span><p>Deep learning models have shown a great effectiveness in recognition of
findings in medical images. However, they cannot handle the ever-changing
clinical environment, bringing newly annotated medical data from different
sources. To exploit the incoming streams of data, these models would benefit
largely from sequentially learning from new samples, without forgetting the
previously obtained knowledge. In this paper we introduce LifeLonger, a
benchmark for continual disease classification on the MedMNIST collection, by
applying existing state-of-the-art continual learning methods. In particular,
we consider three continual learning scenarios, namely, task and class
incremental learning and the newly defined cross-domain incremental learning.
Task and class incremental learning of diseases address the issue of
classifying new samples without re-training the models from scratch, while
cross-domain incremental learning addresses the issue of dealing with datasets
originating from different institutions while retaining the previously obtained
knowledge. We perform a thorough analysis of the performance and examine how
the well-known challenges of continual learning, such as the catastrophic
forgetting exhibit themselves in this setting. The encouraging results
demonstrate that continual learning has a major potential to advance disease
classification and to produce a more robust and efficient learning framework
for clinical settings. The code repository, data partitions and baseline
results for the complete benchmark will be made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Graph-DETR3D: Rethinking Overlapping Regions for Multi-View 3D Object Detection. (arXiv:2204.11582v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11582">
<div class="article-summary-box-inner">
<span><p>3D object detection from multiple image views is a fundamental and
challenging task for visual scene understanding. Due to its low cost and high
efficiency, multi-view 3D object detection has demonstrated promising
application prospects. However, accurately detecting objects through
perspective views in the 3D space is extremely difficult due to the lack of
depth information. Recently, DETR3D introduces a novel 3D-2D query paradigm in
aggregating multi-view images for 3D object detection and achieves
state-of-the-art performance. In this paper, with intensive pilot experiments,
we quantify the objects located at different regions and find that the
"truncated instances" (i.e., at the border regions of each image) are the main
bottleneck hindering the performance of DETR3D. Although it merges multiple
features from two adjacent views in the overlapping regions, DETR3D still
suffers from insufficient feature aggregation, thus missing the chance to fully
boost the detection performance. In an effort to tackle the problem, we propose
Graph-DETR3D to automatically aggregate multi-view imagery information through
graph structure learning (GSL). It constructs a dynamic 3D graph between each
object query and 2D feature maps to enhance the object representations,
especially at the border regions. Besides, Graph-DETR3D benefits from a novel
depth-invariant multi-scale training strategy, which maintains the visual depth
consistency by simultaneously scaling the image size and the object depth.
Extensive experiments on the nuScenes dataset demonstrate the effectiveness and
efficiency of our Graph-DETR3D. Notably, our best model achieves 49.5 NDS on
the nuScenes test leaderboard, achieving new state-of-the-art in comparison
with various published image-view 3D object detectors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Point Cloud Semantic Segmentation using Multi Scale Sparse Convolution Neural Network. (arXiv:2205.01550v6 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.01550">
<div class="article-summary-box-inner">
<span><p>In recent years, with the development of computing resources and LiDAR, point
cloud semantic segmentation has attracted many researchers. For the sparsity of
point clouds, although there is already a way to deal with sparse convolution,
multi-scale features are not considered. In this letter, we propose a feature
extraction module based on multi-scale sparse convolution and a feature
selection module based on channel attention and build a point cloud
segmentation network framework based on this. By introducing multi-scale sparse
convolution, the network could capture richer feature information based on
convolution kernels with different sizes, improving the segmentation result of
point cloud segmentation. Experimental results on Stanford large-scale 3-D
Indoor Spaces(S3DIS) dataset and outdoor dataset(SemanticKITTI), demonstrate
effectiveness and superiority of the proposed mothod.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Task-relevant Representations for Generalization via Characteristic Functions of Reward Sequence Distributions. (arXiv:2205.10218v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10218">
<div class="article-summary-box-inner">
<span><p>Generalization across different environments with the same tasks is critical
for successful applications of visual reinforcement learning (RL) in real
scenarios. However, visual distractions -- which are common in real scenes --
from high-dimensional observations can be hurtful to the learned
representations in visual RL, thus degrading the performance of generalization.
To tackle this problem, we propose a novel approach, namely Characteristic
Reward Sequence Prediction (CRESP), to extract the task-relevant information by
learning reward sequence distributions (RSDs), as the reward signals are
task-relevant in RL and invariant to visual distractions. Specifically, to
effectively capture the task-relevant information via RSDs, CRESP introduces an
auxiliary task -- that is, predicting the characteristic functions of RSDs --
to learn task-relevant representations, because we can well approximate the
high-dimensional distributions by leveraging the corresponding characteristic
functions. Experiments demonstrate that CRESP significantly improves the
performance of generalization on unseen environments, outperforming several
state-of-the-arts on DeepMind Control tasks with different visual distractions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pooling Revisited: Your Receptive Field is Suboptimal. (arXiv:2205.15254v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.15254">
<div class="article-summary-box-inner">
<span><p>The size and shape of the receptive field determine how the network
aggregates local information and affect the overall performance of a model
considerably. Many components in a neural network, such as kernel sizes and
strides for convolution and pooling operations, influence the configuration of
a receptive field. However, they still rely on hyperparameters, and the
receptive fields of existing models result in suboptimal shapes and sizes.
Hence, we propose a simple yet effective Dynamically Optimized Pooling
operation, referred to as DynOPool, which optimizes the scale factors of
feature maps end-to-end by learning the desirable size and shape of its
receptive field in each layer. Any kind of resizing modules in a deep neural
network can be replaced by the operations with DynOPool at a minimal cost.
Also, DynOPool controls the complexity of a model by introducing an additional
loss term that constrains computational cost. Our experiments show that the
models equipped with the proposed learnable resizing module outperform the
baseline networks on multiple datasets in image classification and semantic
segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">D'ARTAGNAN: Counterfactual Video Generation. (arXiv:2206.01651v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.01651">
<div class="article-summary-box-inner">
<span><p>Causally-enabled machine learning frameworks could help clinicians to
identify the best course of treatments by answering counterfactual questions.
We explore this path for the case of echocardiograms by looking into the
variation of the Left Ventricle Ejection Fraction, the most essential clinical
metric gained from these examinations. We combine deep neural networks, twin
causal networks and generative adversarial methods for the first time to build
D'ARTAGNAN (Deep ARtificial Twin-Architecture GeNerAtive Networks), a novel
causal generative model. We demonstrate the soundness of our approach on a
synthetic dataset before applying it to cardiac ultrasound videos to answer the
question: "What would this echocardiogram look like if the patient had a
different ejection fraction?". To do so, we generate new ultrasound videos,
retaining the video style and anatomy of the original patient, while modifying
the Ejection Fraction conditioned on a given input. We achieve an SSIM score of
0.79 and an R2 score of 0.51 on the counterfactual videos. Code and models are
available at: https://github.com/HReynaud/dartagnan.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recursive Deformable Image Registration Network with Mutual Attention. (arXiv:2206.01863v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.01863">
<div class="article-summary-box-inner">
<span><p>Deformable image registration, estimating the spatial transformation between
different images, is an important task in medical imaging. Many previous
studies have used learning-based methods for multi-stage registration to
perform 3D image registration to improve performance. The performance of the
multi-stage approach, however, is limited by the size of the receptive field
where complex motion does not occur at a single spatial scale. We propose a new
registration network combining recursive network architecture and mutual
attention mechanism to overcome these limitations. Compared with the
state-of-the-art deep learning methods, our network based on the recursive
structure achieves the highest accuracy in lung Computed Tomography (CT) data
set (Dice score of 92\% and average surface distance of 3.8mm for lungs) and
one of the most accurate results in abdominal CT data set with 9 organs of
various sizes (Dice score of 55\% and average surface distance of 7.8mm). We
also showed that adding 3 recursive networks is sufficient to achieve the
state-of-the-art results without a significant increase in the inference time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Training of Handwritten Word Recognition for Synthetic-to-Real Adaptation. (arXiv:2206.03149v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03149">
<div class="article-summary-box-inner">
<span><p>Performances of Handwritten Text Recognition (HTR) models are largely
determined by the availability of labeled and representative training samples.
However, in many application scenarios labeled samples are scarce or costly to
obtain. In this work, we propose a self-training approach to train a HTR model
solely on synthetic samples and unlabeled data. The proposed training scheme
uses an initial model trained on synthetic data to make predictions for the
unlabeled target dataset. Starting from this initial model with rather poor
performance, we show that a considerable adaptation is possible by training
against the predicted pseudo-labels. Moreover, the investigated self-training
strategy does not require any manually annotated training samples. We evaluate
the proposed method on four widely used benchmark datasets and show its
effectiveness on closing the gap to a model trained in a fully-supervised
manner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SUPER-IVIM-DC: Intra-voxel incoherent motion based Fetal lung maturity assessment from limited DWI data using supervised learning coupled with data-consistency. (arXiv:2206.03820v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03820">
<div class="article-summary-box-inner">
<span><p>Intra-voxel incoherent motion (IVIM) analysis of fetal lungs
Diffusion-Weighted MRI (DWI) data shows potential in providing quantitative
imaging bio-markers that reflect, indirectly, diffusion and pseudo-diffusion
for non-invasive fetal lung maturation assessment. However, long acquisition
times, due to the large number of different ``b-value'' images required for
IVIM analysis, precluded clinical feasibility. We introduce SUPER-IVIM-DC a
deep-neural-networks (DNN) approach which couples supervised loss with a
data-consistency term to enable IVIM analysis of DWI data acquired with a
limited number of b-values. We demonstrated the added-value of SUPER-IVIM-DC
over both classical and recent DNN approaches for IVIM analysis through
numerical simulations, healthy volunteer study, and IVIM analysis of fetal lung
maturation from fetal DWI data. Our numerical simulations and healthy volunteer
study show that SUPER-IVIM-DC estimates of the IVIM model parameters from
limited DWI data had lower normalized root mean-squared error compared to
previous DNN-based approaches. Further, SUPER-IVIM-DC estimates of the
pseudo-diffusion fraction parameter from limited DWI data of fetal lungs
correlate better with gestational age compared to both to classical and
DNN-based approaches (0.555 vs. 0.463 and 0.310). SUPER-IVIM-DC has the
potential to reduce the long acquisition times associated with IVIM analysis of
DWI data and to provide clinically feasible bio-markers for non-invasive fetal
lung maturity assessment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TBraTS: Trusted Brain Tumor Segmentation. (arXiv:2206.09309v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09309">
<div class="article-summary-box-inner">
<span><p>Despite recent improvements in the accuracy of brain tumor segmentation, the
results still exhibit low levels of confidence and robustness. Uncertainty
estimation is one effective way to change this situation, as it provides a
measure of confidence in the segmentation results. In this paper, we propose a
trusted brain tumor segmentation network which can generate robust segmentation
results and reliable uncertainty estimations without excessive computational
burden and modification of the backbone network. In our method, uncertainty is
modeled explicitly using subjective logic theory, which treats the predictions
of backbone neural network as subjective opinions by parameterizing the class
probabilities of the segmentation as a Dirichlet distribution. Meanwhile, the
trusted segmentation framework learns the function that gathers reliable
evidence from the feature leading to the final segmentation results. Overall,
our unified trusted segmentation framework endows the model with reliability
and robustness to out-of-distribution samples. To evaluate the effectiveness of
our model in robustness and reliability, qualitative and quantitative
experiments are conducted on the BraTS 2019 dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Test-time image-to-image translation ensembling improves out-of-distribution generalization in histopathology. (arXiv:2206.09769v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.09769">
<div class="article-summary-box-inner">
<span><p>Histopathology whole slide images (WSIs) can reveal significant
inter-hospital variability such as illumination, color or optical artifacts.
These variations, caused by the use of different scanning protocols across
medical centers (staining, scanner), can strongly harm algorithms
generalization on unseen protocols. This motivates development of new methods
to limit such drop of performances. In this paper, to enhance robustness on
unseen target protocols, we propose a new test-time data augmentation based on
multi domain image-to-image translation. It allows to project images from
unseen protocol into each source domain before classifying them and ensembling
the predictions. This test-time augmentation method results in a significant
boost of performances for domain generalization. To demonstrate its
effectiveness, our method has been evaluated on 2 different histopathology
tasks where it outperforms conventional domain generalization, standard H&amp;E
specific color augmentation/normalization and standard test-time augmentation
techniques. Our code is publicly available at
https://gitlab.com/vitadx/articles/test-time-i2i-translation-ensembling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Surgical Instrument Segmentation: A Background Image Can Be All You Need. (arXiv:2206.11804v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.11804">
<div class="article-summary-box-inner">
<span><p>Data diversity and volume are crucial to the success of training deep
learning models, while in the medical imaging field, the difficulty and cost of
data collection and annotation are especially huge. Specifically in robotic
surgery, data scarcity and imbalance have heavily affected the model accuracy
and limited the design and deployment of deep learning-based surgical
applications such as surgical instrument segmentation. Considering this, we
rethink the surgical instrument segmentation task and propose a one-to-many
data generation solution that gets rid of the complicated and expensive process
of data collection and annotation from robotic surgery. In our method, we only
utilize a single surgical background tissue image and a few open-source
instrument images as the seed images and apply multiple augmentations and
blending techniques to synthesize amounts of image variations. In addition, we
also introduce the chained augmentation mixing during training to further
enhance the data diversities. The proposed approach is evaluated on the real
datasets of the EndoVis-2018 and EndoVis-2017 surgical scene segmentation. Our
empirical analysis suggests that without the high cost of data collection and
annotation, we can achieve decent surgical instrument segmentation performance.
Moreover, we also observe that our method can deal with novel instrument
prediction in the deployment domain. We hope our inspiring results will
encourage researchers to emphasize data-centric methods to overcome demanding
deep learning limitations besides data shortage, such as class imbalance,
domain adaptation, and incremental learning. Our code is available at
https://github.com/lofrienger/Single_SurgicalScene_For_Segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FetReg2021: A Challenge on Placental Vessel Segmentation and Registration in Fetoscopy. (arXiv:2206.12512v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.12512">
<div class="article-summary-box-inner">
<span><p>Fetoscopy laser photocoagulation is a widely adopted procedure for treating
Twin-to-Twin Transfusion Syndrome (TTTS). The procedure involves
photocoagulation pathological anastomoses to regulate blood exchange among
twins. The procedure is particularly challenging due to the limited field of
view, poor manoeuvrability of the fetoscope, poor visibility, and variability
in illumination. These challenges may lead to increased surgery time and
incomplete ablation. Computer-assisted intervention (CAI) can provide surgeons
with decision support and context awareness by identifying key structures in
the scene and expanding the fetoscopic field of view through video mosaicking.
Research in this domain has been hampered by the lack of high-quality data to
design, develop and test CAI algorithms. Through the Fetoscopic Placental
Vessel Segmentation and Registration (FetReg2021) challenge, which was
organized as part of the MICCAI2021 Endoscopic Vision challenge, we released
the first largescale multicentre TTTS dataset for the development of
generalized and robust semantic segmentation and video mosaicking algorithms.
For this challenge, we released a dataset of 2060 images, pixel-annotated for
vessels, tool, fetus and background classes, from 18 in-vivo TTTS fetoscopy
procedures and 18 short video clips. Seven teams participated in this challenge
and their model performance was assessed on an unseen test dataset of 658
pixel-annotated images from 6 fetoscopic procedures and 6 short clips. The
challenge provided an opportunity for creating generalized solutions for
fetoscopic scene understanding and mosaicking. In this paper, we present the
findings of the FetReg2021 challenge alongside reporting a detailed literature
review for CAI in TTTS fetoscopy. Through this challenge, its analysis and the
release of multi-centre fetoscopic data, we provide a benchmark for future
research in this field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Key-frame Guided Network for Thyroid Nodule Recognition using Ultrasound Videos. (arXiv:2206.13318v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13318">
<div class="article-summary-box-inner">
<span><p>Ultrasound examination is widely used in the clinical diagnosis of thyroid
nodules (benign/malignant). However, the accuracy relies heavily on radiologist
experience. Although deep learning techniques have been investigated for
thyroid nodules recognition. Current solutions are mainly based on static
ultrasound images, with limited temporal information used and inconsistent with
clinical diagnosis. This paper proposes a novel method for the automated
recognition of thyroid nodules through an exhaustive exploration of ultrasound
videos and key-frames. We first propose a detection-localization framework to
automatically identify the clinical key-frame with a typical nodule in each
ultrasound video. Based on the localized key-frame, we develop a key-frame
guided video classification model for thyroid nodule recognition. Besides, we
introduce a motion attention module to help the network focus on significant
frames in an ultrasound video, which is consistent with clinical diagnosis. The
proposed thyroid nodule recognition framework is validated on clinically
collected ultrasound videos, demonstrating superior performance compared with
other state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Efficient Industrial Federated Learning Framework for AIoT: A Face Recognition Application. (arXiv:2206.13398v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13398">
<div class="article-summary-box-inner">
<span><p>Recently, the artificial intelligence of things (AIoT) has been gaining
increasing attention, with an intriguing vision of providing highly intelligent
services through the network connection of things, leading to an advanced
AI-driven ecology. However, recent regulatory restrictions on data privacy
preclude uploading sensitive local data to data centers and utilizing them in a
centralized approach. Directly applying federated learning algorithms in this
scenario could hardly meet the industrial requirements of both efficiency and
accuracy. Therefore, we propose an efficient industrial federated learning
framework for AIoT in terms of a face recognition application. Specifically, we
propose to utilize the concept of transfer learning to speed up federated
training on devices and further present a novel design of a private projector
that helps protect shared gradients without incurring additional memory
consumption or computational cost. Empirical studies on a private Asian face
dataset show that our approach can achieve high recognition accuracy in only 20
communication rounds, demonstrating its effectiveness in prediction and its
efficiency in training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Feature Refinement to Improve High Resolution Image Inpainting. (arXiv:2206.13644v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13644">
<div class="article-summary-box-inner">
<span><p>In this paper, we address the problem of degradation in inpainting quality of
neural networks operating at high resolutions. Inpainting networks are often
unable to generate globally coherent structures at resolutions higher than
their training set. This is partially attributed to the receptive field
remaining static, despite an increase in image resolution. Although downscaling
the image prior to inpainting produces coherent structure, it inherently lacks
detail present at higher resolutions. To get the best of both worlds, we
optimize the intermediate featuremaps of a network by minimizing a multiscale
consistency loss at inference. This runtime optimization improves the
inpainting results and establishes a new state-of-the-art for high resolution
inpainting. Code is available at:
https://github.com/geomagical/lama-with-refiner/tree/refinement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Consistency for Single Domain Generalization in Medical Image Segmentation. (arXiv:2206.13737v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.13737">
<div class="article-summary-box-inner">
<span><p>An organ segmentation method that can generalize to unseen contrasts and
scanner settings can significantly reduce the need for retraining of deep
learning models. Domain Generalization (DG) aims to achieve this goal. However,
most DG methods for segmentation require training data from multiple domains
during training. We propose a novel adversarial domain generalization method
for organ segmentation trained on data from a \emph{single} domain. We
synthesize the new domains via learning an adversarial domain synthesizer (ADS)
and presume that the synthetic domains cover a large enough area of plausible
distributions so that unseen domains can be interpolated from synthetic
domains. We propose a mutual information regularizer to enforce the semantic
consistency between images from the synthetic domains, which can be estimated
by patch-level contrastive learning. We evaluate our method for various organ
segmentation for unseen modalities, scanning protocols, and scanner sites.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-07-02 23:07:27.299677131 UTC">2022-07-02 23:07:27 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>