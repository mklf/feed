<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2022-05-20T01:30:00Z">05-20</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">DDXPlus: A new Dataset for Medical Automatic Diagnosis. (arXiv:2205.09148v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09148">
<div class="article-summary-box-inner">
<span><p>There has been rapidly growing interests in Automatic Diagnosis (AD) and
Automatic Symptom Detection (ASD) systems in the machine learning research
literature, aiming to assist doctors in telemedicine services. These systems
are designed to interact with patients, collect evidence relevant to their
concerns, and make predictions about the underlying diseases. Doctors would
review the interaction, including the evidence and the predictions, before
making their final decisions. Despite the recent progress, an important piece
of doctors' interactions with patients is missing in the design of AD and ASD
systems, namely the differential diagnosis. Its absence is largely due to the
lack of datasets that include such information for models to train on. In this
work, we present a large-scale synthetic dataset that includes a differential
diagnosis, along with the ground truth pathology, for each patient. In
addition, this dataset includes more pathologies, as well as types of symtoms
and antecedents. As a proof-of-concept, we extend several existing AD and ASD
systems to incorporate differential diagnosis, and provide empirical evidence
that using differentials in training signals is essential for such systems to
learn to predict differentials. Dataset available at
https://github.com/bruzwen/ddxplus
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ERNIE-Search: Bridging Cross-Encoder with Dual-Encoder via Self On-the-fly Distillation for Dense Passage Retrieval. (arXiv:2205.09153v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09153">
<div class="article-summary-box-inner">
<span><p>Neural retrievers based on pre-trained language models (PLMs), such as
dual-encoders, have achieved promising performance on the task of open-domain
question answering (QA). Their effectiveness can further reach new
state-of-the-arts by incorporating cross-architecture knowledge distillation.
However, most of the existing studies just directly apply conventional
distillation methods. They fail to consider the particular situation where the
teacher and student have different structures. In this paper, we propose a
novel distillation method that significantly advances cross-architecture
distillation for dual-encoders. Our method 1) introduces a self on-the-fly
distillation method that can effectively distill late interaction (i.e.,
ColBERT) to vanilla dual-encoder, and 2) incorporates a cascade distillation
process to further improve the performance with a cross-encoder teacher.
Extensive experiments are conducted to validate that our proposed solution
outperforms strong baselines and establish a new state-of-the-art on
open-domain QA benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Color Overmodification Emerges from Data-Driven Learning and Pragmatic Reasoning. (arXiv:2205.09172v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09172">
<div class="article-summary-box-inner">
<span><p>Speakers' referential expressions often depart from communicative ideals in
ways that help illuminate the nature of pragmatic language use. Patterns of
overmodification, in which a speaker uses a modifier that is redundant given
their communicative goal, have proven especially informative in this regard. It
seems likely that these patterns are shaped by the environment a speaker is
exposed to in complex ways. Unfortunately, systematically manipulating these
factors during human language acquisition is impossible. In this paper, we
propose to address this limitation by adopting neural networks (NN) as learning
agents. By systematically varying the environments in which these agents are
trained, while keeping the NN architecture constant, we show that
overmodification is more likely with environmental features that are infrequent
or salient. We show that these findings emerge naturally in the context of a
probabilistic model of pragmatic communication.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Carbon Figures of Merit Knowledge Creation with a Hybrid Solution and Carbon Tables API. (arXiv:2205.09175v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09175">
<div class="article-summary-box-inner">
<span><p>Nowadays there are algorithms, methods, and platforms that are being created
to accelerate the discovery of materials that are able to absorb or adsorb
$CO_2$ molecules that are in the atmosphere or during the combustion in power
plants, for instance. In this work an asynchronous REST API is described to
accelerate the creation of Carbon figures of merit knowledge, called Carbon
Tables, because the knowledge is created from tables in scientific PDF
documents and stored in knowledge graphs. The figures of merit knowledge
creation solution uses a hybrid approach, in which heuristics and machine
learning are part of. As a result, one can search the knowledge with mature and
sophisticated cognitive tools, and create more with regards to Carbon figures
of merit.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PreQuEL: Quality Estimation of Machine Translation Outputs in Advance. (arXiv:2205.09178v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09178">
<div class="article-summary-box-inner">
<span><p>We present the task of PreQuEL, Pre-(Quality-Estimation) Learning. A PreQuEL
system predicts how well a given sentence will be translated, without recourse
to the actual translation, thus eschewing unnecessary resource allocation when
translation quality is bound to be low. PreQuEL can be defined relative to a
given MT system (e.g., some industry service) or generally relative to the
state-of-the-art. From a theoretical perspective, PreQuEL places the focus on
the source text, tracing properties, possibly linguistic features, that make a
sentence harder to machine translate.
</p>
<p>We develop a baseline model for the task and analyze its performance. We also
develop a data augmentation method (from parallel corpora), that improves
results substantially. We show that this augmentation method can improve the
performance of the Quality-Estimation task as well. We investigate the
properties of the input text that our model is sensitive to, by testing it on
challenge sets and different languages. We conclude that it is aware of
syntactic and semantic distinctions, and correlates and even over-emphasizes
the importance of standard NLP features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LeRaC: Learning Rate Curriculum. (arXiv:2205.09180v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09180">
<div class="article-summary-box-inner">
<span><p>Most curriculum learning methods require an approach to sort the data samples
by difficulty, which is often cumbersome to perform. In this work, we propose a
novel curriculum learning approach termed Learning Rate Curriculum (LeRaC),
which leverages the use of a different learning rate for each layer of a neural
network to create a data-free curriculum during the initial training epochs.
More specifically, LeRaC assigns higher learning rates to neural layers closer
to the input, gradually decreasing the learning rates as the layers are placed
farther away from the input. The learning rates increase at various paces
during the first training iterations, until they all reach the same value. From
this point on, the neural model is trained as usual. This creates a model-level
curriculum learning strategy that does not require sorting the examples by
difficulty and is compatible with any neural network, generating higher
performance levels regardless of the architecture. We conduct comprehensive
experiments on eight datasets from the computer vision (CIFAR-10, CIFAR-100,
Tiny ImageNet), language (BoolQ, QNLI, RTE) and audio (ESC-50, CREMA-D)
domains, considering various convolutional (ResNet-18, Wide-ResNet-50,
DenseNet-121), recurrent (LSTM) and transformer (CvT, BERT, SepTr)
architectures, comparing our approach with the conventional training regime.
Moreover, we also compare with Curriculum by Smoothing (CBS), a
state-of-the-art data-free curriculum learning approach. Unlike CBS, our
performance improvements over the standard training regime are consistent
across all datasets and models. Furthermore, we significantly surpass CBS in
terms of training time (there is no additional cost over the standard training
regime for LeRaC).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"I'm sorry to hear that": finding bias in language models with a holistic descriptor dataset. (arXiv:2205.09209v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09209">
<div class="article-summary-box-inner">
<span><p>As language models grow in popularity, their biases across all possible
markers of demographic identity should be measured and addressed in order to
avoid perpetuating existing societal harms. Many datasets for measuring bias
currently exist, but they are restricted in their coverage of demographic axes,
and are commonly used with preset bias tests that presuppose which types of
biases the models exhibit. In this work, we present a new, more inclusive
dataset, HOLISTICBIAS, which consists of nearly 600 descriptor terms across 13
different demographic axes. HOLISTICBIAS was assembled in conversation with
experts and community members with lived experience through a participatory
process. We use these descriptors combinatorially in a set of bias measurement
templates to produce over 450,000 unique sentence prompts, and we use these
prompts to explore, identify, and reduce novel forms of bias in several
generative models. We demonstrate that our dataset is highly efficacious for
measuring previously unmeasurable biases in token likelihoods and generations
from language models, as well as in an offensiveness classifier. We will invite
additions and amendments to the dataset, and we hope it will help serve as a
basis for easy-to-use and more standardized methods for evaluating bias in NLP
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Entailment Tree Explanations via Iterative Retrieval-Generation Reasoner. (arXiv:2205.09224v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09224">
<div class="article-summary-box-inner">
<span><p>Large language models have achieved high performance on various question
answering (QA) benchmarks, but the explainability of their output remains
elusive. Structured explanations, called entailment trees, were recently
suggested as a way to explain and inspect a QA system's answer. In order to
better generate such entailment trees, we propose an architecture called
Iterative Retrieval-Generation Reasoner (IRGR). Our model is able to explain a
given hypothesis by systematically generating a step-by-step explanation from
textual premises. The IRGR model iteratively searches for suitable premises,
constructing a single entailment step at a time. Contrary to previous
approaches, our method combines generation steps and retrieval of premises,
allowing the model to leverage intermediate conclusions, and mitigating the
input size limit of baseline encoder-decoder models. We conduct experiments
using the EntailmentBank dataset, where we outperform existing benchmarks on
premise retrieval and entailment tree generation, with around 300% gain in
overall correctness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling Multi-hop Question Answering as Single Sequence Prediction. (arXiv:2205.09226v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09226">
<div class="article-summary-box-inner">
<span><p>Fusion-in-decoder (Fid) (Izacard and Grave, 2020) is a generative question
answering (QA) model that leverages passage retrieval with a pre-trained
transformer and pushed the state of the art on single-hop QA. However, the
complexity of multi-hop QA hinders the effectiveness of the generative QA
approach. In this work, we propose a simple generative approach (PathFid) that
extends the task beyond just answer generation by explicitly modeling the
reasoning process to resolve the answer for multi-hop questions. By linearizing
the hierarchical reasoning path of supporting passages, their key sentences,
and finally the factoid answer, we cast the problem as a single sequence
prediction task. To facilitate complex reasoning with multiple clues, we
further extend the unified flat representation of multiple input documents by
encoding cross-passage interactions. Our extensive experiments demonstrate that
PathFid leads to strong performance gains on two multi-hop QA datasets:
HotpotQA and IIRC. Besides the performance gains, PathFid is more
interpretable, which in turn yields answers that are more faithfully grounded
to the supporting passages and facts compared to the baseline Fid model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PromptDA: Label-guided Data Augmentation for Prompt-based Few Shot Learners. (arXiv:2205.09229v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09229">
<div class="article-summary-box-inner">
<span><p>Recent advances on large pre-trained language models (PLMs) lead impressive
gains on natural language understanding (NLU) tasks with task-specific
fine-tuning. However, direct fine-tuning PLMs heavily relies on large amount of
labeled instances, which are expensive and time-consuming to obtain.
Prompt-based tuning on PLMs has proven valuable for few shot tasks. Existing
works studying prompt-based tuning for few-shot NLU mainly focus on deriving
proper label words with a verbalizer or generating prompt templates for
eliciting semantics from PLMs. In addition, conventional data augmentation
methods have also been verified useful for few-shot tasks. However, there
currently are few data augmentation methods designed for the prompt-based
tuning paradigm. Therefore, we study a new problem of data augmentation for
prompt-based few shot learners. Since label semantics are helpful in
prompt-based tuning, we propose a novel label-guided data augmentation method
PromptDA which exploits the enriched label semantic information for data
augmentation. Experimental results on several few shot text classification
tasks show that our proposed framework achieves superior performance by
effectively leveraging label semantics and data augmentation in language
understanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Limits of Evaluating Embodied Agent Model Generalization Using Validation Sets. (arXiv:2205.09249v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09249">
<div class="article-summary-box-inner">
<span><p>Natural language guided embodied task completion is a challenging problem
since it requires understanding natural language instructions, aligning them
with egocentric visual observations, and choosing appropriate actions to
execute in the environment to produce desired changes. We experiment with
augmenting a transformer model for this task with modules that effectively
utilize a wider field of view and learn to choose whether the next step
requires a navigation or manipulation action. We observed that the proposed
modules resulted in improved, and in fact state-of-the-art performance on an
unseen validation set of a popular benchmark dataset, ALFRED. However, our best
model selected using the unseen validation set underperforms on the unseen test
split of ALFRED, indicating that performance on the unseen validation set may
not in itself be a sufficient indicator of whether model improvements
generalize to unseen test sets. We highlight this result as we believe it may
be a wider phenomenon in machine learning tasks but primarily noticeable only
in benchmarks that limit evaluations on test splits, and highlights the need to
modify benchmark design to better account for variance in model performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Twist Decoding: Diverse Generators Guide Each Other. (arXiv:2205.09273v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09273">
<div class="article-summary-box-inner">
<span><p>Natural language generation technology has recently seen remarkable progress
with large-scale training, and many natural language applications are now built
upon a wide range of generation models. Combining diverse models may lead to
further progress, but conventional ensembling (e.g., shallow fusion) requires
that they share vocabulary/tokenization schemes. We introduce Twist decoding, a
simple and general inference algorithm that generates text while benefiting
from diverse models. Our method does not assume the vocabulary, tokenization or
even generation order is shared. Our extensive evaluations on machine
translation and scientific paper summarization demonstrate that Twist decoding
substantially outperforms each model decoded in isolation over various
scenarios, including cases where domain-specific and general-purpose models are
both available. Twist decoding also consistently outperforms the popular
reranking heuristic where output candidates from one model is rescored by
another. We hope that our work will encourage researchers and practitioners to
examine generation models collectively, not just independently, and to seek out
models with complementary strengths to the currently available models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling Exemplification in Long-form Question Answering via Retrieval. (arXiv:2205.09278v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09278">
<div class="article-summary-box-inner">
<span><p>Exemplification is a process by which writers explain or clarify a concept by
providing an example. While common in all forms of writing, exemplification is
particularly useful in the task of long-form question answering (LFQA), where a
complicated answer can be made more understandable through simple examples. In
this paper, we provide the first computational study of exemplification in QA,
performing a fine-grained annotation of different types of examples (e.g.,
hypotheticals, anecdotes) in three corpora. We show that not only do
state-of-the-art LFQA models struggle to generate relevant examples, but also
that standard evaluation metrics such as ROUGE are insufficient to judge
exemplification quality. We propose to treat exemplification as a
\emph{retrieval} problem in which a partially-written answer is used to query a
large set of human-written examples extracted from a corpus. Our approach
allows a reliable ranking-type automatic metrics that correlates well with
human evaluation. A human evaluation shows that our model's retrieved examples
are more relevant than examples generated from a state-of-the-art LFQA model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are Prompt-based Models Clueless?. (arXiv:2205.09295v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09295">
<div class="article-summary-box-inner">
<span><p>Finetuning large pre-trained language models with a task-specific head has
advanced the state-of-the-art on many natural language understanding
benchmarks. However, models with a task-specific head require a lot of training
data, making them susceptible to learning and exploiting dataset-specific
superficial cues that do not generalize to other datasets. Prompting has
reduced the data requirement by reusing the language model head and formatting
the task input to match the pre-training objective. Therefore, it is expected
that few-shot prompt-based models do not exploit superficial cues. This paper
presents an empirical examination of whether few-shot prompt-based models also
exploit superficial cues. Analyzing few-shot prompt-based models on MNLI, SNLI,
HANS, and COPA has revealed that prompt-based models also exploit superficial
cues. While the models perform well on instances with superficial cues, they
often underperform or only marginally outperform random accuracy on instances
without superficial cues.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Target-Guided Dialogue Response Generation Using Commonsense and Data Augmentation. (arXiv:2205.09314v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09314">
<div class="article-summary-box-inner">
<span><p>Target-guided response generation enables dialogue systems to smoothly
transition a conversation from a dialogue context toward a target sentence.
Such control is useful for designing dialogue systems that direct a
conversation toward specific goals, such as creating non-obtrusive
recommendations or introducing new topics in the conversation. In this paper,
we introduce a new technique for target-guided response generation, which first
finds a bridging path of commonsense knowledge concepts between the source and
the target, and then uses the identified bridging path to generate transition
responses. Additionally, we propose techniques to re-purpose existing dialogue
datasets for target-guided generation. Experiments reveal that the proposed
techniques outperform various baselines on this task. Finally, we observe that
the existing automated metrics for this task correlate poorly with human
judgement ratings. We propose a novel evaluation metric that we demonstrate is
more reliable for target-guided response evaluation. Our work generally enables
dialogue system designers to exercise more control over the conversations that
their systems produce.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning from Bootstrapping and Stepwise Reinforcement Reward: A Semi-Supervised Framework for Text Style Transfer. (arXiv:2205.09324v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09324">
<div class="article-summary-box-inner">
<span><p>Text style transfer is an important task in controllable language generation.
Supervised approaches have pushed performance improvement on style-oriented
rewriting such as formality conversion. However, challenges remain due to the
scarcity of large-scale parallel data in many domains. While unsupervised
approaches do not rely on annotated sentence pairs for each style, they are
often plagued with instability issues such as mode collapse or quality
degradation. To take advantage of both supervised and unsupervised paradigms
and tackle the challenges, in this work, we propose a semi-supervised framework
for text style transfer. First, the learning process is bootstrapped with
supervision guided by automatically constructed pseudo-parallel pairs using
lexical and semantic-based methods. Then the model learns from unlabeled data
via reinforcement rewards. Specifically, we propose to improve the
sequence-to-sequence policy gradient via stepwise reward optimization,
providing fine-grained learning signals and stabilizing the reinforced learning
process. Experimental results show that the proposed approach achieves
state-of-the-art performance on multiple datasets, and produces effective
generation with as minimal as 10\% of training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Let's Talk! Striking Up Conversations via Conversational Visual Question Generation. (arXiv:2205.09327v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09327">
<div class="article-summary-box-inner">
<span><p>An engaging and provocative question can open up a great conversation. In
this work, we explore a novel scenario: a conversation agent views a set of the
user's photos (for example, from social media platforms) and asks an engaging
question to initiate a conversation with the user. The existing
vision-to-question models mostly generate tedious and obvious questions, which
might not be ideals conversation starters. This paper introduces a two-phase
framework that first generates a visual story for the photo set and then uses
the story to produce an interesting question. The human evaluation shows that
our framework generates more response-provoking questions for starting
conversations than other vision-to-question baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-lingual Inflection as a Data Augmentation Method for Parsing. (arXiv:2205.09350v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09350">
<div class="article-summary-box-inner">
<span><p>We propose a morphology-based method for low-resource (LR) dependency
parsing. We train a morphological inflector for target LR languages, and apply
it to related rich-resource (RR) treebanks to create cross-lingual
(x-inflected) treebanks that resemble the target LR language. We use such
inflected treebanks to train parsers in zero- (training on x-inflected
treebanks) and few-shot (training on x-inflected and target language treebanks)
setups. The results show that the method sometimes improves the baselines, but
not consistently.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Subtitle Segmentation for End-to-end Generation Systems. (arXiv:2205.09360v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09360">
<div class="article-summary-box-inner">
<span><p>Subtitles appear on screen as short pieces of text, segmented based on formal
constraints (length) and syntactic/semantic criteria. Subtitle segmentation can
be evaluated with sequence segmentation metrics against a human reference.
However, standard segmentation metrics cannot be applied when systems generate
outputs different than the reference, e.g. with end-to-end subtitling systems.
In this paper, we study ways to conduct reference-based evaluations of
segmentation accuracy irrespective of the textual content. We first conduct a
systematic analysis of existing metrics for evaluating subtitle segmentation.
We then introduce $Sigma$, a new Subtitle Segmentation Score derived from an
approximate upper-bound of BLEU on segmentation boundaries, which allows us to
disentangle the effect of good segmentation from text quality. To compare
$Sigma$ with existing metrics, we further propose a boundary projection method
from imperfect hypotheses to the true reference. Results show that all metrics
are able to reward high quality output but for similar outputs system ranking
depends on each metric's sensitivity to error type. Our thorough analyses
suggest $Sigma$ is a promising segmentation candidate but its reliability over
other segmentation metrics remains to be validated through correlations with
human judgements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformers as Neural Augmentors: Class Conditional Sentence Generation via Variational Bayes. (arXiv:2205.09391v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09391">
<div class="article-summary-box-inner">
<span><p>Data augmentation methods for Natural Language Processing tasks are explored
in recent years, however they are limited and it is hard to capture the
diversity on sentence level. Besides, it is not always possible to perform data
augmentation on supervised tasks. To address those problems, we propose a
neural data augmentation method, which is a combination of Conditional
Variational Autoencoder and encoder-decoder Transformer model. While encoding
and decoding the input sentence, our model captures the syntactic and semantic
representation of the input language with its class condition. Following the
developments in the past years on pre-trained language models, we train and
evaluate our models on several benchmarks to strengthen the downstream tasks.
We compare our method with 3 different augmentation techniques. The presented
results show that, our model increases the performance of current models
compared to other data augmentation techniques with a small amount of
computation power.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Two-Step Question Retrieval for Open-Domain QA. (arXiv:2205.09393v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09393">
<div class="article-summary-box-inner">
<span><p>The retriever-reader pipeline has shown promising performance in open-domain
QA but suffers from a very slow inference speed. Recently proposed question
retrieval models tackle this problem by indexing question-answer pairs and
searching for similar questions. These models have shown a significant increase
in inference speed, but at the cost of lower QA performance compared to the
retriever-reader models. This paper proposes a two-step question retrieval
model, SQuID (Sequential Question-Indexed Dense retrieval) and distant
supervision for training. SQuID uses two bi-encoders for question retrieval.
The first-step retriever selects top-k similar questions, and the second-step
retriever finds the most similar question from the top-k questions. We evaluate
the performance and the computational efficiency of SQuID. The results show
that SQuID significantly increases the performance of existing question
retrieval models with a negligible loss on inference speed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Weakly-Supervised Iterative Graph-Based Approach to Retrieve COVID-19 Misinformation Topics. (arXiv:2205.09416v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09416">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic has been accompanied by an `infodemic' -- of accurate
and inaccurate health information across social media. Detecting misinformation
amidst dynamically changing information landscape is challenging; identifying
relevant keywords and posts is arduous due to the large amount of human effort
required to inspect the content and sources of posts. We aim to reduce the
resource cost of this process by introducing a weakly-supervised iterative
graph-based approach to detect keywords, topics, and themes related to
misinformation, with a focus on COVID-19. Our approach can successfully detect
specific topics from general misinformation-related seed words in a few seed
texts. Our approach utilizes the BERT-based Word Graph Search (BWGS) algorithm
that builds on context-based neural network embeddings for retrieving
misinformation-related posts. We utilize Latent Dirichlet Allocation (LDA)
topic modeling for obtaining misinformation-related themes from the texts
returned by BWGS. Furthermore, we propose the BERT-based Multi-directional Word
Graph Search (BMDWGS) algorithm that utilizes greater starting context
information for misinformation extraction. In addition to a qualitative
analysis of our approach, our quantitative analyses show that BWGS and BMDWGS
are effective in extracting misinformation-related content compared to common
baselines in low data resource settings. Extracting such content is useful for
uncovering prevalent misconceptions and concerns and for facilitating precision
public health messaging campaigns to improve health behaviors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Insights on Neural Representations for End-to-End Speech Recognition. (arXiv:2205.09456v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09456">
<div class="article-summary-box-inner">
<span><p>End-to-end automatic speech recognition (ASR) models aim to learn a
generalised speech representation. However, there are limited tools available
to understand the internal functions and the effect of hierarchical
dependencies within the model architecture. It is crucial to understand the
correlations between the layer-wise representations, to derive insights on the
relationship between neural representations and performance.
</p>
<p>Previous investigations of network similarities using correlation analysis
techniques have not been explored for End-to-End ASR models. This paper
analyses and explores the internal dynamics between layers during training with
CNN, LSTM and Transformer based approaches using Canonical correlation analysis
(CCA) and centered kernel alignment (CKA) for the experiments. It was found
that neural representations within CNN layers exhibit hierarchical correlation
dependencies as layer depth increases but this is mostly limited to cases where
neural representation correlates more closely. This behaviour is not observed
in LSTM architecture, however there is a bottom-up pattern observed across the
training process, while Transformer encoder layers exhibit irregular
coefficiency correlation as neural depth increases. Altogether, these results
provide new insights into the role that neural architectures have upon speech
recognition performance. More specifically, these techniques can be used as
indicators to build better performing speech recognition models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Why only Micro-F1? Class Weighting of Measures for Relation Classification. (arXiv:2205.09460v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09460">
<div class="article-summary-box-inner">
<span><p>Relation classification models are conventionally evaluated using only a
single measure, e.g., micro-F1, macro-F1 or AUC. In this work, we analyze
weighting schemes, such as micro and macro, for imbalanced datasets. We
introduce a framework for weighting schemes, where existing schemes are
extremes, and two new intermediate schemes. We show that reporting results of
different weighting schemes better highlights strengths and weaknesses of a
model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Psychiatric Scale Guided Risky Post Screening for Early Detection of Depression. (arXiv:2205.09497v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09497">
<div class="article-summary-box-inner">
<span><p>Depression is a prominent health challenge to the world, and early risk
detection (ERD) of depression from online posts can be a promising technique
for combating the threat. Early depression detection faces the challenge of
efficiently tackling streaming data, balancing the tradeoff between timeliness,
accuracy and explainability. To tackle these challenges, we propose a
psychiatric scale guided risky post screening method that can capture risky
posts related to the dimensions defined in clinical depression scales, and
providing interpretable diagnostic basis. A Hierarchical Attentional Network
equipped with BERT (HAN-BERT) is proposed to further advance explainable
predictions. For ERD, we propose an online algorithm based on an evolving queue
of risky posts that can significantly reduce the number of model inferences to
boost efficiency. Experiments show that our method outperforms the competitive
feature-based and neural models under conventional depression detection
settings, and achieves simultaneous improvement in both efficacy and efficiency
for ERD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SDS-200: A Swiss German Speech to Standard German Text Corpus. (arXiv:2205.09501v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09501">
<div class="article-summary-box-inner">
<span><p>We present SDS-200, a corpus of Swiss German dialectal speech with Standard
German text translations, annotated with dialect, age, and gender information
of the speakers. The dataset allows for training speech translation, dialect
recognition, and speech synthesis systems, among others. The data was collected
using a web recording tool that is open to the public. Each participant was
given a text in Standard German and asked to translate it to their Swiss German
dialect before recording it. To increase the corpus quality, recordings were
validated by other participants. The data consists of 200 hours of speech by
around 4000 different speakers and covers a large part of the Swiss-German
dialect landscape. We release SDS-200 alongside a baseline speech translation
model, which achieves a word error rate (WER) of 30.3 and a BLEU score of 53.1
on the SDS-200 test set. Furthermore, we use SDS-200 to fine-tune a pre-trained
XLS-R model, achieving 21.6 WER and 64.0 BLEU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Impact of COVID-19 Pandemic on LGBTQ Online Communitie. (arXiv:2205.09511v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09511">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic has disproportionately impacted the lives of
minorities, such as members of the LGBTQ community (lesbian, gay, bisexual,
transgender, and queer) due to pre-existing social disadvantages and health
disparities. Although extensive research has been carried out on the impact of
the COVID-19 pandemic on different aspects of the general population's lives,
few studies are focused on the LGBTQ population. In this paper, we identify a
group of Twitter users who self-disclose to belong to the LGBTQ community. We
develop and evaluate two sets of machine learning classifiers using a
pre-pandemic and a during pandemic dataset to identify Twitter posts exhibiting
minority stress, which is a unique pressure faced by the members of the LGBTQ
population due to their sexual and gender identities. For this task, we collect
a set of 20,593,823 posts by 7,241 self-disclosed LGBTQ users and annotate a
randomly selected subset of 2800 posts. We demonstrate that our best
pre-pandemic and during pandemic models show strong and stable performance for
detecting posts that contain minority stress. We investigate the linguistic
differences in minority stress posts across pre- and during-pandemic periods.
We find that anger words are strongly associated with minority stress during
the COVID-19 pandemic. We explore the impact of the pandemic on the emotional
states of the LGBTQ population by conducting controlled comparisons with the
general population. We adopt propensity score-based matching to perform a
causal analysis. The results show that the LBGTQ population have a greater
increase in the usage of cognitive words and worsened observable attribute in
the usage of positive emotion words than the group of the general population
with similar pre-pandemic behavioral attributes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Simple yet Effective Relation Information Guided Approach for Few-Shot Relation Extraction. (arXiv:2205.09536v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09536">
<div class="article-summary-box-inner">
<span><p>Few-Shot Relation Extraction aims at predicting the relation for a pair of
entities in a sentence by training with a few labelled examples in each
relation. Some recent works have introduced relation information (i.e.,
relation labels or descriptions) to assist model learning based on Prototype
Network. However, most of them constrain the prototypes of each relation class
implicitly with relation information, generally through designing complex
network structures, like generating hybrid features, combining with contrastive
learning or attention networks. We argue that relation information can be
introduced more explicitly and effectively into the model. Thus, this paper
proposes a direct addition approach to introduce relation information.
Specifically, for each relation class, the relation representation is first
generated by concatenating two views of relations (i.e., [CLS] token embedding
and the mean value of embeddings of all tokens) and then directly added to the
original prototype for both train and prediction. Experimental results on the
benchmark dataset FewRel 1.0 show significant improvements and achieve
comparable results to the state-of-the-art, which demonstrates the
effectiveness of our proposed approach. Besides, further analyses verify that
the direct addition is a much more effective way to integrate the relation
representations and the original prototypes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Spoken Language Identification using a Time-Delay Neural Network. (arXiv:2205.09564v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09564">
<div class="article-summary-box-inner">
<span><p>Closed-set spoken language identification is the task of recognizing the
language being spoken in a recorded audio clip from a set of known languages.
In this study, a language identification system was built and trained to
distinguish between Arabic, Spanish, French, and Turkish based on nothing more
than recorded speech. A pre-existing multilingual dataset was used to train a
series of acoustic models based on the Tedlium TDNN model to perform automatic
speech recognition. The system was provided with a custom multilingual language
model and a specialized pronunciation lexicon with language names prepended to
phones. The trained model was used to generate phone alignments to test data
from all four languages, and languages were predicted based on a voting scheme
choosing the most common language prepend in an utterance. Accuracy was
measured by comparing predicted languages to known languages, and was
determined to be very high in identifying Spanish and Arabic, and somewhat
lower in identifying Turkish and French.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Approaching Reflex Predictions as a Classification Problem Using Extended Phonological Alignments. (arXiv:2205.09570v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09570">
<div class="article-summary-box-inner">
<span><p>This work describes an implementation of the "extended alignment" (or
"multitiers") approach for cognate reflex prediction, submitted to "Prediction
of Cognate Reflexes" shared task. Similarly to List2022d, the technique
involves an automatic extension of sequence alignments with multilayered
vectors that encode informational tiers on both site-specific traits, such as
sound classes and distinctive features, as well as contextual and
suprasegmental ones, conveyed by cross-site referrals and replication. The
method allows to generalize the problem of cognate reflex prediction as a
classification problem, with models trained using a parallel corpus of cognate
sets. A model using random forests is trained and evaluated on the shared task
for reflex prediction, and the experimental results are presented and discussed
along with some differences to other implementations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A machine transliteration tool between Uzbek alphabets. (arXiv:2205.09578v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09578">
<div class="article-summary-box-inner">
<span><p>Machine transliteration, as defined in this paper, is a process of
automatically transforming written script of words from a source alphabet into
words of another target alphabet within the same language, while preserving
their meaning, as well as pronunciation. The main goal of this paper is to
present a machine transliteration tool between three common scripts used in
low-resource Uzbek language: the old Cyrillic, currently official Latin, and
newly announced New Latin alphabets. The tool has been created using a
combination of rule-based and fine-tuning approaches. The created tool is
available as an open-source Python package, as well as a web-based application
including a public API. To our knowledge, this is the first machine
transliteration tool that supports the newly announced Latin alphabet of the
Uzbek language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LAGr: Label Aligned Graphs for Better Systematic Generalization in Semantic Parsing. (arXiv:2205.09607v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09607">
<div class="article-summary-box-inner">
<span><p>Semantic parsing is the task of producing structured meaning representations
for natural language sentences. Recent research has pointed out that the
commonly-used sequence-to-sequence (seq2seq) semantic parsers struggle to
generalize systematically, i.e. to handle examples that require recombining
known knowledge in novel settings. In this work, we show that better systematic
generalization can be achieved by producing the meaning representation directly
as a graph and not as a sequence. To this end we propose LAGr (Label Aligned
Graphs), a general framework to produce semantic parses by independently
predicting node and edge labels for a complete multi-layer input-aligned graph.
The strongly-supervised LAGr algorithm requires aligned graphs as inputs,
whereas weakly-supervised LAGr infers alignments for originally unaligned
target graphs using approximate maximum-a-posteriori inference. Experiments
demonstrate that LAGr achieves significant improvements in systematic
generalization upon the baseline seq2seq parsers in both strongly- and
weakly-supervised settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Acceptability Judgements via Examining the Topology of Attention Maps. (arXiv:2205.09630v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09630">
<div class="article-summary-box-inner">
<span><p>The role of the attention mechanism in encoding linguistic knowledge has
received special interest in NLP. However, the ability of the attention heads
to judge the grammatical acceptability of a sentence has been underexplored.
This paper approaches the paradigm of acceptability judgments with topological
data analysis (TDA), showing that the geometric properties of the attention
graph can be efficiently exploited for two standard practices in linguistics:
binary judgments and linguistic minimal pairs. Topological features enhance the
BERT-based acceptability classifier scores by $8$%-$24$% on CoLA in three
languages (English, Italian, and Swedish). By revealing the topological
discrepancy between attention maps of minimal pairs, we achieve the human-level
performance on the BLiMP benchmark, outperforming nine statistical and
Transformer LM baselines. At the same time, TDA provides the foundation for
analyzing the linguistic functions of attention heads and interpreting the
correspondence between the graph features and grammatical phenomena.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Phylogeny-Inspired Adaptation of Multilingual Models to New Languages. (arXiv:2205.09634v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09634">
<div class="article-summary-box-inner">
<span><p>Large pretrained multilingual models, trained on dozens of languages, have
delivered promising results due to cross-lingual learning capabilities on
variety of language tasks. Further adapting these models to specific languages,
especially ones unseen during pre-training, is an important goal towards
expanding the coverage of language technologies. In this study, we show how we
can use language phylogenetic information to improve cross-lingual transfer
leveraging closely related languages in a structured, linguistically-informed
manner. We perform adapter-based training on languages from diverse language
families (Germanic, Uralic, Tupian, Uto-Aztecan) and evaluate on both syntactic
and semantic tasks, obtaining more than 20% relative performance improvements
over strong commonly used baselines, especially on languages unseen during
pre-training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SNaC: Coherence Error Detection for Narrative Summarization. (arXiv:2205.09641v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09641">
<div class="article-summary-box-inner">
<span><p>Progress in summarizing long texts is inhibited by the lack of appropriate
evaluation frameworks. When a long summary must be produced to appropriately
cover the facets of that text, that summary needs to present a coherent
narrative to be understandable by a reader, but current automatic and human
evaluation methods fail to identify gaps in coherence. In this work, we
introduce SNaC, a narrative coherence evaluation framework rooted in
fine-grained annotations for long summaries. We develop a taxonomy of coherence
errors in generated narrative summaries and collect span-level annotations for
6.6k sentences across 150 book and movie screenplay summaries. Our work
provides the first characterization of coherence errors generated by
state-of-the-art summarization models and a protocol for eliciting coherence
judgments from crowd annotators. Furthermore, we show that the collected
annotations allow us to train a strong classifier for automatically localizing
coherence errors in generated summaries as well as benchmarking past work in
coherence modeling. Finally, our SNaC framework can support future work in long
document summarization and coherence evaluation, including improved
summarization modeling and post-hoc summary correction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Great Power, Great Responsibility: Recommendations for Reducing Energy for Training Language Models. (arXiv:2205.09646v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09646">
<div class="article-summary-box-inner">
<span><p>The energy requirements of current natural language processing models
continue to grow at a rapid, unsustainable pace. Recent works highlighting this
problem conclude there is an urgent need for methods that reduce the energy
needs of NLP and machine learning more broadly. In this article, we investigate
techniques that can be used to reduce the energy consumption of common NLP
applications. In particular, we focus on techniques to measure energy usage and
different hardware and datacenter-oriented settings that can be tuned to reduce
energy consumption for training and inference for language models. We
characterize the impact of these settings on metrics such as computational
performance and energy consumption through experiments conducted on a high
performance computing system as well as popular cloud computing platforms.
These techniques can lead to significant reduction in energy consumption when
training language models or their use for inference. For example,
power-capping, which limits the maximum power a GPU can consume, can enable a
15\% decrease in energy usage with marginal increase in overall computation
time when training a transformer-based language model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Named Entity Recognition, Multi-Task Learning, Nested Entities, BERT, Arabic NER Corpus. (arXiv:2205.09651v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09651">
<div class="article-summary-box-inner">
<span><p>This paper presents Wojood, a corpus for Arabic nested Named Entity
Recognition (NER). Nested entities occur when one entity mention is embedded
inside another entity mention. Wojood consists of about 550K Modern Standard
Arabic (MSA) and dialect tokens that are manually annotated with 21 entity
types including person, organization, location, event and date. More
importantly, the corpus is annotated with nested entities instead of the more
common flat annotations. The data contains about 75K entities and 22.5% of
which are nested. The inter-annotator evaluation of the corpus demonstrated a
strong agreement with Cohen's Kappa of 0.979 and an F1-score of 0.976. To
validate our data, we used the corpus to train a nested NER model based on
multi-task learning and AraBERT (Arabic BERT). The model achieved an overall
micro F1-score of 0.884. Our corpus, the annotation guidelines, the source code
and the pre-trained model are publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-augmented Data Selection for Few-shot Dialogue Generation. (arXiv:2205.09661v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09661">
<div class="article-summary-box-inner">
<span><p>The natural language generation (NLG) module in task-oriented dialogue
systems translates structured meaning representations (MRs) into text
responses, which has a great impact on users' experience as the human-machine
interaction interface. However, in practice, developers often only have a few
well-annotated data and confront a high data collection cost to build the NLG
module. In this work, we adopt the self-training framework to deal with the
few-shot MR-to-Text generation problem. We leverage the pre-trained language
model to self-augment many pseudo-labeled data. To prevent the gradual drift
from target data distribution to noisy augmented data distribution, we propose
a novel data selection strategy to select the data that our generation model is
most uncertain about. Compared with existing data selection methods, our method
is: (1) parameter-efficient, which does not require training any additional
neural models, (2) computation-efficient, which only needs to apply several
stochastic forward passes of the model to estimate the uncertainty. We conduct
empirical experiments on two benchmark datasets: FewShotWOZ and FewShotSGD, and
show that our proposed framework consistently outperforms other baselines in
terms of BLEU and ERR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Arabic Ontology -- An Arabic Wordnet with Ontologically Clean Content. (arXiv:2205.09664v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09664">
<div class="article-summary-box-inner">
<span><p>We present a formal Arabic wordnet built on the basis of a carefully designed
ontology hereby referred to as the Arabic Ontology. The ontology provides a
formal representation of the concepts that the Arabic terms convey, and its
content was built with ontological analysis in mind, and benchmarked to
scientific advances and rigorous knowledge sources as much as this is possible,
rather than to only speakers' beliefs as lexicons typically are. A
comprehensive evaluation was conducted thereby demonstrating that the current
version of the top-levels of the ontology can top the majority of the Arabic
meanings. The ontology consists currently of about 1,300 well-investigated
concepts in addition to 11,000 concepts that are partially validated. The
ontology is accessible and searchable through a lexicographic search engine
(https://ontology.birzeit.edu) that also includes about 150 Arabic-multilingual
lexicons, and which are being mapped and enriched using the ontology. The
ontology is fully mapped with Princeton WordNet, Wikidata, and other resources.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Crossword Solving. (arXiv:2205.09665v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09665">
<div class="article-summary-box-inner">
<span><p>We present the Berkeley Crossword Solver, a state-of-the-art approach for
automatically solving crossword puzzles. Our system works by generating answer
candidates for each crossword clue using neural question answering models and
then combines loopy belief propagation with local search to find full puzzle
solutions. Compared to existing approaches, our system improves exact puzzle
accuracy from 57% to 82% on crosswords from The New York Times and obtains
99.9% letter accuracy on themeless puzzles. Our system also won first place at
the top human crossword tournament, which marks the first time that a computer
program has surpassed human performance at this event. To facilitate research
on question answering and crossword solving, we analyze our system's remaining
errors and release a dataset of over six million question-answer pairs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Disentangling Active and Passive Cosponsorship in the U.S. Congress. (arXiv:2205.09674v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09674">
<div class="article-summary-box-inner">
<span><p>In the U.S. Congress, legislators can use active and passive cosponsorship to
support bills. We show that these two types of cosponsorship are driven by two
different motivations: the backing of political colleagues and the backing of
the bill's content. To this end, we develop an Encoder+RGCN based model that
learns legislator representations from bill texts and speech transcripts. These
representations predict active and passive cosponsorship with an F1-score of
0.88. Applying our representations to predict voting decisions, we show that
they are interpretable and generalize to unseen tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ArabGlossBERT: Fine-Tuning BERT on Context-Gloss Pairs for WSD. (arXiv:2205.09685v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09685">
<div class="article-summary-box-inner">
<span><p>Using pre-trained transformer models such as BERT has proven to be effective
in many NLP tasks. This paper presents our work to fine-tune BERT models for
Arabic Word Sense Disambiguation (WSD). We treated the WSD task as a
sentence-pair binary classification task. First, we constructed a dataset of
labeled Arabic context-gloss pairs (~167k pairs) we extracted from the Arabic
Ontology and the large lexicographic database available at Birzeit University.
Each pair was labeled as True or False and target words in each context were
identified and annotated. Second, we used this dataset for fine-tuning three
pre-trained Arabic BERT models. Third, we experimented the use of different
supervised signals used to emphasize target words in context. Our experiments
achieved promising results (accuracy of 84%) although we used a large set of
senses in the experiment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Curras + Baladi: Towards a Levantine Corpus. (arXiv:2205.09692v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09692">
<div class="article-summary-box-inner">
<span><p>The processing of the Arabic language is a complex field of research. This is
due to many factors, including the complex and rich morphology of Arabic, its
high degree of ambiguity, and the presence of several regional varieties that
need to be processed while taking into account their unique characteristics.
When its dialects are taken into account, this language pushes the limits of
NLP to find solutions to problems posed by its inherent nature. It is a
diglossic language; the standard language is used in formal settings and in
education and is quite different from the vernacular languages spoken in the
different regions and influenced by older languages that were historically
spoken in those regions. This should encourage NLP specialists to create
dialect-specific corpora such as the Palestinian morphologically annotated
Curras corpus of Birzeit University. In this work, we present the Lebanese
Corpus Baladi that consists of around 9.6K morphologically annotated tokens.
Since Lebanese and Palestinian dialects are part of the same Levantine
dialectal continuum, and thus highly mutually intelligible, our proposed corpus
was constructed to be used to (1) enrich Curras and transform it into a more
general Levantine corpus and (2) improve Curras by solving detected errors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PLAID: An Efficient Engine for Late Interaction Retrieval. (arXiv:2205.09707v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09707">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models are increasingly important components across
multiple information retrieval (IR) paradigms. Late interaction, introduced
with the ColBERT model and recently refined in ColBERTv2, is a popular paradigm
that holds state-of-the-art status across many benchmarks. To dramatically
speed up the search latency of late interaction, we introduce the
Performance-optimized Late Interaction Driver (PLAID). Without impacting
quality, PLAID swiftly eliminates low-scoring passages using a novel centroid
interaction mechanism that treats every passage as a lightweight bag of
centroids. PLAID uses centroid interaction as well as centroid pruning, a
mechanism for sparsifying the bag of centroids, within a highly-optimized
engine to reduce late interaction search latency by up to 7$\times$ on a GPU
and 45$\times$ on a CPU against vanilla ColBERTv2, while continuing to deliver
state-of-the-art retrieval quality. This allows the PLAID engine with ColBERTv2
to achieve latency of tens of milliseconds on a GPU and tens or just few
hundreds of milliseconds on a CPU at large scale, even at the largest scales we
evaluate with 140M passages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bi-LSTM Scoring Based Similarity Measurement with Agglomerative Hierarchical Clustering (AHC) for Speaker Diarization. (arXiv:2205.09709v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09709">
<div class="article-summary-box-inner">
<span><p>Majority of speech signals across different scenarios are never available
with well-defined audio segments containing only a single speaker. A typical
conversation between two speakers consists of segments where their voices
overlap, interrupt each other or halt their speech in between multiple
sentences. Recent advancements in diarization technology leverage neural
network-based approaches to improvise multiple subsystems of speaker
diarization system comprising of extracting segment-wise embedding features and
detecting changes in the speaker during conversation. However, to identify
speaker through clustering, models depend on methodologies like PLDA to
generate similarity measure between two extracted segments from a given
conversational audio. Since these algorithms ignore the temporal structure of
conversations, they tend to achieve a higher Diarization Error Rate (DER), thus
leading to misdetections both in terms of speaker and change identification.
Therefore, to compare similarity of two speech segments both independently and
sequentially, we propose a Bi-directional Long Short-term Memory network for
estimating the elements present in the similarity matrix. Once the similarity
matrix is generated, Agglomerative Hierarchical Clustering (AHC) is applied to
further identify speaker segments based on thresholding. To evaluate the
performance, Diarization Error Rate (DER%) metric is used. The proposed model
achieves a low DER of 34.80% on a test set of audio samples derived from ICSI
Meeting Corpus as compared to traditional PLDA based similarity measurement
mechanism which achieved a DER of 39.90%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Voxel-informed Language Grounding. (arXiv:2205.09710v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09710">
<div class="article-summary-box-inner">
<span><p>Natural language applied to natural 2D images describes a fundamentally 3D
world. We present the Voxel-informed Language Grounder (VLG), a language
grounding model that leverages 3D geometric information in the form of voxel
maps derived from the visual input using a volumetric reconstruction model. We
show that VLG significantly improves grounding accuracy on SNARE, an object
reference game task. At the time of writing, VLG holds the top place on the
SNARE leaderboard, achieving SOTA results with a 2.0% absolute improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning. (arXiv:2205.09712v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09712">
<div class="article-summary-box-inner">
<span><p>Large language models (LLMs) have been shown to be capable of impressive
few-shot generalisation to new tasks. However, they still tend to perform
poorly on multi-step logical reasoning problems. Here we carry out a
comprehensive evaluation of LLMs on 50 tasks that probe different aspects of
logical reasoning. We show that language models tend to perform fairly well at
single step inference or entailment tasks, but struggle to chain together
multiple reasoning steps to solve more complex problems. In light of this, we
propose a Selection-Inference (SI) framework that exploits pre-trained LLMs as
general processing modules, and alternates between selection and inference to
generate a series of interpretable, casual reasoning steps leading to the final
answer. We show that a 7B parameter LLM used within the SI framework in a
5-shot generalisation setting, with no fine-tuning, yields a performance
improvement of over 100% compared to an equivalent vanilla baseline on a suite
of 10 logical reasoning tasks. The same model in the same setting even
outperforms a significantly larger 280B parameter baseline on the same suite of
tasks. Moreover, answers produced by the SI framework are accompanied by a
causal natural-language-based reasoning trace, which has important implications
for the safety and trustworthiness of the system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RankGen: Improving Text Generation with Large Ranking Models. (arXiv:2205.09726v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09726">
<div class="article-summary-box-inner">
<span><p>Given an input sequence (or prefix), modern language models often assign high
probabilities to output sequences that are repetitive, incoherent, or
irrelevant to the prefix; as such, model-generated text also contains such
artifacts. To address these issues, we present RankGen, an encoder model (1.2B
parameters) that scores model generations given a prefix. RankGen can be
flexibly incorporated as a scoring function in beam search and used to decode
from any pretrained language model. We train RankGen using large-scale
contrastive learning to map a prefix close to the ground-truth sequence that
follows it and far away from two types of negatives: (1) random sequences from
the same document as the prefix, and, which discourage topically-similar but
irrelevant generations; (2) sequences generated from a large language model
conditioned on the prefix, which discourage repetition and hallucination.
Experiments across four different language models (345M-11B parameters) and two
domains show that RankGen significantly outperforms decoding algorithms like
nucleus, top-k, and typical sampling on both automatic metrics (85.0 vs 77.3
MAUVE) as well as human evaluations with English writers (74.5% human
preference over nucleus sampling). Analysis reveals that RankGen outputs are
more relevant to the prefix and improve continuity and coherence compared to
baselines. We open source our model checkpoints, code, and human preferences
with detailed explanations for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Slot Tagging with Intent Features for Task Oriented Natural Language Understanding using BERT. (arXiv:2205.09732v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09732">
<div class="article-summary-box-inner">
<span><p>Recent joint intent detection and slot tagging models have seen improved
performance when compared to individual models. In many real-world datasets,
the slot labels and values have a strong correlation with their intent labels.
In such cases, the intent label information may act as a useful feature to the
slot tagging model. In this paper, we examine the effect of leveraging intent
label features through 3 techniques in the slot tagging task of joint intent
and slot detection models. We evaluate our techniques on benchmark spoken
language datasets SNIPS and ATIS, as well as over a large private Bixby dataset
and observe an improved slot-tagging performance over state-of-the-art models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Harrington Yowlumne Narrative Corpus. (arXiv:2102.00610v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00610">
<div class="article-summary-box-inner">
<span><p>Minority languages continue to lack adequate resources for their development,
especially in the technological domain. Likewise, the J.P. Harrington Papers
collection at the Smithsonian Institution are difficult to access in practical
terms for community members and researchers due to its handwritten and
disorganized format. Our current work seeks to make a portion of this
publicly-available yet problematic material practically accessible for natural
language processing use. Here, we present the Harrington Yowlumne Narrative
Corpus, a corpus of 20 narrative texts that derive from the Tejone\~no Yowlumne
community of the Tinliw rancheria in Kern County, California between 1910 and
1925. We digitally transcribe the texts and, through a Levenshtein
distance-based algorithm and manual checking, we provide gold-standard aligned
normalized and lemmatized text. We likewise provide POS tags for each
lemmatized token via a lexicon-based deterministic approach. Altogether, the
corpus contains 57,136 transcribed characters aligned with 10,719 gold standard
text-normalized words.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-lingual Transfer of Monolingual Models. (arXiv:2109.07348v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07348">
<div class="article-summary-box-inner">
<span><p>Recent studies in zero-shot cross-lingual learning using multilingual models
have falsified the previous hypothesis that shared vocabulary and joint
pre-training are the keys to cross-lingual generalization. Inspired by this
advancement, we introduce a cross-lingual transfer method for monolingual
models based on domain adaptation. We study the effects of such transfer from
four different languages to English. Our experimental results on GLUE show that
the transferred models outperform the native English model independently of the
source language. After probing the English linguistic knowledge encoded in the
representations before and after transfer, we find that semantic information is
retained from the source language, while syntactic information is learned
during transfer. Additionally, the results of evaluating the transferred models
in source language tasks reveal that their performance in the source domain
deteriorates after transfer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Spread of Propaganda by Coordinated Communities on Social Media. (arXiv:2109.13046v2 [cs.SI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13046">
<div class="article-summary-box-inner">
<span><p>Large-scale manipulations on social media have two important characteristics:
(i) use of propaganda to influence others, and (ii) adoption of coordinated
behavior to spread it and to amplify its impact. Despite the connection between
them, these two characteristics have so far been considered in isolation. Here
we aim to bridge this gap. In particular, we analyze the spread of propaganda
and its interplay with coordinated behavior on a large Twitter dataset about
the 2019 UK general election. We first propose and evaluate several metrics for
measuring the use of propaganda on Twitter. Then, we investigate the use of
propaganda by different coordinated communities that participated in the online
debate. The combination of the use of propaganda and coordinated behavior
allows us to uncover the authenticity and harmfulness of the different
communities. Finally, we compare our measures of propaganda and coordination
with automation (i.e., bot) scores and Twitter suspensions, revealing
interesting trends. From a theoretical viewpoint, we introduce a methodology
for analyzing several important dimensions of online behavior that are seldom
conjointly considered. From a practical viewpoint, we provide new insights into
authentic and inauthentic online activities during the 2019 UK general
election.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Lifelong Learning of Multilingual Text-To-Speech Synthesis. (arXiv:2110.04482v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04482">
<div class="article-summary-box-inner">
<span><p>This work presents a lifelong learning approach to train a multilingual
Text-To-Speech (TTS) system, where each language was seen as an individual task
and was learned sequentially and continually. It does not require pooled data
from all languages altogether, and thus alleviates the storage and computation
burden. One of the challenges of lifelong learning methods is "catastrophic
forgetting": in TTS scenario it means that model performance quickly degrades
on previous languages when adapted to a new language. We approach this problem
via a data-replay-based lifelong learning method. We formulate the replay
process as a supervised learning problem, and propose a simple yet effective
dual-sampler framework to tackle the heavily language-imbalanced training
samples. Through objective and subjective evaluations, we show that this
supervised learning formulation outperforms other gradient-based and
regularization-based lifelong learning methods, achieving 43% Mel-Cepstral
Distortion reduction compared to a fine-tuning baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LiST: Lite Prompted Self-training Makes Parameter-Efficient Few-shot Learners. (arXiv:2110.06274v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06274">
<div class="article-summary-box-inner">
<span><p>We present a new method LiST is short for Lite Prompted Self-Training for
parameter-efficient fine-tuning of large pre-trained language models (PLMs) for
few-shot learning. LiST improves over recent methods that adopt prompt-based
fine-tuning (FN) using two key techniques. The first is the use of
self-training to leverage large amounts of unlabeled data for prompt-based FN
in few-shot settings. We use self-training in conjunction with meta-learning
for re-weighting noisy pseudo-prompt labels. Self-training is expensive as it
requires updating all the model parameters repetitively. Therefore, we use a
second technique for light-weight fine-tuning where we introduce a small number
of task-specific parameters that are fine-tuned during self-training while
keeping the PLM encoder frozen. Our experiments show that LiST can effectively
leverage unlabeled data to improve the model performance for few-shot learning.
Additionally, the fine-tuning is efficient as it only updates a small
percentage of parameters and the overall model footprint is reduced since
several tasks can share a common PLM encoder as backbone. A comprehensive study
on six NLU tasks demonstrate LiST to improve by 35% over classic fine-tuning
and 6% over prompt-based FN with 96% reduction in number of trainable
parameters when fine-tuned with no more than 30 labeled examples from each
task. With only 14M tunable parameters, LiST outperforms GPT-3 in-context
learning by 33% on few-shot NLU tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speeding Up Entmax. (arXiv:2111.06832v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.06832">
<div class="article-summary-box-inner">
<span><p>Softmax is the de facto standard in modern neural networks for language
processing when it comes to normalizing logits. However, by producing a dense
probability distribution each token in the vocabulary has a nonzero chance of
being selected at each generation step, leading to a variety of reported
problems in text generation. $\alpha$-entmax of Peters et al. (2019,
<a href="/abs/1905.05702">arXiv:1905.05702</a>) solves this problem, but is considerably slower than softmax.
</p>
<p>In this paper, we propose an alternative to $\alpha$-entmax, which keeps its
virtuous characteristics, but is as fast as optimized softmax and achieves on
par or better performance in machine translation task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transparent Human Evaluation for Image Captioning. (arXiv:2111.08940v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.08940">
<div class="article-summary-box-inner">
<span><p>We establish THumB, a rubric-based human evaluation protocol for image
captioning models. Our scoring rubrics and their definitions are carefully
developed based on machine- and human-generated captions on the MSCOCO dataset.
Each caption is evaluated along two main dimensions in a tradeoff (precision
and recall) as well as other aspects that measure the text quality (fluency,
conciseness, and inclusive language). Our evaluations demonstrate several
critical problems of the current evaluation practice. Human-generated captions
show substantially higher quality than machine-generated ones, especially in
coverage of salient information (i.e., recall), while most automatic metrics
say the opposite. Our rubric-based results reveal that CLIPScore, a recent
metric that uses image features, better correlates with human judgments than
conventional text-only metrics because it is more sensitive to recall. We hope
that this work will promote a more transparent evaluation protocol for image
captioning and its automatic metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bidimensional Leaderboards: Generate and Evaluate Language Hand in Hand. (arXiv:2112.04139v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.04139">
<div class="article-summary-box-inner">
<span><p>Natural language processing researchers have identified limitations of
evaluation methodology for generation tasks, with new questions raised about
the validity of automatic metrics and of crowdworker judgments. Meanwhile,
efforts to improve generation models tend to depend on simple n-gram overlap
metrics (e.g., BLEU, ROUGE). We argue that new advances on models and metrics
should each more directly benefit and inform the other. We therefore propose a
generalization of leaderboards, bidimensional leaderboards (Billboards), that
simultaneously tracks progress in language generation models and metrics for
their evaluation. Unlike conventional unidimensional leaderboards that sort
submitted systems by predetermined metrics, a Billboard accepts both generators
and evaluation metrics as competing entries. A Billboard automatically creates
an ensemble metric that selects and linearly combines a few metrics based on a
global analysis across generators. Further, metrics are ranked based on their
correlation with human judgments. We release four Billboards for machine
translation, summarization, and image captioning. We demonstrate that a linear
ensemble of a few diverse metrics sometimes substantially outperforms existing
metrics in isolation. Our mixed-effects model analysis shows that most
automatic metrics, especially the reference-based ones, overrate machine over
human generation, demonstrating the importance of updating metrics as
generation models become stronger (and perhaps more similar to humans) in the
future. Our project website is available at
https://nlp.cs.washington.edu/billboard/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emojis as Anchors to Detect Arabic Offensive Language and Hate Speech. (arXiv:2201.06723v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.06723">
<div class="article-summary-box-inner">
<span><p>We introduce a generic, language-independent method to collect a large
percentage of offensive and hate tweets regardless of their topics or genres.
We harness the extralinguistic information embedded in the emojis to collect a
large number of offensive tweets. We apply the proposed method on Arabic tweets
and compare it with English tweets - analysing key cultural differences. We
observed a constant usage of these emojis to represent offensiveness throughout
different timespans on Twitter. We manually annotate and publicly release the
largest Arabic dataset for offensive, fine-grained hate speech, vulgar and
violence content. Furthermore, we benchmark the dataset for detecting
offensiveness and hate speech using different transformer architectures and
perform in-depth linguistic analysis. We evaluate our models on external
datasets - a Twitter dataset collected using a completely different method, and
a multi-platform dataset containing comments from Twitter, YouTube and
Facebook, for assessing generalization capability. Competitive results on these
datasets suggest that the data collected using our method captures universal
characteristics of offensive language. Our findings also highlight the common
words used in offensive communications, common targets for hate speech,
specific patterns in violence tweets; and pinpoint common classification errors
that can be attributed to limitations of NLP models. We observe that even
state-of-the-art transformer models may fail to take into account culture,
background and context or understand nuances present in real-world data such as
sarcasm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TourBERT: A pretrained language model for the tourism industry. (arXiv:2201.07449v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.07449">
<div class="article-summary-box-inner">
<span><p>The Bidirectional Encoder Representations from Transformers (BERT) is
currently one of the most important and state-of-the-art models for natural
language. However, it has also been shown that for domain-specific tasks it is
helpful to pretrain BERT on a domain-specific corpus. In this paper, we present
TourBERT, a pretrained language model for tourism. We describe how TourBERT was
developed and evaluated. The evaluations show that TourBERT is outperforming
BERT in all tourism-specific tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Extractive Opinion Summarization Using Sparse Coding. (arXiv:2203.07921v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07921">
<div class="article-summary-box-inner">
<span><p>Opinion summarization is the task of automatically generating summaries that
encapsulate information from multiple user reviews. We present Semantic
Autoencoder (SemAE) to perform extractive opinion summarization in an
unsupervised manner. SemAE uses dictionary learning to implicitly capture
semantic information from the review and learns a latent representation of each
sentence over semantic units. A semantic unit is supposed to capture an
abstract semantic concept. Our extractive summarization algorithm leverages the
representations to identify representative opinions among hundreds of reviews.
SemAE is also able to perform controllable summarization to generate
aspect-specific summaries. We report strong performance on SPACE and AMAZON
datasets, and perform experiments to investigate the functioning of our model.
Our code is publicly available at https://github.com/brcsomnath/SemAE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again. (arXiv:2203.08410v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.08410">
<div class="article-summary-box-inner">
<span><p>The strong few-shot in-context learning capability of large pre-trained
language models (PLMs) such as GPT-3 is highly appealing for application
domains such as biomedicine, which feature high and diverse demands of language
technologies but also high data annotation costs. In this paper, we present the
first systematic and comprehensive study to compare the few-shot performance of
GPT-3 in-context learning with fine-tuning smaller (i.e., BERT-sized) PLMs on
two highly representative biomedical information extraction tasks, named entity
recognition and relation extraction. We follow the true few-shot setting to
avoid overestimating models' few-shot performance by model selection over a
large validation set. We also optimize GPT-3's performance with known
techniques such as contextual calibration and dynamic in-context example
retrieval. However, our results show that GPT-3 still significantly
underperforms compared to simply fine-tuning a smaller PLM. In addition, GPT-3
in-context learning also yields smaller gains in accuracy when more training
data becomes available. Our in-depth analyses further reveal issues of the
in-context learning setting that may be detrimental to information extraction
tasks in general. Given the high cost of experimenting with GPT-3, we hope our
study provides guidance for biomedical researchers and practitioners towards
more promising directions such as fine-tuning small PLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prompt-based System for Personality and Interpersonal Reactivity Prediction. (arXiv:2203.12481v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.12481">
<div class="article-summary-box-inner">
<span><p>This paper describes our proposed method for the Workshop on Computational
Approaches to Subjectivity, Sentiment &amp; Social Media Analysis (WASSA) 2022
shared task on Personality Prediction (PER) and Reactivity Index Prediction
(IRI). In this paper, we adopt the prompt-based learning method with the
pre-trained language model to accomplish these tasks. Specifically, the prompt
is designed to provide knowledge of the extra personalized information for
enhancing the pre-trained model. Data augmentation and model ensemble are
adopted for obtaining better results. Moreover, we also provided the online
software demonstration and the codes of the software for further research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diagonal State Spaces are as Effective as Structured State Spaces. (arXiv:2203.14343v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.14343">
<div class="article-summary-box-inner">
<span><p>Modeling long range dependencies in sequential data is a fundamental step
towards attaining human-level performance in many modalities such as text,
vision, audio and video. While attention-based models are a popular and
effective choice in modeling short-range interactions, their performance on
tasks requiring long range reasoning has been largely inadequate. In an
exciting result, Gu et al. (ICLR 2022) proposed the $\textit{Structured State
Space}$ (S4) architecture delivering large gains over state-of-the-art models
on several long-range tasks across various modalities. The core proposition of
S4 is the parameterization of state matrices via a diagonal plus low rank
structure, allowing efficient computation. In this work, we show that one can
match the performance of S4 even without the low rank correction and thus
assuming the state matrices to be diagonal. Our $\textit{Diagonal State Space}$
(DSS) model matches the performance of S4 on Long Range Arena tasks, speech
classification on Speech Commands dataset, while being conceptually simpler and
straightforward to implement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Can language models learn from explanations in context?. (arXiv:2204.02329v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.02329">
<div class="article-summary-box-inner">
<span><p>Large language models can perform new tasks by adapting to a few in-context
examples. For humans, rapid learning from examples can benefit from
explanations that connect examples to task principles. We therefore investigate
whether explanations of few-shot examples can allow language models to adapt
more effectively. We annotate a set of 40 challenging tasks from BIG-Bench with
explanations of answers to a small subset of questions, as well as a variety of
matched control explanations. We evaluate the effects of various zero-shot and
few-shot prompts that include different types of explanations, instructions,
and controls on the performance of a range of large language models. We analyze
these results using statistical multilevel modeling techniques that account for
the nested dependencies among conditions, tasks, prompts, and models. We find
that explanations of examples can improve performance. Adding untuned
explanations to a few-shot prompt offers a modest improvement in performance;
about 1/3 the effect size of adding few-shot examples, but twice the effect
size of task instructions. We then show that explanations tuned for performance
on a small validation set offer substantially larger benefits; building a
prompt by selecting examples and explanations together substantially improves
performance over selecting examples alone. Hand-tuning explanations can
substantially improve performance on challenging tasks. Furthermore, even
untuned explanations outperform carefully matched controls, suggesting that the
benefits are due to the link between an example and its explanation, rather
than lower-level features of the language used. However, only large models can
benefit from explanations. In summary, explanations can support the in-context
learning abilities of large language models on challenging tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AfriWOZ: Corpus for Exploiting Cross-Lingual Transferability for Generation of Dialogues in Low-Resource, African Languages. (arXiv:2204.08083v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.08083">
<div class="article-summary-box-inner">
<span><p>Dialogue generation is an important NLP task fraught with many challenges.
The challenges become more daunting for low-resource African languages. To
enable the creation of dialogue agents for African languages, we contribute the
first high-quality dialogue datasets for 6 African languages: Swahili, Wolof,
Hausa, Nigerian Pidgin English, Kinyarwanda &amp; Yor\`ub\'a. These datasets
consist of 1,500 turns each, which we translate from a portion of the English
multi-domain MultiWOZ dataset. Subsequently, we investigate &amp; analyze the
effectiveness of modelling through transfer learning by utilziing
state-of-the-art (SoTA) deep monolingual models: DialoGPT and BlenderBot. We
compare the models with a simple seq2seq baseline using perplexity. Besides
this, we conduct human evaluation of single-turn conversations by using
majority votes and measure inter-annotator agreement (IAA). We find that the
hypothesis that deep monolingual models learn some abstractions that generalize
across languages holds. We observe human-like conversations, to different
degrees, in 5 out of the 6 languages. The language with the most transferable
properties is the Nigerian Pidgin English, with a human-likeness score of
78.1%, of which 34.4% are unanimous. We freely provide the datasets and host
the model checkpoints/demos on the HuggingFace hub for public access.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Simple Contrastive Learning Objective for Alleviating Neural Text Degeneration. (arXiv:2205.02517v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.02517">
<div class="article-summary-box-inner">
<span><p>The cross-entropy objective has proved to be an all-purpose training
objective for autoregressive language models (LMs). However, without
considering the penalization of problematic tokens, LMs trained using
cross-entropy exhibit text degeneration. To address this, unlikelihood training
has been proposed to reduce the probability of unlikely tokens predicted by
LMs. But unlikelihood does not consider the relationship between the label
tokens and unlikely token candidates, thus showing marginal improvements in
degeneration. We propose a new contrastive token learning objective that
inherits the advantages of cross-entropy and unlikelihood training and avoids
their limitations. The key idea is to teach a LM to generate high probabilities
for label tokens and low probabilities of negative candidates. Comprehensive
experiments on language modeling and open-domain dialogue generation tasks show
that the proposed contrastive token objective yields much less repetitive
texts, with a higher generation quality than baseline approaches, achieving the
new state-of-the-art performance on text degeneration.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hearing voices at the National Library -- a speech corpus and acoustic model for the Swedish language. (arXiv:2205.03026v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.03026">
<div class="article-summary-box-inner">
<span><p>This paper explains our work in developing new acoustic models for automated
speech recognition (ASR) at KBLab, the infrastructure for data-driven research
at the National Library of Sweden (KB). We evaluate different approaches for a
viable speech-to-text pipeline for audiovisual resources in Swedish, using the
wav2vec 2.0 architecture in combination with speech corpuses created from KB's
collections. These approaches include pretraining an acoustic model for Swedish
from the ground up, and fine-tuning existing monolingual and multilingual
models. The collections-based corpuses we use have been sampled from millions
of hours of speech, with a conscious attempt to balance regional dialects to
produce a more representative, and thus more democratic, model. The acoustic
model this enabled, "VoxRex", outperforms existing models for Swedish ASR. We
also evaluate combining this model with various pretrained language models,
which further enhanced performance. We conclude by highlighting the potential
of such technology for cultural heritage institutions with vast collections of
previously unlabelled audiovisual data. Our models are released for further
exploration and research here: https://huggingface.co/KBLab.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Building for Tomorrow: Assessing the Temporal Persistence of Text Classifiers. (arXiv:2205.05435v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.05435">
<div class="article-summary-box-inner">
<span><p>Where performance of text classification models drops over time due to
changes in data, development of models whose performance persists over time is
important. An ability to predict a model's ability to persist over time can
help design models that can be effectively used over a longer period of time.
In this paper, we look at this problem from a practical perspective by
assessing the ability of a wide range of language models and classification
algorithms to persist over time, as well as how dataset characteristics can
help predict the temporal stability of different models. We perform
longitudinal classification experiments on three datasets spanning between 6
and 19 years, and involving diverse tasks and types of data. We find that one
can estimate how a model will retain its performance over time based on (i) how
well the model performs over a restricted time period and its extrapolation to
a longer time period, and (ii) the linguistic characteristics of the dataset,
such as the familiarity score between subsets from different years. Findings
from these experiments have important implications for the design of text
classification models with the aim of preserving performance over time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NFLAT: Non-Flat-Lattice Transformer for Chinese Named Entity Recognition. (arXiv:2205.05832v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.05832">
<div class="article-summary-box-inner">
<span><p>Recently, Flat-LAttice Transformer (FLAT) has achieved great success in
Chinese Named Entity Recognition (NER). FLAT performs lexical enhancement by
constructing flat lattices, which mitigates the difficulties posed by blurred
word boundaries and the lack of word semantics. In FLAT, the positions of
starting and ending characters are used to connect a matching word. However,
this method is likely to match more words when dealing with long texts,
resulting in long input sequences. Therefore, it significantly increases the
memory and computational costs of the self-attention module. To deal with this
issue, we advocate a novel lexical enhancement method, InterFormer, that
effectively reduces the amount of computational and memory costs by
constructing non-flat lattices. Furthermore, with InterFormer as the backbone,
we implement NFLAT for Chinese NER. NFLAT decouples lexicon fusion and context
feature encoding. Compared with FLAT, it reduces unnecessary attention
calculations in "word-character" and "word-word". This reduces the memory usage
by about 50% and can use more extensive lexicons or higher batches for network
training. The experimental results obtained on several well-known benchmarks
demonstrate the superiority of the proposed method over the state-of-the-art
hybrid (character-word) models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploiting Inductive Bias in Transformers for Unsupervised Disentanglement of Syntax and Semantics with VAEs. (arXiv:2205.05943v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.05943">
<div class="article-summary-box-inner">
<span><p>We propose a generative model for text generation, which exhibits
disentangled latent representations of syntax and semantics. Contrary to
previous work, this model does not need syntactic information such as
constituency parses, or semantic information such as paraphrase pairs. Our
model relies solely on the inductive bias found in attention-based
architectures such as Transformers.
</p>
<p>In the attention of Transformers, keys handle information selection while
values specify what information is conveyed. Our model, dubbed QKVAE, uses
Attention in its decoder to read latent variables where one latent variable
infers keys while another infers values. We run experiments on latent
representations and experiments on syntax/semantics transfer which show that
QKVAE displays clear signs of disentangled syntax and semantics. We also show
that our model displays competitive syntax transfer capabilities when compared
to supervised models and that comparable supervised models need a fairly large
amount of data (more than 50K samples) to outperform it on both syntactic and
semantic transfer. The code for our experiments is publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Generalist Agent. (arXiv:2205.06175v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06175">
<div class="article-summary-box-inner">
<span><p>Inspired by progress in large-scale language modeling, we apply a similar
approach towards building a single generalist agent beyond the realm of text
outputs. The agent, which we refer to as Gato, works as a multi-modal,
multi-task, multi-embodiment generalist policy. The same network with the same
weights can play Atari, caption images, chat, stack blocks with a real robot
arm and much more, deciding based on its context whether to output text, joint
torques, button presses, or other tokens. In this report we describe the model
and the data, and document the current capabilities of Gato.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Budge programming language. (arXiv:2205.07979v2 [cs.PL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.07979">
<div class="article-summary-box-inner">
<span><p>We present a simple, esoteric programming language based on G\"odel numbering
and prime factorization, enhanced with explicit, scoped loops, allowing for
easy program composition. We will show the syntax and semantics and then
provide a few example programs and their evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"What makes a question inquisitive?" A Study on Type-Controlled Inquisitive Question Generation. (arXiv:2205.08056v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08056">
<div class="article-summary-box-inner">
<span><p>We propose a type-controlled framework for inquisitive question generation.
We annotate an inquisitive question dataset with question types, train question
type classifiers, and finetune models for type-controlled question generation.
Empirical results demonstrate that we can generate a variety of questions that
adhere to specific types while drawing from the source texts. We also
investigate strategies for selecting a single question from a generated set,
considering both an informative vs.~inquisitive question classifier and a
pairwise ranker trained from a small set of expert annotations. Question
selection using the pairwise ranker yields strong results in automatic and
manual evaluation. Our human evaluation assesses multiple aspects of the
generated questions, finding that the ranker chooses questions with the best
syntax (4.59), semantics (4.37), and inquisitiveness (3.92) on a scale of 1-5,
even rivaling the performance of human-written questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Rule Induction for Efficient Semi-Supervised Learning. (arXiv:2205.09067v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09067">
<div class="article-summary-box-inner">
<span><p>Semi-supervised learning has shown promise in allowing NLP models to
generalize from small amounts of labeled data. Meanwhile, pretrained
transformer models act as black-box correlation engines that are difficult to
explain and sometimes behave unreliably. In this paper, we propose tackling
both of these challenges via Automatic Rule Induction (ARI), a simple and
general-purpose framework for the automatic discovery and integration of
symbolic rules into pretrained transformer models. First, we extract weak
symbolic rules from low-capacity machine learning models trained on small
amounts of labeled data. Next, we use an attention mechanism to integrate these
rules into high-capacity pretrained transformer models. Last, the
rule-augmented system becomes part of a self-training framework to boost
supervision signal on unlabeled data. These steps can be layered beneath a
variety of existing weak supervision and semi-supervised NLP algorithms in
order to improve performance and interpretability. Experiments across nine
sequence classification and relation extraction tasks suggest that ARI can
improve state-of-the-art methods with no manual effort and minimal
computational overhead.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Dark Solitons in Bose-Einstein Condensates: A Dataset for Many-body Physics Research. (arXiv:2205.09114v1 [cond-mat.quant-gas])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09114">
<div class="article-summary-box-inner">
<span><p>We establish a dataset of over $1.6\times10^4$ experimental images of
Bose-Einstein condensates containing solitonic excitations to enable machine
learning (ML) for many-body physics research. About 33 % of this dataset has
manually assigned and carefully curated labels. The remainder is automatically
labeled using SolDet -- an implementation of a physics-informed ML data
analysis framework -- consisting of a convolutional-neural-network-based
classifier and object detector as well as a statistically motivated
physics-informed classifier and a quality metric. This technical note
constitutes the definitive reference of the dataset, providing an opportunity
for the data science community to develop more sophisticated analysis tools, to
further understand nonlinear many-body physics, and even advance cold atom
experiments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring the Adjugate Matrix Approach to Quaternion Pose Extraction. (arXiv:2205.09116v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09116">
<div class="article-summary-box-inner">
<span><p>Quaternions are important for a wide variety of rotation-related problems in
computer graphics, machine vision, and robotics. We study the nontrivial
geometry of the relationship between quaternions and rotation matrices by
exploiting the adjugate matrix of the characteristic equation of a related
eigenvalue problem to obtain the manifold of the space of a quaternion
eigenvector. We argue that quaternions parameterized by their corresponding
rotation matrices cannot be expressed, for example, in machine learning tasks,
as single-valued functions: the quaternion solution must instead be treated as
a manifold, with different algebraic solutions for each of several
single-valued sectors represented by the adjugate matrix. We conclude with
novel constructions exploiting the quaternion adjugate variables to revisit
several classic pose estimation applications: 2D point-cloud matching, 2D
point-cloud-to-projection matching, 3D point-cloud matching, 3D orthographic
point-cloud-to-projection matching, and 3D perspective
point-cloud-to-projection matching. We find an exact solution to the 3D
orthographic least squares pose extraction problem, and apply it successfully
also to the perspective pose extraction problem with results that improve on
existing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LeRaC: Learning Rate Curriculum. (arXiv:2205.09180v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09180">
<div class="article-summary-box-inner">
<span><p>Most curriculum learning methods require an approach to sort the data samples
by difficulty, which is often cumbersome to perform. In this work, we propose a
novel curriculum learning approach termed Learning Rate Curriculum (LeRaC),
which leverages the use of a different learning rate for each layer of a neural
network to create a data-free curriculum during the initial training epochs.
More specifically, LeRaC assigns higher learning rates to neural layers closer
to the input, gradually decreasing the learning rates as the layers are placed
farther away from the input. The learning rates increase at various paces
during the first training iterations, until they all reach the same value. From
this point on, the neural model is trained as usual. This creates a model-level
curriculum learning strategy that does not require sorting the examples by
difficulty and is compatible with any neural network, generating higher
performance levels regardless of the architecture. We conduct comprehensive
experiments on eight datasets from the computer vision (CIFAR-10, CIFAR-100,
Tiny ImageNet), language (BoolQ, QNLI, RTE) and audio (ESC-50, CREMA-D)
domains, considering various convolutional (ResNet-18, Wide-ResNet-50,
DenseNet-121), recurrent (LSTM) and transformer (CvT, BERT, SepTr)
architectures, comparing our approach with the conventional training regime.
Moreover, we also compare with Curriculum by Smoothing (CBS), a
state-of-the-art data-free curriculum learning approach. Unlike CBS, our
performance improvements over the standard training regime are consistent
across all datasets and models. Furthermore, we significantly surpass CBS in
terms of training time (there is no additional cost over the standard training
regime for LeRaC).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Computing the ensemble spread from deterministic weather predictions using conditional generative adversarial networks. (arXiv:2205.09182v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09182">
<div class="article-summary-box-inner">
<span><p>Ensemble prediction systems are an invaluable tool for weather forecasting.
Practically, ensemble predictions are obtained by running several perturbations
of the deterministic control forecast. However, ensemble prediction is
associated with a high computational cost and often involves statistical
post-processing steps to improve its quality. Here we propose to use
deep-learning-based algorithms to learn the statistical properties of an
ensemble prediction system, the ensemble spread, given only the deterministic
control forecast. Thus, once trained, the costly ensemble prediction system
will not be needed anymore to obtain future ensemble forecasts, and the
statistical properties of the ensemble can be derived from a single
deterministic forecast. We adapt the classical pix2pix architecture to a
three-dimensional model and also experiment with a shared latent space
encoder-decoder model, and train them against several years of operational
(ensemble) weather forecasts for the 500 hPa geopotential height. The results
demonstrate that the trained models indeed allow obtaining a highly accurate
ensemble spread from the control forecast only.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scalable Multi-view Clustering with Graph Filtering. (arXiv:2205.09228v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09228">
<div class="article-summary-box-inner">
<span><p>With the explosive growth of multi-source data, multi-view clustering has
attracted great attention in recent years. Most existing multi-view methods
operate in raw feature space and heavily depend on the quality of original
feature representation. Moreover, they are often designed for feature data and
ignore the rich topology structure information. Accordingly, in this paper, we
propose a generic framework to cluster both attribute and graph data with
heterogeneous features. It is capable of exploring the interplay between
feature and structure. Specifically, we first adopt graph filtering technique
to eliminate high-frequency noise to achieve a clustering-friendly smooth
representation. To handle the scalability challenge, we develop a novel
sampling strategy to improve the quality of anchors. Extensive experiments on
attribute and graph benchmarks demonstrate the superiority of our approach with
respect to state-of-the-art approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MESH2IR: Neural Acoustic Impulse Response Generator for Complex 3D Scenes. (arXiv:2205.09248v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09248">
<div class="article-summary-box-inner">
<span><p>We propose a mesh-based neural network (MESH2IR) to generate acoustic impulse
responses (IRs) for indoor 3D scenes represented using a mesh. The IRs are used
to create a high-quality sound experience in interactive applications and audio
processing. Our method can handle input triangular meshes with arbitrary
topologies (2K - 3M triangles). We present a novel training technique to train
MESH2IR using energy decay relief and highlight its benefits. We also show that
training MESH2IR on IRs preprocessed using our proposed technique significantly
improves the accuracy of IR generation. We reduce the non-linearity in the mesh
space by transforming 3D scene meshes to latent space using a graph convolution
network. Our MESH2IR is more than 200 times faster than a geometric acoustic
algorithm on a CPU and can generate more than 10,000 IRs per second on an
NVIDIA GeForce RTX 2080 Ti GPU for a given furnished indoor 3D scene. The
acoustic metrics are used to characterize the acoustic environment. We show
that the acoustic metrics of the IRs predicted from our MESH2IR match the
ground truth with less than 10% error. We also highlight the benefits of
MESH2IR on audio and speech processing applications such as speech
dereverberation and speech separation. To the best of our knowledge, ours is
the first neural-network-based approach to predict IRs from a given 3D scene
mesh in real-time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Limits of Evaluating Embodied Agent Model Generalization Using Validation Sets. (arXiv:2205.09249v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09249">
<div class="article-summary-box-inner">
<span><p>Natural language guided embodied task completion is a challenging problem
since it requires understanding natural language instructions, aligning them
with egocentric visual observations, and choosing appropriate actions to
execute in the environment to produce desired changes. We experiment with
augmenting a transformer model for this task with modules that effectively
utilize a wider field of view and learn to choose whether the next step
requires a navigation or manipulation action. We observed that the proposed
modules resulted in improved, and in fact state-of-the-art performance on an
unseen validation set of a popular benchmark dataset, ALFRED. However, our best
model selected using the unseen validation set underperforms on the unseen test
split of ALFRED, indicating that performance on the unseen validation set may
not in itself be a sufficient indicator of whether model improvements
generalize to unseen test sets. We highlight this result as we believe it may
be a wider phenomenon in machine learning tasks but primarily noticeable only
in benchmarks that limit evaluations on test splits, and highlights the need to
modify benchmark design to better account for variance in model performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bayesian Convolutional Neural Networks for Limited Data Hyperspectral Remote Sensing Image Classification. (arXiv:2205.09250v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09250">
<div class="article-summary-box-inner">
<span><p>Employing deep neural networks for Hyper-spectral remote sensing (HSRS) image
classification is a challenging task. HSRS images have high dimensionality and
a large number of channels with substantial redundancy between channels. In
addition, the training data for classifying HSRS images is limited and the
amount of available training data is much smaller compared to other
classification tasks. These factors complicate the training process of deep
neural networks with many parameters and cause them to not perform well even
compared to conventional models. Moreover, convolutional neural networks
produce over-confident predictions, which is highly undesirable considering the
aforementioned problem.
</p>
<p>In this work, we use a special class of deep neural networks, namely Bayesian
neural network, to classify HSRS images. To the extent of our knowledge, this
is the first time that this class of neural networks has been used in HSRS
image classification. Bayesian neural networks provide an inherent tool for
measuring uncertainty. We show that a Bayesian network can outperform a
similarly-constructed non-Bayesian convolutional neural network (CNN) and an
off-the-shelf Random Forest (RF). Moreover, experimental results for the Pavia
Centre, Salinas, and Botswana datasets show that the Bayesian network is more
stable and robust to model pruning. Furthermore, we analyze the prediction
uncertainty of the Bayesian model and show that the prediction uncertainty
metric can provide information about the model predictions and has a positive
correlation with the prediction error.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Training Vision-Language Transformers from Captions Alone. (arXiv:2205.09256v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09256">
<div class="article-summary-box-inner">
<span><p>We show that Vision-Language Transformers can be learned without human labels
(e.g. class labels, bounding boxes, etc). Existing work, whether explicitly
utilizing bounding boxes or patches, assumes that the visual backbone must
first be trained on ImageNet class prediction before being integrated into a
multimodal linguistic pipeline. We show that this is not necessary and
introduce a new model Vision-Language from Captions (VLC) built on top of
Masked Auto-Encoders that does not require this supervision. In fact, in a
head-to-head comparison between ViLT, the current state-of-the-art patch-based
vision-language transformer which is pretrained with supervised object
classification, and our model, VLC, we find that our approach 1. outperforms
ViLT on standard benchmarks, 2. provides more interpretable and intuitive patch
visualizations, and 3. is competitive with many larger models that utilize ROIs
trained on annotated bounding-boxes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Free Lunch for Surgical Video Understanding by Distilling Self-Supervisions. (arXiv:2205.09292v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09292">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning has witnessed great progress in vision and NLP;
recently, it also attracted much attention to various medical imaging
modalities such as X-ray, CT, and MRI. Existing methods mostly focus on
building new pretext self-supervision tasks such as reconstruction,
orientation, and masking identification according to the properties of medical
images. However, the publicly available self-supervision models are not fully
exploited. In this paper, we present a powerful yet efficient self-supervision
framework for surgical video understanding. Our key insight is to distill
knowledge from publicly available models trained on large generic datasets4 to
facilitate the self-supervised learning of surgical videos. To this end, we
first introduce a semantic-preserving training scheme to obtain our teacher
model, which not only contains semantics from the publicly available models,
but also can produce accurate knowledge for surgical data. Besides training
with only contrastive learning, we also introduce a distillation objective to
transfer the rich learned information from the teacher model to self-supervised
learning on surgical data. Extensive experiments on two surgical phase
recognition benchmarks show that our framework can significantly improve the
performance of existing self-supervised learning methods. Notably, our
framework demonstrates a compelling advantage under a low-data regime. Our code
is available at https://github.com/xmed-lab/DistillingSelf.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3DConvCaps: 3DUnet with Convolutional Capsule Encoder for Medical Image Segmentation. (arXiv:2205.09299v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09299">
<div class="article-summary-box-inner">
<span><p>Convolutional Neural Networks (CNNs) have achieved promising results in
medical image segmentation. However, CNNs require lots of training data and are
incapable of handling pose and deformation of objects. Furthermore, their
pooling layers tend to discard important information such as positions as well
as CNNs are sensitive to rotation and affine transformation. Capsule network is
a recent new architecture that has achieved better robustness in part-whole
representation learning by replacing pooling layers with dynamic routing and
convolutional strides, which has shown potential results on popular tasks such
as digit classification and object segmentation. In this paper, we propose a 3D
encoder-decoder network with Convolutional Capsule Encoder (called 3DConvCaps)
to learn lower-level features (short-range attention) with convolutional layers
while modeling the higher-level features (long-range dependence) with capsule
layers. Our experiments on multiple datasets including iSeg-2017, Hippocampus,
and Cardiac demonstrate that our 3D 3DConvCaps network considerably outperforms
previous capsule networks and 3D-UNets. We further conduct ablation studies of
network efficiency and segmentation performance under various configurations of
convolution layers and capsule layers at both contracting and expanding paths.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Support-set based Multi-modal Representation Enhancement for Video Captioning. (arXiv:2205.09307v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09307">
<div class="article-summary-box-inner">
<span><p>Video captioning is a challenging task that necessitates a thorough
comprehension of visual scenes. Existing methods follow a typical one-to-one
mapping, which concentrates on a limited sample space while ignoring the
intrinsic semantic associations between samples, resulting in rigid and
uninformative expressions. To address this issue, we propose a novel and
flexible framework, namely Support-set based Multi-modal Representation
Enhancement (SMRE) model, to mine rich information in a semantic subspace
shared between samples. Specifically, we propose a Support-set Construction
(SC) module to construct a support-set to learn underlying connections between
samples and obtain semantic-related visual elements. During this process, we
design a Semantic Space Transformation (SST) module to constrain relative
distance and administrate multi-modal interactions in a self-supervised way.
Extensive experiments on MSVD and MSR-VTT datasets demonstrate that our SMRE
achieves state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Sub-pixel Accurate Quantification of Joint Space Narrowing Progression in Rheumatoid Arthritis. (arXiv:2205.09315v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09315">
<div class="article-summary-box-inner">
<span><p>Rheumatoid arthritis (RA) is a chronic autoimmune disease that primarily
affects peripheral synovial joints, like fingers, wrist and feet. Radiology
plays a critical role in the diagnosis and monitoring of RA. Limited by the
current spatial resolution of radiographic imaging, joint space narrowing (JSN)
progression of RA with the same reason above can be less than one pixel per
year with universal spatial resolution. Insensitive monitoring of JSN can
hinder the radiologist/rheumatologist from making a proper and timely clinical
judgment. In this paper, we propose a novel and sensitive method that we call
partial image phase-only correlation which aims to automatically quantify JSN
progression in the early stages of RA. The majority of the current literature
utilizes the mean error, root-mean-square deviation and standard deviation to
report the accuracy at pixel level. Our work measures JSN progression between a
baseline and its follow-up finger joint images by using the phase spectrum in
the frequency domain. Using this study, the mean error can be reduced to
0.0130mm when applied to phantom radiographs with ground truth, and 0.0519mm
standard deviation for clinical radiography. With its sub-pixel accuracy far
beyond manual measurement, we are optimistic that our work is promising for
automatically quantifying JSN progression.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Demographic Bias in Fingerprint Recognition. (arXiv:2205.09318v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09318">
<div class="article-summary-box-inner">
<span><p>Fingerprint recognition systems have been deployed globally in numerous
applications including personal devices, forensics, law enforcement, banking,
and national identity systems. For these systems to be socially acceptable and
trustworthy, it is critical that they perform equally well across different
demographic groups. In this work, we propose a formal statistical framework to
test for the existence of bias (demographic differentials) in fingerprint
recognition across four major demographic groups (white male, white female,
black male, and black female) for two state-of-the-art (SOTA) fingerprint
matchers operating in verification and identification modes. Experiments on two
different fingerprint databases (with 15,468 and 1,014 subjects) show that
demographic differentials in SOTA fingerprint recognition systems decrease as
the matcher accuracy increases and any small bias that may be evident is likely
due to certain outlier, low-quality fingerprint images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Let's Talk! Striking Up Conversations via Conversational Visual Question Generation. (arXiv:2205.09327v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09327">
<div class="article-summary-box-inner">
<span><p>An engaging and provocative question can open up a great conversation. In
this work, we explore a novel scenario: a conversation agent views a set of the
user's photos (for example, from social media platforms) and asks an engaging
question to initiate a conversation with the user. The existing
vision-to-question models mostly generate tedious and obvious questions, which
might not be ideals conversation starters. This paper introduces a two-phase
framework that first generates a visual story for the photo set and then uses
the story to produce an interesting question. The human evaluation shows that
our framework generates more response-provoking questions for starting
conversations than other vision-to-question baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Physically-Based Editing of Indoor Scene Lighting from a Single Image. (arXiv:2205.09343v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09343">
<div class="article-summary-box-inner">
<span><p>We present a method to edit complex indoor lighting from a single image with
its predicted depth and light source segmentation masks. This is an extremely
challenging problem that requires modeling complex light transport, and
disentangling HDR lighting from material and geometry with only a partial LDR
observation of the scene. We tackle this problem using two novel components: 1)
a holistic scene reconstruction method that estimates scene reflectance and
parametric 3D lighting, and 2) a neural rendering framework that re-renders the
scene from our predictions. We use physically-based indoor light
representations that allow for intuitive editing, and infer both visible and
invisible light sources. Our neural rendering framework combines
physically-based direct illumination and shadow rendering with deep networks to
approximate global illumination. It can capture challenging lighting effects,
such as soft shadows, directional lighting, specular materials, and
interreflections. Previous single image inverse rendering methods usually
entangle scene lighting and geometry and only support applications like object
insertion. Instead, by combining parametric 3D lighting estimation with neural
scene rendering, we demonstrate the first automatic method to achieve full
scene relighting, including light source insertion, removal, and replacement,
from a single image. All source code and data will be publicly released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mip-NeRF RGB-D: Depth Assisted Fast Neural Radiance Fields. (arXiv:2205.09351v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09351">
<div class="article-summary-box-inner">
<span><p>Neural scene representations, such as neural radiance fields (NeRF), are
based on training a multilayer perceptron (MLP) using a set of color images
with known poses. An increasing number of devices now produce RGB-D
information, which has been shown to be very important for a wide range of
tasks. Therefore, the aim of this paper is to investigate what improvements can
be made to these promising implicit representations by incorporating depth
information with the color images. In particular, the recently proposed
Mip-NeRF approach, which uses conical frustums instead of rays for volume
rendering, allows one to account for the varying area of a pixel with distance
from the camera center. The proposed method additionally models depth
uncertainty. This allows to address major limitations of NeRF-based approaches
including improving the accuracy of geometry, reduced artifacts, faster
training time, and shortened prediction time. Experiments are performed on
well-known benchmark scenes, and comparisons show improved accuracy in scene
geometry and photometric reconstruction, while reducing the training time by 3
- 5 times.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Plane Geometry Diagram Parsing. (arXiv:2205.09363v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09363">
<div class="article-summary-box-inner">
<span><p>Geometry diagram parsing plays a key role in geometry problem solving,
wherein the primitive extraction and relation parsing remain challenging due to
the complex layout and between-primitive relationship. In this paper, we
propose a powerful diagram parser based on deep learning and graph reasoning.
Specifically, a modified instance segmentation method is proposed to extract
geometric primitives, and the graph neural network (GNN) is leveraged to
realize relation parsing and primitive classification incorporating geometric
features and prior knowledge. All the modules are integrated into an end-to-end
model called PGDPNet to perform all the sub-tasks simultaneously. In addition,
we build a new large-scale geometry diagram dataset named PGDP5K with primitive
level annotations. Experiments on PGDP5K and an existing dataset IMP-Geometry3K
show that our model outperforms state-of-the-art methods in four sub-tasks
remarkably. Our code, dataset and appendix material are available at
https://github.com/mingliangzhang2018/PGDP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diversity Matters: Fully Exploiting Depth Clues for Reliable Monocular 3D Object Detection. (arXiv:2205.09373v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09373">
<div class="article-summary-box-inner">
<span><p>As an inherently ill-posed problem, depth estimation from single images is
the most challenging part of monocular 3D object detection (M3OD). Many
existing methods rely on preconceived assumptions to bridge the missing spatial
information in monocular images, and predict a sole depth value for every
object of interest. However, these assumptions do not always hold in practical
applications. To tackle this problem, we propose a depth solving system that
fully explores the visual clues from the subtasks in M3OD and generates
multiple estimations for the depth of each target. Since the depth estimations
rely on different assumptions in essence, they present diverse distributions.
Even if some assumptions collapse, the estimations established on the remaining
assumptions are still reliable. In addition, we develop a depth selection and
combination strategy. This strategy is able to remove abnormal estimations
caused by collapsed assumptions, and adaptively combine the remaining
estimations into a single one. In this way, our depth solving system becomes
more precise and robust. Exploiting the clues from multiple subtasks of M3OD
and without introducing any extra information, our method surpasses the current
best method by more than 20% relatively on the Moderate level of test split in
the KITTI 3D object detection benchmark, while still maintaining real-time
efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BabyNet: Residual Transformer Module for Birth Weight Prediction on Fetal Ultrasound Video. (arXiv:2205.09382v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09382">
<div class="article-summary-box-inner">
<span><p>Predicting fetal weight at birth is an important aspect of perinatal care,
particularly in the context of antenatal management, which includes the planned
timing and the mode of delivery. Accurate prediction of weight using prenatal
ultrasound is challenging as it requires images of specific fetal body parts
during advanced pregnancy which is difficult to capture due to poor quality of
images caused by the lack of amniotic fluid. As a consequence, predictions
which rely on standard methods often suffer from significant errors. In this
paper we propose the Residual Transformer Module which extends a 3D
ResNet-based network for analysis of 2D+t spatio-temporal ultrasound video
scans. Our end-to-end method, called BabyNet, automatically predicts fetal
birth weight based on fetal ultrasound video scans. We evaluate BabyNet using a
dedicated clinical set comprising 225 2D fetal ultrasound videos of pregnancies
from 75 patients performed one day prior to delivery. Experimental results show
that BabyNet outperforms several state-of-the-art methods and estimates the
weight at birth with accuracy comparable to human experts. Furthermore,
combining estimates provided by human experts with those computed by BabyNet
yields the best results, outperforming either of other methods by a significant
margin. The source code of BabyNet is available at
https://github.com/SanoScience/BabyNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unconventional Visual Sensors for Autonomous Vehicles. (arXiv:2205.09383v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09383">
<div class="article-summary-box-inner">
<span><p>Autonomous vehicles rely on perception systems to understand their
surroundings for further navigation missions. Cameras are essential for
perception systems due to the advantages of object detection and recognition
provided by modern computer vision algorithms, comparing to other sensors, such
as LiDARs and radars. However, limited by its inherent imaging principle, a
standard RGB camera may perform poorly in a variety of adverse scenarios,
including but not limited to: low illumination, high contrast, bad weather such
as fog/rain/snow, etc. Meanwhile, estimating the 3D information from the 2D
image detection is generally more difficult when compared to LiDARs or radars.
Several new sensing technologies have emerged in recent years to address the
limitations of conventional RGB cameras. In this paper, we review the
principles of four novel image sensors: infrared cameras, range-gated cameras,
polarization cameras, and event cameras. Their comparative advantages, existing
or potential applications, and corresponding data processing algorithms are all
presented in a systematic manner. We expect that this study will assist
practitioners in the autonomous driving society with new perspectives and
insights.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UIF: An Objective Quality Assessment for Underwater Image Enhancement. (arXiv:2205.09392v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09392">
<div class="article-summary-box-inner">
<span><p>Due to complex and volatile lighting environment, underwater imaging can be
readily impaired by light scattering, warping, and noises. To improve the
visual quality, Underwater Image Enhancement (UIE) techniques have been widely
studied. Recent efforts have also been contributed to evaluate and compare the
UIE performances with subjective and objective methods. However, the subjective
evaluation is time-consuming and uneconomic for all images, while existing
objective methods have limited capabilities for the newly-developed UIE
approaches based on deep learning. To fill this gap, we propose an Underwater
Image Fidelity (UIF) metric for objective evaluation of enhanced underwater
images. By exploiting the statistical features of these images, we present to
extract naturalness-related, sharpness-related, and structure-related features.
Among them, the naturalness-related and sharpness-related features evaluate
visual improvement of enhanced images; the structure-related feature indicates
structural similarity between images before and after UIE. Then, we employ
support vector regression to fuse the above three features into a final UIF
metric. In addition, we have also established a large-scale UIE database with
subjective scores, namely Underwater Image Enhancement Database (UIED), which
is utilized as a benchmark to compare all objective metrics. Experimental
results confirm that the proposed UIF outperforms a variety of underwater and
general-purpose image quality metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Oracle-MNIST: a Realistic Image Dataset for Benchmarking Machine Learning Algorithms. (arXiv:2205.09442v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09442">
<div class="article-summary-box-inner">
<span><p>We introduce the Oracle-MNIST dataset, comprising of 28$\times $28 grayscale
images of 30,222 ancient characters from 10 categories, for benchmarking
pattern classification, with particular challenges on image noise and
distortion. The training set totally consists of 27,222 images, and the test
set contains 300 images per class. Oracle-MNIST shares the same data format
with the original MNIST dataset, allowing for direct compatibility with all
existing classifiers and systems, but it constitutes a more challenging
classification task than MNIST. The images of ancient characters suffer from 1)
extremely serious and unique noises caused by three-thousand years of burial
and aging and 2) dramatically variant writing styles by ancient Chinese, which
all make them realistic for machine learning research. The dataset is freely
available at https://github.com/wm-bupt/oracle-mnist.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PYSKL: Towards Good Practices for Skeleton Action Recognition. (arXiv:2205.09443v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09443">
<div class="article-summary-box-inner">
<span><p>We present PYSKL: an open-source toolbox for skeleton-based action
recognition based on PyTorch. The toolbox supports a wide variety of skeleton
action recognition algorithms, including approaches based on GCN and CNN. In
contrast to existing open-source skeleton action recognition projects that
include only one or two algorithms, PYSKL implements six different algorithms
under a unified framework with both the latest and original good practices to
ease the comparison of efficacy and efficiency. We also provide an original
GCN-based skeleton action recognition model named ST-GCN++, which achieves
competitive recognition performance without any complicated attention schemes,
serving as a strong baseline. Meanwhile, PYSKL supports the training and
testing of nine skeleton-based action recognition benchmarks and achieves
state-of-the-art recognition performance on eight of them. To facilitate future
research on skeleton action recognition, we also provide a large number of
trained models and detailed benchmark results to give some insights. PYSKL is
released at https://github.com/kennymckormick/pyskl and is actively maintained.
We will update this report when we add new features or benchmarks. The current
version corresponds to PYSKL v0.2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Enhancement Transformer for Action Segmentation. (arXiv:2205.09445v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09445">
<div class="article-summary-box-inner">
<span><p>Temporal convolutions have been the paradigm of choice in action
segmentation, which enhances long-term receptive fields by increasing
convolution layers. However, high layers cause the loss of local information
necessary for frame recognition. To solve the above problem, a novel
encoder-decoder structure is proposed in this paper, called Cross-Enhancement
Transformer. Our approach can be effective learning of temporal structure
representation with interactive self-attention mechanism. Concatenated each
layer convolutional feature maps in encoder with a set of features in decoder
produced via self-attention. Therefore, local and global information are used
in a series of frame actions simultaneously. In addition, a new loss function
is proposed to enhance the training process that penalizes over-segmentation
errors. Experiments show that our framework performs state-of-the-art on three
challenging datasets: 50Salads, Georgia Tech Egocentric Activities and the
Breakfast dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Image Augmentation Based Momentum Memory Intrinsic Reward for Sparse Reward Visual Scenes. (arXiv:2205.09448v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09448">
<div class="article-summary-box-inner">
<span><p>Many scenes in real life can be abstracted to the sparse reward visual
scenes, where it is difficult for an agent to tackle the task under the
condition of only accepting images and sparse rewards. We propose to decompose
this problem into two sub-problems: the visual representation and the sparse
reward. To address them, a novel framework IAMMIR combining the self-supervised
representation learning with the intrinsic motivation is presented. For visual
representation, a representation driven by a combination of the imageaugmented
forward dynamics and the reward is acquired. For sparse rewards, a new type of
intrinsic reward is designed, the Momentum Memory Intrinsic Reward (MMIR). It
utilizes the difference of the outputs from the current model (online network)
and the historical model (target network) to present the agent's state
familiarity. Our method is evaluated on the visual navigation task with sparse
rewards in Vizdoom. Experiments demonstrate that our method achieves the state
of the art performance in sample efficiency, at least 2 times faster than the
existing methods reaching 100% success rate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Feature Fusion for Unsupervised Domain Adaptive Person Re-identification. (arXiv:2205.09495v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09495">
<div class="article-summary-box-inner">
<span><p>Unsupervised domain adaptive (UDA) person re-identification (ReID) has gained
increasing attention for its effectiveness on the target domain without manual
annotations. Most fine-tuning based UDA person ReID methods focus on encoding
global features for pseudo labels generation, neglecting the local feature that
can provide for the fine-grained information. To handle this issue, we propose
a Learning Feature Fusion (LF2) framework for adaptively learning to fuse
global and local features to obtain a more comprehensive fusion feature
representation. Specifically, we first pre-train our model within a source
domain, then fine-tune the model on unlabeled target domain based on the
teacher-student training strategy. The average weighting teacher network is
designed to encode global features, while the student network updating at each
iteration is responsible for fine-grained local features. By fusing these
multi-view features, multi-level clustering is adopted to generate diverse
pseudo labels. In particular, a learnable Fusion Module (FM) for giving
prominence to fine-grained local information within the global feature is also
proposed to avoid obscure learning of multiple pseudo labels. Experiments show
that our proposed LF2 framework outperforms the state-of-the-art with 73.5% mAP
and 83.7% Rank1 on Market1501 to DukeMTMC-ReID, and achieves 83.2% mAP and
92.8% Rank1 on DukeMTMC-ReID to Market1501.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing the Transferability of Adversarial Examples via a Few Queries. (arXiv:2205.09518v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09518">
<div class="article-summary-box-inner">
<span><p>Due to the vulnerability of deep neural networks, the black-box attack has
drawn great attention from the community. Though transferable priors decrease
the query number of the black-box query attacks in recent efforts, the average
number of queries is still larger than 100, which is easily affected by the
number of queries limit policy. In this work, we propose a novel method called
query prior-based method to enhance the family of fast gradient sign methods
and improve their attack transferability by using a few queries. Specifically,
for the untargeted attack, we find that the successful attacked adversarial
examples prefer to be classified as the wrong categories with higher
probability by the victim model. Therefore, the weighted augmented
cross-entropy loss is proposed to reduce the gradient angle between the
surrogate model and the victim model for enhancing the transferability of the
adversarial examples. Theoretical analysis and extensive experiments
demonstrate that our method could significantly improve the transferability of
gradient-based adversarial attacks on CIFAR10/100 and ImageNet and outperform
the black-box query attack with the same few queries.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Estimating the ultrasound attenuation coefficient using convolutional neural networks -- a feasibility study. (arXiv:2205.09533v1 [physics.med-ph])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09533">
<div class="article-summary-box-inner">
<span><p>Attenuation coefficient (AC) is a fundamental measure of tissue acoustical
properties, which can be used in medical diagnostics. In this work, we
investigate the feasibility of using convolutional neural networks (CNNs) to
directly estimate AC from radio-frequency (RF) ultrasound signals. To develop
the CNNs we used RF signals collected from tissue mimicking numerical phantoms
for the AC values in a range from 0.1 to 1.5 dB/(MHz*cm). The models were
trained based on 1-D patches of RF data. We obtained mean absolute AC
estimation errors of 0.08, 0.12, 0.20, 0.25 for the patch lengths: 10 mm, 5 mm,
2 mm and 1 mm, respectively. We explain the performance of the model by
visualizing the frequency content associated with convolutional filters. Our
study presents that the AC can be calculated using deep learning, and the
weights of the CNNs can have physical interpretation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain Enhanced Arbitrary Image Style Transfer via Contrastive Learning. (arXiv:2205.09542v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09542">
<div class="article-summary-box-inner">
<span><p>In this work, we tackle the challenging problem of arbitrary image style
transfer using a novel style feature representation learning method. A suitable
style representation, as a key component in image stylization tasks, is
essential to achieve satisfactory results. Existing deep neural network based
approaches achieve reasonable results with the guidance from second-order
statistics such as Gram matrix of content features. However, they do not
leverage sufficient style information, which results in artifacts such as local
distortions and style inconsistency. To address these issues, we propose to
learn style representation directly from image features instead of their
second-order statistics, by analyzing the similarities and differences between
multiple styles and considering the style distribution. Specifically, we
present Contrastive Arbitrary Style Transfer (CAST), which is a new style
representation learning and style transfer method via contrastive learning. Our
framework consists of three key components, i.e., a multi-layer style projector
for style code encoding, a domain enhancement module for effective learning of
style distribution, and a generative network for image style transfer. We
conduct qualitative and quantitative evaluations comprehensively to demonstrate
that our approach achieves significantly better results compared to those
obtained via state-of-the-art methods. Code and models are available at
https://github.com/zyxElsa/CAST_pytorch
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Discovering Dynamic Functional Brain Networks via Spatial and Channel-wise Attention. (arXiv:2205.09576v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09576">
<div class="article-summary-box-inner">
<span><p>Using deep learning models to recognize functional brain networks (FBNs) in
functional magnetic resonance imaging (fMRI) has been attracting increasing
interest recently. However, most existing work focuses on detecting static FBNs
from entire fMRI signals, such as correlation-based functional connectivity.
Sliding-window is a widely used strategy to capture the dynamics of FBNs, but
it is still limited in representing intrinsic functional interactive dynamics
at each time step. And the number of FBNs usually need to be set manually. More
over, due to the complexity of dynamic interactions in brain, traditional
linear and shallow models are insufficient in identifying complex and spatially
overlapped FBNs across each time step. In this paper, we propose a novel
Spatial and Channel-wise Attention Autoencoder (SCAAE) for discovering FBNs
dynamically. The core idea of SCAAE is to apply attention mechanism to FBNs
construction. Specifically, we designed two attention modules: 1) spatial-wise
attention (SA) module to discover FBNs in the spatial domain and 2) a
channel-wise attention (CA) module to weigh the channels for selecting the FBNs
automatically. We evaluated our approach on ADHD200 dataset and our results
indicate that the proposed SCAAE method can effectively recover the dynamic
changes of the FBNs at each fMRI time step, without using sliding windows. More
importantly, our proposed hybrid attention modules (SA and CA) do not enforce
assumptions of linearity and independence as previous methods, and thus provide
a novel approach to better understanding dynamic functional brain networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TRT-ViT: TensorRT-oriented Vision Transformer. (arXiv:2205.09579v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09579">
<div class="article-summary-box-inner">
<span><p>We revisit the existing excellent Transformers from the perspective of
practical application. Most of them are not even as efficient as the basic
ResNets series and deviate from the realistic deployment scenario. It may be
due to the current criterion to measure computation efficiency, such as FLOPs
or parameters is one-sided, sub-optimal, and hardware-insensitive. Thus, this
paper directly treats the TensorRT latency on the specific hardware as an
efficiency metric, which provides more comprehensive feedback involving
computational capacity, memory cost, and bandwidth. Based on a series of
controlled experiments, this work derives four practical guidelines for
TensorRT-oriented and deployment-friendly network design, e.g., early CNN and
late Transformer at stage-level, early Transformer and late CNN at block-level.
Accordingly, a family of TensortRT-oriented Transformers is presented,
abbreviated as TRT-ViT. Extensive experiments demonstrate that TRT-ViT
significantly outperforms existing ConvNets and vision Transformers with
respect to the latency/accuracy trade-off across diverse visual tasks, e.g.,
image classification, object detection and semantic segmentation. For example,
at 82.7% ImageNet-1k top-1 accuracy, TRT-ViT is 2.7$\times$ faster than CSWin
and 2.0$\times$ faster than Twins. On the MS-COCO object detection task,
TRT-ViT achieves comparable performance with Twins, while the inference speed
is increased by 2.8$\times$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Trace of PGD-Like Adversarial Attacks. (arXiv:2205.09586v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09586">
<div class="article-summary-box-inner">
<span><p>Adversarial attacks pose safety and security concerns for deep learning
applications. Yet largely imperceptible, a strong PGD-like attack may leave
strong trace in the adversarial example. Since attack triggers the local
linearity of a network, we speculate network behaves in different extents of
linearity for benign examples and adversarial examples. Thus, we construct
Adversarial Response Characteristics (ARC) features to reflect the model's
gradient consistency around the input to indicate the extent of linearity.
Under certain conditions, it shows a gradually varying pattern from benign
example to adversarial example, as the later leads to Sequel Attack Effect
(SAE). ARC feature can be used for informed attack detection (perturbation
magnitude is known) with binary classifier, or uninformed attack detection
(perturbation magnitude is unknown) with ordinal regression. Due to the
uniqueness of SAE to PGD-like attacks, ARC is also capable of inferring other
attack details such as loss function, or the ground-truth label as a
post-processing defense. Qualitative and quantitative evaluations manifest the
effectiveness of ARC feature on CIFAR-10 w/ ResNet-18 and ImageNet w/
ResNet-152 and SwinT-B-IN1K with considerable generalization among PGD-like
attacks despite domain shift. Our method is intuitive, light-weighted,
non-intrusive, and data-undemanding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transferable Physical Attack against Object Detection with Separable Attention. (arXiv:2205.09592v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09592">
<div class="article-summary-box-inner">
<span><p>Transferable adversarial attack is always in the spotlight since deep
learning models have been demonstrated to be vulnerable to adversarial samples.
However, existing physical attack methods do not pay enough attention on
transferability to unseen models, thus leading to the poor performance of
black-box attack.In this paper, we put forward a novel method of generating
physically realizable adversarial camouflage to achieve transferable attack
against detection models. More specifically, we first introduce multi-scale
attention maps based on detection models to capture features of objects with
various resolutions. Meanwhile, we adopt a sequence of composite
transformations to obtain the averaged attention maps, which could curb
model-specific noise in the attention and thus further boost transferability.
Unlike the general visualization interpretation methods where model attention
should be put on the foreground object as much as possible, we carry out attack
on separable attention from the opposite perspective, i.e. suppressing
attention of the foreground and enhancing that of the background. Consequently,
transferable adversarial camouflage could be yielded efficiently with our novel
attention-based loss function. Extensive comparison experiments verify the
superiority of our method to state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Comparative Study of Feature Expansion Unit for 3D Point Cloud Upsampling. (arXiv:2205.09594v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09594">
<div class="article-summary-box-inner">
<span><p>Recently, deep learning methods have shown great success in 3D point cloud
upsampling. Among these methods, many feature expansion units were proposed to
complete point expansion at the end. In this paper, we compare various feature
expansion units by both theoretical analysis and quantitative experiments. We
show that most of the existing feature expansion units process each point
feature independently, while ignoring the feature interaction among different
points. Further, inspired by upsampling module of image super-resolution and
recent success of dynamic graph CNN on point clouds, we propose a novel feature
expansion units named ProEdgeShuffle. Experiments show that our proposed method
can achieve considerable improvement over previous feature expansion units.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CORPS: Cost-free Rigorous Pseudo-labeling based on Similarity-ranking for Brain MRI Segmentation. (arXiv:2205.09601v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09601">
<div class="article-summary-box-inner">
<span><p>Segmentation of brain magnetic resonance images (MRI) is crucial for the
analysis of the human brain and diagnosis of various brain disorders. The
drawbacks of time-consuming and error-prone manual delineation procedures are
aimed to be alleviated by atlas-based and supervised machine learning methods
where the former methods are computationally intense and the latter methods
lack a sufficiently large number of labeled data. With this motivation, we
propose CORPS, a semi-supervised segmentation framework built upon a novel
atlas-based pseudo-labeling method and a 3D deep convolutional neural network
(DCNN) for 3D brain MRI segmentation. In this work, we propose to generate
expert-level pseudo-labels for unlabeled set of images in an order based on a
local intensity-based similarity score to existing labeled set of images and
using a novel atlas-based label fusion method. Then, we propose to train a 3D
DCNN on the combination of expert and pseudo labeled images for binary
segmentation of each anatomical structure. The binary segmentation approach is
proposed to avoid the poor performance of multi-class segmentation methods on
limited and imbalanced data. This also allows to employ a lightweight and
efficient 3D DCNN in terms of the number of filters and reserve memory
resources for training the binary networks on full-scale and full-resolution 3D
MRI volumes instead of 2D/3D patches or 2D slices. Thus, the proposed framework
can encapsulate the spatial contiguity in each dimension and enhance
context-awareness. The experimental results demonstrate the superiority of the
proposed framework over the baseline method both qualitatively and
quantitatively without additional labeling cost for manual labeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLCNet: Rethinking of Ensemble Modeling with Classification Confidence Network. (arXiv:2205.09612v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09612">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a Classification Confidence Network (CLCNet) that
can determine whether the classification model classifies input samples
correctly. It can take a classification result in the form of vector in any
dimension, and return a confidence score as output, which represents the
probability of an instance being classified correctly. We can utilize CLCNet in
a simple cascade structure system consisting of several SOTA (state-of-the-art)
classification models, and our experiments show that the system can achieve the
following advantages: 1. The system can customize the average computation
requirement (FLOPs) per image while inference. 2. Under the same computation
requirement, the performance of the system can exceed any model that has
identical structure with the model in the system, but different in size. In
fact, this is a new type of ensemble modeling. Like general ensemble modeling,
it can achieve higher performance than single classification model, yet our
system requires much less computation than general ensemble modeling. We have
uploaded our code to a github repository:
https://github.com/yaoching0/CLCNet-Rethinking-of-Ensemble-Modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integral Migrating Pre-trained Transformer Encoder-decoders for Visual Object Detection. (arXiv:2205.09613v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09613">
<div class="article-summary-box-inner">
<span><p>Modern object detectors have taken the advantages of pre-trained vision
transformers by using them as backbone networks. However, except for the
backbone networks, other detector components, such as the detector head and the
feature pyramid network, remain randomly initialized, which hinders the
consistency between detectors and pre-trained models. In this study, we propose
to integrally migrate the pre-trained transformer encoder-decoders (imTED) for
object detection, constructing a feature extraction-operation path that is not
only "fully pre-trained" but also consistent with pre-trained models. The
essential improvements of imTED over existing transformer-based detectors are
twofold: (1) it embeds the pre-trained transformer decoder to the detector
head; and (2) it removes the feature pyramid network from the feature
extraction path. Such improvements significantly reduce the proportion of
randomly initialized parameters and enhance the generation capability of
detectors. Experiments on MS COCO dataset demonstrate that imTED consistently
outperforms its counterparts by ~2.8% AP. Without bells and whistles, imTED
improves the state-of-the-art of few-shot object detection by up to 7.6% AP,
demonstrating significantly higher generalization capability. Code will be made
publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EXACT: How to Train Your Accuracy. (arXiv:2205.09615v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09615">
<div class="article-summary-box-inner">
<span><p>Classification tasks are usually evaluated in terms of accuracy. However,
accuracy is discontinuous and cannot be directly optimized using gradient
ascent. Popular methods minimize cross-entropy, Hinge loss, or other surrogate
losses, which can lead to suboptimal results. In this paper, we propose a new
optimization framework by introducing stochasticity to a model's output and
optimizing expected accuracy, i.e. accuracy of the stochastic model. Extensive
experiments on image classification show that the proposed optimization method
is a powerful alternative to widely used classification losses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Masked Image Modeling with Denoising Contrast. (arXiv:2205.09616v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09616">
<div class="article-summary-box-inner">
<span><p>Since the development of self-supervised visual representation learning from
contrastive learning to masked image modeling, there is no significant
difference in essence, that is, how to design proper pretext tasks for vision
dictionary look-up. Masked image modeling recently dominates this line of
research with state-of-the-art performance on vision Transformers, where the
core is to enhance the patch-level visual context capturing of the network via
denoising auto-encoding mechanism. Rather than tailoring image tokenizers with
extra training stages as in previous works, we unleash the great potential of
contrastive learning on denoising auto-encoding and introduce a new
pre-training method, ConMIM, to produce simple intra-image inter-patch
contrastive constraints as the learning objectives for masked patch prediction.
We further strengthen the denoising mechanism with asymmetric designs,
including image perturbations and model progress rates, to improve the network
pre-training. ConMIM-pretrained vision Transformers with various scales achieve
promising results on downstream image classification, semantic segmentation,
object detection, and instance segmentation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Topological Approach for Semi-Supervised Learning. (arXiv:2205.09617v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09617">
<div class="article-summary-box-inner">
<span><p>Nowadays, Machine Learning and Deep Learning methods have become the
state-of-the-art approach to solve data classification tasks. In order to use
those methods, it is necessary to acquire and label a considerable amount of
data; however, this is not straightforward in some fields, since data
annotation is time consuming and might require expert knowledge. This challenge
can be tackled by means of semi-supervised learning methods that take advantage
of both labelled and unlabelled data. In this work, we present new
semi-supervised learning methods based on techniques from Topological Data
Analysis (TDA), a field that is gaining importance for analysing large amounts
of data with high variety and dimensionality. In particular, we have created
two semi-supervised learning methods following two different topological
approaches. In the former, we have used a homological approach that consists in
studying the persistence diagrams associated with the data using the Bottleneck
and Wasserstein distances. In the latter, we have taken into account the
connectivity of the data. In addition, we have carried out a thorough analysis
of the developed methods using 3 synthetic datasets, 5 structured datasets, and
2 datasets of images. The results show that the semi-supervised methods
developed in this work outperform both the results obtained with models trained
with only manually labelled data, and those obtained with classical
semi-supervised learning methods, reaching improvements of up to a 16%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Focused Adversarial Attacks. (arXiv:2205.09624v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09624">
<div class="article-summary-box-inner">
<span><p>Recent advances in machine learning show that neural models are vulnerable to
minimally perturbed inputs, or adversarial examples. Adversarial algorithms are
optimization problems that minimize the accuracy of ML models by perturbing
inputs, often using a model's loss function to craft such perturbations.
State-of-the-art object detection models are characterized by very large output
manifolds due to the number of possible locations and sizes of objects in an
image. This leads to their outputs being sparse and optimization problems that
use them incur a lot of unnecessary computation.
</p>
<p>We propose to use a very limited subset of a model's learned manifold to
compute adversarial examples. Our \textit{Focused Adversarial Attacks} (FA)
algorithm identifies a small subset of sensitive regions to perform
gradient-based adversarial attacks. FA is significantly faster than other
gradient-based attacks when a model's manifold is sparsely activated. Also, its
perturbations are more efficient than other methods under the same perturbation
constraints. We evaluate FA on the COCO 2017 and Pascal VOC 2007 detection
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A graph-transformer for whole slide image classification. (arXiv:2205.09671v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09671">
<div class="article-summary-box-inner">
<span><p>Deep learning is a powerful tool for whole slide image (WSI) analysis.
Typically, when performing supervised deep learning, a WSI is divided into
small patches, trained and the outcomes are aggregated to estimate disease
grade. However, patch-based methods introduce label noise during training by
assuming that each patch is independent with the same label as the WSI and
neglect overall WSI-level information that is significant in disease grading.
Here we present a Graph-Transformer (GT) that fuses a graph-based
representation of an WSI and a vision transformer for processing pathology
images, called GTP, to predict disease grade. We selected $4,818$ WSIs from the
Clinical Proteomic Tumor Analysis Consortium (CPTAC), the National Lung
Screening Trial (NLST), and The Cancer Genome Atlas (TCGA), and used GTP to
distinguish adenocarcinoma (LUAD) and squamous cell carcinoma (LSCC) from
adjacent non-cancerous tissue (normal). First, using NLST data, we developed a
contrastive learning framework to generate a feature extractor. This allowed us
to compute feature vectors of individual WSI patches, which were used to
represent the nodes of the graph followed by construction of the GTP framework.
Our model trained on the CPTAC data achieved consistently high performance on
three-label classification (normal versus LUAD versus LSCC: mean accuracy$=
91.2$ $\pm$ $2.5\%$) based on five-fold cross-validation, and mean accuracy $=
82.3$ $\pm$ $1.0\%$ on external test data (TCGA). We also introduced a
graph-based saliency mapping technique, called GraphCAM, that can identify
regions that are highly associated with the class label. Our findings
demonstrate GTP as an interpretable and effective deep learning framework for
WSI-level classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Greedy Search: Tracking by Multi-Agent Reinforcement Learning-based Beam Search. (arXiv:2205.09676v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09676">
<div class="article-summary-box-inner">
<span><p>Existing trackers usually select a location or proposal with the maximum
score as tracking result for each frame. However, such greedy search scheme
maybe not the optimal choice, especially when encountering challenging tracking
scenarios like heavy occlusions and fast motion. Since the accumulated errors
would make response scores not reliable anymore. In this paper, we propose a
novel multi-agent reinforcement learning based beam search strategy (termed
BeamTracking) to address this issue. Specifically, we formulate the tracking as
a sample selection problem fulfilled by multiple parallel decision-making
processes, each of which aims at picking out one sample as their tracking
result in each frame. We take the target feature, proposal feature, and its
response score as state, and also consider actions predicted by nearby agent,
to train multi-agents to select their actions. When all the frames are
processed, we select the trajectory with the maximum accumulated score as the
tracking result. Extensive experiments on seven popular tracking benchmark
datasets validated the effectiveness of the proposed algorithm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semi-Supervised Learning for Image Classification using Compact Networks in the BioMedical Context. (arXiv:2205.09678v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09678">
<div class="article-summary-box-inner">
<span><p>The development of mobile and on the edge applications that embed deep
convolutional neural models has the potential to revolutionise biomedicine.
However, most deep learning models require computational resources that are not
available in smartphones or edge devices; an issue that can be faced by means
of compact models. The problem with such models is that they are, at least
usually, less accurate than bigger models. In this work, we study how this
limitation can be addressed with the application of semi-supervised learning
techniques. We conduct several statistical analyses to compare performance of
deep compact architectures when trained using semi-supervised learning methods
for tackling image classification tasks in the biomedical context. In
particular, we explore three families of compact networks, and two families of
semi-supervised learning techniques for 10 biomedical tasks. By combining
semi-supervised learning methods with compact networks, it is possible to
obtain a similar performance to standard size networks. In general, the best
results are obtained when combining data distillation with MixNet, and plain
distillation with ResNet-18. Also, in general, NAS networks obtain better
results than manually designed networks and quantized networks. The work
presented in this paper shows the benefits of apply semi-supervised methods to
compact networks; this allow us to create compact models that are not only as
accurate as standard size models, but also faster and lighter. Finally, we have
developed a library that simplifies the construction of compact models using
semi-supervised learning methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VNT-Net: Rotational Invariant Vector Neuron Transformers. (arXiv:2205.09690v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09690">
<div class="article-summary-box-inner">
<span><p>Learning 3D point sets with rotational invariance is an important and
challenging problem in machine learning. Through rotational invariant
architectures, 3D point cloud neural networks are relieved from requiring a
canonical global pose and from exhaustive data augmentation with all possible
rotations. In this work, we introduce a rotational invariant neural network by
combining recently introduced vector neurons with self-attention layers to
build a point cloud vector neuron transformer network (VNT-Net). Vector neurons
are known for their simplicity and versatility in representing SO(3) actions
and are thereby incorporated in common neural operations. Similarly,
Transformer architectures have gained popularity and recently were shown
successful for images by applying directly on sequences of image patches and
achieving superior performance and convergence. In order to benefit from both
worlds, we combine the two structures by mainly showing how to adapt the
multi-headed attention layers to comply with vector neurons operations. Through
this adaptation attention layers become SO(3) and the overall network becomes
rotational invariant. Experiments demonstrate that our network efficiently
handles 3D point cloud objects in arbitrary poses. We also show that our
network achieves higher accuracy when compared to related state-of-the-art
methods and requires less training due to a smaller number of hyperparameters
in common classification and segmentation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">k-strip: A novel segmentation algorithm in k-space for the application of skull stripping. (arXiv:2205.09706v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09706">
<div class="article-summary-box-inner">
<span><p>Objectives: Present a novel deep learning-based skull stripping algorithm for
magnetic resonance imaging (MRI) that works directly in the information rich
k-space.
</p>
<p>Materials and Methods: Using two datasets from different institutions with a
total of 36,900 MRI slices, we trained a deep learning-based model to work
directly with the complex raw k-space data. Skull stripping performed by HD-BET
(Brain Extraction Tool) in the image domain were used as the ground truth.
</p>
<p>Results: Both datasets were very similar to the ground truth (DICE scores of
92\%-98\% and Hausdorff distances of under 5.5 mm). Results on slices above the
eye-region reach DICE scores of up to 99\%, while the accuracy drops in regions
around the eyes and below, with partially blurred output. The output of k-strip
often smoothed edges at the demarcation to the skull. Binary masks are created
with an appropriate threshold.
</p>
<p>Conclusion: With this proof-of-concept study, we were able to show the
feasibility of working in the k-space frequency domain, preserving phase
information, with consistent results. Future research should be dedicated to
discovering additional ways the k-space can be used for innovative image
analysis and further workflows.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bi-LSTM Scoring Based Similarity Measurement with Agglomerative Hierarchical Clustering (AHC) for Speaker Diarization. (arXiv:2205.09709v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09709">
<div class="article-summary-box-inner">
<span><p>Majority of speech signals across different scenarios are never available
with well-defined audio segments containing only a single speaker. A typical
conversation between two speakers consists of segments where their voices
overlap, interrupt each other or halt their speech in between multiple
sentences. Recent advancements in diarization technology leverage neural
network-based approaches to improvise multiple subsystems of speaker
diarization system comprising of extracting segment-wise embedding features and
detecting changes in the speaker during conversation. However, to identify
speaker through clustering, models depend on methodologies like PLDA to
generate similarity measure between two extracted segments from a given
conversational audio. Since these algorithms ignore the temporal structure of
conversations, they tend to achieve a higher Diarization Error Rate (DER), thus
leading to misdetections both in terms of speaker and change identification.
Therefore, to compare similarity of two speech segments both independently and
sequentially, we propose a Bi-directional Long Short-term Memory network for
estimating the elements present in the similarity matrix. Once the similarity
matrix is generated, Agglomerative Hierarchical Clustering (AHC) is applied to
further identify speaker segments based on thresholding. To evaluate the
performance, Diarization Error Rate (DER%) metric is used. The proposed model
achieves a low DER of 34.80% on a test set of audio samples derived from ICSI
Meeting Corpus as compared to traditional PLDA based similarity measurement
mechanism which achieved a DER of 39.90%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Voxel-informed Language Grounding. (arXiv:2205.09710v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09710">
<div class="article-summary-box-inner">
<span><p>Natural language applied to natural 2D images describes a fundamentally 3D
world. We present the Voxel-informed Language Grounder (VLG), a language
grounding model that leverages 3D geometric information in the form of voxel
maps derived from the visual input using a volumetric reconstruction model. We
show that VLG significantly improves grounding accuracy on SNARE, an object
reference game task. At the time of writing, VLG holds the top place on the
SNARE leaderboard, achieving SOTA results with a 2.0% absolute improvement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Light In The Black: An Evaluation of Data Augmentation Techniques for COVID-19 CT's Semantic Segmentation. (arXiv:2205.09722v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09722">
<div class="article-summary-box-inner">
<span><p>With the COVID-19 global pandemic, computer-assisted diagnoses of medical
images have gained much attention, and robust methods of Semantic Segmentation
of Computed Tomography (CT) became highly desirable. Semantic Segmentation of
CT is one of many research fields of automatic detection of COVID-19 and has
been widely explored since the COVID-19 outbreak. In this work, we propose an
extensive analysis of how different data augmentation techniques improve the
training of encoder-decoder neural networks on this problem. Twenty different
data augmentation techniques were evaluated on five different datasets. Each
dataset was validated through a five-fold cross-validation strategy, thus
resulting in over 3,000 experiments. Our findings show that spatial level
transformations are the most promising to improve the learning of neural
networks on this problem.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust and Efficient Medical Imaging with Self-Supervision. (arXiv:2205.09723v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09723">
<div class="article-summary-box-inner">
<span><p>Recent progress in Medical Artificial Intelligence (AI) has delivered systems
that can reach clinical expert level performance. However, such systems tend to
demonstrate sub-optimal "out-of-distribution" performance when evaluated in
clinical settings different from the training environment. A common mitigation
strategy is to develop separate systems for each clinical setting using
site-specific data [1]. However, this quickly becomes impractical as medical
data is time-consuming to acquire and expensive to annotate [2]. Thus, the
problem of "data-efficient generalization" presents an ongoing difficulty for
Medical AI development. Although progress in representation learning shows
promise, their benefits have not been rigorously studied, specifically for
out-of-distribution settings. To meet these challenges, we present REMEDIS, a
unified representation learning strategy to improve robustness and
data-efficiency of medical imaging AI. REMEDIS uses a generic combination of
large-scale supervised transfer learning with self-supervised learning and
requires little task-specific customization. We study a diverse range of
medical imaging tasks and simulate three realistic application scenarios using
retrospective data. REMEDIS exhibits significantly improved in-distribution
performance with up to 11.5% relative improvement in diagnostic accuracy over a
strong supervised baseline. More importantly, our strategy leads to strong
data-efficient generalization of medical imaging AI, matching strong supervised
baselines using between 1% to 33% of retraining data across tasks. These
results suggest that REMEDIS can significantly accelerate the life-cycle of
medical imaging AI development thereby presenting an important step forward for
medical imaging AI to deliver broad impact.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Unified Keyframe Propagation Models. (arXiv:2205.09731v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09731">
<div class="article-summary-box-inner">
<span><p>Many video editing tasks such as rotoscoping or object removal require the
propagation of context across frames. While transformers and other
attention-based approaches that aggregate features globally have demonstrated
great success at propagating object masks from keyframes to the whole video,
they struggle to propagate high-frequency details such as textures faithfully.
We hypothesize that this is due to an inherent bias of global attention towards
low-frequency features. To overcome this limitation, we present a two-stream
approach, where high-frequency features interact locally and low-frequency
features interact globally. The global interaction stream remains robust in
difficult situations such as large camera motions, where explicit alignment
fails. The local interaction stream propagates high-frequency details through
deformable feature aggregation and, informed by the global interaction stream,
learns to detect and correct errors of the deformation field. We evaluate our
two-stream approach for inpainting tasks, where experiments show that it
improves both the propagation of features within a single frame as required for
image inpainting, as well as their propagation from keyframes to target frames.
Applied to video inpainting, our approach leads to 44% and 26% improvements in
FID and LPIPS scores. Code at https://github.com/runwayml/guided-inpainting
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diverse Weight Averaging for Out-of-Distribution Generalization. (arXiv:2205.09739v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09739">
<div class="article-summary-box-inner">
<span><p>Standard neural networks struggle to generalize under distribution shifts.
For out-of-distribution generalization in computer vision, the best current
approach averages the weights along a training run. In this paper, we propose
Diverse Weight Averaging (DiWA) that makes a simple change to this strategy:
DiWA averages the weights obtained from several independent training runs
rather than from a single run. Perhaps surprisingly, averaging these weights
performs well under soft constraints despite the network's nonlinearities. The
main motivation behind DiWA is to increase the functional diversity across
averaged models. Indeed, models obtained from different runs are more diverse
than those collected along a single run thanks to differences in
hyperparameters and training procedures. We motivate the need for diversity by
a new bias-variance-covariance-locality decomposition of the expected error,
exploiting similarities between DiWA and standard functional ensembling.
Moreover, this decomposition highlights that DiWA succeeds when the variance
term dominates, which we show happens when the marginal distribution changes at
test time. Experimentally, DiWA consistently improves the state of the art on
the competitive DomainBed benchmark without inference overhead.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BEVerse: Unified Perception and Prediction in Birds-Eye-View for Vision-Centric Autonomous Driving. (arXiv:2205.09743v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09743">
<div class="article-summary-box-inner">
<span><p>In this paper, we present BEVerse, a unified framework for 3D perception and
prediction based on multi-camera systems. Unlike existing studies focusing on
the improvement of single-task approaches, BEVerse features in producing
spatio-temporal Birds-Eye-View (BEV) representations from multi-camera videos
and jointly reasoning about multiple tasks for vision-centric autonomous
driving. Specifically, BEVerse first performs shared feature extraction and
lifting to generate 4D BEV representations from multi-timestamp and multi-view
images. After the ego-motion alignment, the spatio-temporal encoder is utilized
for further feature extraction in BEV. Finally, multiple task decoders are
attached for joint reasoning and prediction. Within the decoders, we propose
the grid sampler to generate BEV features with different ranges and
granularities for different tasks. Also, we design the method of iterative flow
for memory-efficient future prediction. We show that the temporal information
improves 3D object detection and semantic map construction, while the
multi-task learning can implicitly benefit motion prediction. With extensive
experiments on the nuScenes dataset, we show that the multi-task BEVerse
outperforms existing single-task methods on 3D object detection, semantic map
construction, and motion prediction. Compared with the sequential paradigm,
BEVerse also favors in significantly improved efficiency. The code and trained
models will be released at https://github.com/zhangyp15/BEVerse.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HandoverSim: A Simulation Framework and Benchmark for Human-to-Robot Object Handovers. (arXiv:2205.09747v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.09747">
<div class="article-summary-box-inner">
<span><p>We introduce a new simulation benchmark "HandoverSim" for human-to-robot
object handovers. To simulate the giver's motion, we leverage a recent motion
capture dataset of hand grasping of objects. We create training and evaluation
environments for the receiver with standardized protocols and metrics. We
analyze the performance of a set of baselines and show a correlation with a
real-world evaluation. Code is open sourced at https://handover-sim.github.io.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Review of Generalized Zero-Shot Learning Methods. (arXiv:2011.08641v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08641">
<div class="article-summary-box-inner">
<span><p>Generalized zero-shot learning (GZSL) aims to train a model for classifying
data samples under the condition that some output classes are unknown during
supervised learning. To address this challenging task, GZSL leverages semantic
information of the seen (source) and unseen (target) classes to bridge the gap
between both seen and unseen classes. Since its introduction, many GZSL models
have been formulated. In this review paper, we present a comprehensive review
on GZSL. Firstly, we provide an overview of GZSL including the problems and
challenges. Then, we introduce a hierarchical categorization for the GZSL
methods and discuss the representative methods in each category. In addition,
we discuss the available benchmark data sets and applications of GZSL, along
with a discussion on the research gaps and directions for future
investigations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Multiscale Convolutional Dictionaries for Image Reconstruction. (arXiv:2011.12815v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12815">
<div class="article-summary-box-inner">
<span><p>Convolutional neural networks (CNNs) have been tremendously successful in
solving imaging inverse problems. To understand their success, an effective
strategy is to construct simpler and mathematically more tractable
convolutional sparse coding (CSC) models that share essential ingredients with
CNNs. Existing CSC methods, however, underperform leading CNNs in challenging
inverse problems. We hypothesize that the performance gap may be attributed in
part to how they process images at different spatial scales: While many CNNs
use multiscale feature representations, existing CSC models mostly rely on
single-scale dictionaries. To close the performance gap, we thus propose a
multiscale convolutional dictionary structure. The proposed dictionary
structure is derived from the U-Net, arguably the most versatile and widely
used CNN for image-to-image learning problems. We show that incorporating the
proposed multiscale dictionary in an otherwise standard CSC framework yields
performance competitive with state-of-the-art CNNs across a range of
challenging inverse problems including CT and MRI reconstruction. Our work thus
demonstrates the effectiveness and scalability of the multiscale CSC approach
in solving challenging inverse problems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">D-Unet: A Dual-encoder U-Net for Image Splicing Forgery Detection and Localization. (arXiv:2012.01821v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01821">
<div class="article-summary-box-inner">
<span><p>Recently, many detection methods based on convolutional neural networks
(CNNs) have been proposed for image splicing forgery detection. Most of these
detection methods focus on the local patches or local objects. In fact, image
splicing forgery detection is a global binary classification task that
distinguishes the tampered and non-tampered regions by image fingerprints.
However, some specific image contents are hardly retained by CNN-based
detection networks, but if included, would improve the detection accuracy of
the networks. To resolve these issues, we propose a novel network called
dual-encoder U-Net (D-Unet) for image splicing forgery detection, which employs
an unfixed encoder and a fixed encoder. The unfixed encoder autonomously learns
the image fingerprints that differentiate between the tampered and non-tampered
regions, whereas the fixed encoder intentionally provides the direction
information that assists the learning and detection of the network. This
dual-encoder is followed by a spatial pyramid global-feature extraction module
that expands the global insight of D-Unet for classifying the tampered and
non-tampered regions more accurately. In an experimental comparison study of
D-Unet and state-of-the-art methods, D-Unet outperformed the other methods in
image-level and pixel-level detection, without requiring pre-training or
training on a large number of forgery images. Moreover, it was stably robust to
different attacks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Achieving Domain Generalization in Underwater Object Detection by Domain Mixup and Contrastive Learning. (arXiv:2104.02230v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02230">
<div class="article-summary-box-inner">
<span><p>The performance of existing underwater object detection methods degrades
seriously when facing domain shift caused by complicated underwater
environments. Due to the limitation of the number of domains in the dataset,
deep detectors easily memorize a few seen domains, which leads to low
generalization ability. There are two common ideas to improve the domain
generalization performance. First, it can be inferred that the detector trained
on as many domains as possible is domain-invariant. Second, for the images with
the same semantic content in different domains, their hidden features should be
equivalent. This paper further excavates these two ideas and proposes a domain
generalization framework (named DMC) that learns how to generalize across
domains from Domain Mixup and Contrastive Learning. First, based on the
formation of underwater images, an image in an underwater environment is the
linear transformation of another underwater environment. Thus, a style transfer
model, which outputs a linear transformation matrix instead of the whole image,
is proposed to transform images from one source domain to another, enriching
the domain diversity of the training data. Second, mixup operation interpolates
different domains on the feature level, sampling new domains on the domain
manifold. Third, contrastive loss is selectively applied to features from
different domains to force the model to learn domain invariant features but
retain the discriminative capacity. With our method, detectors will be robust
to domain shift. Also, a domain generalization benchmark S-UODAC2020 for
detection is set up to measure the performance of our method. Comprehensive
experiments on S-UODAC2020 and two object recognition benchmarks (PACS and
VLCS) demonstrate that the proposed method is able to learn domain-invariant
representations, and outperforms other domain generalization methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Denoising Noisy Neural Networks: A Bayesian Approach with Compensation. (arXiv:2105.10699v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10699">
<div class="article-summary-box-inner">
<span><p>Deep neural networks (DNNs) with noisy weights, which we refer to as noisy
neural networks (NoisyNNs), arise from the training and inference of DNNs in
the presence of noise. NoisyNNs emerge in many new applications, including the
wireless transmission of DNNs, the efficient deployment or storage of DNNs in
analog devices, and the truncation or quantization of DNN weights. This paper
studies a fundamental problem of NoisyNNs: how to reconstruct the DNN weights
from their noisy manifestations. While all prior works relied on the maximum
likelihood (ML) estimation, this paper puts forth a denoising approach to
reconstruct DNNs with the aim of maximizing the inference accuracy of the
reconstructed models. The superiority of our denoiser is rigorously proven in
two small-scale problems, wherein we consider a quadratic neural network
function and a shallow feedforward neural network, respectively. When applied
to advanced learning tasks with modern DNN architectures, our denoiser exhibits
significantly better performance than the ML estimator. Consider the average
test accuracy of the denoised DNN model versus the weight variance to noise
power ratio (WNR) performance. When denoising a noisy ResNet34 model arising
from noisy inference, our denoiser outperforms ML estimation by up to 4.1 dB to
achieve a test accuracy of 60%.When denoising a noisy ResNet18 model arising
from noisy training, our denoiser outperforms ML estimation by 13.4 dB and 8.3
dB to achieve test accuracies of 60% and 80%, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BR-NPA: A Non-Parametric High-Resolution Attention Model to improve the Interpretability of Attention. (arXiv:2106.02566v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02566">
<div class="article-summary-box-inner">
<span><p>The prevalence of employing attention mechanisms has brought along concerns
on the interpretability of attention distributions. Although it provides
insights about how a model is operating, utilizing attention as the explanation
of model predictions is still highly dubious. The community is still seeking
more interpretable strategies for better identifying local active regions that
contribute the most to the final decision. To improve the interpretability of
existing attention models, we propose a novel Bilinear Representative
Non-Parametric Attention (BR-NPA) strategy that captures the task-relevant
human-interpretable information. The target model is first distilled to have
higher-resolution intermediate feature maps. From which, representative
features are then grouped based on local pairwise feature similarity, to
produce finer-grained, more precise attention maps highlighting task-relevant
parts of the input. The obtained attention maps are ranked according to the
activity level of the compound feature, which provides information regarding
the important level of the highlighted regions. The proposed model can be
easily adapted in a wide variety of modern deep models, where classification is
involved. Extensive quantitative and qualitative experiments showcase more
comprehensive and accurate visual explanations compared to state-of-the-art
attention models and visualizations methods across multiple tasks including
fine-grained image classification, few-shot classification, and person
re-identification, without compromising the classification accuracy. The
proposed visualization model sheds imperative light on how neural networks `pay
their attention' differently in different tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NODEO: A Neural Ordinary Differential Equation Based Optimization Framework for Deformable Image Registration. (arXiv:2108.03443v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03443">
<div class="article-summary-box-inner">
<span><p>Deformable image registration (DIR), aiming to find spatial correspondence
between images, is one of the most critical problems in the domain of medical
image analysis. In this paper, we present a novel, generic, and accurate
diffeomorphic image registration framework that utilizes neural ordinary
differential equations (NODEs). We model each voxel as a moving particle and
consider the set of all voxels in a 3D image as a high-dimensional dynamical
system whose trajectory determines the targeted deformation field. Our method
leverages deep neural networks for their expressive power in modeling dynamical
systems, and simultaneously optimizes for a dynamical system between the image
pairs and the corresponding transformation. Our formulation allows various
constraints to be imposed along the transformation to maintain desired
regularities. Our experiment results show that our method outperforms the
benchmarks under various metrics. Additionally, we demonstrate the feasibility
to expand our framework to register multiple image sets using a unified form of
transformation,which could possibly serve a wider range of applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">COVID-19 Monitoring System using Social Distancing and Face Mask Detection on Surveillance video datasets. (arXiv:2110.03905v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03905">
<div class="article-summary-box-inner">
<span><p>In the current times, the fear and danger of COVID-19 virus still stands
large. Manual monitoring of social distancing norms is impractical with a large
population moving about and with insufficient task force and resources to
administer them. There is a need for a lightweight, robust and 24X7
video-monitoring system that automates this process. This paper proposes a
comprehensive and effective solution to perform person detection, social
distancing violation detection, face detection and face mask classification
using object detection, clustering and Convolution Neural Network (CNN) based
binary classifier. For this, YOLOv3, Density-based spatial clustering of
applications with noise (DBSCAN), Dual Shot Face Detector (DSFD) and
MobileNetV2 based binary classifier have been employed on surveillance video
datasets. This paper also provides a comparative study of different face
detection and face mask classification models. Finally, a video dataset
labelling method is proposed along with the labelled video dataset to
compensate for the lack of dataset in the community and is used for evaluation
of the system. The system performance is evaluated in terms of accuracy, F1
score as well as the prediction time, which has to be low for practical
applicability. The system performs with an accuracy of 91.2% and F1 score of
90.79% on the labelled video dataset and has an average prediction time of 7.12
seconds for 78 frames of a video.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Fusion Prior for Multi-Focus Image Super Resolution Fusion. (arXiv:2110.05706v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.05706">
<div class="article-summary-box-inner">
<span><p>This paper unifies the multi-focus images fusion (MFIF) and blind super
resolution (SR) problems as the multi-focus image super resolution fusion
(MFISRF) task, and proposes a novel unified dataset-free unsupervised framework
named deep fusion prior (DFP) to address such MFISRF task. DFP consists of
SKIPnet network, DoubleReblur focus measurement tactic, decision embedding
module and loss functions. In particular, DFP can obtain MFISRF only from two
low-resolution inputs without any extent dataset; SKIPnet implementing
unsupervised learning via deep image prior is an end-to-end generated network
acting as the engine of DFP; DoubleReblur is used to determine the primary
decision map without learning but based on estimated PSF and Gaussian kernels
convolution; decision embedding module optimizes the decision map via learning;
and DFP losses composed of content loss, joint gradient loss and gradient limit
loss can obtain high-quality MFISRF results robustly. Experiments have proved
that our proposed DFP approaches and even outperforms those state-of-art MFIF
and SR method combinations. Additionally, DFP is a general framework, thus its
networks and focus measurement tactics can be continuously updated to further
improve the MFISRF performance. DFP codes are open source and will be available
soon at <a href="http://github.com/GuYuanjie/DeepFusionPrior.">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DBSegment: Fast and robust segmentation of deep brain structures -- Evaluation of transportability across acquisition domains. (arXiv:2110.09473v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.09473">
<div class="article-summary-box-inner">
<span><p>Segmenting deep brain structures from magnetic resonance images is important
for patient diagnosis, surgical planning, and research. Most current
state-of-the-art solutions follow a segmentation-by-registration approach,
where subject MRIs are mapped to a template with well-defined segmentations.
However, registration-based pipelines are time-consuming, thus, limiting their
clinical use. This paper uses deep learning to provide a robust and efficient
deep brain segmentation solution. The method consists of a pre-processing step
to conform all MRI images to the same orientation, followed by a convolutional
neural network using the nnU-Net framework. We use a total of 14 datasets from
both research and clinical collections. Of these, seven were used for training
and validation and seven were retained for independent testing. We trained the
network to segment 30 deep brain structures, as well as a brain mask, using
labels generated from a registration-based approach. We evaluated the
generalizability of the network by performing a leave-one-dataset-out
cross-validation, and extensive testing on external datasets. Furthermore, we
assessed cross-domain transportability by evaluating the results separately on
different domains. We achieved an average DSC of 0.89 $\pm$ 0.04 on the
independent testing datasets when compared to the registration-based gold
standard. On our test system, the computation time decreased from 42 minutes
for a reference registration-based pipeline to 1 minute. Our proposed method is
fast, robust, and generalizes with high reliability. It can be extended to the
segmentation of other brain structures. The method is publicly available on
GitHub, as well as a pip package for convenient usage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transparent Human Evaluation for Image Captioning. (arXiv:2111.08940v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.08940">
<div class="article-summary-box-inner">
<span><p>We establish THumB, a rubric-based human evaluation protocol for image
captioning models. Our scoring rubrics and their definitions are carefully
developed based on machine- and human-generated captions on the MSCOCO dataset.
Each caption is evaluated along two main dimensions in a tradeoff (precision
and recall) as well as other aspects that measure the text quality (fluency,
conciseness, and inclusive language). Our evaluations demonstrate several
critical problems of the current evaluation practice. Human-generated captions
show substantially higher quality than machine-generated ones, especially in
coverage of salient information (i.e., recall), while most automatic metrics
say the opposite. Our rubric-based results reveal that CLIPScore, a recent
metric that uses image features, better correlates with human judgments than
conventional text-only metrics because it is more sensitive to recall. We hope
that this work will promote a more transparent evaluation protocol for image
captioning and its automatic metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Single-pass Object-adaptive Data Undersampling and Reconstruction for MRI. (arXiv:2111.09212v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.09212">
<div class="article-summary-box-inner">
<span><p>There is much recent interest in techniques to accelerate the data
acquisition process in MRI by acquiring limited measurements. Often
sophisticated reconstruction algorithms are deployed to maintain high image
quality in such settings. In this work, we propose a data-driven sampler using
a convolutional neural network, MNet, to provide object-specific sampling
patterns adaptive to each scanned object. The network observes very limited
low-frequency k-space data for each object and rapidly predicts the desired
undersampling pattern in one go that achieves high image reconstruction
quality. We propose an accompanying alternating-type training framework with a
mask-backward procedure that efficiently generates training labels for the
sampler network and jointly trains an image reconstruction network.
Experimental results on the fastMRI knee dataset demonstrate the ability of the
proposed learned undersampling network to generate object-specific masks at
fourfold and eightfold acceleration that achieve superior image reconstruction
performance than several existing schemes. The source code for the proposed
joint sampling and reconstruction learning framework is available at
https://github.com/zhishenhuang/mri.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoSSL: Co-Learning of Representation and Classifier for Imbalanced Semi-Supervised Learning. (arXiv:2112.04564v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.04564">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel co-learning framework (CoSSL) with
decoupled representation learning and classifier learning for imbalanced SSL.
To handle the data imbalance, we devise Tail-class Feature Enhancement (TFE)
for classifier learning. Furthermore, the current evaluation protocol for
imbalanced SSL focuses only on balanced test sets, which has limited
practicality in real-world scenarios. Therefore, we further conduct a
comprehensive evaluation under various shifted test distributions. In
experiments, we show that our approach outperforms other methods over a large
range of shifted distributions, achieving state-of-the-art performance on
benchmark datasets ranging from CIFAR-10, CIFAR-100, ImageNet, to Food-101. Our
code will be made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Novel Skeleton-Based Human Activity Discovery Using Particle Swarm Optimization with Gaussian Mutation. (arXiv:2201.05314v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.05314">
<div class="article-summary-box-inner">
<span><p>Human activity discovery aims to cluster the activities performed by humans,
without any prior information of what defines each activity. Most methods
presented in human activity recognition are supervised, where there are labeled
inputs to train the system. In reality, it is difficult to label activities
data because of its huge volume and the variety of activities performed by
humans. In this paper, an unsupervised approach is proposed to perform human
activity discovery in 3D skeleton sequences. First, important frames are
selected based on kinetic energy. Next, the displacement of joints, statistical
displacements, angles, and orientation features are extracted to represent the
activities information. Since not all extracted features have useful
information, the dimension of features is reduced using PCA. Most human
activity discovery proposed are not fully unsupervised. They use pre-segmented
videos before categorizing activities. To deal with this, we have used sliding
time window to segment the time series of activities with some overlapping.
Then, activities are discovered by a hybrid particle swarm optimization with
Gaussian mutation algorithm to provide diverse solutions. Finally, k-means is
applied to the outcome centroids from each iteration of the PSO to overcome the
slow convergence rate of PSO. Experiments on three datasets have been presented
and the results show the proposed method has superior performance in
discovering activities in compared to the other state-of-the-art methods and
has increased accuracy of at least 4 % on average.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Class-Aware Generative Adversarial Transformers for Medical Image Segmentation. (arXiv:2201.10737v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.10737">
<div class="article-summary-box-inner">
<span><p>Transformers have made remarkable progress towards modeling long-range
dependencies within the medical image analysis domain. However, current
transformer-based models suffer from several disadvantages: (1) existing
methods fail to capture the important features of the images due to the naive
tokenization scheme; (2) the models suffer from information loss because they
only consider single-scale feature representations; and (3) the segmentation
label maps generated by the models are not accurate enough without considering
rich semantic contexts and anatomical textures. In this work, we present
CASTformer, a novel type of generative adversarial transformers, for 2D medical
image segmentation. First, we take advantage of the pyramid structure to
construct multi-scale representations and handle multi-scale variations. We
then design a novel class-aware transformer module to better learn the
discriminative regions of objects with semantic structures. Lastly, we utilize
an adversarial training strategy that boosts segmentation accuracy and
correspondingly allows a transformer-based discriminator to capture high-level
semantically correlated contents and low-level anatomical features. Our
experiments demonstrate that CASTformer dramatically outperforms previous
state-of-the-art transformer-based approaches on three benchmarks, obtaining
2.54%-5.88% absolute improvements in Dice over previous models. Further
qualitative experiments provide a more detailed picture of the model's inner
workings, shed light on the challenges in improved transparency, and
demonstrate that transfer learning can greatly improve performance and reduce
the size of medical image datasets in training, making CASTformer a strong
starting point for downstream medical image analysis tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NIMBLE: A Non-rigid Hand Model with Bones and Muscles. (arXiv:2202.04533v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.04533">
<div class="article-summary-box-inner">
<span><p>Emerging Metaverse applications demand reliable, accurate, and photorealistic
reproductions of human hands to perform sophisticated operations as if in the
physical world. While real human hand represents one of the most intricate
coordination between bones, muscle, tendon, and skin, state-of-the-art
techniques unanimously focus on modeling only the skeleton of the hand. In this
paper, we present NIMBLE, a novel parametric hand model that includes the
missing key components, bringing 3D hand model to a new level of realism. We
first annotate muscles, bones and skins on the recent Magnetic Resonance
Imaging hand (MRI-Hand) dataset and then register a volumetric template hand
onto individual poses and subjects within the dataset. NIMBLE consists of 20
bones as triangular meshes, 7 muscle groups as tetrahedral meshes, and a skin
mesh. Via iterative shape registration and parameter learning, it further
produces shape blend shapes, pose blend shapes, and a joint regressor. We
demonstrate applying NIMBLE to modeling, rendering, and visual inference tasks.
By enforcing the inner bones and muscles to match anatomic and kinematic rules,
NIMBLE can animate 3D hands to new poses at unprecedented realism. To model the
appearance of skin, we further construct a photometric HandStage to acquire
high-quality textures and normal maps to model wrinkles and palm print.
Finally, NIMBLE also benefits learning-based hand pose and shape estimation by
either synthesizing rich data or acting directly as a differentiable layer in
the inference network.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Real-time Image Reconstruction with Neural Networks for MRI-guided Radiotherapy. (arXiv:2202.05267v2 [physics.med-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.05267">
<div class="article-summary-box-inner">
<span><p>MRI-guidance techniques that dynamically adapt radiation beams to follow
tumor motion in real-time will lead to more accurate cancer treatments and
reduced collateral healthy tissue damage. The gold-standard for reconstruction
of undersampled MR data is compressed sensing (CS) which is computationally
slow and limits the rate that images can be available for real-time adaptation.
Here, we demonstrate the use of automated transform by manifold approximation
(AUTOMAP), a generalized framework that maps raw MR signal to the target image
domain, to rapidly reconstruct images from undersampled radial k-space data.
The AUTOMAP neural network was trained to reconstruct images from a
golden-angle radial acquisition, a benchmark for motion-sensitive imaging, on
lung cancer patient data and generic images from ImageNet. Model training was
subsequently augmented with motion-encoded k-space data derived from videos in
the YouTube-8M dataset to encourage motion robust reconstruction. We find that
AUTOMAP-reconstructed radial k-space has equivalent accuracy to CS but with
much shorter processing times after initial fine-tuning on retrospectively
acquired lung cancer patient data. Validation of motion-trained models with a
virtual dynamic lung tumor phantom showed that the generalized motion
properties learned from YouTube lead to improved target tracking accuracy. Our
work shows that AUTOMAP can achieve real-time, accurate reconstruction of
radial data. These findings imply that neural-network-based reconstruction is
potentially superior to existing approaches for real-time image guidance
applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GroupViT: Semantic Segmentation Emerges from Text Supervision. (arXiv:2202.11094v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.11094">
<div class="article-summary-box-inner">
<span><p>Grouping and recognition are important components of visual scene
understanding, e.g., for object detection and semantic segmentation. With
end-to-end deep learning systems, grouping of image regions usually happens
implicitly via top-down supervision from pixel-level recognition labels.
Instead, in this paper, we propose to bring back the grouping mechanism into
deep networks, which allows semantic segments to emerge automatically with only
text supervision. We propose a hierarchical Grouping Vision Transformer
(GroupViT), which goes beyond the regular grid structure representation and
learns to group image regions into progressively larger arbitrary-shaped
segments. We train GroupViT jointly with a text encoder on a large-scale
image-text dataset via contrastive losses. With only text supervision and
without any pixel-level annotations, GroupViT learns to group together semantic
regions and successfully transfers to the task of semantic segmentation in a
zero-shot manner, i.e., without any further fine-tuning. It achieves a
zero-shot accuracy of 52.3\% mIoU on the PASCAL VOC 2012 and 22.4\% mIoU on
PASCAL Context datasets, and performs competitively to state-of-the-art
transfer-learning methods requiring greater levels of supervision. We
open-source our code at
\href{https://github.com/NVlabs/GroupViT}{https://github.com/NVlabs/GroupViT}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SepTr: Separable Transformer for Audio Spectrogram Processing. (arXiv:2203.09581v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.09581">
<div class="article-summary-box-inner">
<span><p>Following the successful application of vision transformers in multiple
computer vision tasks, these models have drawn the attention of the signal
processing community. This is because signals are often represented as
spectrograms (e.g. through Discrete Fourier Transform) which can be directly
provided as input to vision transformers. However, naively applying
transformers to spectrograms is suboptimal. Since the axes represent distinct
dimensions, i.e. frequency and time, we argue that a better approach is to
separate the attention dedicated to each axis. To this end, we propose the
Separable Transformer (SepTr), an architecture that employs two transformer
blocks in a sequential manner, the first attending to tokens within the same
frequency bin, and the second attending to tokens within the same time
interval. We conduct experiments on three benchmark data sets, showing that our
separable architecture outperforms conventional vision transformers and other
state-of-the-art methods. Unlike standard transformers, SepTr linearly scales
the number of trainable parameters with the input size, thus having a lower
memory footprint. Our code is available as open source at
https://github.com/ristea/septr.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-modal Learning of Graph Representations using Radar Point Cloud for Long-Range Gesture Recognition. (arXiv:2203.17066v2 [eess.SP] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.17066">
<div class="article-summary-box-inner">
<span><p>Gesture recognition is one of the most intuitive ways of interaction and has
gathered particular attention for human computer interaction. Radar sensors
possess multiple intrinsic properties, such as their ability to work in low
illumination, harsh weather conditions, and being low-cost and compact, making
them highly preferable for a gesture recognition solution. However, most
literature work focuses on solutions with a limited range that is lower than a
meter. We propose a novel architecture for a long-range (1m - 2m) gesture
recognition solution that leverages a point cloud-based cross-learning approach
from camera point cloud to 60-GHz FMCW radar point cloud, which allows learning
better representations while suppressing noise. We use a variant of Dynamic
Graph CNN (DGCNN) for the cross-learning, enabling us to model relationships
between the points at a local and global level and to model the temporal
dynamics a Bi-LSTM network is employed. In the experimental results section, we
demonstrate our model's overall accuracy of 98.4% for five gestures and its
generalization capability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection. (arXiv:2204.02964v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.02964">
<div class="article-summary-box-inner">
<span><p>We present an approach to efficiently and effectively adapt a masked image
modeling (MIM) pre-trained vanilla Vision Transformer (ViT) for object
detection, which is based on our two novel observations: (i) A MIM pre-trained
vanilla ViT encoder can work surprisingly well in the challenging object-level
recognition scenario even with randomly sampled partial observations, e.g.,
only 25% $\sim$ 50% of the input embeddings. (ii) In order to construct
multi-scale representations for object detection from single-scale ViT, a
randomly initialized compact convolutional stem supplants the pre-trained large
kernel patchify stem, and its intermediate features can naturally serve as the
higher resolution inputs of a feature pyramid network without further
upsampling or other manipulations. While the pre-trained ViT is only regarded
as the 3$^{rd}$-stage of our detector's backbone instead of the whole feature
extractor. This results in a ConvNet-ViT hybrid feature extractor. The proposed
detector, named MIMDet, enables a MIM pre-trained vanilla ViT to outperform
hierarchical Swin Transformer by 2.5 box AP and 2.6 mask AP on COCO, and
achieves better results compared with the previous best adapted vanilla ViT
detector using a more modest fine-tuning recipe while converging 2.8$\times$
faster. Code and pre-trained models are available at
https://github.com/hustvl/MIMDet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning with Signatures. (arXiv:2204.07953v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.07953">
<div class="article-summary-box-inner">
<span><p>In this work we investigate the use of the Signature Transform in the context
of Learning. Under this assumption, we advance a supervised framework that
potentially provides state-of-the-art classification accuracy with the use of
few labels without the need of credit assignment and with minimal or no
overfitting. We leverage tools from harmonic analysis by the use of the
signature and log-signature, and use as a score function RMSE and MAE Signature
and log-signature. We develop a closed-form equation to compute probably good
optimal scale factors, as well as the formulation to obtain them by
optimization. Techniques of Signal Processing are addressed to further
characterize the problem. Classification is performed at the CPU level orders
of magnitude faster than other methods. We report results on AFHQ, MNIST and
CIFAR10, achieving 100% accuracy on all tasks assuming we can determine at test
time which probably good optimal scale factor to use for each category.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evolutionary latent space search for driving human portrait generation. (arXiv:2204.11887v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2204.11887">
<div class="article-summary-box-inner">
<span><p>This article presents an evolutionary approach for synthetic human portraits
generation based on the latent space exploration of a generative adversarial
network. The idea is to produce different human face images very similar to a
given target portrait. The approach applies StyleGAN2 for portrait generation
and FaceNet for face similarity evaluation. The evolutionary search is based on
exploring the real-coded latent space of StyleGAN2. The main results over both
synthetic and real images indicate that the proposed approach generates
accurate and diverse solutions, which represent realistic human portraits. The
proposed research can contribute to improving the security of face recognition
systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cracking White-box DNN Watermarks via Invariant Neuron Transforms. (arXiv:2205.00199v2 [cs.CR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.00199">
<div class="article-summary-box-inner">
<span><p>Recently, how to protect the Intellectual Property (IP) of deep neural
networks (DNN) becomes a major concern for the AI industry. To combat potential
model piracy, recent works explore various watermarking strategies to embed
secret identity messages into the prediction behaviors or the internals (e.g.,
weights and neuron activation) of the target model. Sacrificing less
functionality and involving more knowledge about the target model, the latter
branch of watermarking schemes (i.e., white-box model watermarking) is claimed
to be accurate, credible and secure against most known watermark removal
attacks, with emerging research efforts and applications in the industry.
</p>
<p>In this paper, we present the first effective removal attack which cracks
almost all the existing white-box watermarking schemes with provably no
performance overhead and no required prior knowledge. By analyzing these IP
protection mechanisms at the granularity of neurons, we for the first time
discover their common dependence on a set of fragile features of a local neuron
group, all of which can be arbitrarily tampered by our proposed chain of
invariant neuron transforms. On $9$ state-of-the-art white-box watermarking
schemes and a broad set of industry-level DNN architectures, our attack for the
first time reduces the embedded identity message in the protected models to be
almost random. Meanwhile, unlike known removal attacks, our attack requires no
prior knowledge on the training data distribution or the adopted watermark
algorithms, and leaves model functionality intact.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scene Clustering Based Pseudo-labeling Strategy for Multi-modal Aerial View Object Classification. (arXiv:2205.01920v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.01920">
<div class="article-summary-box-inner">
<span><p>Multi-modal aerial view object classification (MAVOC) in Automatic target
recognition (ATR), although an important and challenging problem, has been
under studied. This paper firstly finds that fine-grained data, class imbalance
and various shooting conditions preclude the representational ability of
general image classification. Moreover, the MAVOC dataset has scene aggregation
characteristics. By exploiting these properties, we propose Scene Clustering
Based Pseudo-labeling Strategy (SCP-Label), a simple yet effective method to
employ in post-processing. The SCP-Label brings greater accuracy by assigning
the same label to objects within the same scene while also mitigating bias and
confusion with model ensembles. Its performance surpasses the official baseline
by a large margin of +20.57% Accuracy on Track 1 (SAR), and +31.86% Accuracy on
Track 2 (SAR+EO), demonstrating the potential of SCP-Label as post-processing.
Finally, we win the championship both on Track1 and Track2 in the CVPR 2022
Perception Beyond the Visible Spectrum (PBVS) Workshop MAVOC Challenge. Our
code is available at https://github.com/HowieChangchn/SCP-Label.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models. (arXiv:2205.02152v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.02152">
<div class="article-summary-box-inner">
<span><p>Recent studies indicate that detecting radiographic patterns on CT scans can
yield high sensitivity and specificity for Covid-19 localization. In this
paper, we investigate the appropriateness of deep learning models
transferability, for semantic segmentation of pneumonia-infected areas in CT
images. Transfer learning allows for the fast initialization/reutilization of
detection models, given that large volumes of training data are not available.
Our work explores the efficacy of using pre-trained U-Net architectures, on a
specific CT data set, for identifying Covid-19 side-effects over images from
different datasets. Experimental results indicate improvement in the
segmentation accuracy of identifying Covid-19 infected regions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UnrealNAS: Can We Search Neural Architectures with Unreal Data?. (arXiv:2205.02162v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.02162">
<div class="article-summary-box-inner">
<span><p>Neural architecture search (NAS) has shown great success in the automatic
design of deep neural networks (DNNs). However, the best way to use data to
search network architectures is still unclear and under exploration. Previous
work has analyzed the necessity of having ground-truth labels in NAS and
inspired broad interest. In this work, we take a further step to question
whether real data is necessary for NAS to be effective. The answer to this
question is important for applications with limited amount of accessible data,
and can help people improve NAS by leveraging the extra flexibility of data
generation. To explore if NAS needs real data, we construct three types of
unreal datasets using: 1) randomly labeled real images; 2) generated images and
labels; and 3) generated Gaussian noise with random labels. These datasets
facilitate to analyze the generalization and expressivity of the searched
architectures. We study the performance of architectures searched on these
constructed datasets using popular differentiable NAS methods. Extensive
experiments on CIFAR, ImageNet and CheXpert show that the searched
architectures can achieve promising results compared with those derived from
the conventional NAS pipeline with real labeled data, suggesting the
feasibility of performing NAS with unreal data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CLIP-CLOP: CLIP-Guided Collage and Photomontage. (arXiv:2205.03146v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.03146">
<div class="article-summary-box-inner">
<span><p>The unabated mystique of large-scale neural networks, such as the CLIP dual
image-and-text encoder, popularized automatically generated art. Increasingly
more sophisticated generators enhanced the artworks' realism and visual
appearance, and creative prompt engineering enabled stylistic expression.
Guided by an artist-in-the-loop ideal, we design a gradient-based generator to
produce collages. It requires the human artist to curate libraries of image
patches and to describe (with prompts) the whole image composition, with the
option to manually adjust the patches' positions during generation, thereby
allowing humans to reclaim some control of the process and achieve greater
creative freedom. We explore the aesthetic potentials of high-resolution
collages, and provide an open-source Google Colab as an artistic tool.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConvMAE: Masked Convolution Meets Masked Autoencoders. (arXiv:2205.03892v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.03892">
<div class="article-summary-box-inner">
<span><p>Vision Transformers (ViT) become widely-adopted architectures for various
vision tasks. Masked auto-encoding for feature pretraining and multi-scale
hybrid convolution-transformer architectures can further unleash the potentials
of ViT, leading to state-of-the-art performances on image classification,
detection and semantic segmentation. In this paper, our ConvMAE framework
demonstrates that multi-scale hybrid convolution-transformer can learn more
discriminative representations via the mask auto-encoding scheme. However,
directly using the original masking strategy leads to the heavy computational
cost and pretraining-finetuning discrepancy. To tackle the issue, we adopt the
masked convolution to prevent information leakage in the convolution blocks. A
simple block-wise masking strategy is proposed to ensure computational
efficiency. We also propose to more directly supervise the multi-scale features
of the encoder to boost multi-scale features. Based on our pretrained ConvMAE
models, ConvMAE-Base improves ImageNet-1K finetuning accuracy by 1.4% compared
with MAE-Base. On object detection, ConvMAE-Base finetuned for only 25 epochs
surpasses MAE-Base fined-tuned for 100 epochs by 2.9% box AP and 2.2% mask AP
respectively. Code and pretrained models are available at
https://github.com/Alpha-VL/ConvMAE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incremental-DETR: Incremental Few-Shot Object Detection via Self-Supervised Learning. (arXiv:2205.04042v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.04042">
<div class="article-summary-box-inner">
<span><p>Incremental few-shot object detection aims at detecting novel classes without
forgetting knowledge of the base classes with only a few labeled training data
from the novel classes. Most related prior works are on incremental object
detection that rely on the availability of abundant training samples per novel
class that substantially limits the scalability to real-world setting where
novel data can be scarce. In this paper, we propose the Incremental-DETR that
does incremental few-shot object detection via fine-tuning and self-supervised
learning on the DETR object detector. To alleviate severe over-fitting with few
novel class data, we first fine-tune the class-specific components of DETR with
self-supervision from additional object proposals generated using Selective
Search as pseudo labels. We further introduce a incremental few-shot
fine-tuning strategy with knowledge distillation on the class-specific
components of DETR to encourage the network in detecting novel classes without
catastrophic forgetting. Extensive experiments conducted on standard
incremental object detection and incremental few-shot object detection settings
show that our approach significantly outperforms state-of-the-art methods by a
large margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attracting and Dispersing: A Simple Approach for Source-free Domain Adaptation. (arXiv:2205.04183v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.04183">
<div class="article-summary-box-inner">
<span><p>We propose a simple but effective source-free domain adaptation (SFDA)
method. Treating SFDA as an unsupervised clustering problem and following the
intuition that local neighbors in feature space should have more similar
predictions than other features, we propose to optimize an objective of
prediction consistency. This objective encourages local neighborhood features
in feature space to have similar predictions while features farther away in
feature space have dissimilar predictions, leading to efficient feature
clustering and cluster assignment simultaneously. For efficient training, we
seek to optimize an upper-bound of the objective resulting in two simple terms.
Furthermore, we relate popular existing methods in domain adaptation,
source-free domain adaptation and contrastive learning via the perspective of
discriminability and diversity. The experimental results prove the superiority
of our method, and our method can be adopted as a simple but strong baseline
for future research in SFDA. Our method can be also adapted to source-free
open-set and partial-set DA which further shows the generalization ability of
our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distinction Maximization Loss: Efficiently Improving Classification Accuracy, Uncertainty Estimation, and Out-of-Distribution Detection Simply Replacing the Loss and Calibrating. (arXiv:2205.05874v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.05874">
<div class="article-summary-box-inner">
<span><p>Building robust deterministic neural networks remains a challenge. On the one
hand, some approaches improve out-of-distribution detection at the cost of
reducing classification accuracy in some situations. On the other hand, some
methods simultaneously increase classification accuracy, uncertainty
estimation, and out-of-distribution detection at the expense of reducing the
inference efficiency and requiring training the same model many times to tune
hyperparameters. In this paper, we propose training deterministic neural
networks using our DisMax loss, which works as a drop-in replacement for the
usual SoftMax loss (i.e., the combination of the linear output layer, the
SoftMax activation, and the cross-entropy loss). Starting from the IsoMax+
loss, we create each logit based on the distances to all prototypes rather than
just the one associated with the correct class. We also introduce a mechanism
to combine images to construct what we call fractional probability
regularization. Moreover, we present a fast way to calibrate the network after
training. Finally, we propose a composite score to perform out-of-distribution
detection. Our experiments show that DisMax usually outperforms current
approaches simultaneously in classification accuracy, uncertainty estimation,
and out-of-distribution detection while maintaining deterministic neural
network inference efficiency and avoiding training the same model repetitively
for hyperparameter tuning. The code to reproduce the results is available at
https://github.com/dlmacedo/distinction-maximization-loss.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Test-time Fourier Style Calibration for Domain Generalization. (arXiv:2205.06427v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.06427">
<div class="article-summary-box-inner">
<span><p>The topic of generalizing machine learning models learned on a collection of
source domains to unknown target domains is challenging. While many domain
generalization (DG) methods have achieved promising results, they primarily
rely on the source domains at train-time without manipulating the target
domains at test-time. Thus, it is still possible that those methods can overfit
to source domains and perform poorly on target domains. Driven by the
observation that domains are strongly related to styles, we argue that reducing
the gap between source and target styles can boost models' generalizability. To
solve the dilemma of having no access to the target domain during training, we
introduce Test-time Fourier Style Calibration (TF-Cal) for calibrating the
target domain style on the fly during testing. To access styles, we utilize
Fourier transformation to decompose features into amplitude (style) features
and phase (semantic) features. Furthermore, we present an effective technique
to Augment Amplitude Features (AAF) to complement TF-Cal. Extensive experiments
on several popular DG benchmarks and a segmentation dataset for medical images
demonstrate that our method outperforms state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PillarNet: Real-Time and High-Performance Pillar-based 3D Object Detection. (arXiv:2205.07403v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.07403">
<div class="article-summary-box-inner">
<span><p>Real-time and high-performance 3D object detection is of critical importance
for autonomous driving. Recent top-performing 3D object detectors mainly rely
on point-based or 3D voxel-based convolutions, which are both computationally
inefficient for onboard deployment. While recent researches focus on
point-based or 3D voxel-based convolutions for higher performance, these
methods fail to meet latency and power efficiency requirements especially for
deployment on embedded devices. In contrast, pillar-based methods use merely 2D
convolutions, which consume less computation resources, but they lag far behind
their voxel-based counterparts in detection accuracy. However, the superiority
of such 3D voxel-based methods over pillar-based methods is still broadly
attributed to the effectiveness of 3D convolution neural network (CNN). In this
paper, by examining the primary performance gap between pillar- and voxel-based
detectors, we develop a real-time and high-performance pillar-based detector,
dubbed PillarNet. The proposed PillarNet consists of a powerful encoder network
for effective pillar feature learning, a neck network for spatial-semantic
feature fusion and the commonly used detect head. Using only 2D convolutions,
PillarNet is flexible to an optional pillar size and compatible with classical
2D CNN backbones, such as VGGNet and ResNet. Additionally, PillarNet benefits
from our designed orientation-decoupled IoU regression loss along with the
IoU-aware prediction branch. Extensive experimental results on large-scale
nuScenes Dataset and Waymo Open Dataset demonstrate that the proposed PillarNet
performs well over the state-of-the-art 3D detectors in terms of effectiveness
and efficiency. Code will be made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text Detection & Recognition in the Wild for Robot Localization. (arXiv:2205.08565v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08565">
<div class="article-summary-box-inner">
<span><p>Signage is everywhere and a robot should be able to take advantage of signs
to help it localize (including Visual Place Recognition (VPR)) and map. Robust
text detection &amp; recognition in the wild is challenging due to such factors as
pose, irregular text, illumination, and occlusion. We propose an end-to-end
scene text spotting model that simultaneously outputs the text string and
bounding boxes. This model is more suitable for VPR. Our central contribution
is introducing utilizing an end-to-end scene text spotting framework to
adequately capture the irregular and occluded text regions in different
challenging places. To evaluate our proposed architecture's performance for
VPR, we conducted several experiments on the challenging Self-Collected Text
Place (SCTP) benchmark dataset. The initial experimental results show that the
proposed method outperforms the SOTA methods in terms of precision and recall
when tested on this benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SemiCurv: Semi-Supervised Curvilinear Structure Segmentation. (arXiv:2205.08706v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08706">
<div class="article-summary-box-inner">
<span><p>Recent work on curvilinear structure segmentation has mostly focused on
backbone network design and loss engineering. The challenge of collecting
labelled data, an expensive and labor intensive process, has been overlooked.
While labelled data is expensive to obtain, unlabelled data is often readily
available. In this work, we propose SemiCurv, a semi-supervised learning (SSL)
framework for curvilinear structure segmentation that is able to utilize such
unlabelled data to reduce the labelling burden. Our framework addresses two key
challenges in formulating curvilinear segmentation in a semi-supervised manner.
First, to fully exploit the power of consistency based SSL, we introduce a
geometric transformation as strong data augmentation and then align
segmentation predictions via a differentiable inverse transformation to enable
the computation of pixel-wise consistency. Second, the traditional mean square
error (MSE) on unlabelled data is prone to collapsed predictions and this issue
exacerbates with severe class imbalance (significantly more background pixels).
We propose a N-pair consistency loss to avoid trivial predictions on unlabelled
data. We evaluate SemiCurv on six curvilinear segmentation datasets, and find
that with no more than 5% of the labelled data, it achieves close to 95% of the
performance relative to its fully supervised counterpart.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Financial Time Series Data Augmentation with Generative Adversarial Networks and Extended Intertemporal Return Plots. (arXiv:2205.08924v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.08924">
<div class="article-summary-box-inner">
<span><p>Data augmentation is a key regularization method to support the forecast and
classification performance of highly parameterized models in computer vision.
In the time series domain however, regularization in terms of augmentation is
not equally common even though these methods have proven to mitigate effects
from small sample size or non-stationarity. In this paper we apply state-of-the
art image-based generative models for the task of data augmentation and
introduce the extended intertemporal return plot (XIRP), a new image
representation for time series. Multiple tests are conducted to assess the
quality of the augmentation technique regarding its ability to synthesize time
series effectively and improve forecast results on a subset of the M4
competition. We further investigate the relationship between data set
characteristics and sampling results via Shapley values for feature attribution
on the performance metrics and the optimal ratio of augmented data. Over all
data sets, our approach proves to be effective in reducing the return forecast
error by 7% on 79% of the financial data sets with varying statistical
properties and frequencies.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2022-05-21 23:08:30.252761768 UTC">2022-05-21 23:08:30 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>