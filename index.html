<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-10-18T01:30:00Z">10-18</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparks: Inspiration for Science Writing using Language Models. (arXiv:2110.07640v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07640">
<div class="article-summary-box-inner">
<span><p>Large-scale language models are rapidly improving, performing well on a wide
variety of tasks with little to no customization. In this work we investigate
how language models can support science writing, a challenging writing task
that is both open-ended and highly constrained. We present a system for
generating "sparks", sentences related to a scientific concept intended to
inspire writers. We find that our sparks are more coherent and diverse than a
competitive language model baseline, and approach a human-created gold
standard. In a study with 13 PhD students writing on topics of their own
selection, we find three main use cases of sparks: aiding with crafting
detailed sentences, providing interesting angles to engage readers, and
demonstrating common reader perspectives. We also report on the various reasons
sparks were considered unhelpful, and discuss how we might improve language
models as writing support tools.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GlobalWoZ: Globalizing MultiWoZ to Develop Multilingual Task-Oriented Dialogue Systems. (arXiv:2110.07679v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07679">
<div class="article-summary-box-inner">
<span><p>Much recent progress in task-oriented dialogue (ToD) systems has been driven
by available annotation data across multiple domains for training. Over the
last few years, there has been a move towards data curation for multilingual
ToD systems that are applicable to serve people speaking different languages.
However, existing multilingual ToD datasets either have a limited coverage of
languages due to the high cost of data curation, or ignore the fact that
dialogue entities barely exist in countries speaking these languages. To tackle
these limitations, we introduce a novel data curation method that generates
GlobalWoZ -- a large-scale multilingual ToD dataset globalized from an English
ToD dataset for three unexplored use cases. Our method is based on translating
dialogue templates and filling them with local entities in the target-language
countries. We release our dataset as well as a set of strong baselines to
encourage research on learning multilingual ToD systems for real use cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Large Scale Substitution-based Word Sense Induction. (arXiv:2110.07681v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07681">
<div class="article-summary-box-inner">
<span><p>We present a word-sense induction method based on pre-trained masked language
models (MLMs), which can cheaply scale to large vocabularies and large corpora.
The result is a corpus which is sense-tagged according to a corpus-derived
sense inventory and where each sense is associated with indicative words.
Evaluation on English Wikipedia that was sense-tagged using our method shows
that both the induced senses, and the per-instance sense assignment, are of
high quality even compared to WSD methods, such as Babelfy. Furthermore, by
training a static word embeddings algorithm on the sense-tagged corpus, we
obtain high-quality static senseful embeddings. These outperform existing
senseful embeddings techniques on the WiC dataset and on a new outlier
detection dataset we developed. The data driven nature of the algorithm allows
to induce corpora-specific senses, which may not appear in standard sense
inventories, as we demonstrate using a case study on the scientific domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Making Document-Level Information Extraction Right for the Right Reasons. (arXiv:2110.07686v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07686">
<div class="article-summary-box-inner">
<span><p>Document-level information extraction is a flexible framework compatible with
applications where information is not necessarily localized in a single
sentence. For example, key features of a diagnosis in radiology a report may
not be explicitly stated, but nevertheless can be inferred from the report's
text. However, document-level neural models can easily learn spurious
correlations from irrelevant information. This work studies how to ensure that
these models make correct inferences from complex text and make those
inferences in an auditable way: beyond just being right, are these models
"right for the right reasons?" We experiment with post-hoc evidence extraction
in a predict-select-verify framework using feature attribution techniques.
While this basic approach can extract reasonable evidence, it can be
regularized with small amounts of evidence supervision during training, which
substantially improves the quality of extracted evidence. We evaluate on two
domains: a small-scale labeled dataset of brain MRI reports and a large-scale
modified version of DocRED (Yao et al., 2019) and show that models'
plausibility can be improved with no loss in accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is Stance Detection Topic-Independent and Cross-topic Generalizable? -- A Reproduction Study. (arXiv:2110.07693v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07693">
<div class="article-summary-box-inner">
<span><p>Cross-topic stance detection is the task to automatically detect stances
(pro, against, or neutral) on unseen topics. We successfully reproduce
state-of-the-art cross-topic stance detection work (Reimers et. al., 2019), and
systematically analyze its reproducibility. Our attention then turns to the
cross-topic aspect of this work, and the specificity of topics in terms of
vocabulary and socio-cultural context. We ask: To what extent is stance
detection topic-independent and generalizable across topics? We compare the
model's performance on various unseen topics, and find topic (e.g. abortion,
cloning), class (e.g. pro, con), and their interaction affecting the model's
performance. We conclude that investigating performance on different topics,
and addressing topic-specific vocabulary and context, is a future avenue for
cross-topic stance detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CCQA: A New Web-Scale Question Answering Dataset for Model Pre-Training. (arXiv:2110.07731v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07731">
<div class="article-summary-box-inner">
<span><p>With the rise of large-scale pre-trained language models, open-domain
question-answering (ODQA) has become an important research topic in NLP. Based
on the popular pre-training fine-tuning approach, we posit that an additional
in-domain pre-training stage using a large-scale, natural, and diverse
question-answering (QA) dataset can be beneficial for ODQA. Consequently, we
propose a novel QA dataset based on the Common Crawl project in this paper.
Using the readily available schema.org annotation, we extract around 130
million multilingual question-answer pairs, including about 60 million English
data-points. With this previously unseen number of natural QA pairs, we
pre-train popular language models to show the potential of large-scale
in-domain pre-training for the task of question-answering. In our experiments,
we find that pre-training question-answering models on our Common Crawl
Question Answering dataset (CCQA) achieves promising results in zero-shot, low
resource and fine-tuned settings across multiple tasks, models and benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models. (arXiv:2110.07736v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07736">
<div class="article-summary-box-inner">
<span><p>Recently, NLP models have achieved remarkable progress across a variety of
tasks; however, they have also been criticized for being not robust. Many
robustness problems can be attributed to models exploiting spurious
correlations, or shortcuts between the training data and the task labels.
Models may fail to generalize to out-of-distribution data or be vulnerable to
adversarial attacks if spurious correlations are exploited through the training
process. In this paper, we aim to automatically identify such spurious
correlations in NLP models at scale. We first leverage existing
interpretability methods to extract tokens that significantly affect model's
decision process from the input text. We then distinguish "genuine" tokens and
"spurious" tokens by analyzing model predictions across multiple corpora and
further verify them through knowledge-aware perturbations. We show that our
proposed method can effectively and efficiently identify a scalable set of
"shortcuts", and mitigating these leads to more robust models in multiple
applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hindsight: Posterior-guided training of retrievers for improved open-ended generation. (arXiv:2110.07752v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07752">
<div class="article-summary-box-inner">
<span><p>Many text generation systems benefit from using a retriever to retrieve
passages from a textual knowledge corpus (e.g., Wikipedia) which are then
provided as additional context to the generator. For open-ended generation
tasks (like generating informative utterances in conversations) many varied
passages may be equally relevant and we find that existing methods that jointly
train the retriever and generator underperform: the retriever may not find
relevant passages even amongst the top-10 and hence the generator may not learn
a preference to ground its generated output in them. We propose using an
additional guide retriever that is allowed to use the target output and "in
hindsight" retrieve relevant passages during training. We model the guide
retriever after the posterior distribution Q of passages given the input and
the target output and train it jointly with the standard retriever and the
generator by maximizing the evidence lower bound (ELBo) in expectation over Q.
For informative conversations from the Wizard of Wikipedia dataset, with
posterior-guided training, the retriever finds passages with higher relevance
in the top-10 (23% relative improvement), the generator's responses are more
grounded in the retrieved passage (19% relative improvement) and the end-to-end
system produces better overall output (6.4% relative improvement).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multilingual Bag-of-Entities Model for Zero-Shot Cross-Lingual Text Classification. (arXiv:2110.07792v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07792">
<div class="article-summary-box-inner">
<span><p>We present a multilingual bag-of-entities model that effectively boosts the
performance of zero-shot cross-lingual text classification by extending a
multilingual pre-trained language model (e.g., M-BERT). It leverages the
multilingual nature of Wikidata: entities in multiple languages representing
the same concept are defined with a unique identifier. This enables entities
described in multiple languages to be represented using shared embeddings. A
model trained on entity features in a resource-rich language can thus be
directly applied to other languages. Our experimental results on cross-lingual
topic classification (using the MLDoc and TED-CLDC datasets) and entity typing
(using the SHINRA2020-ML dataset) show that the proposed model consistently
outperforms state-of-the-art models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ContraQA: Question Answering under Contradicting Contexts. (arXiv:2110.07803v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07803">
<div class="article-summary-box-inner">
<span><p>With a rise in false, inaccurate, and misleading information in propaganda,
news, and social media, real-world Question Answering (QA) systems face the
challenges of synthesizing and reasoning over contradicting information to
derive correct answers. This urgency gives rise to the need to make QA systems
robust to misinformation, a topic previously unexplored. We study the risk of
misinformation to QA models by investigating the behavior of the QA model under
contradicting contexts that are mixed with both real and fake information. We
create the first large-scale dataset for this problem, namely Contra-QA, which
contains over 10K human-written and model-generated contradicting pairs of
contexts. Experiments show that QA models are vulnerable under contradicting
contexts brought by misinformation. To defend against such a threat, we build a
misinformation-aware QA system as a counter-measure that integrates question
answering and misinformation detection in a joint fashion.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Alternative Input Signals Ease Transfer in Multilingual Machine Translation. (arXiv:2110.07804v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07804">
<div class="article-summary-box-inner">
<span><p>Recent work in multilingual machine translation (MMT) has focused on the
potential of positive transfer between languages, particularly cases where
higher-resourced languages can benefit lower-resourced ones. While training an
MMT model, the supervision signals learned from one language pair can be
transferred to the other via the tokens shared by multiple source languages.
However, the transfer is inhibited when the token overlap among source
languages is small, which manifests naturally when languages use different
writing systems. In this paper, we tackle inhibited transfer by augmenting the
training data with alternative signals that unify different writing systems,
such as phonetic, romanized, and transliterated input. We test these signals on
Indic and Turkic languages, two language families where the writing systems
differ but languages still share common features. Our results indicate that a
straightforward multi-source self-ensemble -- training a model on a mixture of
various signals and ensembling the outputs of the same model fed with different
signals during inference, outperforms strong ensemble baselines by 1.3 BLEU
points on both language families. Further, we find that incorporating
alternative inputs via self-ensemble can be particularly effective when
training set is small, leading to +5 BLEU when only 5% of the total training
data is accessible. Finally, our analysis demonstrates that including
alternative signals yields more consistency and translates named entities more
accurately, which is crucial for increased factuality of automated systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cascaded Fast and Slow Models for Efficient Semantic Code Search. (arXiv:2110.07811v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07811">
<div class="article-summary-box-inner">
<span><p>The goal of natural language semantic code search is to retrieve a
semantically relevant code snippet from a fixed set of candidates using a
natural language query. Existing approaches are neither effective nor efficient
enough towards a practical semantic code search system. In this paper, we
propose an efficient and accurate semantic code search framework with cascaded
fast and slow models, in which a fast transformer encoder model is learned to
optimize a scalable index for fast retrieval followed by learning a slow
classification-based re-ranking model to improve the performance of the top K
results from the fast retrieval. To further reduce the high memory cost of
deploying two separate models in practice, we propose to jointly train the fast
and slow model based on a single transformer encoder with shared parameters.
The proposed cascaded approach is not only efficient and scalable, but also
achieves state-of-the-art results with an average mean reciprocal ranking (MRR)
score of 0.7795 (across 6 programming languages) as opposed to the previous
state-of-the-art result of 0.713 MRR on the CodeSearchNet benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Meta-learning via Language Model In-context Tuning. (arXiv:2110.07814v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07814">
<div class="article-summary-box-inner">
<span><p>The goal of meta-learning is to learn to adapt to a new task with only a few
labeled examples. To tackle this problem in NLP, we propose $\textit{in-context
tuning}$, which recasts adaptation and prediction as a simple sequence
prediction problem: to form the input sequence, we concatenate the task
instruction, the labeled examples, and the target input to predict; to
meta-train the model to learn from in-context examples, we fine-tune a
pre-trained language model (LM) to predict the target label from the input
sequences on a collection of tasks.
</p>
<p>We benchmark our method on two collections of text classification tasks: LAMA
and BinaryClfs. Compared to first-order MAML which adapts the model with
gradient descent, our method better leverages the inductive bias of LMs to
perform pattern matching, and outperforms MAML by an absolute $6\%$ AUC ROC
score on BinaryClfs, with increasing advantage w.r.t. model size. Compared to
non-fine-tuned in-context learning (i.e. prompting a raw LM), in-context tuning
directly learns to learn from in-context examples. On BinaryClfs, in-context
tuning improves the average AUC-ROC score by an absolute $10\%$, and reduces
the variance with respect to example ordering by 6x and example choices by 2x.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Neural Machine Translation:Can Linguistic Hierarchies Help?. (arXiv:2110.07816v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07816">
<div class="article-summary-box-inner">
<span><p>Multilingual Neural Machine Translation (MNMT) trains a single NMT model that
supports translation between multiple languages, rather than training separate
models for different languages. Learning a single model can enhance the
low-resource translation by leveraging data from multiple languages. However,
the performance of an MNMT model is highly dependent on the type of languages
used in training, as transferring knowledge from a diverse set of languages
degrades the translation performance due to negative transfer. In this paper,
we propose a Hierarchical Knowledge Distillation (HKD) approach for MNMT which
capitalises on language groups generated according to typological features and
phylogeny of languages to overcome the issue of negative transfer. HKD
generates a set of multilingual teacher-assistant models via a selective
knowledge distillation mechanism based on the language groups, and then distils
the ultimate multilingual model from those assistants in an adaptive way.
Experimental results derived from the TED dataset with 53 languages demonstrate
the effectiveness of our approach in avoiding the negative transfer effect in
MNMT, leading to an improved translation performance (about 1 BLEU score on
average) compared to strong baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DirectQuote: A Dataset for Direct Quotation Extraction and Attribution in News Articles. (arXiv:2110.07827v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07827">
<div class="article-summary-box-inner">
<span><p>Quotation extraction and attribution are challenging tasks, aiming at
determining the spans containing quotations and attributing each quotation to
the original speaker. Applying this task to news data is highly related to
fact-checking, media monitoring and news tracking. Direct quotations are more
traceable and informative, and therefore of great significance among different
types of quotations. Therefore, this paper introduces DirectQuote, a corpus
containing 19,760 paragraphs and 10,279 direct quotations manually annotated
from online news media. To the best of our knowledge, this is the largest and
most complete corpus that focuses on direct quotations in news texts. We ensure
that each speaker in the annotation can be linked to a specific named entity on
Wikidata, benefiting various downstream tasks. In addition, for the first time,
we propose several sequence labeling models as baseline methods to extract and
attribute quotations simultaneously in an end-to-end manner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RAP: Robustness-Aware Perturbations for Defending against Backdoor Attacks on NLP Models. (arXiv:2110.07831v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07831">
<div class="article-summary-box-inner">
<span><p>Backdoor attacks, which maliciously control a well-trained model's outputs of
the instances with specific triggers, are recently shown to be serious threats
to the safety of reusing deep neural networks (DNNs). In this work, we propose
an efficient online defense mechanism based on robustness-aware perturbations.
Specifically, by analyzing the backdoor training process, we point out that
there exists a big gap of robustness between poisoned and clean samples.
Motivated by this observation, we construct a word-based robustness-aware
perturbation to distinguish poisoned samples from clean samples to defend
against the backdoor attacks on natural language processing (NLP) models.
Moreover, we give a theoretical analysis about the feasibility of our
robustness-aware perturbation-based defense method. Experimental results on
sentiment analysis and toxic detection tasks show that our method achieves
better defending performance and much lower computational costs than existing
online defense methods. Our code is available at
https://github.com/lancopku/RAP.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Span Detection for Aspect-Based Sentiment Analysis in Vietnamese. (arXiv:2110.07833v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07833">
<div class="article-summary-box-inner">
<span><p>Aspect-based sentiment analysis plays an essential role in natural language
processing and artificial intelligence. Recently, researchers only focused on
aspect detection and sentiment classification but ignoring the sub-task of
detecting user opinion span, which has enormous potential in practical
applications. In this paper, we present a new Vietnamese dataset (UIT-ViSD4SA)
consisting of 35,396 human-annotated spans on 11,122 feedback comments for
evaluating the span detection in aspect-based sentiment analysis. Besides, we
also propose a novel system using Bidirectional Long Short-Term Memory (BiLSTM)
with a Conditional Random Field (CRF) layer (BiLSTM-CRF) for the span detection
task in Vietnamese aspect-based sentiment analysis. The best result is a 62.76%
F1 score (macro) for span detection using BiLSTM-CRF with embedding fusion of
syllable embedding, character embedding, and contextual embedding from
XLM-RoBERTa. In future work, span detection will be extended in many NLP tasks
such as constructive detection, emotion recognition, complaint analysis, and
opinion mining. Our dataset is freely available at
https://github.com/kimkim00/UIT-ViSD4SA for research purposes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Lingual Fine-Grained Entity Typing. (arXiv:2110.07837v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07837">
<div class="article-summary-box-inner">
<span><p>The growth of cross-lingual pre-trained models has enabled NLP tools to
rapidly generalize to new languages. While these models have been applied to
tasks involving entities, their ability to explicitly predict typological
features of these entities across languages has not been established. In this
paper, we present a unified cross-lingual fine-grained entity typing model
capable of handling over 100 languages and analyze this model's ability to
generalize to languages and entities unseen during training. We train this
model on cross-lingual training data collected from Wikipedia hyperlinks in
multiple languages (training languages). During inference, our model takes an
entity mention and context in a particular language (test language, possibly
not in the training languages) and predicts fine-grained types for that entity.
Generalizing to new languages and unseen entities are the fundamental
challenges of this entity typing setup, so we focus our evaluation on these
settings and compare against simple yet powerful string match baselines.
Experimental results show that our approach outperforms the baselines on unseen
languages such as Japanese, Tamil, Arabic, Serbian, and Persian. In addition,
our approach substantially improves performance on unseen entities (even in
unseen languages) over the baselines, and human evaluation shows a strong
ability to predict relevant types in these settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ESPnet2-TTS: Extending the Edge of TTS Research. (arXiv:2110.07840v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07840">
<div class="article-summary-box-inner">
<span><p>This paper describes ESPnet2-TTS, an end-to-end text-to-speech (E2E-TTS)
toolkit. ESPnet2-TTS extends our earlier version, ESPnet-TTS, by adding many
new features, including: on-the-fly flexible pre-processing, joint training
with neural vocoders, and state-of-the-art TTS models with extensions like
full-band E2E text-to-waveform modeling, which simplify the training pipeline
and further enhance TTS performance. The unified design of our recipes enables
users to quickly reproduce state-of-the-art E2E-TTS results. We also provide
many pre-trained models in a unified Python interface for inference, offering a
quick means for users to generate baseline samples and build demos.
Experimental evaluations with English and Japanese corpora demonstrate that our
provided models synthesize utterances comparable to ground-truth ones,
achieving state-of-the-art TTS performance. The toolkit is available online at
https://github.com/espnet/espnet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling Endorsement for Multi-Document Abstractive Summarization. (arXiv:2110.07844v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07844">
<div class="article-summary-box-inner">
<span><p>A crucial difference between single- and multi-document summarization is how
salient content manifests itself in the document(s). While such content may
appear at the beginning of a single document, essential information is
frequently reiterated in a set of documents related to a particular topic,
resulting in an endorsement effect that increases information salience. In this
paper, we model the cross-document endorsement effect and its utilization in
multiple document summarization. Our method generates a synopsis from each
document, which serves as an endorser to identify salient content from other
documents. Strongly endorsed text segments are used to enrich a neural
encoder-decoder model to consolidate them into an abstractive summary. The
method has a great potential to learn from fewer examples to identify salient
content, which alleviates the need for costly retraining when the set of
documents is dynamically adjusted. Through extensive experiments on benchmark
multi-document summarization datasets, we demonstrate the effectiveness of our
proposed method over strong published baselines. Finally, we shed light on
future research directions and discuss broader challenges of this task using a
case study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Segmentation-based News Summarization. (arXiv:2110.07850v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07850">
<div class="article-summary-box-inner">
<span><p>In this paper, we bring a new way of digesting news content by introducing
the task of segmenting a news article into multiple sections and generating the
corresponding summary to each section. We make two contributions towards this
new task. First, we create and make available a dataset, SegNews, consisting of
27k news articles with sections and aligned heading-style section summaries.
Second, we propose a novel segmentation-based language generation model adapted
from pre-trained language models that can jointly segment a document and
produce the summary for each section. Experimental results on SegNews
demonstrate that our model can outperform several state-of-the-art
sequence-to-sequence generation models for this new task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Curriculum Learning for AMR Parsing. (arXiv:2110.07855v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07855">
<div class="article-summary-box-inner">
<span><p>Abstract Meaning Representation (AMR) parsing translates sentences to the
semantic representation with a hierarchical structure, which is recently
empowered by pretrained encoder-decoder models. However, the flat
sentence-to-AMR training paradigm impedes the representation learning of
concepts and relations in the deeper AMR sub-graph. To make the
sequence-to-sequence models better adapt to the inherent AMR structure, we
propose a hierarchical curriculum learning (HCL) which consists of (1)
structure-level curriculum (SC) and (2) instance-level curriculum (IC). SC
switches progressively from shallow to deep AMR sub-graphs while IC transits
from easy to hard AMR instances during training. Extensive experiments show
that BART trained with HCL achieves the state-of-the-art performance on the
AMR-2.0 and AMR-3.0 benchmark, and significantly outperforms baselines on the
structure-dependent evaluation metrics and hard instances.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning. (arXiv:2110.07867v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07867">
<div class="article-summary-box-inner">
<span><p>How can pre-trained language models (PLMs) learn universal representations
and effectively adapt to broad NLP tasks differing a lot superficially? In this
work, we empirically find evidences indicating that the adaptations of PLMs to
various tasks can be reparameterized as optimizing only a few free parameters
in a common low-dimensional intrinsic task subspace, which may help us
understand why PLMs could easily adapt to various NLP tasks with small-scale
data. Specifically, to find such a subspace and examine its universality, we
resort to the recent success of prompt tuning and decompose the soft prompts of
multiple NLP tasks into the same low-dimensional nonlinear subspace, then we
learn to adapt the PLM to unseen tasks or data by only tuning parameters in the
subspace. We dub this pipeline as intrinsic prompt tuning (IPT). In
experiments, we study diverse few-shot NLP tasks and surprisingly find that in
a 5-dimensional subspace found with 100 random tasks, by only tuning 5 free
parameters, we can recover 87% and 65% of the full prompt tuning performance
for 100 seen tasks (using different training data) and 20 unseen tasks,
respectively, showing great generalization ability of the found intrinsic task
subspace. Besides being an analysis tool, IPT could further bring practical
benefits, such as improving the prompt tuning stability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Socially Aware Bias Measurements for Hindi Language Representations. (arXiv:2110.07871v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07871">
<div class="article-summary-box-inner">
<span><p>Language representations are an efficient tool used across NLP, but they are
strife with encoded societal biases. These biases are studied extensively, but
with a primary focus on English language representations and biases common in
the context of Western society. In this work, we investigate the biases present
in Hindi language representations such as caste and religion associated biases.
We demonstrate how biases are unique to specific language representations based
on the history and culture of the region they are widely spoken in, and also
how the same societal bias (such as binary gender associated biases) when
investigated across languages is encoded by different words and text spans.
With this work, we emphasize on the necessity of social-awareness along with
linguistic and grammatical artefacts when modeling language representations, in
order to understand the biases encoded.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer. (arXiv:2110.07904v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07904">
<div class="article-summary-box-inner">
<span><p>As pre-trained language models have gotten larger, there has been growing
interest in parameter-efficient methods to apply these models to downstream
tasks. Building on the PromptTuning approach of Lester et al. (2021), which
learns task-specific soft prompts to condition a frozen language model to
perform downstream tasks, we propose a novel prompt-based transfer learning
approach called SPoT: Soft Prompt Transfer. SPoT first learns a prompt on one
or more source tasks and then uses it to initialize the prompt for a target
task. We show that SPoT significantly boosts the performance of PromptTuning
across many tasks. More importantly, SPoT either matches or outperforms
ModelTuning, which fine-tunes the entire model on each individual task, across
all model sizes while being more parameter-efficient (up to 27,000x fewer
task-specific parameters). We further conduct a large-scale study on task
transferability with 26 NLP tasks and 160 combinations of source-target tasks,
and demonstrate that tasks can often benefit each other via prompt transfer.
Finally, we propose a simple yet efficient retrieval approach that interprets
task prompts as task embeddings to identify the similarity between tasks and
predict the most transferable source tasks for a given novel target task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Speech Recognition using Knowledge Transfer across Learning Processes. (arXiv:2110.07909v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07909">
<div class="article-summary-box-inner">
<span><p>Multilingual end-to-end(E2E) models have shown a great potential in the
expansion of the language coverage in the realm of automatic speech
recognition(ASR). In this paper, we aim to enhance the multilingual ASR
performance in two ways, 1)studying the impact of feeding a one-hot vector
identifying the language, 2)formulating the task with a meta-learning objective
combined with self-supervised learning (SSL). We associate every language with
a distinct task manifold and attempt to improve the performance by transferring
knowledge across learning processes itself as compared to transferring through
final model parameters. We employ this strategy on a dataset comprising of 6
languages for an in-domain ASR task, by minimizing an objective related to
expected gradient path length. Experimental results reveal the best
pre-training strategy resulting in 3.55% relative reduction in overall WER. A
combination of LEAP and SSL yields 3.51% relative reduction in overall WER when
using language ID.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Estimating the Level and Direction of Phonetic Dialect Change in the Northern Netherlands. (arXiv:2110.07918v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07918">
<div class="article-summary-box-inner">
<span><p>This article reports ongoing investigations into phonetic change of dialect
groups in the northern Netherlandic language area, particularly the Frisian and
Low Saxon dialect groups, which are known to differ in vitality. To achieve
this, we combine existing phonetically transcribed corpora with dialectometric
approaches that allow us to quantify change among older male dialect speakers
in a real-time framework. A multidimensional variant of the Levenshtein
distance, combined with methods that induce realistic phonetic distances
between transcriptions, is used to estimate how much dialect groups have
changed between 1990 and 2010, and whether they changed towards Standard Dutch
or away from it. Our analyses indicate that language change is a slow process
in this geographical area. Moreover, the Frisian and Groningen dialect groups
seem to be most stable, while the other Low Saxon varieties (excluding the
Groningen dialect group) were shown to be most prone to change. We offer
possible explanations for our findings, while we discuss shortcomings of the
data and approach in detail, as well as desiderata for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Bridging the Gap: Cross-Lingual Summarization with Compression Rate. (arXiv:2110.07936v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07936">
<div class="article-summary-box-inner">
<span><p>Cross-lingual Summarization (CLS), converting a document into a cross-lingual
summary, is highly related to Machine Translation (MT) task. However, MT
resources are still underutilized for the CLS task. In this paper, we propose a
novel task, Cross-lingual Summarization with Compression rate (CSC), to benefit
cross-lingual summarization through large-scale MT corpus. Through introducing
compression rate, we regard MT task as a special CLS task with the compression
rate of 100%. Hence they can be trained as a unified task, sharing knowledge
more effectively. Moreover, to bridge these two tasks smoothly, we propose a
simple yet effective data augmentation method to produce document-summary pairs
with different compression rates. The proposed method not only improves the
performance of CLS task, but also provides controllability to generate
summaries in desired lengths. Experiments demonstrate that our method
outperforms various strong baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Identifying Causal Influences on Publication Trends and Behavior: A Case Study of the Computational Linguistics Community. (arXiv:2110.07938v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07938">
<div class="article-summary-box-inner">
<span><p>Drawing causal conclusions from observational real-world data is a very much
desired but challenging task. In this paper we present mixed-method analyses to
investigate causal influences of publication trends and behavior on the
adoption, persistence, and retirement of certain research foci --
methodologies, materials, and tasks that are of interest to the computational
linguistics (CL) community. Our key findings highlight evidence of the
transition to rapidly emerging methodologies in the research community (e.g.,
adoption of bidirectional LSTMs influencing the retirement of LSTMs), the
persistent engagement with trending tasks and techniques (e.g., deep learning,
embeddings, generative, and language models), the effect of scientist location
from outside the US, e.g., China on propensity of researching languages beyond
English, and the potential impact of funding for large-scale research programs.
We anticipate this work to provide useful insights about publication trends and
behavior and raise the awareness about the potential for causal inference in
the computational linguistics and a broader scientific community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Don't speak too fast: The impact of data bias on self-supervised speech models. (arXiv:2110.07957v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07957">
<div class="article-summary-box-inner">
<span><p>Self-supervised Speech Models (S3Ms) have been proven successful in many
speech downstream tasks, like ASR. However, how pre-training data affects S3Ms'
downstream behavior remains an unexplored issue. In this paper, we study how
pre-training data affects S3Ms by pre-training models on biased datasets
targeting different factors of speech, including gender, content, and prosody,
and evaluate these pre-trained S3Ms on selected downstream tasks in SUPERB
Benchmark. Our experiments show that S3Ms have tolerance toward gender bias.
Moreover, we find that the content of speech has little impact on the
performance of S3Ms across downstream tasks, but S3Ms do show a preference
toward a slower speech rate.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tracing Origins: Coref-aware Machine Reading Comprehension. (arXiv:2110.07961v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07961">
<div class="article-summary-box-inner">
<span><p>Machine reading comprehension is a heavily-studied research and test field
for evaluating new pre-trained models and fine-tuning strategies, and recent
studies have enriched the pre-trained models with syntactic, semantic and other
linguistic information to improve the performance of the model. In this paper,
we imitated the human's reading process in connecting the anaphoric expressions
and explicitly leverage the coreference information to enhance the word
embeddings from the pre-trained model, in order to highlight the coreference
mentions that must be identified for coreference-intensive question answering
in QUOREF, a relatively new dataset that is specifically designed to evaluate
the coreference-related performance of a model. We used an additional BERT
layer to focus on the coreference mentions, and a Relational Graph
Convolutional Network to model the coreference relations. We demonstrated that
the explicit incorporation of the coreference information in fine-tuning stage
performed better than the incorporation of the coreference information in
training a pre-trained language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scribosermo: Fast Speech-to-Text models for German and other Languages. (arXiv:2110.07982v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07982">
<div class="article-summary-box-inner">
<span><p>Recent Speech-to-Text models often require a large amount of hardware
resources and are mostly trained in English. This paper presents Speech-to-Text
models for German, as well as for Spanish and French with special features: (a)
They are small and run in real-time on microcontrollers like a RaspberryPi. (b)
Using a pretrained English model, they can be trained on consumer-grade
hardware with a relatively small dataset. (c) The models are competitive with
other solutions and outperform them in German. In this respect, the models
combine advantages of other approaches, which only include a subset of the
presented features. Furthermore, the paper provides a new library for handling
datasets, which is focused on easy extension with additional datasets and shows
an optimized way for transfer-learning new languages using a pretrained model
from another language with a similar alphabet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer-based Multi-task Learning for Disaster Tweet Categorisation. (arXiv:2110.08010v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08010">
<div class="article-summary-box-inner">
<span><p>Social media has enabled people to circulate information in a timely fashion,
thus motivating people to post messages seeking help during crisis situations.
These messages can contribute to the situational awareness of emergency
responders, who have a need for them to be categorised according to information
types (i.e. the type of aid services the messages are requesting). We introduce
a transformer-based multi-task learning (MTL) technique for classifying
information types and estimating the priority of these messages. We evaluate
the effectiveness of our approach with a variety of metrics by submitting runs
to the TREC Incident Streams (IS) track: a research initiative specifically
designed for disaster tweet classification and prioritisation. The results
demonstrate that our approach achieves competitive performance in most metrics
as compared to other participating runs. Subsequently, we find that an ensemble
approach combining disparate transformer encoders within our approach helps to
improve the overall effectiveness to a significant extent, achieving
state-of-the-art performance in almost every metric. We make the code publicly
available so that our work can be reproduced and used as a baseline for the
community for future work in this domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Modeling Proficiency with Implicit User Representations. (arXiv:2110.08011v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08011">
<div class="article-summary-box-inner">
<span><p>We introduce the problem of proficiency modeling: Given a user's posts on a
social media platform, the task is to identify the subset of posts or topics
for which the user has some level of proficiency. This enables the filtering
and ranking of social media posts on a given topic as per user proficiency.
Unlike experts on a given topic, proficient users may not have received formal
training and possess years of practical experience, but may be autodidacts,
hobbyists, and people with sustained interest, enabling them to make genuine
and original contributions to discourse. While predicting whether a user is an
expert on a given topic imposes strong constraints on who is a true positive,
proficiency modeling implies a graded scoring, relaxing these constraints. Put
another way, many active social media users can be assumed to possess, or
eventually acquire, some level of proficiency on topics relevant to their
community. We tackle proficiency modeling in an unsupervised manner by
utilizing user embeddings to model engagement with a given topic, as indicated
by a user's preference for authoring related content. We investigate five
alternative approaches to model proficiency, ranging from basic ones to an
advanced, tailored user modeling approach, applied within two real-world
benchmarks for evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Crisis Domain Adaptation Using Sequence-to-sequence Transformers. (arXiv:2110.08015v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08015">
<div class="article-summary-box-inner">
<span><p>User-generated content (UGC) on social media can act as a key source of
information for emergency responders in crisis situations. However, due to the
volume concerned, computational techniques are needed to effectively filter and
prioritise this content as it arises during emerging events. In the literature,
these techniques are trained using annotated content from previous crises. In
this paper, we investigate how this prior knowledge can be best leveraged for
new crises by examining the extent to which crisis events of a similar type are
more suitable for adaptation to new events (cross-domain adaptation). Given the
recent successes of transformers in various language processing tasks, we
propose CAST: an approach for Crisis domain Adaptation leveraging
Sequence-to-sequence Transformers. We evaluate CAST using two major
crisis-related message classification datasets. Our experiments show that our
CAST-based best run without using any target data achieves the state of the art
performance in both in-domain and cross-domain contexts. Moreover, CAST is
particularly effective in one-to-one cross-domain adaptation when trained with
a larger language model. In many-to-one adaptation where multiple crises are
jointly used as the source domain, CAST further improves its performance. In
addition, we find that more similar events are more likely to bring better
adaptation performance whereas fine-tuning using dissimilar events does not
help for adaptation. To aid reproducibility, we open source our code to the
community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Structural Modeling for Dialogue Disentanglement. (arXiv:2110.08018v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08018">
<div class="article-summary-box-inner">
<span><p>Tangled multi-party dialogue context leads to challenges for dialogue reading
comprehension, where multiple dialogue threads flow simultaneously within the
same dialogue history, thus increasing difficulties in understanding a dialogue
history for both human and machine. Dialogue disentanglement aims to clarify
conversation threads in a multi-party dialogue history, thus reducing the
difficulty of comprehending the long disordered dialogue passage. Existing
studies commonly focus on utterance encoding with carefully designed feature
engineering-based methods but pay inadequate attention to dialogue structure.
This work designs a novel model to disentangle multi-party history into
threads, by taking dialogue structure features into account. Specifically,
based on the fact that dialogues are constructed through successive
participation of speakers and interactions between users of interest, we
extract clues of speaker property and reference of users to model the structure
of a long dialogue record. The novel method is evaluated on the Ubuntu IRC
dataset and shows state-of-the-art experimental results in dialogue
disentanglement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Emotion-Cause Pair Extraction in Conversations. (arXiv:2110.08020v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08020">
<div class="article-summary-box-inner">
<span><p>Emotion cause analysis has received considerable attention in recent years.
Previous studies primarily focused on emotion cause extraction from texts in
news articles or microblogs. It is also interesting to discover emotions and
their causes in conversations. As conversation in its natural form is
multimodal, a large number of studies have been carried out on multimodal
emotion recognition in conversations, but there is still a lack of work on
multimodal emotion cause analysis. In this work, we introduce a new task named
Multimodal Emotion-Cause Pair Extraction in Conversations, aiming to jointly
extract emotions and their associated causes from conversations reflected in
multiple modalities (text, audio and video). We accordingly construct a
multimodal conversational emotion cause dataset, Emotion-Cause-in-Friends,
which contains 9,272 multimodal emotion-cause pairs annotated on 13,509
utterances in the sitcom Friends. We finally benchmark the task by establishing
a baseline system that incorporates multimodal features for emotion-cause pair
extraction. Preliminary experimental results demonstrate the potential of
multimodal information fusion for discovering both emotions and causes in
conversations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">StreaMulT: Streaming Multimodal Transformer for Heterogeneous and Arbitrary Long Sequential Data. (arXiv:2110.08021v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08021">
<div class="article-summary-box-inner">
<span><p>This paper tackles the problem of processing and combining efficiently
arbitrary long data streams, coming from different modalities with different
acquisition frequencies. Common applications can be, for instance, long-time
industrial or real-life systems monitoring from multimodal heterogeneous data
(sensor data, monitoring report, images, etc.). To tackle this problem, we
propose StreaMulT, a Streaming Multimodal Transformer, relying on cross-modal
attention and an augmented memory bank to process arbitrary long input
sequences at training time and run in a streaming way at inference. StreaMulT
reproduces state-of-the-art results on CMU-MOSEI dataset, while being able to
deal with much longer inputs than other models such as previous Multimodal
Transformer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UniDS: A Unified Dialogue System for Chit-Chat and Task-oriented Dialogues. (arXiv:2110.08032v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08032">
<div class="article-summary-box-inner">
<span><p>With the advances in deep learning, tremendous progress has been made with
chit-chat dialogue systems and task-oriented dialogue systems. However, these
two systems are often tackled separately in current methods. To achieve more
natural interaction with humans, a dialogue agent needs to be capable of both
chatting and accomplishing tasks. To this end, we propose a unified dialogue
system (UniDS) with the two aforementioned skills. In particular, we design a
unified dialogue data schema, compatible for both chit-chat and task-oriented
dialogues, and we train UniDS with mixed dialogue data from a pretrained
chit-chat dialogue model. Without adding extra parameters to SOTA baselines,
UniDS can alternatively handle chit-chat and task-oriented dialogues in a
unified framework. Experimental results demonstrate that the proposed UniDS
works comparably well as the pure chit-chat system, and it outperforms
state-of-the-art task-oriented dialogue systems. More importantly, UniDS
achieves better robustness as it is able to smoothly switch between two types
of dialogues. These results demonstrate the feasibility and potential of
building an one-for-all dialogue system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Natural Language Adversarial Examples through An Improved Beam Search Algorithm. (arXiv:2110.08036v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08036">
<div class="article-summary-box-inner">
<span><p>The research of adversarial attacks in the text domain attracts many
interests in the last few years, and many methods with a high attack success
rate have been proposed. However, these attack methods are inefficient as they
require lots of queries for the victim model when crafting text adversarial
examples. In this paper, a novel attack model is proposed, its attack success
rate surpasses the benchmark attack methods, but more importantly, its attack
efficiency is much higher than the benchmark attack methods. The novel method
is empirically evaluated by attacking WordCNN, LSTM, BiLSTM, and BERT on four
benchmark datasets. For instance, it achieves a 100\% attack success rate
higher than the state-of-the-art method when attacking BERT and BiLSTM on IMDB,
but the number of queries for the victim models only is 1/4 and 1/6.5 of the
state-of-the-art method, respectively. Also, further experiments show the novel
method has a good transferability on the generated adversarial examples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Semantics: An Opportunity for Effective 6G Communications. (arXiv:2110.08049v1 [cs.IT])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08049">
<div class="article-summary-box-inner">
<span><p>Recently, semantic communications are envisioned as a key enabler of future
6G networks. Back to Shannon's information theory, the goal of communication
has long been to guarantee the correct reception of transmitted messages
irrespective of their meaning. However, in general, whenever communication
occurs to convey a meaning, what matters is the receiver's understanding of the
transmitted message and not necessarily its correct reconstruction. Hence,
semantic communications introduce a new paradigm: transmitting only relevant
information sufficient for the receiver to capture the meaning intended can
save significant communication bandwidth. Thus, this work explores the
opportunity offered by semantic communications for beyond 5G networks. In
particular, we focus on the benefit of semantic compression. We refer to
semantic message as a sequence of well-formed symbols learned from the
"meaning" underlying data, which have to be interpreted at the receiver. This
requires a reasoning unit, here artificial, on a knowledge base: a symbolic
knowledge representation of the specific application. Therefore, we present and
detail a novel architecture that enables representation learning of semantic
symbols for effective semantic communications. We first discuss theoretical
aspects and successfully design objective functions, which help learn effective
semantic encoders and decoders. Eventually, we show promising numerical results
for the scenario of text transmission, especially when the sender and receiver
speak different languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Jurassic is (almost) All You Need: Few-Shot Meaning-to-Text Generation for Open-Domain Dialogue. (arXiv:2110.08094v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08094">
<div class="article-summary-box-inner">
<span><p>One challenge with open-domain dialogue systems is the need to produce
high-quality responses on any topic. We aim to improve the quality and coverage
of Athena, an Alexa Prize dialogue system. We utilize Athena's response
generators (RGs) to create training data for two new neural Meaning-to-Text
RGs, Athena-GPT-Neo and Athena-Jurassic, for the movies, music, TV, sports, and
video game domains. We conduct few-shot experiments, both within and
cross-domain, with different tuning set sizes (2, 3, 10), prompt formats, and
meaning representations (MRs) for sets of WikiData KG triples, and dialogue
acts with 14 possible attribute combinations. Our evaluation uses BLEURT and
human evaluation metrics, and shows that with 10-shot tuning, Athena-Jurassic's
performance is significantly better for coherence and semantic accuracy.
Experiments with 2-shot tuning on completely novel MRs results in a huge
performance drop for Athena-GPT-Neo, whose semantic accuracy falls to 0.41, and
whose untrue hallucination rate increases to 12%. Experiments with dialogue
acts for video games show that with 10-shot tuning, both models learn to
control dialogue acts, but Athena-Jurassic has significantly higher coherence,
and only 4% untrue hallucinations. Our results suggest that Athena-Jurassic can
reliably produce outputs of high-quality for live systems with real users. To
our knowledge, these are the first results demonstrating that few-shot tuning
on a massive language model can create NLGs that generalize to new domains, and
produce high-quality, semantically-controlled, conversational responses
directly from MRs and KG triples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Bot: Prompt-Based Learning for Dialogue Systems. (arXiv:2110.08118v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08118">
<div class="article-summary-box-inner">
<span><p>Learning to converse using only a few examples is a great challenge in
conversational AI. The current best conversational models, which are either
good chit-chatters (e.g., BlenderBot) or goal-oriented systems (e.g., MinTL),
are language models (LMs) fine-tuned on large conversational datasets. Training
these models is expensive, both in terms of computational resources and time,
and it is hard to keep them up to date with new conversational skills. A simple
yet unexplored solution is prompt-based few-shot learning (Brown et al. 2020)
which does not require gradient-based fine-tuning but instead uses a few
examples in the LM context as the only source of learning. In this paper, we
explore prompt-based few-shot learning in dialogue tasks. We benchmark LMs of
different sizes in nine response generation tasks, which include four
knowledge-grounded tasks, a task-oriented generations task, three open-chat
tasks, and controlled stylistic generation, and five conversational parsing
tasks, which include dialogue state tracking, graph path generation, persona
information extraction, document retrieval, and internet query generation. The
current largest released LM (GPT-J-6B) using prompt-based few-shot learning,
and thus requiring no training, achieves competitive performance to fully
trained state-of-the-art models. Moreover, we propose a novel prompt-based
few-shot classifier, that also does not require any fine-tuning, to select the
most appropriate prompt given a dialogue history. Finally, by combining the
power of prompt-based few-shot learning and a Skill Selector, we create an
end-to-end chatbot named the Few-Shot Bot (FSB), which automatically selects
the most appropriate conversational skill, queries different knowledge bases or
the internet, and uses the retrieved knowledge to generate a human-like
response, all using only few dialogue examples per skill.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Breaking Down Multilingual Machine Translation. (arXiv:2110.08130v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08130">
<div class="article-summary-box-inner">
<span><p>While multilingual training is now an essential ingredient in machine
translation (MT) systems, recent work has demonstrated that it has different
effects in different multilingual settings, such as many-to-one, one-to-many,
and many-to-many learning. These training settings expose the encoder and the
decoder in a machine translation model with different data distributions. In
this paper, we examine how different varieties of multilingual training
contribute to learning these two components of the MT model. Specifically, we
compare bilingual models with encoders and/or decoders initialized by
multilingual training. We show that multilingual training is beneficial to
encoders in general, while it only benefits decoders for low-resource languages
(LRLs). We further find the important attention heads for each language pair
and compare their correlations during inference. Our analysis sheds light on
how multilingual translation models work and also enables us to propose methods
to improve performance by training with highly related languages. Our
many-to-one models for high-resource languages and one-to-many models for LRL
outperform the best results reported by Aharoni et al. (2019).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Integrating diverse extraction pathways using iterative predictions for Multilingual Open Information Extraction. (arXiv:2110.08144v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08144">
<div class="article-summary-box-inner">
<span><p>In this paper we investigate a simple hypothesis for the Open Information
Extraction (OpenIE) task, that it may be easier to extract some elements of an
triple if the extraction is conditioned on prior extractions which may be
easier to extract. We successfully exploit this and propose a neural
multilingual OpenIE system that iteratively extracts triples by conditioning
extractions on different elements of the triple leading to a rich set of
extractions. The iterative nature of MiLIE also allows for seamlessly
integrating rule based extraction systems with a neural end-to-end system
leading to improved performance. MiLIE outperforms SOTA systems on multiple
languages ranging from Chinese to Galician thanks to it's ability of combining
multiple extraction pathways. Our analysis confirms that it is indeed true that
certain elements of an extraction are easier to extract than others. Finally,
we introduce OpenIE evaluation datasets for two low resource languages namely
Japanese and Galician.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models. (arXiv:2110.08151v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08151">
<div class="article-summary-box-inner">
<span><p>Recent studies have shown that multilingual pretrained language models can be
effectively improved with cross-lingual alignment information from Wikipedia
entities. However, existing methods only exploit entity information in
pretraining and do not explicitly use entities in downstream tasks. In this
study, we explore the effectiveness of leveraging entity representations for
downstream cross-lingual tasks. We train a multilingual language model with 24
languages with entity representations and show the model consistently
outperforms word-based pretrained models in various cross-lingual transfer
tasks. We also analyze the model and the key insight is that incorporating
entity representations into the input allows us to extract more
language-agnostic features. We also evaluate the model with a multilingual
cloze prompt task with the mLAMA dataset. We show that entity-based prompt
elicits correct factual knowledge more likely than using only word
representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Kronecker Decomposition for GPT Compression. (arXiv:2110.08152v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08152">
<div class="article-summary-box-inner">
<span><p>GPT is an auto-regressive Transformer-based pre-trained language model which
has attracted a lot of attention in the natural language processing (NLP)
domain due to its state-of-the-art performance in several downstream tasks. The
success of GPT is mostly attributed to its pre-training on huge amount of data
and its large number of parameters (from ~100M to billions of parameters).
Despite the superior performance of GPT (especially in few-shot or zero-shot
setup), this overparameterized nature of GPT can be very prohibitive for
deploying this model on devices with limited computational power or memory.
This problem can be mitigated using model compression techniques; however,
compressing GPT models has not been investigated much in the literature. In
this work, we use Kronecker decomposition to compress the linear mappings of
the GPT-22 model. Our Kronecker GPT-2 model (KnGPT2) is initialized based on
the Kronecker decomposed version of the GPT-2 model and then is undergone a
very light pre-training on only a small portion of the training data with
intermediate layer knowledge distillation (ILKD). Finally, our KnGPT2 is
fine-tuned on down-stream tasks using ILKD as well. We evaluate our model on
both language modeling and General Language Understanding Evaluation benchmark
tasks and show that with more efficient pre-training and similar number of
parameters, our KnGPT2 outperforms the existing DistilGPT2 model significantly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DYLE: Dynamic Latent Extraction for Abstractive Long-Input Summarization. (arXiv:2110.08168v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08168">
<div class="article-summary-box-inner">
<span><p>Transformer-based models have achieved state-of-the-art performance on short
text summarization. However, they still struggle with long-input summarization.
In this paper, we present a new approach for long-input summarization: Dynamic
Latent Extraction for Abstractive Summarization. We jointly train an extractor
with an abstractor and treat the extracted text snippets as the latent
variable. We propose extractive oracles to provide the extractor with a strong
learning signal. We introduce consistency loss, which encourages the extractor
to approximate the averaged dynamic weights predicted by the generator. We
conduct extensive tests on two long-input summarization datasets, GovReport
(document) and QMSum (dialogue). Our model significantly outperforms the
current state-of-the-art, including a 6.21 ROUGE-2 improvement on GovReport and
a 2.13 ROUGE-1 improvement on QMSum. Further analysis shows that the dynamic
weights make our generation process highly interpretable. Our code will be
publicly available upon publication.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rewire-then-Probe: A Contrastive Recipe for Probing Biomedical Knowledge of Pre-trained Language Models. (arXiv:2110.08173v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08173">
<div class="article-summary-box-inner">
<span><p>Knowledge probing is crucial for understanding the knowledge transfer
mechanism behind the pre-trained language models (PLMs). Despite the growing
progress of probing knowledge for PLMs in the general domain, specialised areas
such as biomedical domain are vastly under-explored. To catalyse the research
in this direction, we release a well-curated biomedical knowledge probing
benchmark, MedLAMA, which is constructed based on the Unified Medical Language
System (UMLS) Metathesaurus. We test a wide spectrum of state-of-the-art PLMs
and probing approaches on our benchmark, reaching at most 3% of acc@10. While
highlighting various sources of domain-specific challenges that amount to this
underwhelming performance, we illustrate that the underlying PLMs have a higher
potential for probing tasks. To achieve this, we propose Contrastive-Probe, a
novel self-supervised contrastive probing approach, that adjusts the underlying
PLMs without using any probing data. While Contrastive-Probe pushes the acc@10
to 28%, the performance gap still remains notable. Our human expert evaluation
suggests that the probing performance of our Contrastive-Probe is still
under-estimated as UMLS still does not include the full spectrum of factual
knowledge. We hope MedLAMA and Contrastive-Probe facilitate further
developments of more suited probing techniques for this domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MixQG: Neural Question Generation with Mixed Answer Types. (arXiv:2110.08175v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08175">
<div class="article-summary-box-inner">
<span><p>Asking good questions is an essential ability for both human and machine
intelligence. However, existing neural question generation approaches mainly
focus on the short factoid type of answers. In this paper, we propose a neural
question generator, MixQG, to bridge this gap. We combine 9 question answering
datasets with diverse answer types, including yes/no, multiple-choice,
extractive, and abstractive answers, to train a single generative model. We
show with empirical results that our model outperforms existing work in both
seen and unseen domains and can generate questions with different cognitive
levels when conditioned on different answer types. Our code is released and
well-integrated with the Huggingface library to facilitate various downstream
applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The World of an Octopus: How Reporting Bias Influences a Language Model's Perception of Color. (arXiv:2110.08182v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08182">
<div class="article-summary-box-inner">
<span><p>Recent work has raised concerns about the inherent limitations of text-only
pretraining. In this paper, we first demonstrate that reporting bias, the
tendency of people to not state the obvious, is one of the causes of this
limitation, and then investigate to what extent multimodal training can
mitigate this issue. To accomplish this, we 1) generate the Color Dataset
(CoDa), a dataset of human-perceived color distributions for 521 common
objects; 2) use CoDa to analyze and compare the color distribution found in
text, the distribution captured by language models, and a human's perception of
color; and 3) investigate the performance differences between text-only and
multimodal models on CoDa. Our results show that the distribution of colors
that a language model recovers correlates more strongly with the inaccurate
distribution found in text than with the ground-truth, supporting the claim
that reporting bias negatively impacts and inherently limits text-only
training. We then demonstrate that multimodal models can leverage their visual
training to mitigate these effects, providing a promising avenue for future
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse Progressive Distillation: Resolving Overfitting under Pretrain-and-Finetune Paradigm. (arXiv:2110.08190v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08190">
<div class="article-summary-box-inner">
<span><p>Various pruning approaches have been proposed to reduce the footprint
requirements of Transformer-based language models. Conventional wisdom is that
pruning reduces the model expressiveness and thus is more likely to underfit
than overfit compared to the original model. However, under the trending
pretrain-and-finetune paradigm, we argue that pruning increases the risk of
overfitting if pruning was performed at the fine-tuning phase, as it increases
the amount of information a model needs to learn from the downstream task,
resulting in relative data deficiency. In this paper, we aim to address the
overfitting issue under the pretrain-and-finetune paradigm to improve pruning
performance via progressive knowledge distillation (KD) and sparse pruning.
Furthermore, to mitigate the interference between different strategies of
learning rate, pruning and distillation, we propose a three-stage learning
framework. We show for the first time that reducing the risk of overfitting can
help the effectiveness of pruning under the pretrain-and-finetune paradigm.
Experiments on multiple datasets of GLUE benchmark show that our method
achieves highly competitive pruning performance over the state-of-the-art
competitors across different pruning ratio constraints.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Why don't people use character-level machine translation?. (arXiv:2110.08191v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08191">
<div class="article-summary-box-inner">
<span><p>We present a literature and empirical survey that critically assesses the
state of the art in character-level modeling for machine translation (MT).
Despite evidence in the literature that character-level systems are comparable
with subword systems, they are virtually never used in competitive setups in
WMT competitions. We empirically show that even with recent modeling
innovations in character-level natural language processing, character-level MT
systems still struggle to match their subword-based counterparts both in terms
of translation quality and training and inference speed. Character-level MT
systems show neither better domain robustness, nor better morphological
generalization, despite being often so motivated. On the other hand, they tend
to be more robust towards source side noise and the translation quality does
not degrade with increasing beam size at decoding time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BBQ: A Hand-Built Bias Benchmark for Question Answering. (arXiv:2110.08193v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08193">
<div class="article-summary-box-inner">
<span><p>It is well documented that NLP models learn social biases present in the
world, but little work has been done to show how these biases manifest in
actual model outputs for applied tasks like question answering (QA). We
introduce the Bias Benchmark for QA (BBQ), a dataset consisting of
question-sets constructed by the authors that highlight \textit{attested}
social biases against people belonging to protected classes along nine
different social dimensions relevant for U.S. English-speaking contexts. Our
task evaluates model responses at two distinct levels: (i) given an
under-informative context, test how strongly model answers reflect social
biases, and (ii) given an adequately informative context, test whether the
model's biases still override a correct answer choice. We find that models
strongly rely on stereotypes when the context is ambiguous, meaning that the
model's outputs consistently reproduce harmful biases in this setting. Though
models are much more accurate when the context provides an unambiguous answer,
they still rely on stereotyped information and achieve an accuracy 2.5
percentage points higher on examples where the correct answer aligns with a
social bias, with this accuracy difference widening to 5 points for examples
targeting gender.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multitask Prompted Training Enables Zero-Shot Task Generalization. (arXiv:2110.08207v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08207">
<div class="article-summary-box-inner">
<span><p>Large language models have recently been shown to attain reasonable zero-shot
generalization on a diverse set of tasks. It has been hypothesized that this is
a consequence of implicit multitask learning in language model training. Can
zero-shot generalization instead be directly induced by explicit multitask
learning? To test this question at scale, we develop a system for easily
mapping general natural language tasks into a human-readable prompted form. We
convert a large set of supervised datasets, each with multiple prompts using
varying natural language. These prompted datasets allow for benchmarking the
ability of a model to perform completely unseen tasks specified in natural
language. We fine-tune a pretrained encoder-decoder model on this multitask
mixture covering a wide variety of tasks. The model attains strong zero-shot
performance on several standard datasets, often outperforming models 16x its
size. Further, our approach attains strong performance on a subset of tasks
from the BIG-Bench benchmark, outperforming models 6x its size. All prompts and
trained models are available at github.com/bigscience-workshop/promptsource/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Identity Preserving Normal to Dysarthric Voice Conversion. (arXiv:2110.08213v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08213">
<div class="article-summary-box-inner">
<span><p>We present a voice conversion framework that converts normal speech into
dysarthric speech while preserving the speaker identity. Such a framework is
essential for (1) clinical decision making processes and alleviation of patient
stress, (2) data augmentation for dysarthric speech recognition. This is an
especially challenging task since the converted samples should capture the
severity of dysarthric speech while being highly natural and possessing the
speaker identity of the normal speaker. To this end, we adopted a two-stage
framework, which consists of a sequence-to-sequence model and a nonparallel
frame-wise model. Objective and subjective evaluations were conducted on the
UASpeech dataset, and results showed that the method was able to yield
reasonable naturalness and capture severity aspects of the pathological speech.
On the other hand, the similarity to the normal source speaker's voice was
limited and requires further improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Incremental Speech Synthesis For Speech-To-Speech Translation. (arXiv:2110.08214v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08214">
<div class="article-summary-box-inner">
<span><p>In a speech-to-speech translation (S2ST) pipeline, the text-to-speech (TTS)
module is an important component for delivering the translated speech to users.
To enable incremental S2ST, the TTS module must be capable of synthesizing and
playing utterances while its input text is still streaming in. In this work, we
focus on improving the incremental synthesis performance of TTS models. With a
simple data augmentation strategy based on prefixes, we are able to improve the
incremental TTS quality to approach offline performance. Furthermore, we bring
our incremental TTS system to the practical scenario in combination with an
upstream simultaneous speech translation system, and show the gains also carry
over to this use-case. In addition, we propose latency metrics tailored to S2ST
applications, and investigate methods for latency reduction in this context.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DialFact: A Benchmark for Fact-Checking in Dialogue. (arXiv:2110.08222v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08222">
<div class="article-summary-box-inner">
<span><p>Fact-checking is an essential tool to mitigate the spread of misinformation
and disinformation, however, it has been often explored to verify formal
single-sentence claims instead of casual conversational claims. To study the
problem, we introduce the task of fact-checking in dialogue. We construct
DialFact, a testing benchmark dataset of 22,245 annotated conversational
claims, paired with pieces of evidence from Wikipedia. There are three
sub-tasks in DialFact: 1) Verifiable claim detection task distinguishes whether
a response carries verifiable factual information; 2) Evidence retrieval task
retrieves the most relevant Wikipedia snippets as evidence; 3) Claim
verification task predicts a dialogue response to be supported, refuted, or not
enough information. We found that existing fact-checking models trained on
non-dialogue data like FEVER fail to perform well on our task, and thus, we
propose a simple yet data-efficient solution to effectively improve
fact-checking performance in dialogue. We point out unique challenges in
DialFact such as handling the colloquialisms, coreferences, and retrieval
ambiguities in the error analysis to shed light on future research in this
direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Guiding Visual Question Generation. (arXiv:2110.08226v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08226">
<div class="article-summary-box-inner">
<span><p>In traditional Visual Question Generation (VQG), most images have multiple
concepts (e.g. objects and categories) for which a question could be generated,
but models are trained to mimic an arbitrary choice of concept as given in
their training data. This makes training difficult and also poses issues for
evaluation -- multiple valid questions exist for most images but only one or a
few are captured by the human references. We present Guiding Visual Question
Generation - a variant of VQG which conditions the question generator on
categorical information based on expectations on the type of question and the
objects it should explore. We propose two variants: (i) an explicitly guided
model that enables an actor (human or automated) to select which objects and
categories to generate a question for; and (ii) an implicitly guided model that
learns which objects and categories to condition on, based on discrete latent
variables. The proposed models are evaluated on an answer-category augmented
VQA dataset and our quantitative results show a substantial improvement over
the current state of the art (over 9 BLEU-4 increase). Human evaluation
validates that guidance helps the generation of questions that are
grammatically coherent and relevant to the given image and objects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Domain Data Integration for Named Entity Disambiguation in Biomedical Text. (arXiv:2110.08228v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08228">
<div class="article-summary-box-inner">
<span><p>Named entity disambiguation (NED), which involves mapping textual mentions to
structured entities, is particularly challenging in the medical domain due to
the presence of rare entities. Existing approaches are limited by the presence
of coarse-grained structural resources in biomedical knowledge bases as well as
the use of training datasets that provide low coverage over uncommon resources.
In this work, we address these issues by proposing a cross-domain data
integration method that transfers structural knowledge from a general text
knowledge base to the medical domain. We utilize our integration scheme to
augment structural resources and generate a large biomedical NED dataset for
pretraining. Our pretrained model with injected structural knowledge achieves
state-of-the-art performance on two benchmark medical NED datasets: MedMentions
and BC5CDR. Furthermore, we improve disambiguation of rare entities by up to 57
accuracy points.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Intent-based Product Collections for E-commerce using Pretrained Language Models. (arXiv:2110.08241v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08241">
<div class="article-summary-box-inner">
<span><p>Building a shopping product collection has been primarily a human job. With
the manual efforts of craftsmanship, experts collect related but diverse
products with common shopping intent that are effective when displayed
together, e.g., backpacks, laptop bags, and messenger bags for freshman bag
gifts. Automatically constructing a collection requires an ML system to learn a
complex relationship between the customer's intent and the product's
attributes. However, there have been challenging points, such as 1) long and
complicated intent sentences, 2) rich and diverse product attributes, and 3) a
huge semantic gap between them, making the problem difficult. In this paper, we
use a pretrained language model (PLM) that leverages textual attributes of
web-scale products to make intent-based product collections. Specifically, we
train a BERT with triplet loss by setting an intent sentence to an anchor and
corresponding products to positive examples. Also, we improve the performance
of the model by search-based negative sampling and category-wise positive pair
augmentation. Our model significantly outperforms the search-based baseline
model for intent-based product matching in offline evaluations. Furthermore,
online experimental results on our e-commerce platform show that the PLM-based
method can construct collections of products with increased CTR, CVR, and
order-diversity compared to expert-crafted collections.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Dubber: Dubbing for Silent Videos According to Scripts. (arXiv:2110.08243v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08243">
<div class="article-summary-box-inner">
<span><p>Dubbing is a post-production process of re-recording actors' dialogues, which
is extensively used in filmmaking and video production. It is usually performed
manually by professional voice actors who read lines with proper prosody, and
in synchronization with the pre-recorded videos. In this work, we propose
Neural Dubber, the first neural network model to solve a novel automatic video
dubbing (AVD) task: synthesizing human speech synchronized with the given
silent video from the text. Neural Dubber is a multi-modal text-to-speech (TTS)
model that utilizes the lip movement in the video to control the prosody of the
generated speech. Furthermore, an image-based speaker embedding (ISE) module is
developed for the multi-speaker setting, which enables Neural Dubber to
generate speech with a reasonable timbre according to the speaker's face.
Experiments on the chemistry lecture single-speaker dataset and LRS2
multi-speaker dataset show that Neural Dubber can generate speech audios on par
with state-of-the-art TTS models in terms of speech quality. Most importantly,
both qualitative and quantitative evaluations show that Neural Dubber can
control the prosody of synthesized speech by the video, and generate
high-fidelity speech temporally synchronized with the video.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tricks for Training Sparse Translation Models. (arXiv:2110.08246v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08246">
<div class="article-summary-box-inner">
<span><p>Multi-task learning with an unbalanced data distribution skews model learning
towards high resource tasks, especially when model capacity is fixed and fully
shared across all tasks. Sparse scaling architectures, such as BASELayers,
provide flexible mechanisms for different tasks to have a variable number of
parameters, which can be useful to counterbalance skewed data distributions. We
find that that sparse architectures for multilingual machine translation can
perform poorly out of the box, and propose two straightforward techniques to
mitigate this - a temperature heating mechanism and dense pre-training.
Overall, these methods improve performance on two multilingual translation
benchmarks compared to standard BASELayers and Dense scaling baselines, and in
combination, more than 2x model convergence speed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks. (arXiv:2110.08247v1 [cs.CR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08247">
<div class="article-summary-box-inner">
<span><p>Backdoor attacks are a kind of emergent security threat in deep learning.
When a deep neural model is injected with a backdoor, it will behave normally
on standard inputs but give adversary-specified predictions once the input
contains specific backdoor triggers. Current textual backdoor attacks have poor
attack performance in some tough situations. In this paper, we find two simple
tricks that can make existing textual backdoor attacks much more harmful. The
first trick is to add an extra training task to distinguish poisoned and clean
data during the training of the victim model, and the second one is to use all
the clean training data rather than remove the original clean data
corresponding to the poisoned data. These two tricks are universally applicable
to different attack models. We conduct experiments in three tough situations
including clean data fine-tuning, low poisoning rate, and label-consistent
attacks. Experimental results show that the two tricks can significantly
improve attack performance. This paper exhibits the great potential harmfulness
of backdoor attacks. All the code and data will be made public to facilitate
further research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Direct simultaneous speech to speech translation. (arXiv:2110.08250v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08250">
<div class="article-summary-box-inner">
<span><p>We present the first direct simultaneous speech-to-speech translation
(Simul-S2ST) model, with the ability to start generating translation in the
target speech before consuming the full source speech content and independently
from intermediate text representations. Our approach leverages recent progress
on direct speech-to-speech translation with discrete units. Instead of
continuous spectrogram features, a sequence of direct representations, which
are learned in a unsupervised manner, are predicted from the model and passed
directly to a vocoder for speech synthesis. The simultaneous policy then
operates on source speech features and target discrete units. Finally, a
vocoder synthesize the target speech from discrete units on-the-fly. We carry
out numerical studies to compare cascaded and direct approach on Fisher
Spanish-English dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Order-Free Tag Relations for Context-Aware Recommendation. (arXiv:2012.02957v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02957">
<div class="article-summary-box-inner">
<span><p>Tag recommendation relies on either a ranking function for top-$k$ tags or an
autoregressive generation method. However, the previous methods neglect one of
two seemingly conflicting yet desirable characteristics of a tag set:
orderlessness and inter-dependency. While the ranking approach fails to address
the inter-dependency among tags when they are ranked, the autoregressive
approach fails to take orderlessness into account because it is designed to
utilize sequential relations among tokens. We propose a sequence-oblivious
generation method for tag recommendation, in which the next tag to be generated
is independent of the order of the generated tags and the order of the ground
truth tags occurring in training data. Empirical results on two different
domains, Instagram and Stack Overflow, show that our method is significantly
superior to the previous approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trankit: A Light-Weight Transformer-based Toolkit for Multilingual Natural Language Processing. (arXiv:2101.03289v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03289">
<div class="article-summary-box-inner">
<span><p>We introduce Trankit, a light-weight Transformer-based Toolkit for
multilingual Natural Language Processing (NLP). It provides a trainable
pipeline for fundamental NLP tasks over 100 languages, and 90 pretrained
pipelines for 56 languages. Built on a state-of-the-art pretrained language
model, Trankit significantly outperforms prior multilingual NLP pipelines over
sentence segmentation, part-of-speech tagging, morphological feature tagging,
and dependency parsing while maintaining competitive performance for
tokenization, multi-word token expansion, and lemmatization over 90 Universal
Dependencies treebanks. Despite the use of a large pretrained transformer, our
toolkit is still efficient in memory usage and speed. This is achieved by our
novel plug-and-play mechanism with Adapters where a multilingual pretrained
transformer is shared across pipelines for different languages. Our toolkit
along with pretrained models and code are publicly available at:
https://github.com/nlp-uoregon/trankit. A demo website for our toolkit is also
available at: <a href="http://nlp.uoregon.edu/trankit.">this http URL</a> Finally, we create a demo video
for Trankit at: https://youtu.be/q0KGP3zGjGc.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ultra-High Dimensional Sparse Representations with Binarization for Efficient Text Retrieval. (arXiv:2104.07198v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07198">
<div class="article-summary-box-inner">
<span><p>The semantic matching capabilities of neural information retrieval can
ameliorate synonymy and polysemy problems of symbolic approaches. However,
neural models' dense representations are more suitable for re-ranking, due to
their inefficiency. Sparse representations, either in symbolic or latent form,
are more efficient with an inverted index. Taking the merits of the sparse and
dense representations, we propose an ultra-high dimensional (UHD)
representation scheme equipped with directly controllable sparsity. UHD's large
capacity and minimal noise and interference among the dimensions allow for
binarized representations, which are highly efficient for storage and search.
Also proposed is a bucketing method, where the embeddings from multiple layers
of BERT are selected/merged to represent diverse linguistic aspects. We test
our models with MS MARCO and TREC CAR, showing that our models outperforms
other sparse models
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DWUG: A large Resource of Diachronic Word Usage Graphs in Four Languages. (arXiv:2104.08540v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08540">
<div class="article-summary-box-inner">
<span><p>Word meaning is notoriously difficult to capture, both synchronically and
diachronically. In this paper, we describe the creation of the largest resource
of graded contextualized, diachronic word meaning annotation in four different
languages, based on 100,000 human semantic proximity judgments. We thoroughly
describe the multi-round incremental annotation process, the choice for a
clustering algorithm to group usages into senses, and possible - diachronic and
synchronic - uses for this dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Low-Rank Subspaces for Unsupervised Entity Linking. (arXiv:2104.08737v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08737">
<div class="article-summary-box-inner">
<span><p>Entity linking is an important problem with many applications. Most previous
solutions were designed for settings where annotated training data is
available, which is, however, not the case in numerous domains. We propose a
light-weight and scalable entity linking method, Eigenthemes, that relies
solely on the availability of entity names and a referent knowledge base.
Eigenthemes exploits the fact that the entities that are truly mentioned in a
document (the "gold entities") tend to form a semantically dense subset of the
set of all candidate entities in the document. Geometrically speaking, when
representing entities as vectors via some given embedding, the gold entities
tend to lie in a low-rank subspace of the full embedding space. Eigenthemes
identifies this subspace using the singular value decomposition and scores
candidate entities according to their proximity to the subspace. On the
empirical front, we introduce multiple strong baselines that compare favorably
to (and sometimes even outperform) the existing state of the art. Extensive
experiments on benchmark datasets from a variety of real-world domains showcase
the effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GraphTMT: Unsupervised Graph-based Topic Modeling from Video Transcripts. (arXiv:2105.01466v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01466">
<div class="article-summary-box-inner">
<span><p>To unfold the tremendous amount of multimedia data uploaded daily to social
media platforms, effective topic modeling techniques are needed. Existing work
tends to apply topic models on written text datasets. In this paper, we propose
a topic extractor on video transcripts. Exploiting neural word embeddings
through graph-based clustering, we aim to improve usability and semantic
coherence. Unlike most topic models, this approach works without knowing the
true number of topics, which is important when no such assumption can or should
be made. Experimental results on the real-life multimodal dataset MuSe-CaR
demonstrates that our approach GraphTMT extracts coherent and meaningful topics
and outperforms baseline methods. Furthermore, we successfully demonstrate the
applicability of our approach on the popular Citysearch corpus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpretable agent communication from scratch (with a generic visual processor emerging on the side). (arXiv:2106.04258v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04258">
<div class="article-summary-box-inner">
<span><p>As deep networks begin to be deployed as autonomous agents, the issue of how
they can communicate with each other becomes important. Here, we train two deep
nets from scratch to perform realistic referent identification through
unsupervised emergent communication. We show that the largely interpretable
emergent protocol allows the nets to successfully communicate even about object
types they did not see at training time. The visual representations induced as
a by-product of our training regime, moreover, show comparable quality, when
re-used as generic visual features, to a recent self-supervised learning model.
Our results provide concrete evidence of the viability of (interpretable)
emergent deep net communication in a more realistic scenario than previously
considered, as well as establishing an intriguing link between this field and
self-supervised visual learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Constraining Linear-chain CRFs to Regular Languages. (arXiv:2106.07306v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07306">
<div class="article-summary-box-inner">
<span><p>A major challenge in structured prediction is to represent the
interdependencies within output structures. When outputs are structured as
sequences, linear-chain conditional random fields (CRFs) are a widely used
model class which can learn \textit{local} dependencies in the output. However,
the CRF's Markov assumption makes it impossible for CRFs to represent
distributions with \textit{nonlocal} dependencies, and standard CRFs are unable
to respect nonlocal constraints of the data (such as global arity constraints
on output labels). We present a generalization of CRFs that can enforce a broad
class of constraints, including nonlocal ones, by specifying the space of
possible output structures as a regular language $\mathcal{L}$. The resulting
regular-constrained CRF (RegCCRF) has the same formal properties as a standard
CRF, but assigns zero probability to all label sequences not in $\mathcal{L}$.
Notably, RegCCRFs can incorporate their constraints during training, while
related models only enforce constraints during decoding. We prove that
constrained training is never worse than constrained decoding, and show
empirically that it can be substantially better in practice. Additionally, we
demonstrate a practical benefit on downstream tasks by incorporating a RegCCRF
into a deep neural model for semantic role labeling, exceeding state-of-the-art
results on a standard dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SemEval-2021 Task 11: NLPContributionGraph -- Structuring Scholarly NLP Contributions for a Research Knowledge Graph. (arXiv:2106.07385v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07385">
<div class="article-summary-box-inner">
<span><p>There is currently a gap between the natural language expression of scholarly
publications and their structured semantic content modeling to enable
intelligent content search. With the volume of research growing exponentially
every year, a search feature operating over semantically structured content is
compelling. The SemEval-2021 Shared Task NLPContributionGraph (a.k.a. 'the NCG
task') tasks participants to develop automated systems that structure
contributions from NLP scholarly articles in the English language. Being the
first-of-its-kind in the SemEval series, the task released structured data from
NLP scholarly articles at three levels of information granularity, i.e. at
sentence-level, phrase-level, and phrases organized as triples toward Knowledge
Graph (KG) building. The sentence-level annotations comprised the few sentences
about the article's contribution. The phrase-level annotations were scientific
term and predicate phrases from the contribution sentences. Finally, the
triples constituted the research overview KG. For the Shared Task,
participating systems were then expected to automatically classify contribution
sentences, extract scientific terms and relations from the sentences, and
organize them as KG triples.
</p>
<p>Overall, the task drew a strong participation demographic of seven teams and
27 participants. The best end-to-end task system classified contribution
sentences at 57.27% F1, phrases at 46.41% F1, and triples at 22.28% F1. While
the absolute performance to generate triples remains low, in the conclusion of
this article, the difficulty of producing such data and as a consequence of
modeling it is highlighted.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emotion analysis and detection during COVID-19. (arXiv:2107.11020v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11020">
<div class="article-summary-box-inner">
<span><p>Crises such as natural disasters, global pandemics, and social unrest
continuously threaten our world and emotionally affect millions of people
worldwide in distinct ways. Understanding emotions that people express during
large-scale crises helps inform policy makers and first responders about the
emotional states of the population as well as provide emotional support to
those who need such support. We present CovidEmo, ~3K English tweets labeled
with emotions and temporally distributed across 18 months. Our analyses reveal
the emotional toll caused by COVID-19, and changes of the social narrative and
associated emotions over time. Motivated by the time-sensitive nature of crises
and the cost of large-scale annotation efforts, we examine how well large
pre-trained language models generalize across domains and timeline in the task
of perceived emotion prediction in the context of COVID-19. Our analyses
suggest that cross-domain information transfers occur, yet there are still
significant gaps. We propose semi-supervised learning as a way to bridge this
gap, obtaining significantly better performance using unlabeled data from the
target domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Argumentative Dialogue System for COVID-19 Vaccine Information. (arXiv:2107.12079v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12079">
<div class="article-summary-box-inner">
<span><p>Dialogue systems are widely used in AI to support timely and interactive
communication with users. We propose a general-purpose dialogue system
architecture that leverages computational argumentation to perform reasoning
and provide consistent and explainable answers. We illustrate the system using
a COVID-19 vaccine information case study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Affective Decoding for Empathetic Response Generation. (arXiv:2108.08102v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08102">
<div class="article-summary-box-inner">
<span><p>Understanding speaker's feelings and producing appropriate responses with
emotion connection is a key communicative skill for empathetic dialogue
systems. In this paper, we propose a simple technique called Affective Decoding
for empathetic response generation. Our method can effectively incorporate
emotion signals during each decoding step, and can additionally be augmented
with an auxiliary dual emotion encoder, which learns separate embeddings for
the speaker and listener given the emotion base of the dialogue. Extensive
empirical studies show that our models are perceived to be more empathetic by
human evaluations, in comparison to several strong mainstream methods for
empathetic responding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Morality-based Assertion and Homophily on Social Media: A Cultural Comparison between English and Japanese Languages. (arXiv:2108.10643v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10643">
<div class="article-summary-box-inner">
<span><p>Moral psychology is a domain that deals with moral identity, appraisals and
emotions. Previous work has primarily focused on moral development and the
associated role of culture. Knowing that language is an inherent element of a
culture, we used the social media platform Twitter to compare moral behaviors
of Japanese tweets with English tweets. The five basic moral foundations, i.e.,
Care, Fairness, Ingroup, Authority and Purity, along with the associated
emotional valence were compared between English and Japanese tweets. The tweets
from Japanese users depicted relatively higher Fairness, Ingroup, and Purity,
whereas English tweets expressed more positive emotions for all moral
dimensions. Considering moral similarities in connecting users on social media,
we quantified homophily concerning different moral dimensions using our
proposed method. The moral dimensions Care, Authority and Purity for English
and Ingroup, Authority and Purity for Japanese depicted homophily on Twitter.
Overall, our study uncovers the underlying cultural differences with respect to
moral behavior in English- and Japanese-speaking users.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AutoTriggER: Named Entity Recognition with Auxiliary Trigger Extraction. (arXiv:2109.04726v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04726">
<div class="article-summary-box-inner">
<span><p>Deep neural models for low-resource named entity recognition (NER) have shown
impressive results by leveraging distant super-vision or other meta-level
information (e.g. explanation). However, the costs of acquiring such additional
information are generally prohibitive, especially in domains where existing
resources (e.g. databases to be used for distant supervision) may not exist. In
this paper, we present a novel two-stage framework (AutoTriggER) to improve NER
performance by automatically generating and leveraging "entity triggers" which
are essentially human-readable clues in the text that can help guide the model
to make better decisions. Thus, the framework is able to both create and
leverage auxiliary supervision by itself. Through experiments on three
well-studied NER datasets, we show that our automatically extracted triggers
are well-matched to human triggers, and AutoTriggER improves performance over a
RoBERTa-CRFarchitecture by nearly 0.5 F1 points on average and much more in a
low resource setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Evaluating Biomedical BERT Models for Vocabulary Alignment at Scale in the UMLS Metathesaurus. (arXiv:2109.13348v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.13348">
<div class="article-summary-box-inner">
<span><p>The current UMLS (Unified Medical Language System) Metathesaurus construction
process for integrating over 200 biomedical source vocabularies is expensive
and error-prone as it relies on the lexical algorithms and human editors for
deciding if the two biomedical terms are synonymous. Recent advances in Natural
Language Processing such as Transformer models like BERT and its biomedical
variants with contextualized word embeddings have achieved state-of-the-art
(SOTA) performance on downstream tasks. We aim to validate if these approaches
using the BERT models can actually outperform the existing approaches for
predicting synonymy in the UMLS Metathesaurus. In the existing Siamese Networks
with LSTM and BioWordVec embeddings, we replace the BioWordVec embeddings with
the biomedical BERT embeddings extracted from each BERT model using different
ways of extraction. In the Transformer architecture, we evaluate the use of the
different biomedical BERT models that have been pre-trained using different
datasets and tasks. Given the SOTA performance of these BERT models for other
downstream tasks, our experiments yield surprisingly interesting results: (1)
in both model architectures, the approaches employing these biomedical
BERT-based models do not outperform the existing approaches using Siamese
Network with BioWordVec embeddings for the UMLS synonymy prediction task, (2)
the original BioBERT large model that has not been pre-trained with the UMLS
outperforms the SapBERT models that have been pre-trained with the UMLS, and
(3) using the Siamese Networks yields better performance for synonymy
prediction when compared to using the biomedical BERT models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TEACh: Task-driven Embodied Agents that Chat. (arXiv:2110.00534v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00534">
<div class="article-summary-box-inner">
<span><p>Robots operating in human spaces must be able to engage in natural language
interaction with people, both understanding and executing instructions, and
using conversation to resolve ambiguity and recover from mistakes. To study
this, we introduce TEACh, a dataset of over 3,000 human--human, interactive
dialogues to complete household tasks in simulation. A Commander with access to
oracle information about a task communicates in natural language with a
Follower. The Follower navigates through and interacts with the environment to
complete tasks varying in complexity from "Make Coffee" to "Prepare Breakfast",
asking questions and getting additional information from the Commander. We
propose three benchmarks using TEACh to study embodied intelligence challenges,
and we evaluate initial models' abilities in dialogue understanding, language
grounding, and task execution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speech Technology for Everyone: Automatic Speech Recognition for Non-Native English with Transfer Learning. (arXiv:2110.00678v3 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00678">
<div class="article-summary-box-inner">
<span><p>To address the performance gap of English ASR models on L2 English speakers,
we evaluate fine-tuning of pretrained wav2vec 2.0 models (Baevski et al., 2020;
Xu et al., 2021) on L2-ARCTIC, a non-native English speech corpus (Zhao et al.,
2018) under different training settings. We compare \textbf{(a)} models trained
with a combination of diverse accents to ones trained with only specific
accents and \textbf{(b)} results from different single-accent models. Our
experiments demonstrate the promise of developing ASR models for non-native
English speakers, even with small amounts of L2 training data and even without
a language model. Our models also excel in the zero-shot setting where we train
on multiple L2 datasets and test on a blind L2 test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MoEfication: Conditional Computation of Transformer Models for Efficient Inference. (arXiv:2110.01786v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01786">
<div class="article-summary-box-inner">
<span><p>Transformer-based pre-trained language models can achieve superior
performance on most NLP tasks due to large parameter capacity, but also lead to
huge computation cost. Fortunately, we observe that most inputs only activate a
tiny ratio of neurons of large Transformer-based models during inference.
Hence, we propose to transform a large model into its mixture-of-experts (MoE)
version with equal model size, namely MoEfication, which could accelerate
large-model inference by conditional computation based on the sparse activation
phenomenon. MoEfication consists of two steps: (1) splitting the parameters of
feed-forward neural networks (FFNs) into multiple parts as experts, and (2)
building expert routers to decide which experts will be used for each input.
Experimental results show that the MoEfied models can significantly reduce
computation cost, e.g., only activating 20% FFN parameters of a
700-million-parameter model without performance degradation on several
downstream tasks including text classification and machine reading
comprehension.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Internal Language Model Adaptation with Text-Only Data for End-to-End Speech Recognition. (arXiv:2110.05354v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.05354">
<div class="article-summary-box-inner">
<span><p>Text-only adaptation of an end-to-end (E2E) model remains a challenging task
for automatic speech recognition (ASR). Language model (LM) fusion-based
approaches require an additional external LM during inference, significantly
increasing the computation cost. To overcome this, we propose an internal LM
adaptation (ILMA) of the E2E model using text-only data. Trained with
audio-transcript pairs, an E2E model implicitly learns an internal LM that
characterizes the token sequence probability which is approximated by the E2E
model output after zeroing out the encoder contribution. During ILMA, we
fine-tune the internal LM, i.e., the E2E components excluding the encoder, to
minimize a cross-entropy loss. To make ILMA effective, it is essential to train
the E2E model with an internal LM loss besides the standard E2E loss.
Furthermore, we propose to regularize ILMA by minimizing the Kullback-Leibler
divergence between the output distributions of the adapted and unadapted
internal LMs. ILMA is the most effective when we update only the last linear
layer of the joint network. ILMA enables a fast text-only adaptation of the E2E
model without increasing the run-time computational cost. Experimented with
30K-hour trained transformer transducer models, ILMA achieves up to 34.9%
relative word error rate reduction from the unadapted baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Brief Introduction to Automatic Differentiation for Machine Learning. (arXiv:2110.06209v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06209">
<div class="article-summary-box-inner">
<span><p>Machine learning and neural network models in particular have been improving
the state of the art performance on many artificial intelligence related tasks.
Neural network models are typically implemented using frameworks that perform
gradient based optimization methods to fit a model to a dataset. These
frameworks use a technique of calculating derivatives called automatic
differentiation (AD) which removes the burden of performing derivative
calculations from the model designer. In this report we describe AD, its
motivations, and different implementation approaches. We briefly describe
dataflow programming as it relates to AD. Lastly, we present example programs
that are implemented with Tensorflow and PyTorch, which are two commonly used
AD frameworks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tell Me How to Survey: Literature Review Made Simple with Automatic Reading Path Generation. (arXiv:2110.06354v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06354">
<div class="article-summary-box-inner">
<span><p>Recent years have witnessed the dramatic growth of paper volumes with plenty
of new research papers published every day, especially in the area of computer
science. How to glean papers worth reading from the massive literature to do a
quick survey or keep up with the latest advancement about a specific research
topic has become a challenging task. Existing academic search engines such as
Google Scholar return relevant papers by individually calculating the relevance
between each paper and query. However, such systems usually omit the
prerequisite chains of a research topic and cannot form a meaningful reading
path. In this paper, we introduce a new task named Reading Path Generation
(RPG) which aims at automatically producing a path of papers to read for a
given query. To serve as a research benchmark, we further propose SurveyBank, a
dataset consisting of large quantities of survey papers in the field of
computer science as well as their citation relationships. Each survey paper
contains key phrases extracted from its title and multi-level reading lists
inferred from its references. Furthermore, we propose a
graph-optimization-based approach for reading path generation which takes the
relationship between papers into account. Extensive evaluations demonstrate
that our approach outperforms other baselines. A Real-time Reading Path
Generation System (RePaGer) has been also implemented with our designed model.
To the best of our knowledge, we are the first to target this important
research problem. Our source code of RePaGer system and SurveyBank dataset can
be found on here.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-lingual COVID-19 Fake News Detection. (arXiv:2110.06495v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06495">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic poses a great threat to global public health.
Meanwhile, there is massive misinformation associated with the pandemic which
advocates unfounded or unscientific claims. Even major social media and news
outlets have made an extra effort in debunking COVID-19 misinformation, most of
the fact-checking information is in English, whereas some unmoderated COVID-19
misinformation is still circulating in other languages, threatening the health
of less-informed people in immigrant communities and developing countries. In
this paper, we make the first attempt to detect COVID-19 misinformation in a
low-resource language (Chinese) only using the fact-checked news in a
high-resource language (English). We start by curating a Chinese real&amp;fake news
dataset according to existing fact-checking information. Then, we propose a
deep learning framework named CrossFake to jointly encode the cross-lingual
news body texts and capture the news content as much as possible. Empirical
results on our dataset demonstrate the effectiveness of CrossFake under the
cross-lingual setting and it also outperforms several monolingual and
cross-lingual fake news detectors. The dataset is available at
https://github.com/YingtongDou/CrossFake.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Well-classified Examples are Underestimated in Classification with Deep Neural Networks. (arXiv:2110.06537v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06537">
<div class="article-summary-box-inner">
<span><p>The conventional wisdom behind learning deep classification models is to
focus on bad-classified examples and ignore well-classified examples that are
far from the decision boundary. For instance, when training with cross-entropy
loss, examples with higher likelihoods (i.e., well-classified examples)
contribute smaller gradients in back-propagation. However, we theoretically
show that this common practice hinders representation learning, energy
optimization, and the growth of margin. To counteract this deficiency, we
propose to reward well-classified examples with additive bonuses to revive
their contribution to learning. This counterexample theoretically addresses
these three issues. We empirically support this claim by directly verify the
theoretical results or through the significant performance improvement with our
counterexample on diverse tasks, including image classification, graph
classification, and machine translation. Furthermore, this paper shows that
because our idea can solve these three issues, we can deal with complex
scenarios, such as imbalanced classification, OOD detection, and applications
under adversarial attacks. Code is available at:
https://github.com/lancopku/well-classified-examples-are-underestimated.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Speaker-aware Parallel Hierarchical Attentive Encoder-Decoder Model for Multi-turn Dialogue Generation. (arXiv:2110.06823v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06823">
<div class="article-summary-box-inner">
<span><p>This paper presents a novel open-domain dialogue generation model emphasizing
the differentiation of speakers in multi-turn conversations. Differing from
prior work that solely relies on the content of conversation history to
generate a response, we argue that capturing relative social relations among
utterances (i.e., generated by either the same speaker or different persons)
benefits the machine capturing fine-grained context information from a
conversation history to improve context coherence in the generated response.
Given that, we propose a speaker-aware Parallel Hierarchical Attentive
Encoder-Decoder (PHAED) model that aims to model each utterance with the
awareness of its speaker and contextual associations with the same speaker's
previous messages. Specifically, in a conversation involving two speakers, we
regard the utterances from one speaker as responses and those from the other as
queries. After understanding queries via our encoder with inner-query and
inter-query encodings, our decoder reuses the hidden states of previously
generated responses, instead of reconstructing these by the encoder, to
generate a new response. Our empirical results show that PHAED outperforms the
state-of-the-art in both automatic and human evaluations. Furthermore, our
ablation study shows that dialogue models with speaker tokens can generally
decrease the possibility of generating non-coherent responses regarding the
conversation context.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Core Challenges in Embodied Vision-Language Planning. (arXiv:2106.13948v2 [cs.LG] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13948">
<div class="article-summary-box-inner">
<span><p>Recent advances in the areas of multimodal machine learning and artificial
intelligence (AI) have led to the development of challenging tasks at the
intersection of Computer Vision, Natural Language Processing, and Embodied AI.
Whereas many approaches and previous survey pursuits have characterised one or
two of these dimensions, there has not been a holistic analysis at the center
of all three. Moreover, even when combinations of these topics are considered,
more focus is placed on describing, e.g., current architectural methods, as
opposed to also illustrating high-level challenges and opportunities for the
field. In this survey paper, we discuss Embodied Vision-Language Planning
(EVLP) tasks, a family of prominent embodied navigation and manipulation
problems that jointly use computer vision and natural language. We propose a
taxonomy to unify these tasks and provide an in-depth analysis and comparison
of the new and current algorithmic approaches, metrics, simulated environments,
as well as the datasets used for EVLP tasks. Finally, we present the core
challenges that we believe new EVLP works should seek to address, and we
advocate for task construction that enables model generalizability and furthers
real-world deployment.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">HumBugDB: A Large-scale Acoustic Mosquito Dataset. (arXiv:2110.07607v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07607">
<div class="article-summary-box-inner">
<span><p>This paper presents the first large-scale multi-species dataset of acoustic
recordings of mosquitoes tracked continuously in free flight. We present 20
hours of audio recordings that we have expertly labelled and tagged precisely
in time. Significantly, 18 hours of recordings contain annotations from 36
different species. Mosquitoes are well-known carriers of diseases such as
malaria, dengue and yellow fever. Collecting this dataset is motivated by the
need to assist applications which utilise mosquito acoustics to conduct surveys
to help predict outbreaks and inform intervention policy. The task of detecting
mosquitoes from the sound of their wingbeats is challenging due to the
difficulty in collecting recordings from realistic scenarios. To address this,
as part of the HumBug project, we conducted global experiments to record
mosquitoes ranging from those bred in culture cages to mosquitoes captured in
the wild. Consequently, the audio recordings vary in signal-to-noise ratio and
contain a broad range of indoor and outdoor background environments from
Tanzania, Thailand, Kenya, the USA and the UK. In this paper we describe in
detail how we collected, labelled and curated the data. The data is provided
from a PostgreSQL database, which contains important metadata such as the
capture method, age, feeding status and gender of the mosquitoes. Additionally,
we provide code to extract features and train Bayesian convolutional neural
networks for two key tasks: the identification of mosquitoes from their
corresponding background environments, and the classification of detected
mosquitoes into species. Our extensive dataset is both challenging to machine
learning researchers focusing on acoustic identification, and critical to
entomologists, geo-spatial modellers and other domain experts to understand
mosquito behaviour, model their distribution, and manage the threat they pose
to humans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D Structure from 2D Microscopy images using Deep Learning. (arXiv:2110.07608v1 [q-bio.QM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07608">
<div class="article-summary-box-inner">
<span><p>Understanding the structure of a protein complex is crucial indetermining its
function. However, retrieving accurate 3D structures from microscopy images is
highly challenging, particularly as many imaging modalities are
two-dimensional. Recent advances in Artificial Intelligence have been applied
to this problem, primarily using voxel based approaches to analyse sets of
electron microscopy images. Herewe present a deep learning solution for
reconstructing the protein com-plexes from a number of 2D single molecule
localization microscopy images, with the solution being completely
unconstrained. Our convolutional neural network coupled with a differentiable
renderer predicts pose and derives a single structure. After training, the
network is dis-carded, with the output of this method being a structural model
which fits the data-set. We demonstrate the performance of our system on two
protein complexes: CEP152 (which comprises part of the proximal toroid of the
centriole) and centrioles.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-contact Atrial Fibrillation Detection from Face Videos by Learning Systolic Peaks. (arXiv:2110.07610v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07610">
<div class="article-summary-box-inner">
<span><p>Objective: We propose a non-contact approach for atrial fibrillation (AF)
detection from face videos. Methods: Face videos, electrocardiography (ECG),
and contact photoplethysmography (PPG) from 100 healthy subjects and 100 AF
patients are recorded. All the videos in the healthy group are labeled as
healthy. Videos in the patient group are labeled as AF, sinus rhythm (SR), or
atrial flutter (AFL) by cardiologists. We use the 3D convolutional neural
network for remote PPG measurement and propose a novel loss function
(Wasserstein distance) to use the timing of systolic peaks from contact PPG as
the label for our model training. Then a set of heart rate variability (HRV)
features are calculated from the inter-beat intervals, and a support vector
machine (SVM) classifier is trained with HRV features. Results: Our proposed
method can accurately extract systolic peaks from face videos for AF detection.
The proposed method is trained with subject-independent 10-fold
cross-validation with 30s video clips and tested on two tasks. 1)
Classification of healthy versus AF: the accuracy, sensitivity, and specificity
are 96.16%, 95.71%, and 96.23%. 2) Classification of SR versus AF: the
accuracy, sensitivity, and specificity are 95.31%, 98.66%, and 91.11%.
Conclusion: We achieve good performance of non-contact AF detection by learning
systolic peaks. Significance: non-contact AF detection can be used for
self-screening of AF symptom for suspectable populations at home, or
self-monitoring of AF recurrence after treatment for the chronical patients.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Non-deep Networks. (arXiv:2110.07641v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07641">
<div class="article-summary-box-inner">
<span><p>Depth is the hallmark of deep neural networks. But more depth means more
sequential computation and higher latency. This begs the question -- is it
possible to build high-performing "non-deep" neural networks? We show that it
is. To do so, we use parallel subnetworks instead of stacking one layer after
another. This helps effectively reduce depth while maintaining high
performance. By utilizing parallel substructures, we show, for the first time,
that a network with a depth of just 12 can achieve top-1 accuracy over 80% on
ImageNet, 96% on CIFAR10, and 81% on CIFAR100. We also show that a network with
a low-depth (12) backbone can achieve an AP of 48% on MS-COCO. We analyze the
scaling rules for our design and show how to increase performance without
changing the network's depth. Finally, we provide a proof of concept for how
non-deep networks could be used to build low-latency recognition systems. Code
is available at https://github.com/imankgoyal/NonDeepNetworks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Talking Detection In Collaborative Learning Environments. (arXiv:2110.07646v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07646">
<div class="article-summary-box-inner">
<span><p>We study the problem of detecting talking activities in collaborative
learning videos. Our approach uses head detection and projections of the
log-magnitude of optical flow vectors to reduce the problem to a simple
classification of small projection images without the need for training
complex, 3-D activity classification systems. The small projection images are
then easily classified using a simple majority vote of standard classifiers.
For talking detection, our proposed approach is shown to significantly
outperform single activity systems. We have an overall accuracy of 59% compared
to 42% for Temporal Segment Network (TSN) and 45% for Convolutional 3D (C3D).
In addition, our method is able to detect multiple talking instances from
multiple speakers, while also detecting the speakers themselves.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interactive Analysis of CNN Robustness. (arXiv:2110.07667v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07667">
<div class="article-summary-box-inner">
<span><p>While convolutional neural networks (CNNs) have found wide adoption as
state-of-the-art models for image-related tasks, their predictions are often
highly sensitive to small input perturbations, which the human vision is robust
against. This paper presents Perturber, a web-based application that allows
users to instantaneously explore how CNN activations and predictions evolve
when a 3D input scene is interactively perturbed. Perturber offers a large
variety of scene modifications, such as camera controls, lighting and shading
effects, background modifications, object morphing, as well as adversarial
attacks, to facilitate the discovery of potential vulnerabilities. Fine-tuned
model versions can be directly compared for qualitative evaluation of their
robustness. Case studies with machine learning experts have shown that
Perturber helps users to quickly generate hypotheses about model
vulnerabilities and to qualitatively compare model behavior. Using quantitative
analyses, we could replicate users' insights with other CNN architectures and
input images, yielding new insights about the vulnerability of adversarially
trained models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Augmenting Imitation Experience via Equivariant Representations. (arXiv:2110.07668v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07668">
<div class="article-summary-box-inner">
<span><p>The robustness of visual navigation policies trained through imitation often
hinges on the augmentation of the training image-action pairs. Traditionally,
this has been done by collecting data from multiple cameras, by using standard
data augmentations from computer vision, such as adding random noise to each
image, or by synthesizing training images. In this paper we show that there is
another practical alternative for data augmentation for visual navigation based
on extrapolating viewpoint embeddings and actions nearby the ones observed in
the training data. Our method makes use of the geometry of the visual
navigation problem in 2D and 3D and relies on policies that are functions of
equivariant embeddings, as opposed to images. Given an image-action pair from a
training navigation dataset, our neural network model predicts the latent
representations of images at nearby viewpoints, using the equivariance
property, and augments the dataset. We then train a policy on the augmented
dataset. Our simulation results indicate that policies trained in this way
exhibit reduced cross-track error, and require fewer interventions compared to
policies trained using standard augmentation methods. We also show similar
results in autonomous visual navigation by a real ground robot along a path of
over 500m.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Appearance Editing with Free-viewpoint Neural Rendering. (arXiv:2110.07674v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07674">
<div class="article-summary-box-inner">
<span><p>We present a neural rendering framework for simultaneous view synthesis and
appearance editing of a scene from multi-view images captured under known
environment illumination. Existing approaches either achieve view synthesis
alone or view synthesis along with relighting, without direct control over the
scene's appearance. Our approach explicitly disentangles the appearance and
learns a lighting representation that is independent of it. Specifically, we
independently estimate the BRDF and use it to learn a lighting-only
representation of the scene. Such disentanglement allows our approach to
generalize to arbitrary changes in appearance while performing view synthesis.
We show results of editing the appearance of a real scene, demonstrating that
our approach produces plausible appearance editing. The performance of our view
synthesis approach is demonstrated to be at par with state-of-the-art
approaches on both real and synthetic data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shaping embodied agent behavior with activity-context priors from egocentric video. (arXiv:2110.07692v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07692">
<div class="article-summary-box-inner">
<span><p>Complex physical tasks entail a sequence of object interactions, each with
its own preconditions -- which can be difficult for robotic agents to learn
efficiently solely through their own experience. We introduce an approach to
discover activity-context priors from in-the-wild egocentric video captured
with human worn cameras. For a given object, an activity-context prior
represents the set of other compatible objects that are required for activities
to succeed (e.g., a knife and cutting board brought together with a tomato are
conducive to cutting). We encode our video-based prior as an auxiliary reward
function that encourages an agent to bring compatible objects together before
attempting an interaction. In this way, our model translates everyday human
experience into embodied agent skills. We demonstrate our idea using egocentric
EPIC-Kitchens video of people performing unscripted kitchen activities to
benefit virtual household robotic agents performing various complex tasks in
AI2-iTHOR, significantly accelerating agent learning. Project page:
<a href="http://vision.cs.utexas.edu/projects/ego-rewards/">this http URL</a>
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ASK: Adaptively Selecting Key Local Features for RGB-D Scene Recognition. (arXiv:2110.07703v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07703">
<div class="article-summary-box-inner">
<span><p>Indoor scene images usually contain scattered objects and various scene
layouts, which make RGB-D scene classification a challenging task. Existing
methods still have limitations for classifying scene images with great spatial
variability. Thus, how to extract local patch-level features effectively using
only image labels is still an open problem for RGB-D scene recognition. In this
paper, we propose an efficient framework for RGB-D scene recognition, which
adaptively selects important local features to capture the great spatial
variability of scene images. Specifically, we design a differentiable local
feature selection (DLFS) module, which can extract the appropriate number of
key local scenerelated features. Discriminative local theme-level and
object-level representations can be selected with the DLFS module from the
spatially-correlated multi-modal RGB-D features. We take advantage of the
correlation between RGB and depth modalities to provide more cues for selecting
local features. To ensure that discriminative local features are selected, the
variational mutual information maximization loss is proposed. Additionally, the
DLFS module can be easily extended to select local features of different
scales. By concatenating the local-orderless and global structured multi-modal
features, the proposed framework can achieve state-of-the-art performance on
public RGB-D scene recognition datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gray Matter Segmentation in Ultra High Resolution 7 Tesla ex vivo T2w MRI of Human Brain Hemispheres. (arXiv:2110.07711v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07711">
<div class="article-summary-box-inner">
<span><p>Ex vivo MRI of the brain provides remarkable advantages over in vivo MRI for
visualizing and characterizing detailed neuroanatomy. However, automated
cortical segmentation methods in ex vivo MRI are not well developed, primarily
due to limited availability of labeled datasets, and heterogeneity in scanner
hardware and acquisition protocols. In this work, we present a high resolution
7 Tesla dataset of 32 ex vivo human brain specimens. We benchmark the cortical
mantle segmentation performance of nine neural network architectures, trained
and evaluated using manually-segmented 3D patches sampled from specific
cortical regions, and show excellent generalizing capabilities across whole
brain hemispheres in different specimens, and also on unseen images acquired at
different magnetic field strength and imaging sequences. Finally, we provide
cortical thickness measurements across key regions in 3D ex vivo human brain
images. Our code and processed datasets are publicly available at
https://github.com/Pulkit-Khandelwal/picsl-ex-vivo-segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Scene Reconstruction and Object Detection System for Assisting Autonomous Vehicle. (arXiv:2110.07716v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07716">
<div class="article-summary-box-inner">
<span><p>In the current computer vision era classifying scenes through video
surveillance systems is a crucial task. Artificial Intelligence (AI) Video
Surveillance technologies have been advanced remarkably while artificial
intelligence and deep learning ascended into the system. Adopting the superior
compounds of deep learning visual classification methods achieved enormous
accuracy in classifying visual scenes. However, the visual classifiers face
difficulties examining the scenes in dark visible areas, especially during the
nighttime. Also, the classifiers face difficulties in identifying the contexts
of the scenes. This paper proposed a deep learning model that reconstructs dark
visual scenes to clear scenes like daylight, and the method recognizes visual
actions for the autonomous vehicle. The proposed model achieved 87.3 percent
accuracy for scene reconstruction and 89.2 percent in scene understanding and
detection tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Human-guided Conditional Variational Generative Modeling for Automated Urban Planning. (arXiv:2110.07717v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07717">
<div class="article-summary-box-inner">
<span><p>Urban planning designs land-use configurations and can benefit building
livable, sustainable, safe communities. Inspired by image generation, deep
urban planning aims to leverage deep learning to generate land-use
configurations. However, urban planning is a complex process. Existing studies
usually ignore the need of personalized human guidance in planning, and spatial
hierarchical structure in planning generation. Moreover, the lack of
large-scale land-use configuration samples poses a data sparsity challenge.
This paper studies a novel deep human guided urban planning method to jointly
solve the above challenges. Specifically, we formulate the problem into a deep
conditional variational autoencoder based framework. In this framework, we
exploit the deep encoder-decoder design to generate land-use configurations. To
capture the spatial hierarchy structure of land uses, we enforce the decoder to
generate both the coarse-grained layer of functional zones, and the
fine-grained layer of POI distributions. To integrate human guidance, we allow
humans to describe what they need as texts and use these texts as a model
condition input. To mitigate training data sparsity and improve model
robustness, we introduce a variational Gaussian embedding mechanism. It not
just allows us to better approximate the embedding space distribution of
training data and sample a larger population to overcome sparsity, but also
adds more probabilistic randomness into the urban planning generation to
improve embedding diversity so as to improve robustness. Finally, we present
extensive experiments to validate the enhanced performances of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Attack across Datasets. (arXiv:2110.07718v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07718">
<div class="article-summary-box-inner">
<span><p>It has been observed that Deep Neural Networks (DNNs) are vulnerable to
transfer attacks in the query-free black-box setting. However, all the previous
studies on transfer attack assume that the white-box surrogate models possessed
by the attacker and the black-box victim models are trained on the same
dataset, which means the attacker implicitly knows the label set and the input
size of the victim model. However, this assumption is usually unrealistic as
the attacker may not know the dataset used by the victim model, and further,
the attacker needs to attack any randomly encountered images that may not come
from the same dataset. Therefore, in this paper we define a new Generalized
Transferable Attack (GTA) problem where we assume the attacker has a set of
surrogate models trained on different datasets (with different label sets and
image sizes), and none of them is equal to the dataset used by the victim
model. We then propose a novel method called Image Classification Eraser (ICE)
to erase classification information for any encountered images from arbitrary
dataset. Extensive experiments on Cifar-10, Cifar-100, and TieredImageNet
demonstrate the effectiveness of the proposed ICE on the GTA problem.
Furthermore, we show that existing transfer attack methods can be modified to
tackle the GTA problem, but with significantly worse performance compared with
ICE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Certified Patch Robustness via Smoothed Vision Transformers. (arXiv:2110.07719v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07719">
<div class="article-summary-box-inner">
<span><p>Certified patch defenses can guarantee robustness of an image classifier to
arbitrary changes within a bounded contiguous region. But, currently, this
robustness comes at a cost of degraded standard accuracies and slower inference
times. We demonstrate how using vision transformers enables significantly
better certified patch robustness that is also more computationally efficient
and does not incur a substantial drop in standard accuracy. These improvements
stem from the inherent ability of the vision transformer to gracefully handle
largely masked images. Our code is available at
https://github.com/MadryLab/smoothed-vit.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Decomposing Convolutional Neural Networks into Reusable and Replaceable Modules. (arXiv:2110.07720v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07720">
<div class="article-summary-box-inner">
<span><p>Training from scratch is the most common way to build a Convolutional Neural
Network (CNN) based model. What if we can build new CNN models by reusing parts
from previously build CNN models? What if we can improve a CNN model by
replacing (possibly faulty) parts with other parts? In both cases, instead of
training, can we identify the part responsible for each output class (module)
in the model(s) and reuse or replace only the desired output classes to build a
model? Prior work has proposed decomposing dense-based networks into modules
(one for each output class) to enable reusability and replaceability in various
scenarios. However, this work is limited to the dense layers and based on the
one-to-one relationship between the nodes in consecutive layers. Due to the
shared architecture in the CNN model, prior work cannot be adapted directly. In
this paper, we propose to decompose a CNN model used for image classification
problems into modules for each output class. These modules can further be
reused or replaced to build a new model. We have evaluated our approach with
CIFAR-10, CIFAR-100, and ImageNet tiny datasets with three variations of ResNet
models and found that enabling decomposition comes with a small cost (2.38% and
0.81% for top-1 and top-5 accuracy, respectively). Also, building a model by
reusing or replacing modules can be done with a 2.3% and 0.5% average loss of
accuracy. Furthermore, reusing and replacing these modules reduces CO2e
emission by ~37 times compared to training the model from scratch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EMDS-7: Environmental Microorganism Image Dataset Seventh Version for Multiple Object Detection Evaluation. (arXiv:2110.07723v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07723">
<div class="article-summary-box-inner">
<span><p>The Environmental Microorganism Image Dataset Seventh Version (EMDS-7) is a
microscopic image data set, including the original Environmental Microorganism
images (EMs) and the corresponding object labeling files in ".XML" format file.
The EMDS-7 data set consists of 41 types of EMs, which has a total of 2365
images and 13216 labeled objects. The EMDS-7 database mainly focuses on the
object detection. In order to prove the effectiveness of EMDS-7, we select the
most commonly used deep learning methods (Faster-RCNN, YOLOv3, YOLOv4, SSD and
RetinaNet) and evaluation indices for testing and evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multifocal Stereoscopic Projection Mapping. (arXiv:2110.07726v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07726">
<div class="article-summary-box-inner">
<span><p>Stereoscopic projection mapping (PM) allows a user to see a three-dimensional
(3D) computer-generated (CG) object floating over physical surfaces of
arbitrary shapes around us using projected imagery. However, the current
stereoscopic PM technology only satisfies binocular cues and is not capable of
providing correct focus cues, which causes a vergence--accommodation conflict
(VAC). Therefore, we propose a multifocal approach to mitigate VAC in
stereoscopic PM. Our primary technical contribution is to attach electrically
focus-tunable lenses (ETLs) to active shutter glasses to control both vergence
and accommodation. Specifically, we apply fast and periodical focal sweeps to
the ETLs, which causes the "virtual image'" (as an optical term) of a scene
observed through the ETLs to move back and forth during each sweep period. A 3D
CG object is projected from a synchronized high-speed projector only when the
virtual image of the projected imagery is located at a desired distance. This
provides an observer with the correct focus cues required. In this study, we
solve three technical issues that are unique to stereoscopic PM: (1) The 3D CG
object is displayed on non-planar and even moving surfaces; (2) the physical
surfaces need to be shown without the focus modulation; (3) the shutter glasses
additionally need to be synchronized with the ETLs and the projector. We also
develop a novel compensation technique to deal with the "lens breathing"
artifact that varies the retinal size of the virtual image through focal length
modulation. Further, using a proof-of-concept prototype, we demonstrate that
our technique can present the virtual image of a target 3D CG object at the
correct depth. Finally, we validate the advantage provided by our technique by
comparing it with conventional stereoscopic PM using a user study on a
depth-matching task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Learning of Neural Collision Handler for Complex 3D Mesh Deformations. (arXiv:2110.07727v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07727">
<div class="article-summary-box-inner">
<span><p>We present a robust learning algorithm to detect and handle collisions in 3D
deforming meshes. Our collision detector is represented as a bilevel deep
autoencoder with an attention mechanism that identifies colliding mesh
sub-parts. We use a numerical optimization algorithm to resolve penetrations
guided by the network. Our learned collision handler can resolve collisions for
unseen, high-dimensional meshes with thousands of vertices. To obtain stable
network performance in such large and unseen spaces, we progressively insert
new collision data based on the errors in network inferences. We automatically
label these data using an analytical collision detector and progressively
fine-tune our detection networks. We evaluate our method for collision handling
of complex, 3D meshes coming from several datasets with different shapes and
topologies, including datasets corresponding to dressed and undressed human
poses, cloth simulations, and human hand poses acquired using multiview capture
systems. Our approach outperforms supervised learning methods and achieves
$93.8-98.1\%$ accuracy compared to the groundtruth by analytic methods.
Compared to prior learning methods, our approach results in a $5.16\%-25.50\%$
lower false negative rate in terms of collision checking and a $9.65\%-58.91\%$
higher success rate in collision handling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-training Molecular Graph Representation with 3D Geometry. (arXiv:2110.07728v1 [q-bio.QM])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07728">
<div class="article-summary-box-inner">
<span><p>Molecular graph representation learning is a fundamental problem in modern
drug and material discovery. Molecular graphs are typically modeled by their 2D
topological structures, but it has been recently discovered that 3D geometric
information plays a more vital role in predicting molecular functionalities.
However, the lack of 3D information in real-world scenarios has significantly
impeded the learning of geometric graph representation. To cope with this
challenge, we propose the Graph Multi-View Pre-training (GraphMVP) framework
where self-supervised learning (SSL) is performed by leveraging the
correspondence and consistency between 2D topological structures and 3D
geometric views. GraphMVP effectively learns a 2D molecular graph encoder that
is enhanced by richer and more discriminative 3D geometry. We further provide
theoretical insights to justify the effectiveness of GraphMVP. Finally,
comprehensive experiments show that GraphMVP can consistently outperform
existing graph SSL methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Beyond Classification: Directly Training Spiking Neural Networks for Semantic Segmentation. (arXiv:2110.07742v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07742">
<div class="article-summary-box-inner">
<span><p>Spiking Neural Networks (SNNs) have recently emerged as the low-power
alternative to Artificial Neural Networks (ANNs) because of their sparse,
asynchronous, and binary event-driven processing. Due to their energy
efficiency, SNNs have a high possibility of being deployed for real-world,
resource-constrained systems such as autonomous vehicles and drones. However,
owing to their non-differentiable and complex neuronal dynamics, most previous
SNN optimization methods have been limited to image recognition. In this paper,
we explore the SNN applications beyond classification and present semantic
segmentation networks configured with spiking neurons. Specifically, we first
investigate two representative SNN optimization techniques for recognition
tasks (i.e., ANN-SNN conversion and surrogate gradient learning) on semantic
segmentation datasets. We observe that, when converted from ANNs, SNNs suffer
from high latency and low performance due to the spatial variance of features.
Therefore, we directly train networks with surrogate gradient learning,
resulting in lower latency and higher performance than ANN-SNN conversion.
Moreover, we redesign two fundamental ANN segmentation architectures (i.e.,
Fully Convolutional Networks and DeepLab) for the SNN domain. We conduct
experiments on two public semantic segmentation benchmarks including the PASCAL
VOC2012 dataset and the DDD17 event-based dataset. In addition to showing the
feasibility of SNNs for semantic segmentation, we show that SNNs can be more
robust and energy-efficient compared to their ANN counterparts in this domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A deep learning model for classification of diabetic retinopathy in eye fundus images based on retinal lesion detection. (arXiv:2110.07745v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07745">
<div class="article-summary-box-inner">
<span><p>Diabetic retinopathy (DR) is the result of a complication of diabetes
affecting the retina. It can cause blindness, if left undiagnosed and
untreated. An ophthalmologist performs the diagnosis by screening each patient
and analyzing the retinal lesions via ocular imaging. In practice, such
analysis is time-consuming and cumbersome to perform. This paper presents a
model for automatic DR classification on eye fundus images. The approach
identifies the main ocular lesions related to DR and subsequently diagnoses the
illness. The proposed method follows the same workflow as the clinicians,
providing information that can be interpreted clinically to support the
prediction. A subset of the kaggle EyePACS and the Messidor-2 datasets, labeled
with ocular lesions, is made publicly available. The kaggle EyePACS subset is
used as a training set and the Messidor-2 as a test set for lesions and DR
classification models. For DR diagnosis, our model has an area-under-the-curve,
sensitivity, and specificity of 0.948, 0.886, and 0.875, respectively, which
competes with state-of-the-art approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">"Knights": First Place Submission for VIPriors21 Action Recognition Challenge at ICCV 2021. (arXiv:2110.07758v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07758">
<div class="article-summary-box-inner">
<span><p>This technical report presents our approach "Knights" to solve the action
recognition task on a small subset of Kinetics-400 i.e. Kinetics400ViPriors
without using any extra-data. Our approach has 3 main components:
state-of-the-art Temporal Contrastive self-supervised pretraining, video
transformer models, and optical flow modality. Along with the use of standard
test-time augmentation, our proposed solution achieves 73% on
Kinetics400ViPriors test set, which is the best among all of the other entries
Visual Inductive Priors for Data-Efficient Computer Vision's Action Recognition
Challenge, ICCV 2021.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D Reconstruction of Curvilinear Structures with Stereo Matching DeepConvolutional Neural Networks. (arXiv:2110.07766v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07766">
<div class="article-summary-box-inner">
<span><p>Curvilinear structures frequently appear in microscopy imaging as the object
of interest. Crystallographic defects, i.e., dislocations, are one of the
curvilinear structures that have been repeatedly investigated under
transmission electron microscopy (TEM) and their 3D structural information is
of great importance for understanding the properties of materials. 3D
information of dislocations is often obtained by tomography which is a
cumbersome process since it is required to acquire many images with different
tilt angles and similar imaging conditions. Although, alternative stereoscopy
methods lower the number of required images to two, they still require human
intervention and shape priors for accurate 3D estimation. We propose a fully
automated pipeline for both detection and matching of curvilinear structures in
stereo pairs by utilizing deep convolutional neural networks (CNNs) without
making any prior assumption on 3D shapes. In this work, we mainly focus on 3D
reconstruction of dislocations from stereo pairs of TEM images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Application of Homomorphic Encryption in Medical Imaging. (arXiv:2110.07768v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07768">
<div class="article-summary-box-inner">
<span><p>In this technical report, we explore the use of homomorphic encryption (HE)
in the context of training and predicting with deep learning (DL) models to
deliver strict \textit{Privacy by Design} services, and to enforce a zero-trust
model of data governance. First, we show how HE can be used to make predictions
over medical images while preventing unauthorized secondary use of data, and
detail our results on a disease classification task with OCT images. Then, we
demonstrate that HE can be used to secure the training of DL models through
federated learning, and report some experiments using 3D chest CT-Scans for a
nodule detection task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">4D flight trajectory prediction using a hybrid Deep Learning prediction method based on ADS-B technology: a case study of Hartsfield-Jackson Atlanta International Airport(ATL). (arXiv:2110.07774v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07774">
<div class="article-summary-box-inner">
<span><p>The core of any flight schedule is the trajectories. In particular, 4D
trajectories are the most crucial component for flight attribute prediction. In
particular, 4D trajectories are the most crucial component for flight attribute
prediction. Each trajectory contains spatial and temporal features that are
associated with uncertainties that make the prediction process complex. Today
because of the increasing demand for air transportation, it is compulsory for
airports and airlines to have an optimized schedule to use all of the airport's
infrastructure potential. This is possible using advanced trajectory prediction
methods. This paper proposes a novel hybrid deep learning model to extract the
spatial and temporal features considering the uncertainty of the prediction
model for Hartsfield-Jackson Atlanta International Airport(ATL). Automatic
Dependent Surveillance-Broadcast (ADS-B) data are used as input to the models.
This research is conducted in three steps: (a) data preprocessing; (b)
prediction by a hybrid Convolutional Neural Network and Gated Recurrent Unit
(CNN-GRU) along with a 3D-CNN model; (c) The third and last step is the
comparison of the model's performance with the proposed model by comparing the
experimental results. The deep model uncertainty is considered using the
Mont-Carlo dropout (MC-Dropout). Mont-Carlo dropouts are added to the network
layers to enhance the model's prediction performance by a robust approach of
switching off between different neurons. The results show that the proposed
model has low error measurements compared to the other models (i.e., 3D CNN,
CNN-GRU). The model with MC-dropout reduces the error further by an average of
21 %.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeuroView: Explainable Deep Network Decision Making. (arXiv:2110.07778v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07778">
<div class="article-summary-box-inner">
<span><p>Deep neural networks (DNs) provide superhuman performance in numerous
computer vision tasks, yet it remains unclear exactly which of a DN's units
contribute to a particular decision. NeuroView is a new family of DN
architectures that are interpretable/explainable by design. Each member of the
family is derived from a standard DN architecture by vector quantizing the unit
output values and feeding them into a global linear classifier. The resulting
architecture establishes a direct, causal link between the state of each unit
and the classification decision. We validate NeuroView on standard datasets and
classification tasks to show that how its unit/class mapping aids in
understanding the decision-making process.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Active Learning for Improved Semi-Supervised Semantic Segmentation in Satellite Images. (arXiv:2110.07782v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07782">
<div class="article-summary-box-inner">
<span><p>Remote sensing data is crucial for applications ranging from monitoring
forest fires and deforestation to tracking urbanization. Most of these tasks
require dense pixel-level annotations for the model to parse visual information
from limited labeled data available for these satellite images. Due to the
dearth of high-quality labeled training data in this domain, there is a need to
focus on semi-supervised techniques. These techniques generate pseudo-labels
from a small set of labeled examples which are used to augment the labeled
training set. This makes it necessary to have a highly representative and
diverse labeled training set. Therefore, we propose to use an active
learning-based sampling strategy to select a highly representative set of
labeled training data. We demonstrate our proposed method's effectiveness on
two existing semantic segmentation datasets containing satellite images: UC
Merced Land Use Classification Dataset and DeepGlobe Land Cover Classification
Dataset. We report a 27% improvement in mIoU with as little as 2% labeled data
using active learning sampling strategies over randomly sampling the small set
of labeled training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DG-Labeler and DGL-MOTS Dataset: Boost the Autonomous Driving Perception. (arXiv:2110.07790v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07790">
<div class="article-summary-box-inner">
<span><p>Multi-object tracking and segmentation (MOTS) is a critical task for
autonomous driving applications. The existing MOTS studies face two critical
challenges: 1) the published datasets inadequately capture the real-world
complexity for network training to address various driving settings; 2) the
working pipeline annotation tool is under-studied in the literature to improve
the quality of MOTS learning examples. In this work, we introduce the
DG-Labeler and DGL-MOTS dataset to facilitate the training data annotation for
the MOTS task and accordingly improve network training accuracy and efficiency.
DG-Labeler uses the novel Depth-Granularity Module to depict the instance
spatial relations and produce fine-grained instance masks. Annotated by
DG-Labeler, our DGL-MOTS dataset exceeds the prior effort (i.e., KITTI MOTS and
BDD100K) in data diversity, annotation quality, and temporal representations.
Results on extensive cross-dataset evaluations indicate significant performance
improvements for several state-of-the-art methods trained on our DGL-MOTS
dataset. We believe our DGL-MOTS Dataset and DG-Labeler hold the valuable
potential to boost the visual perception of future transportation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Occupancy Estimation from Thermal Images. (arXiv:2110.07796v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07796">
<div class="article-summary-box-inner">
<span><p>We propose a non-intrusive, and privacy-preserving occupancy estimation
system for smart environments. The proposed scheme uses thermal images to
detect the number of people in a given area. The occupancy estimation model is
designed using the concepts of intensity-based and motion-based human
segmentation. The notion of difference catcher, connected component labeling,
noise filter, and memory propagation are utilized to estimate the occupancy
number. We use a real dataset to demonstrate the effectiveness of the proposed
system.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EFENet: Reference-based Video Super-Resolution with Enhanced Flow Estimation. (arXiv:2110.07797v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07797">
<div class="article-summary-box-inner">
<span><p>In this paper, we consider the problem of reference-based video
super-resolution(RefVSR), i.e., how to utilize a high-resolution (HR) reference
frame to super-resolve a low-resolution (LR) video sequence. The existing
approaches to RefVSR essentially attempt to align the reference and the input
sequence, in the presence of resolution gap and long temporal range. However,
they either ignore temporal structure within the input sequence, or suffer
accumulative alignment errors. To address these issues, we propose EFENet to
exploit simultaneously the visual cues contained in the HR reference and the
temporal information contained in the LR sequence. EFENet first globally
estimates cross-scale flow between the reference and each LR frame. Then our
novel flow refinement module of EFENet refines the flow regarding the furthest
frame using all the estimated flows, which leverages the global temporal
information within the sequence and therefore effectively reduces the alignment
errors. We provide comprehensive evaluations to validate the strengths of our
approach, and to demonstrate that the proposed framework outperforms the
state-of-the-art methods. Code is available at
https://github.com/IndigoPurple/EFENet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Purification through Representation Disentanglement. (arXiv:2110.07801v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07801">
<div class="article-summary-box-inner">
<span><p>Deep learning models are vulnerable to adversarial examples and make
incomprehensible mistakes, which puts a threat on their real-world deployment.
Combined with the idea of adversarial training, preprocessing-based defenses
are popular and convenient to use because of their task independence and good
generalizability. Current defense methods, especially purification, tend to
remove ``noise" by learning and recovering the natural images. However,
different from random noise, the adversarial patterns are much easier to be
overfitted during model training due to their strong correlation to the images.
In this work, we propose a novel adversarial purification scheme by presenting
disentanglement of natural images and adversarial perturbations as a
preprocessing defense. With extensive experiments, our defense is shown to be
generalizable and make significant protection against unseen strong adversarial
attacks. It reduces the success rates of state-of-the-art \textbf{ensemble}
attacks from \textbf{61.7\%} to \textbf{14.9\%} on average, superior to a
number of existing methods. Notably, our defense restores the perturbed images
perfectly and does not hurt the clean accuracy of backbone models, which is
highly desirable in practice.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PTQ-SL: Exploring the Sub-layerwise Post-training Quantization. (arXiv:2110.07809v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07809">
<div class="article-summary-box-inner">
<span><p>Network quantization is a powerful technique to compress convolutional neural
networks. The quantization granularity determines how to share the scaling
factors in weights, which affects the performance of network quantization. Most
existing approaches share the scaling factors layerwisely or channelwisely for
quantization of convolutional layers. Channelwise quantization and layerwise
quantization have been widely used in various applications. However, other
quantization granularities are rarely explored. In this paper, we will explore
the sub-layerwise granularity that shares the scaling factor across multiple
input and output channels. We propose an efficient post-training quantization
method in sub-layerwise granularity (PTQ-SL). Then we systematically experiment
on various granularities and observe that the prediction accuracy of the
quantized neural network has a strong correlation with the granularity.
Moreover, we find that adjusting the position of the channels can improve the
performance of sub-layerwise quantization. Therefore, we propose a method to
reorder the channels for sub-layerwise quantization. The experiments
demonstrate that the sub-layerwise quantization with appropriate channel
reordering can outperform the channelwise quantization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gait-based Frailty Assessment using Image Representation of IMU Signals and Deep CNN. (arXiv:2110.07821v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07821">
<div class="article-summary-box-inner">
<span><p>Frailty is a common and critical condition in elderly adults, which may lead
to further deterioration of health. However, difficulties and complexities
exist in traditional frailty assessments based on activity-related
questionnaires. These can be overcome by monitoring the effects of frailty on
the gait. In this paper, it is shown that by encoding gait signals as images,
deep learning-based models can be utilized for the classification of gait type.
Two deep learning models (a) SS-CNN, based on single stride input images, and
(b) MS-CNN, based on 3 consecutive strides were proposed. It was shown that
MS-CNN performs best with an accuracy of 85.1\%, while SS-CNN achieved an
accuracy of 77.3\%. This is because MS-CNN can observe more features
corresponding to stride-to-stride variations which is one of the key symptoms
of frailty. Gait signals were encoded as images using STFT, CWT, and GAF. While
the MS-CNN model using GAF images achieved the best overall accuracy and
precision, CWT has a slightly better recall. This study demonstrates how image
encoded gait data can be used to exploit the full potential of deep learning
CNN models for the assessment of frailty.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding and Improving Robustness of Vision Transformers through Patch-based Negative Augmentation. (arXiv:2110.07858v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07858">
<div class="article-summary-box-inner">
<span><p>We investigate the robustness of vision transformers (ViTs) through the lens
of their special patch-based architectural structure, i.e., they process an
image as a sequence of image patches. We find that ViTs are surprisingly
insensitive to patch-based transformations, even when the transformation
largely destroys the original semantics and makes the image unrecognizable by
humans. This indicates that ViTs heavily use features that survived such
transformations but are generally not indicative of the semantic class to
humans. Further investigations show that these features are useful but
non-robust, as ViTs trained on them can achieve high in-distribution accuracy,
but break down under distribution shifts. From this understanding, we ask: can
training the model to rely less on these features improve ViT robustness and
out-of-distribution performance? We use the images transformed with our
patch-based operations as negatively augmented views and offer losses to
regularize the training away from using non-robust features. This is a
complementary view to existing research that mostly focuses on augmenting
inputs with semantic-preserving transformations to enforce models' invariance.
We show that patch-based negative augmentation consistently improves robustness
of ViTs across a wide set of ImageNet based robustness benchmarks. Furthermore,
we find our patch-based negative augmentation are complementary to traditional
(positive) data augmentation, and together boost the performance further. All
the code in this work will be open-sourced.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Receptive Field Broadening and Boosting for Salient Object Detection. (arXiv:2110.07859v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07859">
<div class="article-summary-box-inner">
<span><p>Salient object detection requires a comprehensive and scalable receptive
field to locate the visually significant objects in the image. Recently, the
emergence of visual transformers and multi-branch modules has significantly
enhanced the ability of neural networks to perceive objects at different
scales. However, compared to the traditional backbone, the calculation process
of transformers is time-consuming. Moreover, different branches of the
multi-branch modules could cause the same error back propagation in each
training iteration, which is not conducive to extracting discriminative
features. To solve these problems, we propose a bilateral network based on
transformer and CNN to efficiently broaden local details and global semantic
information simultaneously. Besides, a Multi-Head Boosting (MHB) strategy is
proposed to enhance the specificity of different network branches. By
calculating the errors of different prediction heads, each branch can
separately pay more attention to the pixels that other branches predict
incorrectly. Moreover, Unlike multi-path parallel training, MHB randomly
selects one branch each time for gradient back propagation in a boosting way.
Additionally, an Attention Feature Fusion Module (AF) is proposed to fuse two
types of features according to respective characteristics. Comprehensive
experiments on five benchmark datasets demonstrate that the proposed method can
achieve a significant performance improvement compared with the
state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Single volume lung biomechanics from chest computed tomography using a mode preserving generative adversarial network. (arXiv:2110.07878v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07878">
<div class="article-summary-box-inner">
<span><p>Local tissue expansion of the lungs is typically derived by registering
computed tomography (CT) scans acquired at multiple lung volumes. However,
acquiring multiple scans incurs increased radiation dose, time, and cost, and
may not be possible in many cases, thus restricting the applicability of
registration-based biomechanics. We propose a generative adversarial learning
approach for estimating local tissue expansion directly from a single CT scan.
The proposed framework was trained and evaluated on 2500 subjects from the
SPIROMICS cohort. Once trained, the framework can be used as a
registration-free method for predicting local tissue expansion. We evaluated
model performance across varying degrees of disease severity and compared its
performance with two image-to-image translation frameworks - UNet and Pix2Pix.
Our model achieved an overall PSNR of 18.95 decibels, SSIM of 0.840, and
Spearman's correlation of 0.61 at a high spatial resolution of 1 mm3.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Advances and Challenges in Deep Lip Reading. (arXiv:2110.07879v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07879">
<div class="article-summary-box-inner">
<span><p>Driven by deep learning techniques and large-scale datasets, recent years
have witnessed a paradigm shift in automatic lip reading. While the main thrust
of Visual Speech Recognition (VSR) was improving accuracy of Audio Speech
Recognition systems, other potential applications, such as biometric
identification, and the promised gains of VSR systems, have motivated extensive
efforts on developing the lip reading technology. This paper provides a
comprehensive survey of the state-of-the-art deep learning based VSR research
with a focus on data challenges, task-specific complications, and the
corresponding solutions. Advancements in these directions will expedite the
transformation of silent speech interface from theory to practice. We also
discuss the main modules of a VSR pipeline and the influential datasets.
Finally, we introduce some typical VSR application concerns and impediments to
real-world scenarios as well as future research directions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PolyNet: Polynomial Neural Network for 3D Shape Recognition with PolyShape Representation. (arXiv:2110.07882v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07882">
<div class="article-summary-box-inner">
<span><p>3D shape representation and its processing have substantial effects on 3D
shape recognition. The polygon mesh as a 3D shape representation has many
advantages in computer graphics and geometry processing. However, there are
still some challenges for the existing deep neural network (DNN)-based methods
on polygon mesh representation, such as handling the variations in the degree
and permutations of the vertices and their pairwise distances. To overcome
these challenges, we propose a DNN-based method (PolyNet) and a specific
polygon mesh representation (PolyShape) with a multi-resolution structure.
PolyNet contains two operations; (1) a polynomial convolution (PolyConv)
operation with learnable coefficients, which learns continuous distributions as
the convolutional filters to share the weights across different vertices, and
(2) a polygonal pooling (PolyPool) procedure by utilizing the multi-resolution
structure of PolyShape to aggregate the features in a much lower dimension. Our
experiments demonstrate the strength and the advantages of PolyNet on both 3D
shape classification and retrieval tasks compared to existing polygon
mesh-based methods and its superiority in classifying graph representations of
images. The code is publicly available from
https://myavartanoo.github.io/polynet/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Unsupervised Domain Adaptive Re-Identification via Source-Guided Selection of Pseudo-Labeling Hyperparameters. (arXiv:2110.07897v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07897">
<div class="article-summary-box-inner">
<span><p>Unsupervised Domain Adaptation (UDA) for re-identification (re-ID) is a
challenging task: to avoid a costly annotation of additional data, it aims at
transferring knowledge from a domain with annotated data to a domain of
interest with only unlabeled data. Pseudo-labeling approaches have proven to be
effective for UDA re-ID. However, the effectiveness of these approaches heavily
depends on the choice of some hyperparameters (HP) that affect the generation
of pseudo-labels by clustering. The lack of annotation in the domain of
interest makes this choice non-trivial. Current approaches simply reuse the
same empirical value for all adaptation tasks and regardless of the target data
representation that changes through pseudo-labeling training phases. As this
simplistic choice may limit their performance, we aim at addressing this issue.
We propose new theoretical grounds on HP selection for clustering UDA re-ID as
well as method of automatic and cyclic HP tuning for pseudo-labeling UDA
clustering: HyPASS. HyPASS consists in incorporating two modules in
pseudo-labeling methods: (i) HP selection based on a labeled source validation
set and (ii) conditional domain alignment of feature discriminativeness to
improve HP selection based on source samples. Experiments on commonly used
person re-ID and vehicle re-ID datasets show that our proposed HyPASS
consistently improves the best state-of-the-art methods in re-ID compared to
the commonly used empirical HP setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Infer Kinematic Hierarchies for Novel Object Instances. (arXiv:2110.07911v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07911">
<div class="article-summary-box-inner">
<span><p>Manipulating an articulated object requires perceiving itskinematic
hierarchy: its parts, how each can move, and howthose motions are coupled.
Previous work has explored per-ception for kinematics, but none infers a
complete kinematichierarchy on never-before-seen object instances, without
relyingon a schema or template. We present a novel perception systemthat
achieves this goal. Our system infers the moving parts ofan object and the
kinematic couplings that relate them. Toinfer parts, it uses a point cloud
instance segmentation neuralnetwork and to infer kinematic hierarchies, it uses
a graphneural network to predict the existence, direction, and typeof edges
(i.e. joints) that relate the inferred parts. We trainthese networks using
simulated scans of synthetic 3D models.We evaluate our system on simulated
scans of 3D objects, andwe demonstrate a proof-of-concept use of our system to
drivereal-world robotic manipulation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Combining CNNs With Transformer for Multimodal 3D MRI Brain Tumor Segmentation With Self-Supervised Pretraining. (arXiv:2110.07919v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07919">
<div class="article-summary-box-inner">
<span><p>We apply an ensemble of modified TransBTS, nnU-Net, and a combination of both
for the segmentation task of the BraTS 2021 challenge. In fact, we change the
original architecture of the TransBTS model by adding Squeeze-and-Excitation
blocks, an increasing number of CNN layers, replacing positional encoding in
Transformer block with a learnable Multilayer Perceptron (MLP) embeddings,
which makes Transformer adjustable to any input size during inference. With
these modifications, we are able to largely improve TransBTS performance.
Inspired by a nnU-Net framework we decided to combine it with our modified
TransBTS by changing the architecture inside nnU-Net to our custom model. On
the Validation set of BraTS 2021, the ensemble of these approaches achieves
0.8496, 0.8698, 0.9256 Dice score and 15.72, 11.057, 3.374 HD95 for enhancing
tumor, tumor core, and whole tumor, correspondingly. Our code is publicly
available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Generation using Texture Co-occurrence and Spatial Self-Similarity for Debiasing. (arXiv:2110.07920v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07920">
<div class="article-summary-box-inner">
<span><p>Classification models trained on biased datasets usually perform poorly on
out-of-distribution samples since biased representations are embedded into the
model. Recently, adversarial learning methods have been proposed to disentangle
biased representations, but it is challenging to discard only the biased
features without altering other relevant information. In this paper, we propose
a novel de-biasing approach that explicitly generates additional images using
texture representations of oppositely labeled images to enlarge the training
dataset and mitigate the effect of biases when training a classifier. Every new
generated image contains similar spatial information from a source image while
transferring textures from a target image of opposite label. Our model
integrates a texture co-occurrence loss that determines whether a generated
image's texture is similar to that of the target, and a spatial self-similarity
loss that determines whether the spatial details between the generated and
source images are well preserved. Both generated and original training images
are further used to train a classifier that is able to avoid learning unknown
bias representations. We employ three distinct artificially designed datasets
with known biases to demonstrate the ability of our method to mitigate bias
information, and report competitive performance over existing state-of-the-art
methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relation Preserving Triplet Mining for Stabilizing the Triplet Loss in Vehicle Re-identification. (arXiv:2110.07933v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07933">
<div class="article-summary-box-inner">
<span><p>Object appearances often change dramatically with pose variations. This
creates a challenge for embedding schemes that seek to map instances with the
same object ID to locations that are as close as possible. This issue becomes
significantly heightened in complex computer vision tasks such as
re-identification(re-id). In this paper, we suggest these dramatic appearance
changes are indications that an object ID is composed of multiple natural
groups and it is counter-productive to forcefully map instances from different
groups to a common location. This leads us to introduce Relation Preserving
Triplet Mining (RPTM), a feature matching guided triplet mining scheme, that
ensures triplets will respect the natural sub-groupings within an object ID. We
use this triplet mining mechanism to establish a pose-aware, well-conditioned
triplet cost function. This allows a single network to be trained with fixed
parameters across three challenging benchmarks, while still providing
state-of-the-art re-identification results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Generating Identifiable Virtual Faces. (arXiv:2110.07986v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07986">
<div class="article-summary-box-inner">
<span><p>Face anonymization with generative models have become increasingly prevalent
since they sanitize private information by generating virtual face images,
ensuring both privacy and image utility. Such virtual face images are usually
not identifiable after the removal or protection of the original identity. In
this paper, we formalize and tackle the problem of generating identifiable
virtual face images. Our virtual face images are visually different from the
original ones for privacy protection. In addition, they are bound with new
virtual identities, which can be directly used for face recognition. We propose
an Identifiable Virtual Face Generator (IVFG) to generate the virtual face
images. The IVFG projects the latent vectors of the original face images into
virtual ones according to a user specific key, based on which the virtual face
images are generated. To make the virtual face images identifiable, we propose
a multi-task learning objective as well as a triplet styled training strategy
to learn the IVFG. Various experiments demonstrate the effectiveness of the
IVFG for generate identifiable virtual face images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pose-guided Generative Adversarial Net for Novel View Action Synthesis. (arXiv:2110.07993v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07993">
<div class="article-summary-box-inner">
<span><p>We focus on the problem of novel-view human action synthesis. Given an action
video, the goal is to generate the same action from an unseen viewpoint.
Naturally, novel view video synthesis is more challenging than image synthesis.
It requires the synthesis of a sequence of realistic frames with temporal
coherency. Besides, transferring the different actions to a novel target view
requires awareness of action category and viewpoint change simultaneously. To
address these challenges, we propose a novel framework named Pose-guided Action
Separable Generative Adversarial Net (PAS-GAN), which utilizes pose to
alleviate the difficulty of this task. First, we propose a recurrent
pose-transformation module which transforms actions from the source view to the
target view and generates novel view pose sequence in 2D coordinate space.
Second, a well-transformed pose sequence enables us to separatethe action and
background in the target view. We employ a novel local-global spatial
transformation module to effectively generate sequential video features in the
target view using these action and background features. Finally, the generated
video features are used to synthesize human action with the help of a 3D
decoder. Moreover, to focus on dynamic action in the video, we propose a novel
multi-scale action-separable loss which further improves the video quality. We
conduct extensive experiments on two large-scale multi-view human action
datasets, NTU-RGBD and PKU-MMD, demonstrating the effectiveness of PAS-GAN
which outperforms existing approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pyramid Correlation based Deep Hough Voting for Visual Object Tracking. (arXiv:2110.07994v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07994">
<div class="article-summary-box-inner">
<span><p>Most of the existing Siamese-based trackers treat tracking problem as a
parallel task of classification and regression. However, some studies show that
the sibling head structure could lead to suboptimal solutions during the
network training. Through experiments we find that, without regression, the
performance could be equally promising as long as we delicately design the
network to suit the training objective. We introduce a novel voting-based
classification-only tracking algorithm named Pyramid Correlation based Deep
Hough Voting (short for PCDHV), to jointly locate the top-left and bottom-right
corners of the target. Specifically we innovatively construct a Pyramid
Correlation module to equip the embedded feature with fine-grained local
structures and global spatial contexts; The elaborately designed Deep Hough
Voting module further take over, integrating long-range dependencies of pixels
to perceive corners; In addition, the prevalent discretization gap is simply
yet effectively alleviated by increasing the spatial resolution of the feature
maps while exploiting channel-space relationships. The algorithm is general,
robust and simple. We demonstrate the effectiveness of the module through a
series of ablation experiments. Without bells and whistles, our tracker
achieves better or comparable performance to the SOTA algorithms on three
challenging benchmarks (TrackingNet, GOT-10k and LaSOT) while running at a
real-time speed of 80 FPS. Codes and models will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MaGNET: Uniform Sampling from Deep Generative Network Manifolds Without Retraining. (arXiv:2110.08009v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08009">
<div class="article-summary-box-inner">
<span><p>Deep Generative Networks (DGNs) are extensively employed in Generative
Adversarial Networks (GANs), Variational Autoencoders (VAEs), and their
variants to approximate the data manifold, and data distribution on that
manifold. However, training samples are often obtained based on preferences,
costs, or convenience producing artifacts in the empirical data distribution
e.g., the large fraction of smiling faces in the CelebA dataset or the large
fraction of dark-haired individuals in FFHQ. These inconsistencies will be
reproduced when sampling from the trained DGN, which has far-reaching potential
implications for fairness, data augmentation, anomaly detection, domain
adaptation, and beyond. In response, we develop a differential geometry based
sampler -- coined MaGNET -- that, given any trained DGN, produces samples that
are uniformly distributed on the learned manifold. We prove theoretically and
empirically that our technique produces a uniform distribution on the manifold
regardless of the training set distribution. We perform a range of experiments
on various datasets and DGNs. One of them considers the state-of-the-art
StyleGAN2 trained on FFHQ dataset, where uniform sampling via MaGNET increases
distribution precision and recall by 4.1% &amp; 3.0% and decreases gender bias by
41.2%, without requiring labels or retraining.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Channel and Weight Pruning for Model Acceleration on Moblie Devices. (arXiv:2110.08013v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08013">
<div class="article-summary-box-inner">
<span><p>For practical deep neural network design on mobile devices, it is essential
to consider the constraints incurred by the computational resources and the
inference latency in various applications. Among deep network acceleration
related approaches, pruning is a widely adopted practice to balance the
computational resource consumption and the accuracy, where unimportant
connections can be removed either channel-wisely or randomly with a minimal
impact on model accuracy. The channel pruning instantly results in a
significant latency reduction, while the random weight pruning is more flexible
to balance the latency and accuracy. In this paper, we present a unified
framework with Joint Channel pruning and Weight pruning (JCW), and achieves a
better Pareto-frontier between the latency and accuracy than previous model
compression approaches. To fully optimize the trade-off between the latency and
accuracy, we develop a tailored multi-objective evolutionary algorithm in the
JCW framework, which enables one single search to obtain the optimal candidate
architectures for various deployment requirements. Extensive experiments
demonstrate that the JCW achieves a better trade-off between the latency and
accuracy against various state-of-the-art pruning methods on the ImageNet
classification dataset. Our codes are available at
https://github.com/jcw-anonymous/JCW.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tensor-to-Image: Image-to-Image Translation with Vision Transformers. (arXiv:2110.08037v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08037">
<div class="article-summary-box-inner">
<span><p>Transformers gain huge attention since they are first introduced and have a
wide range of applications. Transformers start to take over all areas of deep
learning and the Vision transformers paper also proved that they can be used
for computer vision tasks. In this paper, we utilized a vision
transformer-based custom-designed model, tensor-to-image, for the image to
image translation. With the help of self-attention, our model was able to
generalize and apply to different problems without a single modification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Attacks on ML Defense Models Competition. (arXiv:2110.08042v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08042">
<div class="article-summary-box-inner">
<span><p>Due to the vulnerability of deep neural networks (DNNs) to adversarial
examples, a large number of defense techniques have been proposed to alleviate
this problem in recent years. However, the progress of building more robust
models is usually hampered by the incomplete or incorrect robustness
evaluation. To accelerate the research on reliable evaluation of adversarial
robustness of the current defense models in image classification, the TSAIL
group at Tsinghua University and the Alibaba Security group organized this
competition along with a CVPR 2021 workshop on adversarial machine learning
(https://aisecure-workshop.github.io/amlcvpr2021/). The purpose of this
competition is to motivate novel attack algorithms to evaluate adversarial
robustness more effectively and reliably. The participants were encouraged to
develop stronger white-box attack algorithms to find the worst-case robustness
of different defenses. This competition was conducted on an adversarial
robustness evaluation platform -- ARES (https://github.com/thu-ml/ares), and is
held on the TianChi platform
(https://tianchi.aliyun.com/competition/entrance/531847/introduction) as one of
the series of AI Security Challengers Program. After the competition, we
summarized the results and established a new adversarial robustness benchmark
at https://ml.cs.tsinghua.edu.cn/ares-bench/, which allows users to upload
adversarial attack algorithms and defense models for evaluation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Layer Pseudo-Supervision for Histopathology Tissue Semantic Segmentation using Patch-level Classification Labels. (arXiv:2110.08048v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08048">
<div class="article-summary-box-inner">
<span><p>Tissue-level semantic segmentation is a vital step in computational
pathology. Fully-supervised models have already achieved outstanding
performance with dense pixel-level annotations. However, drawing such labels on
the giga-pixel whole slide images is extremely expensive and time-consuming. In
this paper, we use only patch-level classification labels to achieve tissue
semantic segmentation on histopathology images, finally reducing the annotation
efforts. We proposed a two-step model including a classification and a
segmentation phases. In the classification phase, we proposed a CAM-based model
to generate pseudo masks by patch-level labels. In the segmentation phase, we
achieved tissue semantic segmentation by our proposed Multi-Layer
Pseudo-Supervision. Several technical novelties have been proposed to reduce
the information gap between pixel-level and patch-level annotations. As a part
of this paper, we introduced a new weakly-supervised semantic segmentation
(WSSS) dataset for lung adenocarcinoma (LUAD-HistoSeg). We conducted several
experiments to evaluate our proposed model on two datasets. Our proposed model
outperforms two state-of-the-art WSSS approaches. Note that we can achieve
comparable quantitative and qualitative results with the fully-supervised
model, with only around a 2\% gap for MIoU and FwIoU. By comparing with manual
labeling, our model can greatly save the annotation time from hours to minutes.
The source code is available at: \url{https://github.com/ChuHan89/WSSS-Tissue}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FlexConv: Continuous Kernel Convolutions with Differentiable Kernel Sizes. (arXiv:2110.08059v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08059">
<div class="article-summary-box-inner">
<span><p>When designing Convolutional Neural Networks (CNNs), one must select the size
of the convolutional kernels before training. Recent works show CNNs benefit
from different kernel sizes at different layers, but exploring all possible
combinations is unfeasible in practice. A more efficient approach is to learn
the kernel size during training. However, existing works that learn the kernel
size have a limited bandwidth. These approaches scale kernels by dilation, and
thus the detail they can describe is limited. In this work, we propose
FlexConv, a novel convolutional operation with which high bandwidth
convolutional kernels of learnable kernel size can be learned at a fixed
parameter cost. FlexNets model long-term dependencies without the use of
pooling, achieve state-of-the-art performance on several sequential datasets,
outperform recent works with learned kernel sizes, and are competitive with
much deeper ResNets on image benchmark datasets. Additionally, FlexNets can be
deployed at higher resolutions than those seen during training. To avoid
aliasing, we propose a novel kernel parameterization with which the frequency
of the kernels can be analytically controlled. Our novel kernel
parameterization shows higher descriptive power and faster convergence speed
than existing parameterizations. This leads to important improvements in
classification accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Reliable Shot Identification for Complex Event Detection via Visual-Semantic Embedding. (arXiv:2110.08063v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08063">
<div class="article-summary-box-inner">
<span><p>Multimedia event detection is the task of detecting a specific event of
interest in an user-generated video on websites. The most fundamental challenge
facing this task lies in the enormously varying quality of the video as well as
the high-level semantic abstraction of event inherently. In this paper, we
decompose the video into several segments and intuitively model the task of
complex event detection as a multiple instance learning problem by representing
each video as a "bag" of segments in which each segment is referred to as an
instance. Instead of treating the instances equally, we associate each instance
with a reliability variable to indicate its importance and then select reliable
instances for training. To measure the reliability of the varying instances
precisely, we propose a visual-semantic guided loss by exploiting low-level
feature from visual information together with instance-event similarity based
high-level semantic feature. Motivated by curriculum learning, we introduce a
negative elastic-net regularization term to start training the classifier with
instances of high reliability and gradually taking the instances with
relatively low reliability into consideration. An alternative optimization
algorithm is developed to solve the proposed challenging non-convex non-smooth
problem. Experimental results on standard datasets, i.e., TRECVID MEDTest 2013
and TRECVID MEDTest 2014, demonstrate the effectiveness and superiority of the
proposed method to the baseline algorithms.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automated Quality Control of Vacuum Insulated Glazing by Convolutional Neural Network Image Classification. (arXiv:2110.08079v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08079">
<div class="article-summary-box-inner">
<span><p>Vacuum Insulated Glazing (VIG) is a highly thermally insulating window
technology, which boasts an extremely thin profile and lower weight as compared
to gas-filled insulated glazing units of equivalent performance. The VIG is a
double-pane configuration with a submillimeter vacuum gap between the panes and
therefore under constant atmospheric pressure over their service life. Small
pillars are positioned between the panes to maintain the gap, which can damage
the glass reducing the lifetime of the VIG unit. To efficiently assess any
surface damage on the glass, an automated damage detection system is highly
desirable. For the purpose of classifying the damage, we have developed,
trained, and tested a deep learning computer vision system using convolutional
neural networks. The classification model flawlessly classified the test
dataset with an area under the curve (AUC) for the receiver operating
characteristic (ROC) of 100%. We have automatically cropped the images down to
their relevant information by using Faster-RCNN to locate the position of the
pillars. We employ the state-of-the-art methods Grad-CAM and Score-CAM of
explainable Artificial Intelligence (XAI) to provide an understanding of the
internal mechanisms and were able to show that our classifier outperforms
ResNet50V2 for identification of crack locations and geometry. The proposed
methods can therefore be used to detect systematic defects even without large
amounts of training data. Further analyses of our model's predictive
capabilities demonstrates its superiority over state-of-the-art models
(ResNet50V2, ResNet101V2 and ResNet152V2) in terms of convergence speed,
accuracy, precision at 100% recall and AUC for ROC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-modal Aggregation Network for Fast MR Imaging. (arXiv:2110.08080v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08080">
<div class="article-summary-box-inner">
<span><p>Magnetic resonance (MR) imaging is a commonly used scanning technique for
disease detection, diagnosis and treatment monitoring. Although it is able to
produce detailed images of organs and tissues with better contrast, it suffers
from a long acquisition time, which makes the image quality vulnerable to say
motion artifacts. Recently, many approaches have been developed to reconstruct
full-sampled images from partially observed measurements in order to accelerate
MR imaging. However, most of these efforts focus on reconstruction over a
single modality or simple fusion of multiple modalities, neglecting the
discovery of correlation knowledge at different feature level. In this work, we
propose a novel Multi-modal Aggregation Network, named MANet, which is capable
of discovering complementary representations from a fully sampled auxiliary
modality, with which to hierarchically guide the reconstruction of a given
target modality. In our MANet, the representations from the fully sampled
auxiliary and undersampled target modalities are learned independently through
a specific network. Then, a guided attention module is introduced in each
convolutional stage to selectively aggregate multi-modal features for better
reconstruction, yielding comprehensive, multi-scale, multi-modal feature
fusion. Moreover, our MANet follows a hybrid domain learning framework, which
allows it to simultaneously recover the frequency signal in the $k$-space
domain as well as restore the image details from the image domain. Extensive
experiments demonstrate the superiority of the proposed approach over
state-of-the-art MR image reconstruction methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Prediction of Lung CT Scores of Systemic Sclerosis by Cascaded Regression Neural Networks. (arXiv:2110.08085v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08085">
<div class="article-summary-box-inner">
<span><p>Visually scoring lung involvement in systemic sclerosis from CT scans plays
an important role in monitoring progression, but its labor intensiveness
hinders practical application. We proposed, therefore, an automatic scoring
framework that consists of two cascaded deep regression neural networks. The
first (3D) network aims to predict the craniocaudal position of five
anatomically defined scoring levels on the 3D CT scans. The second (2D) network
receives the resulting 2D axial slices and predicts the scores. We used 227 3D
CT scans to train and validate the first network, and the resulting 1135 axial
slices were used in the second network. Two experts scored independently a
subset of data to obtain intra- and interobserver variabilities and the ground
truth for all data was obtained in consensus. To alleviate the unbalance in
training labels in the second network, we introduced a sampling technique and
to increase the diversity of the training samples synthetic data was generated,
mimicking ground glass and reticulation patterns. The 4-fold cross validation
showed that our proposed network achieved an average MAE of 5.90, 4.66 and
4.49, weighted kappa of 0.66, 0.58 and 0.65 for total score (TOT), ground glass
(GG) and reticular pattern (RET), respectively. Our network performed slightly
worse than the best experts on TOT and GG prediction but it has competitive
performance on RET prediction and has the potential to be an objective
alternative for the visual scoring of SSc in CT thorax studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Trade-offs of Local SGD at Scale: An Empirical Study. (arXiv:2110.08133v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08133">
<div class="article-summary-box-inner">
<span><p>As datasets and models become increasingly large, distributed training has
become a necessary component to allow deep neural networks to train in
reasonable amounts of time. However, distributed training can have substantial
communication overhead that hinders its scalability. One strategy for reducing
this overhead is to perform multiple unsynchronized SGD steps independently on
each worker between synchronization steps, a technique known as local SGD. We
conduct a comprehensive empirical study of local SGD and related methods on a
large-scale image classification task. We find that performing local SGD comes
at a price: lower communication costs (and thereby faster training) are
accompanied by lower accuracy. This finding is in contrast from the
smaller-scale experiments in prior work, suggesting that local SGD encounters
challenges at scale. We further show that incorporating the slow momentum
framework of Wang et al. (2020) consistently improves accuracy without
requiring additional communication, hinting at future directions for
potentially escaping this trade-off.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Tailed, Multi-Headed, Spatial Dynamic Memory refined Text-to-Image Synthesis. (arXiv:2110.08143v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08143">
<div class="article-summary-box-inner">
<span><p>Synthesizing high-quality, realistic images from text-descriptions is a
challenging task, and current methods synthesize images from text in a
multi-stage manner, typically by first generating a rough initial image and
then refining image details at subsequent stages. However, existing methods
that follow this paradigm suffer from three important limitations. Firstly,
they synthesize initial images without attempting to separate image attributes
at a word-level. As a result, object attributes of initial images (that provide
a basis for subsequent refinement) are inherently entangled and ambiguous in
nature. Secondly, by using common text-representations for all regions, current
methods prevent us from interpreting text in fundamentally different ways at
different parts of an image. Different image regions are therefore only allowed
to assimilate the same type of information from text at each refinement stage.
Finally, current methods generate refinement features only once at each
refinement stage and attempt to address all image aspects in a single shot.
This single-shot refinement limits the precision with which each refinement
stage can learn to improve the prior image. Our proposed method introduces
three novel components to address these shortcomings: (1) An initial generation
stage that explicitly generates separate sets of image features for each word
n-gram. (2) A spatial dynamic memory module for refinement of images. (3) An
iterative multi-headed mechanism to make it easier to improve upon multiple
image aspects. Experimental results demonstrate that our Multi-Headed Spatial
Dynamic Memory image refinement with our Multi-Tailed Word-level Initial
Generation (MSMT-GAN) performs favourably against the previous state of the art
on the CUB and COCO datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accurate Fine-grained Layout Analysis for the Historical Tibetan Document Based on the Instance Segmentation. (arXiv:2110.08164v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08164">
<div class="article-summary-box-inner">
<span><p>Accurate layout analysis without subsequent text-line segmentation remains an
ongoing challenge, especially when facing the Kangyur, a kind of historical
Tibetan document featuring considerable touching components and mottled
background. Aiming at identifying different regions in document images, layout
analysis is indispensable for subsequent procedures such as character
recognition. However, there was only a little research being carried out to
perform line-level layout analysis which failed to deal with the Kangyur. To
obtain the optimal results, a fine-grained sub-line level layout analysis
approach is presented. Firstly, we introduced an accelerated method to build
the dataset which is dynamic and reliable. Secondly, enhancement had been made
to the SOLOv2 according to the characteristics of the Kangyur. Then, we fed the
enhanced SOLOv2 with the prepared annotation file during the training phase.
Once the network is trained, instances of the text line, sentence, and titles
can be segmented and identified during the inference stage. The experimental
results show that the proposed method delivers a decent 72.7% AP on our
dataset. In general, this preliminary research provides insights into the
fine-grained sub-line level layout analysis and testifies the SOLOv2-based
approaches. We also believe that the proposed methods can be adopted on other
language documents with various layouts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The World of an Octopus: How Reporting Bias Influences a Language Model's Perception of Color. (arXiv:2110.08182v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08182">
<div class="article-summary-box-inner">
<span><p>Recent work has raised concerns about the inherent limitations of text-only
pretraining. In this paper, we first demonstrate that reporting bias, the
tendency of people to not state the obvious, is one of the causes of this
limitation, and then investigate to what extent multimodal training can
mitigate this issue. To accomplish this, we 1) generate the Color Dataset
(CoDa), a dataset of human-perceived color distributions for 521 common
objects; 2) use CoDa to analyze and compare the color distribution found in
text, the distribution captured by language models, and a human's perception of
color; and 3) investigate the performance differences between text-only and
multimodal models on CoDa. Our results show that the distribution of colors
that a language model recovers correlates more strongly with the inaccurate
distribution found in text than with the ground-truth, supporting the claim
that reporting bias negatively impacts and inherently limits text-only
training. We then demonstrate that multimodal models can leverage their visual
training to mitigate these effects, providing a promising avenue for future
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Crop Rotation Modeling for Deep Learning-Based Parcel Classification from Satellite Time Series. (arXiv:2110.08187v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08187">
<div class="article-summary-box-inner">
<span><p>While annual crop rotations play a crucial role for agricultural
optimization, they have been largely ignored for automated crop type mapping.
In this paper, we take advantage of the increasing quantity of annotated
satellite data to propose the first deep learning approach modeling
simultaneously the inter- and intra-annual agricultural dynamics of parcel
classification. Along with simple training adjustments, our model provides an
improvement of over 6.6 mIoU points over the current state-of-the-art of crop
classification. Furthermore, we release the first large-scale multi-year
agricultural dataset with over 300,000 annotated parcels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Guided Point Contrastive Learning for Semi-supervised Point Cloud Semantic Segmentation. (arXiv:2110.08188v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08188">
<div class="article-summary-box-inner">
<span><p>Rapid progress in 3D semantic segmentation is inseparable from the advances
of deep network models, which highly rely on large-scale annotated data for
training. To address the high cost and challenges of 3D point-level labeling,
we present a method for semi-supervised point cloud semantic segmentation to
adopt unlabeled point clouds in training to boost the model performance.
Inspired by the recent contrastive loss in self-supervised tasks, we propose
the guided point contrastive loss to enhance the feature representation and
model generalization ability in semi-supervised setting. Semantic predictions
on unlabeled point clouds serve as pseudo-label guidance in our loss to avoid
negative pairs in the same category. Also, we design the confidence guidance to
ensure high-quality feature learning. Besides, a category-balanced sampling
strategy is proposed to collect positive and negative samples to mitigate the
class imbalance problem. Extensive experiments on three datasets (ScanNet V2,
S3DIS, and SemanticKITTI) show the effectiveness of our semi-supervised method
to improve the prediction quality with unlabeled data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attention meets Geometry: Geometry Guided Spatial-Temporal Attention for Consistent Self-Supervised Monocular Depth Estimation. (arXiv:2110.08192v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08192">
<div class="article-summary-box-inner">
<span><p>Inferring geometrically consistent dense 3D scenes across a tuple of
temporally consecutive images remains challenging for self-supervised monocular
depth prediction pipelines. This paper explores how the increasingly popular
transformer architecture, together with novel regularized loss formulations,
can improve depth consistency while preserving accuracy. We propose a spatial
attention module that correlates coarse depth predictions to aggregate local
geometric information. A novel temporal attention mechanism further processes
the local geometric information in a global context across consecutive images.
Additionally, we introduce geometric constraints between frames regularized by
photometric cycle consistency. By combining our proposed regularization and the
novel spatial-temporal-attention module we fully leverage both the geometric
and appearance-based consistency across monocular frames. This yields
geometrically meaningful attention and improves temporal depth stability and
accuracy compared to previous methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shared Visual Representations of Drawing for Communication: How do different biases affect human interpretability and intent?. (arXiv:2110.08203v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08203">
<div class="article-summary-box-inner">
<span><p>We present an investigation into how representational losses can affect the
drawings produced by artificial agents playing a communication game. Building
upon recent advances, we show that a combination of powerful pretrained encoder
networks, with appropriate inductive biases, can lead to agents that draw
recognisable sketches, whilst still communicating well. Further, we start to
develop an approach to help automatically analyse the semantic content being
conveyed by a sketch and demonstrate that current approaches to inducing
perceptual biases lead to a notion of objectness being a key feature despite
the agent training being self-supervised.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Combining Diverse Feature Priors. (arXiv:2110.08220v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08220">
<div class="article-summary-box-inner">
<span><p>To improve model generalization, model designers often restrict the features
that their models use, either implicitly or explicitly. In this work, we
explore the design space of leveraging such feature priors by viewing them as
distinct perspectives on the data. Specifically, we find that models trained
with diverse sets of feature priors have less overlapping failure modes, and
can thus be combined more effectively. Moreover, we demonstrate that jointly
training such models on additional (unlabeled) data allows them to correct each
other's mistakes, which, in turn, leads to better generalization and resilience
to spurious correlations. Code available at
https://github.com/MadryLab/copriors.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Guiding Visual Question Generation. (arXiv:2110.08226v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08226">
<div class="article-summary-box-inner">
<span><p>In traditional Visual Question Generation (VQG), most images have multiple
concepts (e.g. objects and categories) for which a question could be generated,
but models are trained to mimic an arbitrary choice of concept as given in
their training data. This makes training difficult and also poses issues for
evaluation -- multiple valid questions exist for most images but only one or a
few are captured by the human references. We present Guiding Visual Question
Generation - a variant of VQG which conditions the question generator on
categorical information based on expectations on the type of question and the
objects it should explore. We propose two variants: (i) an explicitly guided
model that enables an actor (human or automated) to select which objects and
categories to generate a question for; and (ii) an implicitly guided model that
learns which objects and categories to condition on, based on discrete latent
variables. The proposed models are evaluated on an answer-category augmented
VQA dataset and our quantitative results show a substantial improvement over
the current state of the art (over 9 BLEU-4 increase). Human evaluation
validates that guidance helps the generation of questions that are
grammatically coherent and relevant to the given image and objects.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fire Together Wire Together: A Dynamic Pruning Approach with Self-Supervised Mask Prediction. (arXiv:2110.08232v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08232">
<div class="article-summary-box-inner">
<span><p>Dynamic model pruning is a recent direction that allows for the inference of
a different sub-network for each input sample during deployment. However,
current dynamic methods rely on learning a continuous channel gating through
regularization by inducing sparsity loss. This formulation introduces
complexity in balancing different losses (e.g task loss, regularization loss).
In addition, regularization-based methods lack transparent tradeoff
hyperparameter selection to realize computational budget. Our contribution is
twofold: 1) decoupled task and pruning training. 2) Simple hyperparameter
selection that enables FLOPs reduction estimation before training. We propose
to predict a mask to process k filters in a layer based on the activation of
its previous layer. We pose the problem as a self-supervised binary
classification problem. Each mask predictor module is trained to predict if the
log-likelihood of each filter in the current layer belongs to the top-k
activated filters. The value k is dynamically estimated for each input based on
a novel criterion using the mass of heatmaps. We show experiments on several
neural architectures, such as VGG, ResNet, and MobileNet on CIFAR and ImageNet
datasets. On CIFAR, we reach similar accuracy to SOTA methods with 15% and 24%
higher FLOPs reduction. Similarly in ImageNet, we achieve a lower drop in
accuracy with up to 13% improvement in FLOPs reduction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Dubber: Dubbing for Silent Videos According to Scripts. (arXiv:2110.08243v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08243">
<div class="article-summary-box-inner">
<span><p>Dubbing is a post-production process of re-recording actors' dialogues, which
is extensively used in filmmaking and video production. It is usually performed
manually by professional voice actors who read lines with proper prosody, and
in synchronization with the pre-recorded videos. In this work, we propose
Neural Dubber, the first neural network model to solve a novel automatic video
dubbing (AVD) task: synthesizing human speech synchronized with the given
silent video from the text. Neural Dubber is a multi-modal text-to-speech (TTS)
model that utilizes the lip movement in the video to control the prosody of the
generated speech. Furthermore, an image-based speaker embedding (ISE) module is
developed for the multi-speaker setting, which enables Neural Dubber to
generate speech with a reasonable timbre according to the speaker's face.
Experiments on the chemistry lecture single-speaker dataset and LRS2
multi-speaker dataset show that Neural Dubber can generate speech audios on par
with state-of-the-art TTS models in terms of speech quality. Most importantly,
both qualitative and quantitative evaluations show that Neural Dubber can
control the prosody of synthesized speech by the video, and generate
high-fidelity speech temporally synchronized with the video.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Performance, Successes and Limitations of Deep Learning Semantic Segmentation of Multiple Defects in Transmission Electron Micrographs. (arXiv:2110.08244v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.08244">
<div class="article-summary-box-inner">
<span><p>In this work, we perform semantic segmentation of multiple defect types in
electron microscopy images of irradiated FeCrAl alloys using a deep learning
Mask Regional Convolutional Neural Network (Mask R-CNN) model. We conduct an
in-depth analysis of key model performance statistics, with a focus on
quantities such as predicted distributions of defect shapes, defect sizes, and
defect areal densities relevant to informing modeling and understanding of
irradiated Fe-based materials properties. To better understand the performance
and present limitations of the model, we provide examples of useful evaluation
tests which include a suite of random splits, and dataset size-dependent and
domain-targeted cross validation tests. Overall, we find that the current model
is a fast, effective tool for automatically characterizing and quantifying
multiple defect types in microscopy images, with a level of accuracy on par
with human domain expert labelers. More specifically, the model can achieve
average defect identification F1 scores as high as 0.8, and, based on random
cross validation, have low overall average (+/- standard deviation) defect size
and density percentage errors of 7.3 (+/- 3.8)% and 12.7 (+/- 5.3)%,
respectively. Further, our model predicts the expected material hardening to
within 10-20 MPa (about 10% of total hardening), which is about the same error
level as experiments. Our targeted evaluation tests also suggest the best path
toward improving future models is not expanding existing databases with more
labeled images but instead data additions that target weak points of the model
domain, such as images from different microscopes, imaging conditions,
irradiation environments, and alloy types. Finally, we discuss the first phase
of an effort to provide an easy-to-use, open-source object detection tool to
the broader community for identifying defects in new images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Stream Dynamic Video Summarization. (arXiv:1812.00108v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1812.00108">
<div class="article-summary-box-inner">
<span><p>With vast amounts of video content being uploaded to the Internet every
minute, video summarization becomes critical for efficient browsing, searching,
and indexing of visual content. Nonetheless, the spread of social and
egocentric cameras creates an abundance of sparse scenarios captured by several
devices, and ultimately required to be jointly summarized. In this paper, we
discuss the problem of summarizing videos recorded independently by several
dynamic cameras that intermittently share the field of view. We present a
robust framework that (a) identifies a diverse set of important events among
moving cameras that often are not capturing the same scene, and (b) selects the
most representative view(s) at each event to be included in a universal
summary. Due to the lack of an applicable alternative, we collected a new
multi-view egocentric dataset, Multi-Ego. Our dataset is recorded
simultaneously by three cameras, covering a wide variety of real-life
scenarios. The footage is annotated by multiple individuals under various
summarization configurations, with a consensus analysis ensuring a reliable
ground truth. We conduct extensive experiments on the compiled dataset in
addition to three other standard benchmarks that show the robustness and the
advantage of our approach in both supervised and unsupervised settings.
Additionally, we show that our approach learns collectively from data of varied
number-of-views and orthogonal to other summarization methods, deeming it
scalable and generic.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On-the-fly Global Embeddings Using Random Projections for Extreme Multi-label Classification. (arXiv:1912.08140v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.08140">
<div class="article-summary-box-inner">
<span><p>The goal of eXtreme Multi-label Learning (XML) is to automatically annotate a
given data point with the most relevant subset of labels from an extremely
large vocabulary of labels (e.g., a million labels). Lately, many attempts have
been made to address this problem that achieve reasonable performance on
benchmark datasets. In this paper, rather than coming-up with an altogether new
method, our objective is to present and validate a simple baseline for this
task. Precisely, we investigate an on-the-fly global and structure preserving
feature embedding technique using random projections whose learning phase is
independent of training samples and label vocabulary. Further, we show how an
ensemble of multiple such learners can be used to achieve further boost in
prediction accuracy with only linear increase in training and prediction time.
Experiments on three public XML benchmarks show that the proposed approach
obtains competitive accuracy compared with many existing methods. Additionally,
it also provides around 6572x speed-up ratio in terms of training time and
around 14.7x reduction in model-size compared to the closest competitors on the
largest publicly available dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KiU-Net: Overcomplete Convolutional Architectures for Biomedical Image and Volumetric Segmentation. (arXiv:2010.01663v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01663">
<div class="article-summary-box-inner">
<span><p>Most methods for medical image segmentation use U-Net or its variants as they
have been successful in most of the applications. After a detailed analysis of
these "traditional" encoder-decoder based approaches, we observed that they
perform poorly in detecting smaller structures and are unable to segment
boundary regions precisely. This issue can be attributed to the increase in
receptive field size as we go deeper into the encoder. The extra focus on
learning high level features causes the U-Net based approaches to learn less
information about low-level features which are crucial for detecting small
structures. To overcome this issue, we propose using an overcomplete
convolutional architecture where we project our input image into a higher
dimension such that we constrain the receptive field from increasing in the
deep layers of the network. We design a new architecture for image
segmentation- KiU-Net which has two branches: (1) an overcomplete convolutional
network Kite-Net which learns to capture fine details and accurate edges of the
input, and (2) U-Net which learns high level features. Furthermore, we also
propose KiU-Net 3D which is a 3D convolutional architecture for volumetric
segmentation. We perform a detailed study of KiU-Net by performing experiments
on five different datasets covering various image modalities like ultrasound
(US), magnetic resonance imaging (MRI), computed tomography (CT), microscopic
and fundus images. The proposed method achieves a better performance as
compared to all the recent methods with an additional benefit of fewer
parameters and faster convergence. Additionally, we also demonstrate that the
extensions of KiU-Net based on residual blocks and dense blocks result in
further performance improvements. The implementation of KiU-Net can be found
here: https://github.com/jeya-maria-jose/KiU-Net-pytorch
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hyperspectral Image Classification -- Traditional to Deep Models: A Survey for Future Prospects. (arXiv:2101.06116v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06116">
<div class="article-summary-box-inner">
<span><p>Hyperspectral Imaging (HSI) has been extensively utilized in many real-life
applications because it benefits from the detailed spectral information
contained in each pixel. Notably, the complex characteristics i.e., the
nonlinear relation among the captured spectral information and the
corresponding object of HSI data make accurate classification challenging for
traditional methods. In the last few years, Deep Learning (DL) has been
substantiated as a powerful feature extractor that effectively addresses the
nonlinear problems that appeared in a number of computer vision tasks. This
prompts the deployment of DL for HSI classification (HSIC) which revealed good
performance. This survey enlists a systematic overview of DL for HSIC and
compared state-of-the-art strategies of the said topic. Primarily, we will
encapsulate the main challenges of traditional machine learning for HSIC and
then we will acquaint the superiority of DL to address these problems. This
survey breakdown the state-of-the-art DL frameworks into spectral-features,
spatial-features, and together spatial-spectral features to systematically
analyze the achievements (future research directions as well) of these
frameworks for HSIC. Moreover, we will consider the fact that DL requires a
large number of labeled training examples whereas acquiring such a number for
HSIC is challenging in terms of time and cost. Therefore, this survey discusses
some strategies to improve the generalization performance of DL strategies
which can provide some future guidelines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sandwich Batch Normalization: A Drop-In Replacement for Feature Distribution Heterogeneity. (arXiv:2102.11382v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11382">
<div class="article-summary-box-inner">
<span><p>We present Sandwich Batch Normalization (SaBN), a frustratingly easy
improvement of Batch Normalization (BN) with only a few lines of code changes.
SaBN is motivated by addressing the inherent feature distribution heterogeneity
that one can be identified in many tasks, which can arise from data
heterogeneity (multiple input domains) or model heterogeneity (dynamic
architectures, model conditioning, etc.). Our SaBN factorizes the BN affine
layer into one shared sandwich affine layer, cascaded by several parallel
independent affine layers. Concrete analysis reveals that, during optimization,
SaBN promotes balanced gradient norms while still preserving diverse gradient
directions -- a property that many application tasks seem to favor. We
demonstrate the prevailing effectiveness of SaBN as a drop-in replacement in
four tasks: conditional image generation, neural architecture search (NAS),
adversarial training, and arbitrary style transfer. Leveraging SaBN immediately
achieves better Inception Score and FID on CIFAR-10 and ImageNet conditional
image generation with three state-of-the-art GANs; boosts the performance of a
state-of-the-art weight-sharing NAS algorithm significantly on NAS-Bench-201;
substantially improves the robust and standard accuracies for adversarial
defense; and produces superior arbitrary stylized results. We also provide
visualizations and analysis to help understand why SaBN works. Codes are
available at: https://github.com/VITA-Group/Sandwich-Batch-Normalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Collapsible Linear Blocks for Super-Efficient Super Resolution. (arXiv:2103.09404v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09404">
<div class="article-summary-box-inner">
<span><p>With the advent of smart devices that support 4K and 8K resolution, Single
Image Super Resolution (SISR) has become an important computer vision problem.
However, most super resolution deep networks are computationally very
expensive. In this paper, we propose Super-Efficient Super Resolution (SESR)
networks that establish a new state-of-the-art for efficient super resolution.
Our approach is based on linear overparameterization of CNNs and creates an
efficient model architecture for SISR. With theoretical analysis, we uncover
the limitations of existing overparameterization methods and show how the
proposed method alleviates them. Detailed experiments across six benchmark
datasets demonstrate that SESR achieves similar or better image quality than
state-of-the-art models while requiring 2x to 330x fewer Multiply-Accumulate
(MAC) operations. As a result, SESR can be used on constrained hardware to
perform x2 (1080p to 4K) and x4 (1080p to 8K) SISR. Towards this, we simulate
hardware performance numbers for a commercial mobile Neural Processing Unit
(NPU) for 1080p to 4K (x2) and 1080p to 8K (x4) SISR. Our results highlight the
challenges faced by super resolution on AI accelerators and demonstrate that
SESR is significantly faster (e.g., 6x-8x higher FPS) than existing models on
mobile-NPUs. The code for this work is available at
https://github.com/ARM-software/sesr.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Adversarial Robustness of Vision Transformers. (arXiv:2103.15670v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15670">
<div class="article-summary-box-inner">
<span><p>Following the success in advancing natural language processing and
understanding, transformers are expected to bring revolutionary changes to
computer vision. This work provides the first and comprehensive study on the
robustness of vision transformers (ViTs) against adversarial perturbations.
Tested on various white-box and transfer attack settings, we find that ViTs
possess better adversarial robustness when compared with convolutional neural
networks (CNNs). This observation also holds for certified robustness. We
summarize the following main observations contributing to the improved
robustness of ViTs:
</p>
<p>1) Features learned by ViTs contain less low-level information and are more
generalizable, which contributes to superior robustness against adversarial
perturbations.
</p>
<p>2) Introducing convolutional or tokens-to-token blocks for learning low-level
features in ViTs can improve classification accuracy but at the cost of
adversarial robustness.
</p>
<p>3) Increasing the proportion of transformers in the model structure (when the
model consists of both transformer and CNN blocks) leads to better robustness.
But for a pure transformer model, simply increasing the size or adding layers
cannot guarantee a similar effect.
</p>
<p>4) Pre-training on larger datasets does not significantly improve adversarial
robustness though it is critical for training ViTs.
</p>
<p>5) Adversarial training is also applicable to ViT for training robust models.
</p>
<p>Furthermore, feature visualization and frequency analysis are conducted for
explanation. The results show that ViTs are less sensitive to high-frequency
perturbations than CNNs and there is a high correlation between how well the
model learns low-level features and its robustness against different
frequency-based perturbations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SOON: Scenario Oriented Object Navigation with Graph-based Exploration. (arXiv:2103.17138v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.17138">
<div class="article-summary-box-inner">
<span><p>The ability to navigate like a human towards a language-guided target from
anywhere in a 3D embodied environment is one of the 'holy grail' goals of
intelligent robots. Most visual navigation benchmarks, however, focus on
navigating toward a target from a fixed starting point, guided by an elaborate
set of instructions that depicts step-by-step. This approach deviates from
real-world problems in which human-only describes what the object and its
surrounding look like and asks the robot to start navigation from anywhere.
Accordingly, in this paper, we introduce a Scenario Oriented Object Navigation
(SOON) task. In this task, an agent is required to navigate from an arbitrary
position in a 3D embodied environment to localize a target following a scene
description. To give a promising direction to solve this task, we propose a
novel graph-based exploration (GBE) method, which models the navigation state
as a graph and introduces a novel graph-based exploration approach to learn
knowledge from the graph and stabilize training by learning sub-optimal
trajectories. We also propose a new large-scale benchmark named From Anywhere
to Object (FAO) dataset. To avoid target ambiguity, the descriptions in FAO
provide rich semantic scene information includes: object attribute, object
relationship, region description, and nearby region description. Our
experiments reveal that the proposed GBE outperforms various state-of-the-arts
on both FAO and R2R datasets. And the ablation studies on FAO validates the
quality of the dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hypercorrelation Squeeze for Few-Shot Segmentation. (arXiv:2104.01538v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01538">
<div class="article-summary-box-inner">
<span><p>Few-shot semantic segmentation aims at learning to segment a target object
from a query image using only a few annotated support images of the target
class. This challenging task requires to understand diverse levels of visual
cues and analyze fine-grained correspondence relations between the query and
the support images. To address the problem, we propose Hypercorrelation Squeeze
Networks (HSNet) that leverages multi-level feature correlation and efficient
4D convolutions. It extracts diverse features from different levels of
intermediate convolutional layers and constructs a collection of 4D correlation
tensors, i.e., hypercorrelations. Using efficient center-pivot 4D convolutions
in a pyramidal architecture, the method gradually squeezes high-level semantic
and low-level geometric cues of the hypercorrelation into precise segmentation
masks in coarse-to-fine manner. The significant performance improvements on
standard few-shot segmentation benchmarks of PASCAL-5i, COCO-20i, and FSS-1000
verify the efficacy of the proposed method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Joint Representation Learning and Novel Category Discovery on Single- and Multi-modal Data. (arXiv:2104.12673v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12673">
<div class="article-summary-box-inner">
<span><p>This paper studies the problem of novel category discovery on single- and
multi-modal data with labels from different but relevant categories. We present
a generic, end-to-end framework to jointly learn a reliable representation and
assign clusters to unlabelled data. To avoid over-fitting the learnt embedding
to labelled data, we take inspiration from self-supervised representation
learning by noise-contrastive estimation and extend it to jointly handle
labelled and unlabelled data. In particular, we propose using category
discrimination on labelled data and cross-modal discrimination on multi-modal
data to augment instance discrimination used in conventional contrastive
learning approaches. We further employ Winner-Take-All (WTA) hashing algorithm
on the shared representation space to generate pairwise pseudo labels for
unlabelled data to better predict cluster assignments. We thoroughly evaluate
our framework on large-scale multi-modal video benchmarks Kinetics-400 and
VGG-Sound, and image benchmarks CIFAR10, CIFAR100 and ImageNet, obtaining
state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning. (arXiv:2105.04906v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04906">
<div class="article-summary-box-inner">
<span><p>Recent self-supervised methods for image representation learning are based on
maximizing the agreement between embedding vectors from different views of the
same image. A trivial solution is obtained when the encoder outputs constant
vectors. This collapse problem is often avoided through implicit biases in the
learning architecture, that often lack a clear justification or interpretation.
In this paper, we introduce VICReg (Variance-Invariance-Covariance
Regularization), a method that explicitly avoids the collapse problem with a
simple regularization term on the variance of the embeddings along each
dimension individually. VICReg combines the variance term with a decorrelation
mechanism based on redundancy reduction and covariance regularization, and
achieves results on par with the state of the art on several downstream tasks.
In addition, we show that incorporating our new variance term into other
methods helps stabilize the training and leads to performance improvements.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LuvHarris: A Practical Corner Detector for Event-cameras. (arXiv:2105.11443v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11443">
<div class="article-summary-box-inner">
<span><p>There have been a number of corner detection methods proposed for event
cameras in the last years, since event-driven computer vision has become more
accessible. Current state-of-the-art have either unsatisfactory accuracy or
real-time performance when considered for practical use, for example when a
camera is randomly moved in an unconstrained environment. In this paper, we
present yet another method to perform corner detection, dubbed look-up
event-Harris (luvHarris), that employs the Harris algorithm for high accuracy
but manages an improved event throughput. Our method has two major
contributions, 1. a novel "threshold ordinal event-surface" that removes
certain tuning parameters and is well suited for Harris operations, and 2. an
implementation of the Harris algorithm such that the computational load per
event is minimised and computational heavy convolutions are performed only
"as-fast-as-possible", i.e. only as computational resources are available. The
result is a practical, real-time, and robust corner detector that runs more
than 2.6x the speed of current state-of-the-art; a necessity when using
high-resolution event-camera in real-time. We explain the considerations taken
for the approach, compare the algorithm to current state-of-the-art in terms of
computational performance and detection accuracy, and discuss the validity of
the proposed approach for event cameras.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ImVoxelNet: Image to Voxels Projection for Monocular and Multi-View General-Purpose 3D Object Detection. (arXiv:2106.01178v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01178">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce the task of multi-view RGB-based 3D object
detection as an end-to-end optimization problem. To address this problem, we
propose ImVoxelNet, a novel fully convolutional method of 3D object detection
based on monocular or multi-view RGB images. The number of monocular images in
each multi-view input can variate during training and inference; actually, this
number might be unique for each multi-view input. ImVoxelNet successfully
handles both indoor and outdoor scenes, which makes it general-purpose.
Specifically, it achieves state-of-the-art results in car detection on KITTI
(monocular) and nuScenes (multi-view) benchmarks among all methods that accept
RGB images. Moreover, it surpasses existing RGB-based 3D object detection
methods on the SUN RGB-D dataset. On ScanNet, ImVoxelNet sets a new benchmark
for multi-view 3D object detection. The source code and the trained models are
available at https://github.com/saic-vul/imvoxelnet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Neural Network Robustness via Persistency of Excitation. (arXiv:2106.02078v5 [stat.ML] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02078">
<div class="article-summary-box-inner">
<span><p>Improving adversarial robustness of neural networks remains a major
challenge. Fundamentally, training a neural network via gradient descent is a
parameter estimation problem. In adaptive control, maintaining persistency of
excitation (PoE) is integral to ensuring convergence of parameter estimates in
dynamical systems to their true values. We show that parameter estimation with
gradient descent can be modeled as a sampling of an adaptive linear
time-varying continuous system. Leveraging this model, and with inspiration
from Model-Reference Adaptive Control (MRAC), we prove a sufficient condition
to constrain gradient descent updates to reference persistently excited
trajectories converging to the true parameters. The sufficient condition is
achieved when the learning rate is less than the inverse of the Lipschitz
constant of the gradient of loss function. We provide an efficient technique
for estimating the corresponding Lipschitz constant in practice using extreme
value theory. Our experimental results in both standard and adversarial
training illustrate that networks trained with the PoE-motivated learning rate
schedule have similar clean accuracy but are significantly more robust to
adversarial attacks than models trained using current state-of-the-art
heuristics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ParticleAugment: Sampling-Based Data Augmentation. (arXiv:2106.08693v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08693">
<div class="article-summary-box-inner">
<span><p>We present an automated data augmentation approach for image classification.
We formulate the problem as Monte Carlo sampling where our goal is to
approximate the optimal augmentation policies. We propose a particle filtering
scheme for the policy search where the probability of applying a set of
augmentation operations forms the state of the filter. We measure the policy
performance based on the loss function difference between a reference and the
actual model, which we afterwards use to re-weight the particles and finally
update the policy. In our experiments, we show that our formulation for
automated augmentation reaches promising results on CIFAR-10, CIFAR-100, and
ImageNet datasets using the standard network architectures for this problem. By
comparing with the related work, our method reaches a balance between the
computational cost of policy search and the model performance. Our code will be
made publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Toward Affective XAI: Facial Affect Analysis for Understanding Explainable Human-AI Interactions. (arXiv:2106.08761v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08761">
<div class="article-summary-box-inner">
<span><p>As machine learning approaches are increasingly used to augment human
decision-making, eXplainable Artificial Intelligence (XAI) research has
explored methods for communicating system behavior to humans. However, these
approaches often fail to account for the emotional responses of humans as they
interact with explanations. Facial affect analysis, which examines human facial
expressions of emotions, is one promising lens for understanding how users
engage with explanations. Therefore, in this work, we aim to (1) identify which
facial affect features are pronounced when people interact with XAI interfaces,
and (2) develop a multitask feature embedding for linking facial affect signals
with participants' use of explanations. Our analyses and results show that the
occurrence and values of facial AU1 and AU4, and Arousal are heightened when
participants fail to use explanations effectively. This suggests that facial
affect analysis should be incorporated into XAI to personalize explanations to
individuals' interaction styles and to adapt explanations based on the
difficulty of the task performed.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PICCOLO: Point Cloud-Centric Omnidirectional Localization. (arXiv:2108.06545v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06545">
<div class="article-summary-box-inner">
<span><p>We present PICCOLO, a simple and efficient algorithm for omnidirectional
localization. Given a colored point cloud and a 360 panorama image of a scene,
our objective is to recover the camera pose at which the panorama image is
taken. Our pipeline works in an off-the-shelf manner with a single image given
as a query and does not require any training of neural networks or collecting
ground-truth poses of images. Instead, we match each point cloud color to the
holistic view of the panorama image with gradient-descent optimization to find
the camera pose. Our loss function, called sampling loss, is point
cloud-centric, evaluated at the projected location of every point in the point
cloud. In contrast, conventional photometric loss is image-centric, comparing
colors at each pixel location. With a simple change in the compared entities,
sampling loss effectively overcomes the severe visual distortion of
omnidirectional images, and enjoys the global context of the 360 view to handle
challenging scenarios for visual localization. PICCOLO outperforms existing
omnidirectional localization algorithms in both accuracy and stability when
evaluated in various environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">edge-SR: Super-Resolution For The Masses. (arXiv:2108.10335v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10335">
<div class="article-summary-box-inner">
<span><p>Classic image scaling (e.g. bicubic) can be seen as one convolutional layer
and a single upscaling filter. Its implementation is ubiquitous in all display
devices and image processing software. In the last decade deep learning systems
have been introduced for the task of image super-resolution (SR), using several
convolutional layers and numerous filters. These methods have taken over the
benchmarks of image quality for upscaling tasks. Would it be possible to
replace classic upscalers with deep learning architectures on edge devices such
as display panels, tablets, laptop computers, etc.? On one hand, the current
trend in Edge-AI chips shows a promising future in this direction, with rapid
development of hardware that can run deep-learning tasks efficiently. On the
other hand, in image SR only few architectures have pushed the limit to extreme
small sizes that can actually run on edge devices at real-time. We explore
possible solutions to this problem with the aim to fill the gap between classic
upscalers and small deep learning configurations. As a transition from classic
to deep-learning upscaling we propose edge-SR (eSR), a set of one-layer
architectures that use interpretable mechanisms to upscale images. Certainly, a
one-layer architecture cannot reach the quality of deep learning systems.
Nevertheless, we find that for high speed requirements, eSR becomes better at
trading-off image quality and runtime performance. Filling the gap between
classic and deep-learning architectures for image upscaling is critical for
massive adoption of this technology. It is equally important to have an
interpretable system that can reveal the inner strategies to solve this problem
and guide us to future improvements and better understanding of larger
networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic labelling of urban point clouds using data fusion. (arXiv:2108.13757v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13757">
<div class="article-summary-box-inner">
<span><p>In this paper we describe an approach to semi-automatically create a labelled
dataset for semantic segmentation of urban street-level point clouds. We use
data fusion techniques using public data sources such as elevation data and
large-scale topographical maps to automatically label parts of the point cloud,
after which only limited human effort is needed to check the results and make
amendments where needed. This drastically limits the time needed to create a
labelled dataset that is extensive enough to train deep semantic segmentation
models. We apply our method to point clouds of the Amsterdam region, and
successfully train a RandLA-Net semantic segmentation model on the labelled
dataset. These results demonstrate the potential of smart data fusion and
semantic segmentation for the future of smart city planning and management.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conditional Extreme Value Theory for Open Set Video Domain Adaptation. (arXiv:2109.00522v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00522">
<div class="article-summary-box-inner">
<span><p>With the advent of media streaming, video action recognition has become
progressively important for various applications, yet at the high expense of
requiring large-scale data labelling. To overcome the problem of expensive data
labelling, domain adaptation techniques have been proposed that transfers
knowledge from fully labelled data (i.e., source domain) to unlabelled data
(i.e., target domain). The majority of video domain adaptation algorithms are
proposed for closed-set scenarios in which all the classes are shared among the
domains. In this work, we propose an open-set video domain adaptation approach
to mitigate the domain discrepancy between the source and target data, allowing
the target data to contain additional classes that do not belong to the source
domain. Different from previous works, which only focus on improving accuracy
for shared classes, we aim to jointly enhance the alignment of shared classes
and recognition of unknown samples. Towards this goal, class-conditional
extreme value theory is applied to enhance the unknown recognition.
Specifically, the entropy values of target samples are modelled as generalised
extreme value distributions, which allows separating unknown samples lying in
the tail of the distribution. To alleviate the negative transfer issue, weights
computed by the distance from the sample entropy to the threshold are leveraged
in adversarial learning in the sense that confident source and target samples
are aligned, and unconfident samples are pushed away. The proposed method has
been thoroughly evaluated on both small-scale and large-scale cross-domain
video datasets and achieved the state-of-the-art performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Oriented Object Detection in Aerial Images Based on Area Ratio of Parallelogram. (arXiv:2109.10187v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10187">
<div class="article-summary-box-inner">
<span><p>Rotated object detection is a challenging task in aerial images since the
objects in aerial images are displayed in arbitrary directions and are
frequently densely packed. Although considerable progress has been made, there
are still challenges that existing regression-based rotation detectors suffer
from the representation ambiguity. In this paper, we propose a simple,
practical framework to optimize the bounding box regression for rotating
objects. Rather than directly regressing the five parameters (coordinates of
the central point, width, height, and rotation angle) or the four vertices, we
employ the area ratio of the parallelogram (ARP) to describe a multi-oriented
object accurately. Specifically, ARP regresses coordinates of the center point,
height, and width of the oriented object's minimum circumscribed rectangle and
three area ratios. It may facilitate learning offset and avoid the issue of
angular periodicity or label points sequence for oriented objects. To further
remedy the confusion issue of nearly horizontal objects, the area ratio between
the object and its minimal circumscribed rectangle has been used to guide the
selection of horizontal or oriented detection for each object. The rotation
efficient IOU loss (R-EIOU) connects the flat bounding box with the three area
ratios and improves the accuracy of the rotating bounding. Experimental results
on remote sensing datasets, including HRSC2016, DOTA, and UCAS-AOD, show that
our method achieves superior detection performance than many state-of-the-art
approaches. The code and model will be coming with the paper published.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mixed-supervised segmentation: Confidence maximization helps knowledge distillation. (arXiv:2109.10902v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.10902">
<div class="article-summary-box-inner">
<span><p>Despite achieving promising results in a breadth of medical image
segmentation tasks, deep neural networks require large training datasets with
pixel-wise annotations. Obtaining these curated datasets is a cumbersome
process which limits the application in scenarios where annotated images are
scarce. Mixed supervision is an appealing alternative for mitigating this
obstacle, where only a small fraction of the data contains complete pixel-wise
annotations and other images have a weaker form of supervision. In this work,
we propose a dual-branch architecture, where the upper branch (teacher)
receives strong annotations, while the bottom one (student) is driven by
limited supervision and guided by the upper branch. Combined with a standard
cross-entropy loss over the labeled pixels, our novel formulation integrates
two important terms: (i) a Shannon entropy loss defined over the
less-supervised images, which encourages confident student predictions in the
bottom branch; and (ii) a Kullback-Leibler (KL) divergence term, which
transfers the knowledge of the strongly supervised branch to the
less-supervised branch and guides the entropy (student-confidence) term to
avoid trivial solutions. We show that the synergy between the entropy and KL
divergence yields substantial improvements in performance. We also discuss an
interesting link between Shannon-entropy minimization and standard pseudo-mask
generation, and argue that the former should be preferred over the latter for
leveraging information from unlabeled pixels. Quantitative and qualitative
results on two publicly available datasets demonstrate that our method
significantly outperforms other strategies for semantic segmentation within a
mixed-supervision framework, as well as recent semi-supervised approaches.
Moreover, we show that the branch trained with reduced supervision and guided
by the top branch largely outperforms the latter.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Real-Time Tactile Grasp Force Sensing Using Fingernail Imaging via Deep Neural Networks. (arXiv:2109.15231v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.15231">
<div class="article-summary-box-inner">
<span><p>This paper has introduced a novel approach for the real-time estimation of 3D
tactile forces exerted by human fingertips via vision only. The introduced
approach is entirely monocular vision-based and does not require any physical
force sensor. Therefore, it is scalable, non-intrusive, and easily fused with
other perception systems such as body pose estimation, making it ideal for HRI
applications where force sensing is necessary. The introduced approach consists
of three main modules: finger tracking for detection and tracking of each
individual finger, image alignment for preserving the spatial information in
the images, and the force model for estimating the 3D forces from coloration
patterns in the images. The model has been implemented experimentally, and the
results have shown a maximum RMS error of 8.4% (for the entire range of force
levels) along all three directions. The estimation accuracy is comparable to
the offline models in the literature, such as EigneNail, while, this model is
capable of performing force estimation at 30 frames per second.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TEACh: Task-driven Embodied Agents that Chat. (arXiv:2110.00534v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.00534">
<div class="article-summary-box-inner">
<span><p>Robots operating in human spaces must be able to engage in natural language
interaction with people, both understanding and executing instructions, and
using conversation to resolve ambiguity and recover from mistakes. To study
this, we introduce TEACh, a dataset of over 3,000 human--human, interactive
dialogues to complete household tasks in simulation. A Commander with access to
oracle information about a task communicates in natural language with a
Follower. The Follower navigates through and interacts with the environment to
complete tasks varying in complexity from "Make Coffee" to "Prepare Breakfast",
asking questions and getting additional information from the Commander. We
propose three benchmarks using TEACh to study embodied intelligence challenges,
and we evaluate initial models' abilities in dialogue understanding, language
grounding, and task execution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HDR-cGAN: Single LDR to HDR Image Translation using Conditional GAN. (arXiv:2110.01660v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.01660">
<div class="article-summary-box-inner">
<span><p>The prime goal of digital imaging techniques is to reproduce the realistic
appearance of a scene. Low Dynamic Range (LDR) cameras are incapable of
representing the wide dynamic range of the real-world scene. The captured
images turn out to be either too dark (underexposed) or too bright
(overexposed). Specifically, saturation in overexposed regions makes the task
of reconstructing a High Dynamic Range (HDR) image from single LDR image
challenging. In this paper, we propose a deep learning based approach to
recover details in the saturated areas while reconstructing the HDR image. We
formulate this problem as an image-to-image (I2I) translation task. To this
end, we present a novel conditional GAN (cGAN) based framework trained in an
end-to-end fashion over the HDR-REAL and HDR-SYNTH datasets. Our framework uses
an overexposed mask obtained from a pre-trained segmentation model to
facilitate the hallucination task of adding details in the saturated regions.
We demonstrate the effectiveness of the proposed method by performing an
extensive quantitative and qualitative comparison with several state-of-the-art
single-image HDR reconstruction techniques.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantum pixel representations and compression for $N$-dimensional images. (arXiv:2110.04405v2 [quant-ph] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.04405">
<div class="article-summary-box-inner">
<span><p>We introduce a novel and uniform framework for quantum pixel representations
that overarches many of the most popular representations proposed in the recent
literature, such as (I)FRQI, (I)NEQR, MCRQI, and (I)NCQI. The proposed QPIXL
framework results in more efficient circuit implementations and significantly
reduces the gate complexity for all considered quantum pixel representations.
Our method only requires a linear number of gates in terms of the number of
pixels and does not use ancilla qubits. Furthermore, the circuits only consist
of Ry gates and CNOT gates making them practical in the NISQ era. Additionally,
we propose a circuit and image compression algorithm that is shown to be highly
effective, being able to reduce the necessary gates to prepare an FRQI state
for example scientific images by up to 90% without sacrificing image quality.
Our algorithms are made publicly available as part of QPIXL++, a Quantum Image
Pixel Library.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learnable Adaptive Cosine Estimator (LACE) for Image Classification. (arXiv:2110.05324v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.05324">
<div class="article-summary-box-inner">
<span><p>In this work, we propose a new loss to improve feature discriminability and
classification performance. Motivated by the adaptive cosine/coherence
estimator (ACE), our proposed method incorporates angular information that is
inherently learned by artificial neural networks. Our learnable ACE (LACE)
transforms the data into a new "whitened" space that improves the inter-class
separability and intra-class compactness. We compare our LACE to alternative
state-of-the art softmax-based and feature regularization approaches. Our
results show that the proposed method can serve as a viable alternative to
cross entropy and angular softmax approaches. Our code is publicly available:
https://github.com/GatorSense/LACE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Well-classified Examples are Underestimated in Classification with Deep Neural Networks. (arXiv:2110.06537v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06537">
<div class="article-summary-box-inner">
<span><p>The conventional wisdom behind learning deep classification models is to
focus on bad-classified examples and ignore well-classified examples that are
far from the decision boundary. For instance, when training with cross-entropy
loss, examples with higher likelihoods (i.e., well-classified examples)
contribute smaller gradients in back-propagation. However, we theoretically
show that this common practice hinders representation learning, energy
optimization, and the growth of margin. To counteract this deficiency, we
propose to reward well-classified examples with additive bonuses to revive
their contribution to learning. This counterexample theoretically addresses
these three issues. We empirically support this claim by directly verify the
theoretical results or through the significant performance improvement with our
counterexample on diverse tasks, including image classification, graph
classification, and machine translation. Furthermore, this paper shows that
because our idea can solve these three issues, we can deal with complex
scenarios, such as imbalanced classification, OOD detection, and applications
under adversarial attacks. Code is available at:
https://github.com/lancopku/well-classified-examples-are-underestimated.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do We Need to Directly Access the Source Datasets for Domain Generalization?. (arXiv:2110.06736v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06736">
<div class="article-summary-box-inner">
<span><p>Domain generalization (DG) aims to learn a generalizable model from multiple
known source domains for unknown target domains. Tremendous data distributed
across lots of places/devices nowadays that can not be directly accessed due to
privacy protection, especially in some crucial areas like finance and medical
care. However, most of the existing DG algorithms assume that all the source
datasets are accessible and can be mixed for domain-invariant semantics
extraction, which may fail in real-world applications. In this paper, we
introduce a challenging setting of training a generalizable model by using
distributed source datasets without directly accessing them. We propose a novel
method for this setting, which first trains a model on each source dataset and
then conduct data-free model fusion that fuses the trained models
layer-by-layer based on their semantic similarities, which aggregates different
levels of semantics from the distributed sources indirectly. The fused model is
then transmitted and trained on each dataset, we further introduce cross-layer
semantic calibration for domain-invariant semantics enhancement, which aligns
feature maps between the fused model and a fixed local model with an attention
mechanism. Extensive experiments on multiple DG datasets show the significant
performance of our method in tackling this challenging setting, which is even
on par or superior to the performance of the state-of-the-art DG approaches in
the standard DG setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Learning by Estimating Twin Class Distributions. (arXiv:2110.07402v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07402">
<div class="article-summary-box-inner">
<span><p>We present TWIST, a novel self-supervised representation learning method by
classifying large-scale unlabeled datasets in an end-to-end way. We employ a
siamese network terminated by a softmax operation to produce twin class
distributions of two augmented images. Without supervision, we enforce the
class distributions of different augmentations to be consistent. In the
meantime, we regularize the class distributions to make them sharp and diverse.
Specifically, we minimize the entropy of the distribution for each sample to
make the class prediction for each sample assertive and maximize the entropy of
the mean distribution to make the predictions of different samples diverse. In
this way, TWIST can naturally avoid the trivial solutions without specific
designs such as asymmetric network, stop-gradient operation, or momentum
encoder. Different from the clustering-based methods which alternate between
clustering and learning, our method is a single learning process guided by a
unified loss function. As a result, TWIST outperforms state-of-the-art methods
on a wide range of tasks, including unsupervised classification, linear
classification, semi-supervised learning, transfer learning, and some dense
prediction tasks such as detection and segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TDACNN: Target-domain-free Domain Adaptation Convolutional Neural Network for Drift Compensation in Gas Sensors. (arXiv:2110.07509v2 [q-bio.QM] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07509">
<div class="article-summary-box-inner">
<span><p>Sensor drift is a long-existing unpredictable problem that deteriorates the
performance of gaseous substance recognition, calling for an antidrift domain
adaptation algorithm. However, the prerequisite for traditional methods to
achieve fine results is to have data from both nondrift distributions (source
domain) and drift distributions (target domain) for domain alignment, which is
usually unrealistic and unachievable in real-life scenarios. To compensate for
this, in this paper, deep learning based on a target-domain-free domain
adaptation convolutional neural network (TDACNN) is proposed. The main concept
is that CNNs extract not only the domain-specific features of samples but also
the domain-invariant features underlying both the source and target domains.
Making full use of these various levels of embedding features can lead to
comprehensive utilization of different levels of characteristics, thus
achieving drift compensation by the extracted intermediate features between two
domains. In the TDACNN, a flexible multibranch backbone with a multiclassifier
structure is proposed under the guidance of bionics, which utilizes multiple
embedding features comprehensively without involving target domain data during
training. A classifier ensemble method based on maximum mean discrepancy (MMD)
is proposed to evaluate all the classifiers jointly based on the credibility of
the pseudolabel. To optimize network training, an additive angular margin
softmax loss with parameter dynamic adjustment is utilized. Experiments on two
drift datasets under different settings demonstrate the superiority of TDACNN
compared with several state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NeRS: Neural Reflectance Surfaces for Sparse-view 3D Reconstruction in the Wild. (arXiv:2110.07604v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07604">
<div class="article-summary-box-inner">
<span><p>Recent history has seen a tremendous growth of work exploring implicit
representations of geometry and radiance, popularized through Neural Radiance
Fields (NeRF). Such works are fundamentally based on a (implicit) volumetric
representation of occupancy, allowing them to model diverse scene structure
including translucent objects and atmospheric obscurants. But because the vast
majority of real-world scenes are composed of well-defined surfaces, we
introduce a surface analog of such implicit models called Neural Reflectance
Surfaces (NeRS). NeRS learns a neural shape representation of a closed surface
that is diffeomorphic to a sphere, guaranteeing water-tight reconstructions.
Even more importantly, surface parameterizations allow NeRS to learn (neural)
bidirectional surface reflectance functions (BRDFs) that factorize
view-dependent appearance into environmental illumination, diffuse color
(albedo), and specular "shininess." Finally, rather than illustrating our
results on synthetic scenes or controlled in-the-lab capture, we assemble a
novel dataset of multi-view images from online marketplaces for selling goods.
Such "in-the-wild" multi-view image sets pose a number of challenges, including
a small number of views with unknown/rough camera estimates. We demonstrate
that surface-based neural reconstructions enable learning from such data,
outperforming volumetric neural rendering-based reconstructions. We hope that
NeRS serves as a first step toward building scalable, high-quality libraries of
real-world shape, materials, and illumination. The project page with code and
video visualizations can be found at https://jasonyzhang.com/ners.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learn-to-Race: A Multimodal Control Environment for Autonomous Racing. (arXiv:2103.11575v3 [cs.RO] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11575">
<div class="article-summary-box-inner">
<span><p>Existing research on autonomous driving primarily focuses on urban driving,
which is insufficient for characterising the complex driving behaviour
underlying high-speed racing. At the same time, existing racing simulation
frameworks struggle in capturing realism, with respect to visual rendering,
vehicular dynamics, and task objectives, inhibiting the transfer of learning
agents to real-world contexts. We introduce a new environment, where agents
Learn-to-Race (L2R) in simulated competition-style racing, using multimodal
information--from virtual cameras to a comprehensive array of inertial
measurement sensors. Our environment, which includes a simulator and an
interfacing training framework, accurately models vehicle dynamics and racing
conditions. In this paper, we release the Arrival simulator for autonomous
racing. Next, we propose the L2R task with challenging metrics, inspired by
learning-to-drive challenges, Formula-style racing, and multimodal trajectory
prediction for autonomous driving. Additionally, we provide the L2R framework
suite, facilitating simulated racing on high-precision models of real-world
tracks. Finally, we provide an official L2R task dataset of expert
demonstrations, as well as a series of baseline experiments and reference
implementations. We make all code available:
https://github.com/learn-to-race/l2r.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Core Challenges in Embodied Vision-Language Planning. (arXiv:2106.13948v2 [cs.LG] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13948">
<div class="article-summary-box-inner">
<span><p>Recent advances in the areas of multimodal machine learning and artificial
intelligence (AI) have led to the development of challenging tasks at the
intersection of Computer Vision, Natural Language Processing, and Embodied AI.
Whereas many approaches and previous survey pursuits have characterised one or
two of these dimensions, there has not been a holistic analysis at the center
of all three. Moreover, even when combinations of these topics are considered,
more focus is placed on describing, e.g., current architectural methods, as
opposed to also illustrating high-level challenges and opportunities for the
field. In this survey paper, we discuss Embodied Vision-Language Planning
(EVLP) tasks, a family of prominent embodied navigation and manipulation
problems that jointly use computer vision and natural language. We propose a
taxonomy to unify these tasks and provide an in-depth analysis and comparison
of the new and current algorithmic approaches, metrics, simulated environments,
as well as the datasets used for EVLP tasks. Finally, we present the core
challenges that we believe new EVLP works should seek to address, and we
advocate for task construction that enables model generalizability and furthers
real-world deployment.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-10-18 23:02:37.369561831 UTC">2021-10-18 23:02:37 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>