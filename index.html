<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-09-06T01:30:00Z">09-06</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Challenges in Generalization in Open Domain Question Answering. (arXiv:2109.01156v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01156">
<div class="article-summary-box-inner">
<span><p>Recent work on Open Domain Question Answering has shown that there is a large
discrepancy in model performance between novel test questions and those that
largely overlap with training questions. However, it is as of yet unclear which
aspects of novel questions that make them challenging. Drawing upon studies on
systematic generalization, we introduce and annotate questions according to
three categories that measure different levels and kinds of generalization:
training set overlap, compositional generalization (comp-gen), and novel entity
generalization (novel-entity). When evaluating six popular parametric and
non-parametric models, we find that for the established Natural Questions and
TriviaQA datasets, even the strongest model performance for
comp-gen/novel-entity is 13.1/5.4% and 9.6/1.5% lower compared to that for the
full test set -- indicating the challenge posed by these types of questions.
Furthermore, we show that whilst non-parametric models can handle questions
containing novel entities, they struggle with those requiring compositional
generalization. Through thorough analysis we find that key question difficulty
factors are: cascading errors from the retrieval component, frequency of
question pattern, and frequency of the entity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Conformer: Progressive Downsampling and Grouped Attention for Automatic Speech Recognition. (arXiv:2109.01163v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01163">
<div class="article-summary-box-inner">
<span><p>The recently proposed Conformer architecture has shown state-of-the-art
performances in Automatic Speech Recognition by combining convolution with
attention to model both local and global dependencies. In this paper, we study
how to reduce the Conformer architecture complexity with a limited computing
budget, leading to a more efficient architecture design that we call Efficient
Conformer. We introduce progressive downsampling to the Conformer encoder and
propose a novel attention mechanism named grouped attention, allowing us to
reduce attention complexity from $O(n^{2}d)$ to $O(n^{2}d / g)$ for sequence
length $n$, hidden dimension $d$ and group size parameter $g$. We also
experiment the use of strided multi-head self-attention as a global
downsampling operation. Our experiments are performed on the LibriSpeech
dataset with CTC and RNN-Transducer losses. We show that within the same
computing budget, the proposed architecture achieves better performances with
faster training and decoding compared to the Conformer. Our 13M parameters CTC
model achieves competitive WERs of 3.6\%/9.0\% without using a language model
and 2.7\%/6.7\% with an external n-gram language model on the
test-clean/test-other sets while being 29\% faster than our CTC Conformer
baseline at inference and 36\% faster to train.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ranking Scientific Papers Using Preference Learning. (arXiv:2109.01190v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01190">
<div class="article-summary-box-inner">
<span><p>Peer review is the main quality control mechanism in academia. Quality of
scientific work has many dimensions; coupled with the subjective nature of the
reviewing task, this makes final decision making based on the reviews and
scores therein very difficult and time-consuming. To assist with this important
task, we cast it as a paper ranking problem based on peer review texts and
reviewer scores. We introduce a novel, multi-faceted generic evaluation
framework for making final decisions based on peer reviews that takes into
account effectiveness, efficiency and fairness of the evaluated system. We
propose a novel approach to paper ranking based on Gaussian Process Preference
Learning (GPPL) and evaluate it on peer review data from the ACL-2018
conference. Our experiments demonstrate the superiority of our GPPL-based
approach over prior work, while highlighting the importance of using both texts
and review scores for paper ranking during peer review aggregation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Establishing Interlingua in Multilingual Language Models. (arXiv:2109.01207v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01207">
<div class="article-summary-box-inner">
<span><p>Large multilingual language models show remarkable zero-shot cross-lingual
transfer performance on a range of tasks. Follow-up works hypothesized that
these models internally project representations of different languages into a
shared interlingual space. However, they produced contradictory results. In
this paper, we correct %one of the previous works the famous prior work
claiming that "BERT is not an Interlingua" and show that with the proper choice
of sentence representation different languages actually do converge to a shared
space in such language models. Furthermore, we demonstrate that this
convergence pattern is robust across four measures of correlation similarity
and six mBERT-like models. We then extend our analysis to 28 diverse languages
and find that the interlingual space exhibits a particular structure similar to
the linguistic relatedness of languages. We also highlight a few outlier
languages that seem to fail to converge to the shared space. The code for
replicating our results is available at the following URL:
https://github.com/maksym-del/interlingua.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantifying Reproducibility in NLP and ML. (arXiv:2109.01211v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01211">
<div class="article-summary-box-inner">
<span><p>Reproducibility has become an intensely debated topic in NLP and ML over
recent years, but no commonly accepted way of assessing reproducibility, let
alone quantifying it, has so far emerged. The assumption has been that wider
scientific reproducibility terminology and definitions are not applicable to
NLP/ML, with the result that many different terms and definitions have been
proposed, some diametrically opposed. In this paper, we test this assumption,
by taking the standard terminology and definitions from metrology and applying
them directly to NLP/ML. We find that we are able to straightforwardly derive a
practical framework for assessing reproducibility which has the desirable
property of yielding a quantified degree of reproducibility that is comparable
across different reproduction studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">So Cloze yet so Far: N400 Amplitude is Better Predicted by Distributional Information than Human Predictability Judgements. (arXiv:2109.01226v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01226">
<div class="article-summary-box-inner">
<span><p>More predictable words are easier to process - they are read faster and
elicit smaller neural signals associated with processing difficulty, most
notably, the N400 component of the event-related brain potential. Thus, it has
been argued that prediction of upcoming words is a key component of language
comprehension, and that studying the amplitude of the N400 is a valuable way to
investigate the predictions that we make. In this study, we investigate whether
the linguistic predictions of computational language models or humans better
reflect the way in which natural language stimuli modulate the amplitude of the
N400. One important difference in the linguistic predictions of humans versus
computational language models is that while language models base their
predictions exclusively on the preceding linguistic context, humans may rely on
other factors. We find that the predictions of three top-of-the-line
contemporary language models - GPT-3, RoBERTa, and ALBERT - match the N400 more
closely than human predictions. This suggests that the predictive processes
underlying the N400 may be more sensitive to the surface-level statistics of
language than previously thought.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Conditionality for Natural Language Generation. (arXiv:2109.01229v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01229">
<div class="article-summary-box-inner">
<span><p>Large scale pretrained language models have demonstrated state-of-the-art
performance in language understanding tasks. Their application has recently
expanded into multimodality learning, leading to improved representations
combining vision and language. However, progress in adapting language models
towards conditional Natural Language Generation (NLG) has been limited to a
single modality, generally text. We propose MAnTiS, Multimodal Adaptation for
Text Synthesis, a general approach for multimodal conditionality in
transformer-based NLG models. In this method, we pass inputs from each modality
through modality-specific encoders, project to textual token space, and finally
join to form a conditionality prefix. We fine-tune the pretrained language
model and encoders with the conditionality prefix guiding the generation. We
apply MAnTiS to the task of product description generation, conditioning a
network on both product images and titles to generate descriptive text. We
demonstrate that MAnTiS outperforms strong baseline approaches on standard NLG
scoring metrics. Furthermore, qualitative assessments demonstrate that MAnTiS
can generate human quality descriptions consistent with given multimodal
inputs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Study on Leveraging Position Embeddings for Target-oriented Opinion Words Extraction. (arXiv:2109.01238v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01238">
<div class="article-summary-box-inner">
<span><p>Target-oriented opinion words extraction (TOWE) (Fan et al., 2019b) is a new
subtask of target-oriented sentiment analysis that aims to extract opinion
words for a given aspect in text. Current state-of-the-art methods leverage
position embeddings to capture the relative position of a word to the target.
However, the performance of these methods depends on the ability to incorporate
this information into word representations. In this paper, we explore a variety
of text encoders based on pretrained word embeddings or language models that
leverage part-of-speech and position embeddings, aiming to examine the actual
contribution of each component in TOWE. We also adapt a graph convolutional
network (GCN) to enhance word representations by incorporating syntactic
information. Our experimental results demonstrate that BiLSTM-based models can
effectively encode position information into word representations while using a
GCN only achieves marginal gains. Interestingly, our simple methods outperform
several state-of-the-art complex neural structures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Entity Linking and Discovery via Arborescence-based Supervised Clustering. (arXiv:2109.01242v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01242">
<div class="article-summary-box-inner">
<span><p>Previous work has shown promising results in performing entity linking by
measuring not only the affinities between mentions and entities but also those
amongst mentions. In this paper, we present novel training and inference
procedures that fully utilize mention-to-mention affinities by building minimum
arborescences (i.e., directed spanning trees) over mentions and entities across
documents in order to make linking decisions. We also show that this method
gracefully extends to entity discovery, enabling the clustering of mentions
that do not have an associated entity in the knowledge base. We evaluate our
approach on the Zero-Shot Entity Linking dataset and MedMentions, the largest
publicly available biomedical dataset, and show significant improvements in
performance for both entity linking and discovery compared to identically
parameterized models. We further show significant efficiency improvements with
only a small loss in accuracy over previous work, which use more
computationally expensive models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Prompt-Based Models Really Understand the Meaning of their Prompts?. (arXiv:2109.01247v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01247">
<div class="article-summary-box-inner">
<span><p>Recently, a boom of papers have shown extraordinary progress in few-shot
learning with various prompt-based models. Such success can give the impression
that prompts help models to learn faster in the same way that humans learn
faster when provided with task instructions expressed in natural language. In
this study, we experiment with over 30 prompts manually written for natural
language inference (NLI). We find that models learn just as fast with many
prompts that are intentionally irrelevant or even pathologically misleading as
they do with instructively "good" prompts. Additionally, we find that model
performance is more dependent on the choice of the LM target words (a.k.a. the
"verbalizer" that converts LM vocabulary prediction to class labels) than on
the text of the prompt itself. In sum, we find little evidence that suggests
existing prompt-based models truly understand the meaning of their given
prompts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Context-Aware Hierarchical BERT Fusion Network for Multi-turn Dialog Act Detection. (arXiv:2109.01267v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01267">
<div class="article-summary-box-inner">
<span><p>The success of interactive dialog systems is usually associated with the
quality of the spoken language understanding (SLU) task, which mainly
identifies the corresponding dialog acts and slot values in each turn. By
treating utterances in isolation, most SLU systems often overlook the semantic
context in which a dialog act is expected. The act dependency between turns is
non-trivial and yet critical to the identification of the correct semantic
representations. Previous works with limited context awareness have exposed the
inadequacy of dealing with complexity in multiproned user intents, which are
subject to spontaneous change during turn transitions. In this work, we propose
to enhance SLU in multi-turn dialogs, employing a context-aware hierarchical
BERT fusion Network (CaBERT-SLU) to not only discern context information within
a dialog but also jointly identify multiple dialog acts and slots in each
utterance. Experimental results show that our approach reaches new
state-of-the-art (SOTA) performances in two complicated multi-turn dialogue
datasets with considerable improvements compared with previous methods, which
only consider single utterances for multiple intents and slot filling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Open-Source Dataset and A Multi-Task Model for Malay Named Entity Recognition. (arXiv:2109.01293v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01293">
<div class="article-summary-box-inner">
<span><p>Named entity recognition (NER) is a fundamental task of natural language
processing (NLP). However, most state-of-the-art research is mainly oriented to
high-resource languages such as English and has not been widely applied to
low-resource languages. In Malay language, relevant NER resources are limited.
In this work, we propose a dataset construction framework, which is based on
labeled datasets of homologous languages and iterative optimization, to build a
Malay NER dataset (MYNER) comprising 28,991 sentences (over 384 thousand
tokens). Additionally, to better integrate boundary information for NER, we
propose a multi-task (MT) model with a bidirectional revision (Bi-revision)
mechanism for Malay NER task. Specifically, an auxiliary task, boundary
detection, is introduced to improve NER training in both explicit and implicit
ways. Furthermore, a gated ignoring mechanism is proposed to conduct
conditional label transfer and alleviate error propagation by the auxiliary
task. Experimental results demonstrate that our model achieves comparable
results over baselines on MYNER. The dataset and the model in this paper would
be publicly released as a benchmark dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Information Symmetry Matters: A Modal-Alternating Propagation Network for Few-Shot Learning. (arXiv:2109.01295v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01295">
<div class="article-summary-box-inner">
<span><p>Semantic information provides intra-class consistency and inter-class
discriminability beyond visual concepts, which has been employed in Few-Shot
Learning (FSL) to achieve further gains. However, semantic information is only
available for labeled samples but absent for unlabeled samples, in which the
embeddings are rectified unilaterally by guiding the few labeled samples with
semantics. Therefore, it is inevitable to bring a cross-modal bias between
semantic-guided samples and nonsemantic-guided samples, which results in an
information asymmetry problem. To address this problem, we propose a
Modal-Alternating Propagation Network (MAP-Net) to supplement the absent
semantic information of unlabeled samples, which builds information symmetry
among all samples in both visual and semantic modalities. Specifically, the
MAP-Net transfers the neighbor information by the graph propagation to generate
the pseudo-semantics for unlabeled samples guided by the completed visual
relationships and rectify the feature embeddings. In addition, due to the large
discrepancy between visual and semantic modalities, we design a Relation
Guidance (RG) strategy to guide the visual relation vectors via semantics so
that the propagated information is more beneficial. Extensive experimental
results on three semantic-labeled datasets, i.e., Caltech-UCSD-Birds 200-2011,
SUN Attribute Database, and Oxford 102 Flower, have demonstrated that our
proposed method achieves promising performance and outperforms the
state-of-the-art approaches, which indicates the necessity of information
symmetry.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Indexing Context-Sensitive Reachability. (arXiv:2109.01321v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01321">
<div class="article-summary-box-inner">
<span><p>Many context-sensitive data flow analyses can be formulated as a variant of
the all-pairs Dyck-CFL reachability problem, which, in general, is of sub-cubic
time complexity and quadratic space complexity. Such high complexity
significantly limits the scalability of context-sensitive data flow analysis
and is not affordable for analyzing large-scale software. This paper presents
\textsc{Flare}, a reduction from the CFL reachability problem to the
conventional graph reachability problem for context-sensitive data flow
analysis. This reduction allows us to benefit from recent advances in
reachability indexing schemes, which often consume almost linear space for
answering reachability queries in almost constant time. We have applied our
reduction to a context-sensitive alias analysis and a context-sensitive
information-flow analysis for C/C++ programs. Experimental results on standard
benchmarks and open-source software demonstrate that we can achieve orders of
magnitude speedup at the cost of only moderate space to store the indexes. The
implementation of our approach is publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting Speaker Personas from Conversational Texts. (arXiv:2109.01330v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01330">
<div class="article-summary-box-inner">
<span><p>Personas are useful for dialogue response prediction. However, the personas
used in current studies are pre-defined and hard to obtain before a
conversation. To tackle this issue, we study a new task, named Speaker Persona
Detection (SPD), which aims to detect speaker personas based on the plain
conversational text. In this task, a best-matched persona is searched out from
candidates given the conversational text. This is a many-to-many semantic
matching task because both contexts and personas in SPD are composed of
multiple sentences. The long-term dependency and the dynamic redundancy among
these sentences increase the difficulty of this task. We build a dataset for
SPD, dubbed as Persona Match on Persona-Chat (PMPC). Furthermore, we evaluate
several baseline models and propose utterance-to-profile (U2P) matching
networks for this task. The U2P models operate at a fine granularity which
treat both contexts and personas as sets of multiple sequences. Then, each
sequence pair is scored and an interpretable overall score is obtained for a
context-persona pair through aggregation. Evaluation results show that the U2P
models outperform their baseline counterparts significantly.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Modeling, Lexical Translation, Reordering: The Training Process of NMT through the Lens of Classical SMT. (arXiv:2109.01396v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01396">
<div class="article-summary-box-inner">
<span><p>Differently from the traditional statistical MT that decomposes the
translation task into distinct separately learned components, neural machine
translation uses a single neural network to model the entire translation
process. Despite neural machine translation being de-facto standard, it is
still not clear how NMT models acquire different competences over the course of
training, and how this mirrors the different models in traditional SMT. In this
work, we look at the competences related to three core SMT components and find
that during training, NMT first focuses on learning target-side language
modeling, then improves translation quality approaching word-by-word
translation, and finally learns more complicated reordering patterns. We show
that this behavior holds for several models and language pairs. Additionally,
we explain how such an understanding of the training process can be useful in
practice and, as an example, show how it can be used to improve vanilla
non-autoregressive neural machine translation by guiding teacher model
selection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Exploratory Study on Utilising the Web of Linked Data for Product Data Mining. (arXiv:2109.01411v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01411">
<div class="article-summary-box-inner">
<span><p>The Linked Open Data practice has led to a significant growth of structured
data on the Web in the last decade. Such structured data describe real-world
entities in a machine-readable way, and have created an unprecedented
opportunity for research in the field of Natural Language Processing. However,
there is a lack of studies on how such data can be used, for what kind of
tasks, and to what extent they can be useful for these tasks. This work focuses
on the e-commerce domain to explore methods of utilising such structured data
to create language resources that may be used for product classification and
linking. We process billions of structured data points in the form of RDF
n-quads, to create multi-million words of product-related corpora that are
later used in three different ways for creating of language resources: training
word embedding models, continued pre-training of BERT-like language models, and
training Machine Translation models that are used as a proxy to generate
product-related keywords. Our evaluation on an extensive set of benchmarks
shows word embeddings to be the most reliable and consistent method to improve
the accuracy on both tasks (with up to 6.9 percentage points in macro-average
F1 on some datasets). The other two methods however, are not as useful. Our
analysis shows that this could be due to a number of reasons, including the
biased domain representation in the structured data and lack of vocabulary
coverage. We share our datasets and discuss how our lessons learned could be
taken forward to inform future research in this direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LG4AV: Combining Language Models and Graph Neural Networks for Author Verification. (arXiv:2109.01479v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01479">
<div class="article-summary-box-inner">
<span><p>The automatic verification of document authorships is important in various
settings. Researchers are for example judged and compared by the amount and
impact of their publications and public figures are confronted by their posts
on social media platforms. Therefore, it is important that authorship
information in frequently used web services and platforms is correct. The
question whether a given document is written by a given author is commonly
referred to as authorship verification (AV). While AV is a widely investigated
problem in general, only few works consider settings where the documents are
short and written in a rather uniform style. This makes most approaches
unpractical for online databases and knowledge graphs in the scholarly domain.
Here, authorships of scientific publications have to be verified, often with
just abstracts and titles available. To this point, we present our novel
approach LG4AV which combines language models and graph neural networks for
authorship verification. By directly feeding the available texts in a
pre-trained transformer architecture, our model does not need any hand-crafted
stylometric features that are not meaningful in scenarios where the writing
style is, at least to some extent, standardized. By the incorporation of a
graph neural network structure, our model can benefit from relations between
authors that are meaningful with respect to the verification process. For
example, scientific authors are more likely to write about topics that are
addressed by their co-authors and twitter users tend to post about the same
subjects as people they follow. We experimentally evaluate our model and study
to which extent the inclusion of co-authorships enhances verification decisions
in bibliometric environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contrastive Representation Learning for Exemplar-Guided Paraphrase Generation. (arXiv:2109.01484v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01484">
<div class="article-summary-box-inner">
<span><p>Exemplar-Guided Paraphrase Generation (EGPG) aims to generate a target
sentence which conforms to the style of the given exemplar while encapsulating
the content information of the source sentence. In this paper, we propose a new
method with the goal of learning a better representation of the style andthe
content. This method is mainly motivated by the recent success of contrastive
learning which has demonstrated its power in unsupervised feature extraction
tasks. The idea is to design two contrastive losses with respect to the content
and the style by considering two problem characteristics during training. One
characteristic is that the target sentence shares the same content with the
source sentence, and the second characteristic is that the target sentence
shares the same style with the exemplar. These two contrastive losses are
incorporated into the general encoder-decoder paradigm. Experiments on two
datasets, namely QQP-Pos and ParaNMT, demonstrate the effectiveness of our
proposed constrastive losses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Biomedical Data-to-Text Generation via Fine-Tuning Transformers. (arXiv:2109.01518v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01518">
<div class="article-summary-box-inner">
<span><p>Data-to-text (D2T) generation in the biomedical domain is a promising - yet
mostly unexplored - field of research. Here, we apply neural models for D2T
generation to a real-world dataset consisting of package leaflets of European
medicines. We show that fine-tuned transformers are able to generate realistic,
multisentence text from data in the biomedical domain, yet have important
limitations. We also release a new dataset (BioLeaflets) for benchmarking D2T
generation models in the biomedical domain.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Longitudinal Multi-modal Dataset for Dementia Monitoring and Diagnosis. (arXiv:2109.01537v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01537">
<div class="article-summary-box-inner">
<span><p>Dementia is a family of neurogenerative conditions affecting memory and
cognition in an increasing number of individuals in our globally aging
population. Automated analysis of language, speech and paralinguistic
indicators have been gaining popularity as potential indicators of cognitive
decline. Here we propose a novel longitudinal multi-modal dataset collected
from people with mild dementia and age matched controls over a period of
several months in a natural setting. The multi-modal data consists of spoken
conversations, a subset of which are transcribed, as well as typed and written
thoughts and associated extra-linguistic information such as pen strokes and
keystrokes. We describe the dataset in detail and proceed to focus on a task
using the speech modality. The latter involves distinguishing controls from
people with dementia by exploiting the longitudinal nature of the data. Our
experiments showed significant differences in how the speech varied from
session to session in the control and dementia groups.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Neural Models for Natural Language Processing in the Face of Distributional Shift. (arXiv:2109.01558v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01558">
<div class="article-summary-box-inner">
<span><p>The dominating NLP paradigm of training a strong neural predictor to perform
one task on a specific dataset has led to state-of-the-art performance in a
variety of applications (eg. sentiment classification, span-prediction based
question answering or machine translation). However, it builds upon the
assumption that the data distribution is stationary, ie. that the data is
sampled from a fixed distribution both at training and test time. This way of
training is inconsistent with how we as humans are able to learn from and
operate within a constantly changing stream of information. Moreover, it is
ill-adapted to real-world use cases where the data distribution is expected to
shift over the course of a model's lifetime.
</p>
<p>The first goal of this thesis is to characterize the different forms this
shift can take in the context of natural language processing, and propose
benchmarks and evaluation metrics to measure its effect on current deep
learning architectures. We then proceed to take steps to mitigate the effect of
distributional shift on NLP models. To this end, we develop methods based on
parametric reformulations of the distributionally robust optimization
framework. Empirically, we demonstrate that these approaches yield more robust
models as demonstrated on a selection of realistic problems. In the third and
final part of this thesis, we explore ways of efficiently adapting existing
models to new domains or tasks. Our contribution to this topic takes
inspiration from information geometry to derive a new gradient update rule
which alleviate catastrophic forgetting issues during adaptation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextualized Embeddings based Convolutional Neural Networks for Duplicate Question Identification. (arXiv:2109.01560v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01560">
<div class="article-summary-box-inner">
<span><p>Question Paraphrase Identification (QPI) is a critical task for large-scale
Question-Answering forums. The purpose of QPI is to determine whether a given
pair of questions are semantically identical or not. Previous approaches for
this task have yielded promising results, but have often relied on complex
recurrence mechanisms that are expensive and time-consuming in nature. In this
paper, we propose a novel architecture combining a Bidirectional Transformer
Encoder with Convolutional Neural Networks for the QPI task. We produce the
predictions from the proposed architecture using two different inference
setups: Siamese and Matched Aggregation. Experimental results demonstrate that
our model achieves state-of-the-art performance on the Quora Question Pairs
dataset. We empirically prove that the addition of convolution layers to the
model architecture improves the results in both inference setups. We also
investigate the impact of partial and complete fine-tuning and analyze the
trade-off between computational power and accuracy in the process. Based on the
obtained results, we conclude that the Matched-Aggregation setup consistently
outperforms the Siamese setup. Our work provides insights into what
architecture combinations and setups are likely to produce better results for
the QPI task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning from Multiple Noisy Augmented Data Sets for Better Cross-Lingual Spoken Language Understanding. (arXiv:2109.01583v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01583">
<div class="article-summary-box-inner">
<span><p>Lack of training data presents a grand challenge to scaling out spoken
language understanding (SLU) to low-resource languages. Although various data
augmentation approaches have been proposed to synthesize training data in
low-resource target languages, the augmented data sets are often noisy, and
thus impede the performance of SLU models. In this paper we focus on mitigating
noise in augmented data. We develop a denoising training approach. Multiple
models are trained with data produced by various augmented methods. Those
models provide supervision signals to each other. The experimental results show
that our method outperforms the existing state of the art by 3.05 and 4.24
percentage points on two benchmark datasets, respectively. The code will be
made open sourced on github.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Lingual Training with Dense Retrieval for Document Retrieval. (arXiv:2109.01628v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01628">
<div class="article-summary-box-inner">
<span><p>Dense retrieval has shown great success in passage ranking in English.
However, its effectiveness in document retrieval for non-English languages
remains unexplored due to the limitation in training resources. In this work,
we explore different transfer techniques for document ranking from English
annotations to multiple non-English languages. Our experiments on the test
collections in six languages (Chinese, Arabic, French, Hindi, Bengali, Spanish)
from diverse language families reveal that zero-shot model-based transfer using
mBERT improves the search quality in non-English mono-lingual retrieval. Also,
we find that weakly-supervised target language transfer yields competitive
performances against the generation-based target language transfer that
requires external translators and query generators.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Empirical Study of Named Entity Recognition Performance Using Distribution-aware Word Embedding. (arXiv:2109.01636v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01636">
<div class="article-summary-box-inner">
<span><p>With the fast development of Deep Learning techniques, Named Entity
Recognition (NER) is becoming more and more important in the information
extraction task. The greatest difficulty that the NER task faces is to keep the
detectability even when types of NE and documents are unfamiliar. Realizing
that the specificity information may contain potential meanings of a word and
generate semantic-related features for word embedding, we develop a
distribution-aware word embedding and implement three different methods to make
use of the distribution information in a NER framework. And the result shows
that the performance of NER will be improved if the word specificity is
incorporated into existing NER methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Finetuned Language Models Are Zero-Shot Learners. (arXiv:2109.01652v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01652">
<div class="article-summary-box-inner">
<span><p>This paper explores a simple method for improving the zero-shot learning
abilities of language models. We show that instruction tuning -- finetuning
language models on a collection of tasks described via instructions --
substantially boosts zero-shot performance on unseen tasks.
</p>
<p>We take a 137B parameter pretrained language model and instruction-tune it on
over 60 NLP tasks verbalized via natural language instruction templates. We
evaluate this instruction-tuned model, which we call FLAN, on unseen task
types. FLAN substantially improves the performance of its unmodified
counterpart and surpasses zero-shot 175B GPT-3 on 19 of 25 tasks that we
evaluate. FLAN even outperforms few-shot GPT-3 by a large margin on ANLI, RTE,
BoolQ, AI2-ARC, OpenbookQA, and StoryCloze. Ablation studies reveal that number
of tasks and model scale are key components to the success of instruction
tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CREAK: A Dataset for Commonsense Reasoning over Entity Knowledge. (arXiv:2109.01653v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01653">
<div class="article-summary-box-inner">
<span><p>Most benchmark datasets targeting commonsense reasoning focus on everyday
scenarios: physical knowledge like knowing that you could fill a cup under a
waterfall [Talmor et al., 2019], social knowledge like bumping into someone is
awkward [Sap et al., 2019], and other generic situations. However, there is a
rich space of commonsense inferences anchored to knowledge about specific
entities: for example, deciding the truthfulness of a claim "Harry Potter can
teach classes on how to fly on a broomstick." Can models learn to combine
entity knowledge with commonsense reasoning in this fashion? We introduce
CREAK, a testbed for commonsense reasoning about entity knowledge, bridging
fact-checking about entities (Harry Potter is a wizard and is skilled at riding
a broomstick) with commonsense inferences (if you're good at a skill you can
teach others how to do it). Our dataset consists of 13k human-authored English
claims about entities that are either true or false, in addition to a small
contrast set. Crowdworkers can easily come up with these statements and human
performance on the dataset is high (high 90s); we argue that models should be
able to blend entity knowledge and commonsense reasoning to do well here. In
our experiments, we focus on the closed-book setting and observe that a
baseline model finetuned on existing fact verification benchmark struggles on
CREAK. Training a model on CREAK improves accuracy by a substantial margin, but
still falls short of human performance. Our benchmark provides a unique probe
into natural language understanding models, testing both its ability to
retrieve facts (e.g., who teaches at the University of Chicago?) and unstated
commonsense knowledge (e.g., butlers do not yell at guests).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exposure Bias versus Self-Recovery: Are Distortions Really Incremental for Autoregressive Text Generation?. (arXiv:1905.10617v10 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.10617">
<div class="article-summary-box-inner">
<span><p>Exposure bias has been regarded as a central problem for auto-regressive
language models (LM). It claims that teacher forcing would cause the test-time
generation to be incrementally distorted due to the training-generation
discrepancy. Although a lot of algorithms have been proposed to avoid teacher
forcing and therefore alleviate exposure bias, there is little work showing how
serious the exposure bias problem actually is. In this work, we focus on the
task of open-ended language generation, propose metrics to quantify the impact
of exposure bias in the aspects of quality, diversity, and consistency. Our key
intuition is that if we feed ground-truth data prefixes (instead of prefixes
generated by the model itself) into the model and ask it to continue the
generation, the performance should become much better because the
training-generation discrepancy in the prefix is removed. Both automatic and
human evaluations are conducted in our experiments. On the contrary to the
popular belief in exposure bias, we find that the the distortion induced by the
prefix discrepancy is limited, and does not seem to be incremental during the
generation. Moreover, our analysis reveals an interesting self-recovery ability
of the LM, which we hypothesize to be countering the harmful effects from
exposure bias.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Survey on Publicly Available Sinhala Natural Language Processing Tools and Research. (arXiv:1906.02358v10 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.02358">
<div class="article-summary-box-inner">
<span><p>Sinhala is the native language of the Sinhalese people who make up the
largest ethnic group of Sri Lanka. The language belongs to the globe-spanning
language tree, Indo-European. However, due to poverty in both linguistic and
economic capital, Sinhala, in the perspective of Natural Language Processing
tools and research, remains a resource-poor language which has neither the
economic drive its cousin English has nor the sheer push of the law of numbers
a language such as Chinese has. A number of research groups from Sri Lanka have
noticed this dearth and the resultant dire need for proper tools and research
for Sinhala natural language processing. However, due to various reasons, these
attempts seem to lack coordination and awareness of each other. The objective
of this paper is to fill that gap of a comprehensive literature survey of the
publicly available Sinhala natural language tools and research so that the
researchers working in this field can better utilize contributions of their
peers. As such, we shall be uploading this paper to arXiv and perpetually
update it periodically to reflect the advances made in the field.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adjusting for Confounders with Text: Challenges and an Empirical Evaluation Framework for Causal Inference. (arXiv:2009.09961v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.09961">
<div class="article-summary-box-inner">
<span><p>Leveraging text, such as social media posts, for causal inferences requires
the use of NLP models to 'learn' and adjust for confounders, which could
otherwise impart bias. However, evaluating such models is challenging, as
ground truth is almost never available. We demonstrate the need for empirical
evaluation frameworks for causal inference in natural language by showing that
existing, commonly used models regularly disagree with one another on real
world tasks. We contribute the first such framework, generalizing several
challenges across these real world tasks. Using this framework, we evaluate a
large set of commonly used causal inference models based on propensity scores
and identify their strengths and weaknesses to inform future improvements. We
make all tasks, data, and models public to inform applications and encourage
additional research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CR-Walker: Tree-Structured Graph Reasoning and Dialog Acts for Conversational Recommendation. (arXiv:2010.10333v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.10333">
<div class="article-summary-box-inner">
<span><p>Growing interests have been attracted in Conversational Recommender Systems
(CRS), which explore user preference through conversational interactions in
order to make appropriate recommendation. However, there is still a lack of
ability in existing CRS to (1) traverse multiple reasoning paths over
background knowledge to introduce relevant items and attributes, and (2)
arrange selected entities appropriately under current system intents to control
response generation. To address these issues, we propose CR-Walker in this
paper, a model that performs tree-structured reasoning on a knowledge graph,
and generates informative dialog acts to guide language generation. The unique
scheme of tree-structured reasoning views the traversed entity at each hop as
part of dialog acts to facilitate language generation, which links how entities
are selected and expressed. Automatic and human evaluations show that CR-Walker
can arrive at more accurate recommendation, and generate more informative and
engaging responses.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Where Are You? Localization from Embodied Dialog. (arXiv:2011.08277v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08277">
<div class="article-summary-box-inner">
<span><p>We present Where Are You? (WAY), a dataset of ~6k dialogs in which two humans
-- an Observer and a Locator -- complete a cooperative localization task. The
Observer is spawned at random in a 3D environment and can navigate from
first-person views while answering questions from the Locator. The Locator must
localize the Observer in a detailed top-down map by asking questions and giving
instructions. Based on this dataset, we define three challenging tasks:
Localization from Embodied Dialog or LED (localizing the Observer from dialog
history), Embodied Visual Dialog (modeling the Observer), and Cooperative
Localization (modeling both agents). In this paper, we focus on the LED task --
providing a strong baseline model with detailed ablations characterizing both
dataset biases and the importance of various modeling choices. Our best model
achieves 32.7% success at identifying the Observer's location within 3m in
unseen buildings, vs. 70.4% for human Locators.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CascadeBERT: Accelerating Inference of Pre-trained Language Models via Calibrated Complete Models Cascade. (arXiv:2012.14682v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14682">
<div class="article-summary-box-inner">
<span><p>Dynamic early exiting aims to accelerate the inference of pre-trained
language models (PLMs) by emitting predictions in internal layers without
passing through the entire model. In this paper, we empirically analyze the
working mechanism of dynamic early exiting and find that it faces a performance
bottleneck under high speed-up ratios. On one hand, the PLMs' representations
in shallow layers lack high-level semantic information and thus are not
sufficient for accurate predictions. On the other hand, the exiting decisions
made by internal classifiers are unreliable, leading to wrongly emitted early
predictions. We instead propose a new framework for accelerating the inference
of PLMs, CascadeBERT, which dynamically selects proper-sized and complete
models in a cascading manner, providing comprehensive representations for
predictions. We further devise a difficulty-aware objective, encouraging the
model to output the class probability that reflects the real difficulty of each
instance for a more reliable cascading mechanism. Experimental results show
that CascadeBERT can achieve an overall 15\% improvement under 4$\times$
speed-up compared with existing dynamic early exiting methods on six
classification tasks, yielding more calibrated and accurate predictions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Which Linguist Invented the Lightbulb? Presupposition Verification for Question-Answering. (arXiv:2101.00391v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00391">
<div class="article-summary-box-inner">
<span><p>Many Question-Answering (QA) datasets contain unanswerable questions, but
their treatment in QA systems remains primitive. Our analysis of the Natural
Questions (Kwiatkowski et al. 2019) dataset reveals that a substantial portion
of unanswerable questions ($\sim$21%) can be explained based on the presence of
unverifiable presuppositions. We discuss the shortcomings of current models in
handling such questions, and describe how an improved system could handle them.
Through a user preference study, we demonstrate that the oracle behavior of our
proposed system that provides responses based on presupposition failure is
preferred over the oracle behavior of existing QA systems. Then we discuss how
our proposed system could be implemented, presenting a novel framework that
breaks down the problem into three steps: presupposition generation,
presupposition verification and explanation generation. We report our progress
in tackling each subproblem, and present a preliminary approach to integrating
these steps into an existing QA system. We find that adding presuppositions and
their verifiability to an existing model yields modest gains in downstream
performance and unanswerability detection. The biggest bottleneck is the
verification component, which needs to be substantially improved for the
integrated system to approach ideal behavior -- even transfer from the best
entailment models currently falls short.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CDLM: Cross-Document Language Modeling. (arXiv:2101.00406v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00406">
<div class="article-summary-box-inner">
<span><p>We introduce a new pretraining approach geared for multi-document language
modeling, incorporating two key ideas into the masked language modeling
self-supervised objective. First, instead of considering documents in
isolation, we pretrain over sets of multiple related documents, encouraging the
model to learn cross-document relationships. Second, we improve over recent
long-range transformers by introducing dynamic global attention that has access
to the entire input to predict masked tokens. We release CDLM (Cross-Document
Language Model), a new general language model for multi-document setting that
can be easily applied to downstream tasks. Our extensive analysis shows that
both ideas are essential for the success of CDLM, and work in synergy to set
new state-of-the-art results for several multi-text tasks. Code and models are
available at https://github.com/aviclu/CDLM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections. (arXiv:2104.04670v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04670">
<div class="article-summary-box-inner">
<span><p>Large pre-trained language models (LMs) such as GPT-3 have acquired a
surprising ability to perform zero-shot learning. For example, to classify
sentiment without any training examples, we can "prompt" the LM with the review
and the label description "Does the user like this movie?", and ask whether the
next word is "yes" or "no". However, the next word prediction training
objective is still misaligned with the target zero-shot learning objective. To
address this weakness, we propose meta-tuning, which directly optimizes the
zero-shot learning objective by fine-tuning pre-trained language models on a
collection of datasets. We focus on classification tasks, and construct the
meta-dataset by aggregating 43 existing datasets and annotating 441 label
descriptions in a question-answering (QA) format. When evaluated on unseen
tasks, meta-tuned models outperform a same-sized QA model and the previous SOTA
zero-shot learning system based on natural language inference. Additionally,
increasing parameter count from 220M to 770M improves AUC-ROC scores by 6.3%,
and we forecast that even larger models would perform better. Therefore,
measuring zero-shot learning performance on language models out-of-the-box
might underestimate their true potential, and community-wide efforts on
aggregating datasets and unifying their formats can help build models that
answer prompts better.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction. (arXiv:2104.07650v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07650">
<div class="article-summary-box-inner">
<span><p>Recently, prompt-tuning has achieved promising results on some few-shot
classification tasks. The core idea of prompt-tuning is to insert text pieces,
i.e., templates, into the input and transform a classification task into a
masked language modeling problem. However, as for relation extraction,
determining the appropriate prompt template requires domain expertise. Single
label word handcrafted or auto-searched is cumbersome and time-consuming to
verify their effectiveness in non-few-shot scenarios. Further, there exist
abundant semantic knowledge among the entities and relation labels which cannot
be ignored. To this end, we focus on incorporating knowledge into prompt-tuning
for relation extraction and propose a knowledge-aware prompt-tuning with
synergistic optimization (KnowPrompt) approach. Specifically, we inject entity
and relation knowledge into prompt construction with learnable virtual template
words and answer words and jointly optimize their representation with knowledge
constraints. Extensive experimental results on five datasets with standard and
low-resource settings demonstrate the effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sublanguage: A Serious Issue Affects Pretrained Models in Legal Domain. (arXiv:2104.07782v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07782">
<div class="article-summary-box-inner">
<span><p>Legal English is a sublanguage that is important for everyone but not for
everyone to understand. Pretrained models have become best practices among
current deep learning approaches for different problems. It would be a waste or
even a danger if these models were applied in practice without knowledge of the
sublanguage of the law. In this paper, we raise the issue and propose a trivial
solution by introducing BERTLaw a legal sublanguage pretrained model. The
paper's experiments demonstrate the superior effectiveness of the method
compared to the baseline pretrained model
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KI-BERT: Infusing Knowledge Context for Better Language and Domain Understanding. (arXiv:2104.08145v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08145">
<div class="article-summary-box-inner">
<span><p>Contextualized entity representations learned by state-of-the-art
transformer-based language models (TLMs) like BERT, GPT, T5, etc., leverage the
attention mechanism to learn the data context from training data corpus.
However, these models do not use the knowledge context. Knowledge context can
be understood as semantics about entities and their relationship with
neighboring entities in knowledge graphs. We propose a novel and effective
technique to infuse knowledge context from multiple knowledge graphs for
conceptual and ambiguous entities into TLMs during fine-tuning. It projects
knowledge graph embeddings in the homogeneous vector-space, introduces new
token-types for entities, aligns entity position ids, and a selective attention
mechanism. We take BERT as a baseline model and implement the
"Knowledge-Infused BERT" by infusing knowledge context from ConceptNet and
WordNet, which significantly outperforms BERT and other recent knowledge-aware
BERT variants like ERNIE, SenseBERT, and BERT_CS over eight different subtasks
of GLUE benchmark. The KI-BERT-base model even significantly outperforms
BERT-large for domain-specific tasks like SciTail and academic subsets of QQP,
QNLI, and MNLI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extract, Denoise and Enforce: Evaluating and Improving Concept Preservation for Text-to-Text Generation. (arXiv:2104.08724v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08724">
<div class="article-summary-box-inner">
<span><p>Prior studies on text-to-text generation typically assume that the model
could figure out what to attend to in the input and what to include in the
output via seq2seq learning, with only the parallel training data and no
additional guidance. However, it remains unclear whether current models can
preserve important concepts in the source input, as seq2seq learning does not
have explicit focus on the concepts and commonly used evaluation metrics also
treat concepts equally important as other tokens. In this paper, we present a
systematic analysis that studies whether current seq2seq models, especially
pre-trained language models, are good enough for preserving important input
concepts and to what extent explicitly guiding generation with the concepts as
lexical constraints is beneficial. We answer the above questions by conducting
extensive analytical experiments on four representative text-to-text generation
tasks. Based on the observations, we then propose a simple yet effective
framework to automatically extract, denoise, and enforce important input
concepts as lexical constraints. This new method performs comparably or better
than its unconstrained counterpart on automatic metrics, demonstrates higher
coverage for concept preservation, and receives better ratings in the human
evaluation. Our code is available at https://github.com/morningmoni/EDE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Verdi: Quality Estimation and Error Detection for Bilingual Corpora. (arXiv:2105.14878v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14878">
<div class="article-summary-box-inner">
<span><p>Translation Quality Estimation is critical to reducing post-editing efforts
in machine translation and to cross-lingual corpus cleaning. As a research
problem, quality estimation (QE) aims to directly estimate the quality of
translation in a given pair of source and target sentences, and highlight the
words that need corrections, without referencing to golden translations. In
this paper, we propose Verdi, a novel framework for word-level and
sentence-level post-editing effort estimation for bilingual corpora. Verdi
adopts two word predictors to enable diverse features to be extracted from a
pair of sentences for subsequent quality estimation, including a
transformer-based neural machine translation (NMT) model and a pre-trained
cross-lingual language model (XLM). We exploit the symmetric nature of
bilingual corpora and apply model-level dual learning in the NMT predictor,
which handles a primal task and a dual task simultaneously with weight sharing,
leading to stronger context prediction ability than single-direction NMT
models. By taking advantage of the dual learning scheme, we further design a
novel feature to directly encode the translated target information without
relying on the source context. Extensive experiments conducted on WMT20 QE
tasks demonstrate that our method beats the winner of the competition and
outperforms other baseline methods by a great margin. We further use the
sentence-level scores provided by Verdi to clean a parallel corpus and observe
benefits on both model performance and training efficiency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multilingual Coreference Resolution with Harmonized Annotations. (arXiv:2107.12088v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12088">
<div class="article-summary-box-inner">
<span><p>In this paper, we present coreference resolution experiments with a newly
created multilingual corpus CorefUD. We focus on the following languages:
Czech, Russian, Polish, German, Spanish, and Catalan. In addition to
monolingual experiments, we combine the training data in multilingual
experiments and train two joined models -- for Slavic languages and for all the
languages together. We rely on an end-to-end deep learning model that we
slightly adapted for the CorefUD corpus. Our results show that we can profit
from harmonized annotations, and using joined models helps significantly for
the languages with smaller training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Dataset for Answering Time-Sensitive Questions. (arXiv:2108.06314v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06314">
<div class="article-summary-box-inner">
<span><p>Time is an important dimension in our physical world. Lots of facts can
evolve with respect to time. For example, the U.S. President might change every
four years. Therefore, it is important to consider the time dimension and
empower the existing QA models to reason over time. However, the existing QA
datasets contain rather few time-sensitive questions, hence not suitable for
diagnosing or benchmarking the model's temporal reasoning capability. In order
to promote research in this direction, we propose to construct a time-sensitive
QA dataset. The dataset is constructed by 1) mining time-evolving facts from
WikiData and align them to their corresponding Wikipedia page, 2) employing
crowd workers to verify and calibrate these noisy facts, 3) generating
question-answer pairs based on the annotated time-sensitive facts. Our dataset
poses challenges in the aspect of both temporal understanding and temporal
reasoning. We evaluate different SoTA long-document QA systems like BigBird and
FiD on our dataset. The best-performing model FiD can only achieve 46\%
accuracy, still far behind the human performance of 87\%. We demonstrate that
these models are still lacking the ability to perform consistent temporal
reasoning. Therefore, we believe that our dataset could serve as a benchmark to
develop NLP models more sensitive to temporal shift. The dataset and code are
released in~\url{https://github.com/wenhuchen/Time-Sensitive-QA}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Affective Decoding for Empathetic Response Generation. (arXiv:2108.08102v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08102">
<div class="article-summary-box-inner">
<span><p>Understanding speaker's feelings and producing appropriate responses with
emotion connection is a key communicative skill for empathetic dialogue
systems. In this paper, we propose a simple technique called Affective Decoding
for empathetic response generation. Our method can effectively incorporate
emotion signals during each decoding step, and can additionally be augmented
with an auxiliary dual emotion encoder, which learns separate embeddings for
the speaker and listener given the emotion base of the dialogue. Extensive
empirical studies show that our models are perceived to be more empathetic by
human evaluations, in comparison to several strong mainstream methods for
empathetic responding.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Partition Filter Network for Joint Entity and Relation Extraction. (arXiv:2108.12202v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12202">
<div class="article-summary-box-inner">
<span><p>In joint entity and relation extraction, existing work either sequentially
encode task-specific features, leading to an imbalance in inter-task feature
interaction where features extracted later have no direct contact with those
that come first. Or they encode entity features and relation features in a
parallel manner, meaning that feature representation learning for each task is
largely independent of each other except for input sharing. We propose a
partition filter network to model two-way interaction between tasks properly,
where feature encoding is decomposed into two steps: partition and filter. In
our encoder, we leverage two gates: entity and relation gate, to segment
neurons into two task partitions and one shared partition. The shared partition
represents inter-task information valuable to both tasks and is evenly shared
across two tasks to ensure proper two-way interaction. The task partitions
represent intra-task information and are formed through concerted efforts of
both gates, making sure that encoding of task-specific features is dependent
upon each other. Experiment results on five public datasets show that our model
performs significantly better than previous approaches. In addition, contrary
to what previous work claims, our auxiliary experiments suggest that relation
prediction is contributory to named entity prediction in a non-negligible way.
The source code can be found at https://github.com/Coopercoppers/PFN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ProtoInfoMax: Prototypical Networks with Mutual Information Maximization for Out-of-Domain Detection. (arXiv:2108.12229v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12229">
<div class="article-summary-box-inner">
<span><p>The ability to detect Out-of-Domain (OOD) inputs has been a critical
requirement in many real-world NLP applications since the inclusion of
unsupported OOD inputs may lead to catastrophic failure of systems. However, it
remains an empirical question whether current algorithms can tackle such
problem reliably in a realistic scenario where zero OOD training data is
available. In this study, we propose ProtoInfoMax, a new architecture that
extends Prototypical Networks to simultaneously process In-Domain (ID) and OOD
sentences via Mutual Information Maximization (InfoMax) objective. Experimental
results show that our proposed method can substantially improve performance up
to 20% for OOD detection in low resource settings of text classification. We
also show that ProtoInfoMax is less prone to typical over-confidence Error of
Neural Networks, leading to more reliable ID and OOD prediction outcomes.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NEREL: A Russian Dataset with Nested Named Entities, Relations and Events. (arXiv:2108.13112v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13112">
<div class="article-summary-box-inner">
<span><p>In this paper, we present NEREL, a Russian dataset for named entity
recognition and relation extraction. NEREL is significantly larger than
existing Russian datasets: to date it contains 56K annotated named entities and
39K annotated relations. Its important difference from previous datasets is
annotation of nested named entities, as well as relations within nested
entities and at the discourse level. NEREL can facilitate development of novel
models that can extract relations between nested named entities, as well as
relations on both sentence and document levels. NEREL also contains the
annotation of events involving named entities and their roles in the events.
The NEREL collection is available via https://github.com/nerel-ds/NEREL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tree-constrained Pointer Generator for End-to-end Contextual Speech Recognition. (arXiv:2109.00627v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00627">
<div class="article-summary-box-inner">
<span><p>Contextual knowledge is important for real-world automatic speech recognition
(ASR) applications. In this paper, a novel tree-constrained pointer generator
(TCPGen) component is proposed that incorporates such knowledge as a list of
biasing words into both attention-based encoder-decoder and transducer
end-to-end ASR models in a neural-symbolic way. TCPGen structures the biasing
words into an efficient prefix tree to serve as its symbolic input and creates
a neural shortcut between the tree and the final ASR output distribution to
facilitate recognising biasing words during decoding. Systems were trained and
evaluated on the Librispeech corpus where biasing words were extracted at the
scales of an utterance, a chapter, or a book to simulate different application
scenarios. Experimental results showed that TCPGen consistently improved word
error rates (WERs) compared to the baselines, and in particular, achieved
significant WER reductions on the biasing words. TCPGen is highly efficient: it
can handle 5,000 biasing words and distractors and only add a small overhead to
memory use and computation cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LegaLMFiT: Efficient Short Legal Text Classification with LSTM Language Model Pre-Training. (arXiv:2109.00993v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00993">
<div class="article-summary-box-inner">
<span><p>Large Transformer-based language models such as BERT have led to broad
performance improvements on many NLP tasks. Domain-specific variants of these
models have demonstrated excellent performance on a variety of specialised
tasks. In legal NLP, BERT-based models have led to new state-of-the-art results
on multiple tasks. The exploration of these models has demonstrated the
importance of capturing the specificity of the legal language and its
vocabulary. However, such approaches suffer from high computational costs,
leading to a higher ecological impact and lower accessibility. Our findings,
focusing on English language legal text, show that lightweight LSTM-based
Language Models are able to capture enough information from a small legal text
pretraining corpus and achieve excellent performance on short legal text
classification tasks. This is achieved with a significantly reduced
computational overhead compared to BERT-based models. However, our method also
shows degraded performance on a more complex task, multi-label classification
of longer documents, highlighting the limitations of this lightweight approach.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Optimal Target Shape for LiDAR Pose Estimation. (arXiv:2109.01181v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01181">
<div class="article-summary-box-inner">
<span><p>Targets are essential in problems such as object tracking in cluttered or
textureless environments, camera (and multi-sensor) calibration tasks, and
simultaneous localization and mapping (SLAM). Target shapes for these tasks
typically are symmetric (square, rectangular, or circular) and work well for
structured, dense sensor data such as pixel arrays (i.e., image). However,
symmetric shapes lead to pose ambiguity when using sparse sensor data such as
LiDAR point clouds and suffer from the quantization uncertainty of the LiDAR.
This paper introduces the concept of optimizing target shape to remove pose
ambiguity for LiDAR point clouds. A target is designed to induce large
gradients at edge points under rotation and translation relative to the LiDAR
to ameliorate the quantization uncertainty associated with point cloud
sparseness. Moreover, given a target shape, we present a means that leverages
the target's geometry to estimate the target's vertices while globally
estimating the pose. Both the simulation and the experimental results (verified
by a motion capture system) confirm that by using the optimal shape and the
global solver, we achieve centimeter error in translation and a few degrees in
rotation even when a partially illuminated target is placed 30 meters away. All
the implementations and datasets are available at
https://github.com/UMich-BipedLab/optimal_shape_global_pose_estimation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">roadscene2vec: A Tool for Extracting and Embedding Road Scene-Graphs. (arXiv:2109.01183v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01183">
<div class="article-summary-box-inner">
<span><p>Recently, road scene-graph representations used in conjunction with graph
learning techniques have been shown to outperform state-of-the-art deep
learning techniques in tasks including action classification, risk assessment,
and collision prediction. To enable the exploration of applications of road
scene-graph representations, we introduce roadscene2vec: an open-source tool
for extracting and embedding road scene-graphs. The goal of roadscene2vec is to
enable research into the applications and capabilities of road scene-graphs by
providing tools for generating scene-graphs, graph learning models to generate
spatio-temporal scene-graph embeddings, and tools for visualizing and analyzing
scene-graph-based methodologies. The capabilities of roadscene2vec include (i)
customized scene-graph generation from either video clips or data from the
CARLA simulator, (ii) multiple configurable spatio-temporal graph embedding
models and baseline CNN-based models, (iii) built-in functionality for using
graph and sequence embeddings for risk assessment and collision prediction
applications, (iv) tools for evaluating transfer learning, and (v) utilities
for visualizing scene-graphs and analyzing the explainability of graph learning
models. We demonstrate the utility of roadscene2vec for these use cases with
experimental results and qualitative evaluations for both graph learning models
and CNN-based models. roadscene2vec is available at
https://github.com/AICPS/roadscene2vec.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Remote Multilinear Compressive Learning with Adaptive Compression. (arXiv:2109.01184v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01184">
<div class="article-summary-box-inner">
<span><p>Multilinear Compressive Learning (MCL) is an efficient signal acquisition and
learning paradigm for multidimensional signals. The level of signal compression
affects the detection or classification performance of a MCL model, with higher
compression rates often associated with lower inference accuracy. However,
higher compression rates are more amenable to a wider range of applications,
especially those that require low operating bandwidth and minimal energy
consumption such as Internet-of-Things (IoT) applications. Many communication
protocols provide support for adaptive data transmission to maximize the
throughput and minimize energy consumption. By developing compressive sensing
and learning models that can operate with an adaptive compression rate, we can
maximize the informational content throughput of the whole application. In this
paper, we propose a novel optimization scheme that enables such a feature for
MCL models. Our proposal enables practical implementation of adaptive
compressive signal acquisition and inference systems. Experimental results
demonstrated that the proposed approach can significantly reduce the amount of
computations required during the training phase of remote learning systems but
also improve the informational content throughput via adaptive-rate sensing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Reliable, Self-Adaptive Face Identification Framework via Lyapunov Optimization. (arXiv:2109.01212v1 [cs.DC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01212">
<div class="article-summary-box-inner">
<span><p>Realtime face identification (FID) from a video feed is highly
computation-intensive, and may exhaust computation resources if performed on a
device with a limited amount of resources (e.g., a mobile device). In general,
FID performs better when images are sampled at a higher rate, minimizing false
negatives. However, performing it at an overwhelmingly high rate exposes the
system to the risk of a queue overflow that hampers the system's reliability.
This paper proposes a novel, queue-aware FID framework that adapts the sampling
rate to maximize the FID performance while avoiding a queue overflow by
implementing the Lyapunov optimization. A preliminary evaluation via a
trace-based simulation confirms the effectiveness of the framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DeepTracks: Geopositioning Maritime Vehicles in Video Acquired from a Moving Platform. (arXiv:2109.01235v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01235">
<div class="article-summary-box-inner">
<span><p>Geopositioning and tracking a moving boat at sea is a very challenging
problem, requiring boat detection, matching and estimating its GPS location
from imagery with no common features. The problem can be stated as follows:
given imagery from a camera mounted on a moving platform with known GPS
location as the only valid sensor, we predict the geoposition of a target boat
visible in images. Our solution uses recent ML algorithms, the camera-scene
geometry and Bayesian filtering. The proposed pipeline first detects and tracks
the target boat's location in the image with the strategy of tracking by
detection. This image location is then converted to geoposition to the local
sea coordinates referenced to the camera GPS location using plane projective
geometry. Finally, target boat local coordinates are transformed to global GPS
coordinates to estimate the geoposition. To achieve a smooth geotrajectory, we
apply unscented Kalman filter (UKF) which implicitly overcomes small detection
errors in the early stages of the pipeline. We tested the performance of our
approach using GPS ground truth and show the accuracy and speed of the
estimated geopositions. Our code is publicly available at
https://github.com/JianliWei1995/AI-Track-at-Sea.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Two Shifts for Crop Mapping: Leveraging Aggregate Crop Statistics to Improve Satellite-based Maps in New Regions. (arXiv:2109.01246v1 [stat.AP])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01246">
<div class="article-summary-box-inner">
<span><p>Crop type mapping at the field level is critical for a variety of
applications in agricultural monitoring, and satellite imagery is becoming an
increasingly abundant and useful raw input from which to create crop type maps.
Still, in many regions crop type mapping with satellite data remains
constrained by a scarcity of field-level crop labels for training supervised
classification models. When training data is not available in one region,
classifiers trained in similar regions can be transferred, but shifts in the
distribution of crop types as well as transformations of the features between
regions lead to reduced classification accuracy. We present a methodology that
uses aggregate-level crop statistics to correct the classifier by accounting
for these two types of shifts. To adjust for shifts in the crop type
composition we present a scheme for properly reweighting the posterior
probabilities of each class that are output by the classifier. To adjust for
shifts in features we propose a method to estimate and remove linear shifts in
the mean feature vector. We demonstrate that this methodology leads to
substantial improvements in overall classification accuracy when using Linear
Discriminant Analysis (LDA) to map crop types in Occitanie, France and in
Western Province, Kenya. When using LDA as our base classifier, we found that
in France our methodology led to percent reductions in misclassifications
ranging from 2.8% to 42.2% (mean = 21.9%) over eleven different training
departments, and in Kenya the percent reductions in misclassification were
6.6%, 28.4%, and 42.7% for three training regions. While our methodology was
statistically motivated by the LDA classifier, it can be applied to any type of
classifier. As an example, we demonstrate its successful application to improve
a Random Forest classifier.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CAP-Net: Correspondence-Aware Point-view Fusion Network for 3D Shape Analysis. (arXiv:2109.01291v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01291">
<div class="article-summary-box-inner">
<span><p>Learning 3D representations by fusing point cloud and multi-view data has
been proven to be fairly effective. While prior works typically focus on
exploiting global features of the two modalities, in this paper we argue that
more discriminative features can be derived by modeling "where to fuse". To
investigate this, we propose a novel Correspondence-Aware Point-view Fusion Net
(CAPNet). The core element of CAP-Net is a module named Correspondence-Aware
Fusion (CAF) which integrates the local features of the two modalities based on
their correspondence scores. We further propose to filter out correspondence
scores with low values to obtain salient local correspondences, which reduces
redundancy for the fusion process. In our CAP-Net, we utilize the CAF modules
to fuse the multi-scale features of the two modalities both bidirectionally and
hierarchically in order to obtain more informative features. Comprehensive
evaluations on popular 3D shape benchmarks covering 3D object classification
and retrieval show the superiority of the proposed framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Information Symmetry Matters: A Modal-Alternating Propagation Network for Few-Shot Learning. (arXiv:2109.01295v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01295">
<div class="article-summary-box-inner">
<span><p>Semantic information provides intra-class consistency and inter-class
discriminability beyond visual concepts, which has been employed in Few-Shot
Learning (FSL) to achieve further gains. However, semantic information is only
available for labeled samples but absent for unlabeled samples, in which the
embeddings are rectified unilaterally by guiding the few labeled samples with
semantics. Therefore, it is inevitable to bring a cross-modal bias between
semantic-guided samples and nonsemantic-guided samples, which results in an
information asymmetry problem. To address this problem, we propose a
Modal-Alternating Propagation Network (MAP-Net) to supplement the absent
semantic information of unlabeled samples, which builds information symmetry
among all samples in both visual and semantic modalities. Specifically, the
MAP-Net transfers the neighbor information by the graph propagation to generate
the pseudo-semantics for unlabeled samples guided by the completed visual
relationships and rectify the feature embeddings. In addition, due to the large
discrepancy between visual and semantic modalities, we design a Relation
Guidance (RG) strategy to guide the visual relation vectors via semantics so
that the propagated information is more beneficial. Extensive experimental
results on three semantic-labeled datasets, i.e., Caltech-UCSD-Birds 200-2011,
SUN Attribute Database, and Oxford 102 Flower, have demonstrated that our
proposed method achieves promising performance and outperforms the
state-of-the-art approaches, which indicates the necessity of information
symmetry.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Taught Cross-Domain Few-Shot Learning with Weakly Supervised Object Localization and Task-Decomposition. (arXiv:2109.01302v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01302">
<div class="article-summary-box-inner">
<span><p>The domain shift between the source and target domain is the main challenge
in Cross-Domain Few-Shot Learning (CD-FSL). However, the target domain is
absolutely unknown during the training on the source domain, which results in
lacking directed guidance for target tasks. We observe that since there are
similar backgrounds in target domains, it can apply self-labeled samples as
prior tasks to transfer knowledge onto target tasks. To this end, we propose a
task-expansion-decomposition framework for CD-FSL, called Self-Taught (ST)
approach, which alleviates the problem of non-target guidance by constructing
task-oriented metric spaces. Specifically, Weakly Supervised Object
Localization (WSOL) and self-supervised technologies are employed to enrich
task-oriented samples by exchanging and rotating the discriminative regions,
which generates a more abundant task set. Then these tasks are decomposed into
several tasks to finish the task of few-shot recognition and rotation
classification. It helps to transfer the source knowledge onto the target tasks
and focus on discriminative regions. We conduct extensive experiments under the
cross-domain setting including 8 target domains: CUB, Cars, Places, Plantae,
CropDieases, EuroSAT, ISIC, and ChestX. Experimental results demonstrate that
the proposed ST approach is applicable to various metric-based models, and
provides promising improvements in CD-FSL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-centred Strong Augmentation via Contrastive Learning for Unsupervised Lesion Detection and Segmentation. (arXiv:2109.01303v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01303">
<div class="article-summary-box-inner">
<span><p>The scarcity of high quality medical image annotations hinders the
implementation of accurate clinical applications for detecting and segmenting
abnormal lesions. To mitigate this issue, the scientific community is working
on the development of unsupervised anomaly detection (UAD) systems that learn
from a training set containing only normal (i.e., healthy) images, where
abnormal samples (i.e., unhealthy) are detected and segmented based on how much
they deviate from the learned distribution of normal samples. One significant
challenge faced by UAD methods is how to learn effective low-dimensional image
representations that are sensitive enough to detect and segment abnormal
lesions of varying size, appearance and shape. To address this challenge, we
propose a novel self-supervised UAD pre-training algorithm, named Multi-centred
Strong Augmentation via Contrastive Learning (MSACL). MSACL learns
representations by separating several types of strong and weak augmentations of
normal image samples, where the weak augmentations represent normal images and
strong augmentations denote synthetic abnormal images. To produce such strong
augmentations, we introduce MedMix, a novel data augmentation strategy that
creates new training images with realistic looking lesions (i.e., anomalies) in
normal images. The pre-trained representations from MSACL are generic and can
be used to improve the efficacy of different types of off-the-shelf
state-of-the-art (SOTA) UAD models. Comprehensive experimental results show
that the use of MSACL largely improves these SOTA UAD models on four medical
imaging datasets from diverse organs, namely colonoscopy, fundus screening and
covid-19 chest-ray datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Video Pose Distillation for Few-Shot, Fine-Grained Sports Action Recognition. (arXiv:2109.01305v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01305">
<div class="article-summary-box-inner">
<span><p>Human pose is a useful feature for fine-grained sports action understanding.
However, pose estimators are often unreliable when run on sports video due to
domain shift and factors such as motion blur and occlusions. This leads to poor
accuracy when downstream tasks, such as action recognition, depend on pose.
End-to-end learning circumvents pose, but requires more labels to generalize.
</p>
<p>We introduce Video Pose Distillation (VPD), a weakly-supervised technique to
learn features for new video domains, such as individual sports that challenge
pose estimation. Under VPD, a student network learns to extract robust pose
features from RGB frames in the sports video, such that, whenever pose is
considered reliable, the features match the output of a pretrained teacher pose
detector. Our strategy retains the best of both pose and end-to-end worlds,
exploiting the rich visual patterns in raw video frames, while learning
features that agree with the athletes' pose and motion in the target video
domain to avoid over-fitting to patterns unrelated to athletes' motion.
</p>
<p>VPD features improve performance on few-shot, fine-grained action
recognition, retrieval, and detection tasks in four real-world sports video
datasets, without requiring additional ground-truth pose annotations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised multi-latent space reinforcement learning framework for video summarization in ultrasound imaging. (arXiv:2109.01309v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01309">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic has highlighted the need for a tool to speed up triage
in ultrasound scans and provide clinicians with fast access to relevant
information. The proposed video-summarization technique is a step in this
direction that provides clinicians access to relevant key-frames from a given
ultrasound scan (such as lung ultrasound) while reducing resource, storage and
bandwidth requirements. We propose a new unsupervised reinforcement learning
(RL) framework with novel rewards that facilitates unsupervised learning
avoiding tedious and impractical manual labelling for summarizing ultrasound
videos to enhance its utility as a triage tool in the emergency department (ED)
and for use in telemedicine. Using an attention ensemble of encoders, the high
dimensional image is projected into a low dimensional latent space in terms of:
a) reduced distance with a normal or abnormal class (classifier encoder), b)
following a topology of landmarks (segmentation encoder), and c) the distance
or topology agnostic latent representation (convolutional autoencoders). The
decoder is implemented using a bi-directional long-short term memory (Bi-LSTM)
which utilizes the latent space representation from the encoder. Our new
paradigm for video summarization is capable of delivering classification labels
and segmentation of key landmarks for each of the summarized keyframes.
Validation is performed on lung ultrasound (LUS) dataset, that typically
represent potential use cases in telemedicine and ED triage acquired from
different medical centers across geographies (India, Spain and Canada).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Semantic Segmentation on VSPW Dataset through Aggregation of Transformer Models. (arXiv:2109.01316v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01316">
<div class="article-summary-box-inner">
<span><p>Semantic segmentation is an important task in computer vision, from which
some important usage scenarios are derived, such as autonomous driving, scene
parsing, etc. Due to the emphasis on the task of video semantic segmentation,
we participated in this competition. In this report, we briefly introduce the
solutions of team 'BetterThing' for the ICCV2021 - Video Scene Parsing in the
Wild Challenge. Transformer is used as the backbone for extracting video frame
features, and the final result is the aggregation of the output of two
Transformer models, SWIN and VOLO. This solution achieves 57.3% mIoU, which is
ranked 3rd place in the Video Scene Parsing in the Wild Challenge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Access Control Using Spatially Invariant Permutation of Feature Maps for Semantic Segmentation Models. (arXiv:2109.01332v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01332">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose an access control method that uses the spatially
invariant permutation of feature maps with a secret key for protecting semantic
segmentation models. Segmentation models are trained and tested by permuting
selected feature maps with a secret key. The proposed method allows rightful
users with the correct key not only to access a model to full capacity but also
to degrade the performance for unauthorized users. Conventional access control
methods have focused only on image classification tasks, and these methods have
never been applied to semantic segmentation tasks. In an experiment, the
protected models were demonstrated to allow rightful users to obtain almost the
same performance as that of non-protected models but also to be robust against
access by unauthorized users without a key. In addition, a conventional method
with block-wise transformations was also verified to have degraded performance
under semantic segmentation models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual-Camera Super-Resolution with Aligned Attention Modules. (arXiv:2109.01349v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01349">
<div class="article-summary-box-inner">
<span><p>We present a novel approach to reference-based super-resolution (RefSR) with
the focus on dual-camera super-resolution (DCSR), which utilizes reference
images for high-quality and high-fidelity results. Our proposed method
generalizes the standard patch-based feature matching with spatial alignment
operations. We further explore the dual-camera super-resolution that is one
promising application of RefSR, and build a dataset that consists of 146 image
pairs from the main and telephoto cameras in a smartphone. To bridge the domain
gaps between real-world images and the training images, we propose a
self-supervised domain adaptation strategy for real-world images. Extensive
experiments on our dataset and a public benchmark demonstrate clear improvement
achieved by our method over state of the art in both quantitative evaluation
and visual comparisons.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Spatially varying white balancing for mixed and non-uniform illuminants. (arXiv:2109.01350v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01350">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel white balance adjustment, called "spatially
varying white balancing," for single, mixed, and non-uniform illuminants. By
using n diagonal matrices along with a weight, the proposed method can reduce
lighting effects on all spatially varying colors in an image under such
illumination conditions. In contrast, conventional white balance adjustments do
not consider the correcting of all colors except under a single illuminant.
Also, multi-color balance adjustments can map multiple colors into
corresponding ground truth colors, although they may cause the rank deficiency
problem to occur as a non-diagonal matrix is used, unlike white balancing. In
an experiment, the effectiveness of the proposed method is shown under mixed
and non-uniform illuminants, compared with conventional white and multi-color
balancing. Moreover, under a single illuminant, the proposed method has almost
the same performance as the conventional white balancing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MitoVis: A Visually-guided Interactive Intelligent System for Neuronal Mitochondria Analysis. (arXiv:2109.01351v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01351">
<div class="article-summary-box-inner">
<span><p>Neurons have a polarized structure, including dendrites and axons, and
compartment-specific functions can be affected by dwelling mitochondria. It is
known that the morphology of mitochondria is closely related to the functions
of neurons and neurodegenerative diseases. Even though several deep learning
methods have been developed to automatically analyze the morphology of
mitochondria, the application of existing methods to actual analysis still
encounters several difficulties. Since the performance of pre-trained deep
learning model may vary depending on the target data, re-training of the model
is often required. Besides, even though deep learning has shown superior
performance under a constrained setup, there are always errors that need to be
corrected by humans in real analysis. To address these issues, we introduce
MitoVis, a novel visualization system for end-to-end data processing and
interactive analysis of the morphology of neuronal mitochondria. MitoVis
enables interactive fine-tuning of a pre-trained neural network model without
the domain knowledge of machine learning, which allows neuroscientists to
easily leverage deep learning in their research. MitoVis also provides novel
visual guides and interactive proofreading functions so that the users can
quickly identify and correct errors in the result with minimal effort. We
demonstrate the usefulness and efficacy of the system via a case study
conducted by a neuroscientist on a real analysis scenario. The result shows
that MitoVis allows up to 15x faster analysis with similar accuracy compared to
the fully manual analysis method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Edge-featured Graph Neural Architecture Search. (arXiv:2109.01356v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01356">
<div class="article-summary-box-inner">
<span><p>Graph neural networks (GNNs) have been successfully applied to learning
representation on graphs in many relational tasks. Recently, researchers study
neural architecture search (NAS) to reduce the dependence of human expertise
and explore better GNN architectures, but they over-emphasize entity features
and ignore latent relation information concealed in the edges. To solve this
problem, we incorporate edge features into graph search space and propose
Edge-featured Graph Neural Architecture Search to find the optimal GNN
architecture. Specifically, we design rich entity and edge updating operations
to learn high-order representations, which convey more generic message passing
mechanisms. Moreover, the architecture topology in our search space allows to
explore complex feature dependence of both entities and edges, which can be
efficiently optimized by differentiable search strategy. Experiments at three
graph tasks on six datasets show EGNAS can search better GNNs with higher
performance than current state-of-the-art human-designed and searched-based
GNNs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Learning Spatially Discriminative Feature Representations. (arXiv:2109.01359v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01359">
<div class="article-summary-box-inner">
<span><p>The backbone of traditional CNN classifier is generally considered as a
feature extractor, followed by a linear layer which performs the
classification. We propose a novel loss function, termed as CAM-loss, to
constrain the embedded feature maps with the class activation maps (CAMs) which
indicate the spatially discriminative regions of an image for particular
categories. CAM-loss drives the backbone to express the features of target
category and suppress the features of non-target categories or background, so
as to obtain more discriminative feature representations. It can be simply
applied in any CNN architecture with neglectable additional parameters and
calculations. Experimental results show that CAM-loss is applicable to a
variety of network structures and can be combined with mainstream
regularization methods to improve the performance of image classification. The
strong generalization ability of CAM-loss is validated in the transfer learning
and few shot learning tasks. Based on CAM-loss, we also propose a novel
CAAM-CAM matching knowledge distillation method. This method directly uses the
CAM generated by the teacher network to supervise the CAAM generated by the
student network, which effectively improves the accuracy and convergence rate
of the student network.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning for Fitness. (arXiv:2109.01376v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01376">
<div class="article-summary-box-inner">
<span><p>We present Fitness tutor, an application for maintaining correct posture
during workout exercises or doing yoga. Current work on fitness focuses on
suggesting food supplements, accessing workouts, workout wearables does a great
job in improving the fitness. Meanwhile, the current situation is making
difficult to monitor workouts by trainee. Inspired by healthcare innovations
like robotic surgery, we design a novel application Fitness tutor which can
guide the workouts using pose estimation. Pose estimation can be deployed on
the reference image for gathering data and guide the user with the data. This
allow Fitness tutor to guide the workouts (both exercise and yoga) in remote
conditions with a single reference posture as image. We use posenet model in
tensorflow with p5js for developing skeleton. Fitness tutor is an application
of pose estimation model in bringing a realtime teaching experience in fitness.
Our experiments shows that it can leverage potential of pose estimation models
by providing guidance in realtime.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Segmentation of turbulent computational fluid dynamics simulations with unsupervised ensemble learning. (arXiv:2109.01381v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01381">
<div class="article-summary-box-inner">
<span><p>Computer vision and machine learning tools offer an exciting new way for
automatically analyzing and categorizing information from complex computer
simulations. Here we design an ensemble machine learning framework that can
independently and robustly categorize and dissect simulation data output
contents of turbulent flow patterns into distinct structure catalogues. The
segmentation is performed using an unsupervised clustering algorithm, which
segments physical structures by grouping together similar pixels in simulation
images. The accuracy and robustness of the resulting segment region boundaries
are enhanced by combining information from multiple simultaneously-evaluated
clustering operations. The stacking of object segmentation evaluations is
performed using image mask combination operations. This statistically-combined
ensemble (SCE) of different cluster masks allows us to construct cluster
reliability metrics for each pixel and for the associated segments without any
prior user input. By comparing the similarity of different cluster occurrences
in the ensemble, we can also assess the optimal number of clusters needed to
describe the data. Furthermore, by relying on ensemble-averaged spatial segment
region boundaries, the SCE method enables reconstruction of more accurate and
robust region of interest (ROI) boundaries for the different image data
clusters. We apply the SCE algorithm to 2-dimensional simulation data snapshots
of magnetically-dominated fully-kinetic turbulent plasma flows where accurate
ROI boundaries are needed for geometrical measurements of intermittent flow
structures known as current sheets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Occlusion-Invariant Rotation-Equivariant Semi-Supervised Depth Based Cross-View Gait Pose Estimation. (arXiv:2109.01397v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01397">
<div class="article-summary-box-inner">
<span><p>Accurate estimation of three-dimensional human skeletons from depth images
can provide important metrics for healthcare applications, especially for
biomechanical gait analysis. However, there exist inherent problems associated
with depth images captured from a single view. The collected data is greatly
affected by occlusions where only partial surface data can be recorded.
Furthermore, depth images of human body exhibit heterogeneous characteristics
with viewpoint changes, and the estimated poses under local coordinate systems
are expected to go through equivariant rotations. Most existing pose estimation
models are sensitive to both issues. To address this, we propose a novel
approach for cross-view generalization with an occlusion-invariant
semi-supervised learning framework built upon a novel rotation-equivariant
backbone. Our model was trained with real-world data from a single view and
unlabelled synthetic data from multiple views. It can generalize well on the
real-world data from all the other unseen views. Our approach has shown
superior performance on gait analysis on our ICL-Gait dataset compared to other
state-of-the-arts and it can produce more convincing keypoints on ITOP dataset,
than its provided "ground truth".
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CX-ToM: Counterfactual Explanations with Theory-of-Mind for Enhancing Human Trust in Image Recognition Models. (arXiv:2109.01401v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01401">
<div class="article-summary-box-inner">
<span><p>We propose CX-ToM, short for counterfactual explanations with theory-of mind,
a new explainable AI (XAI) framework for explaining decisions made by a deep
convolutional neural network (CNN). In contrast to the current methods in XAI
that generate explanations as a single shot response, we pose explanation as an
iterative communication process, i.e. dialog, between the machine and human
user. More concretely, our CX-ToM framework generates sequence of explanations
in a dialog by mediating the differences between the minds of machine and human
user. To do this, we use Theory of Mind (ToM) which helps us in explicitly
modeling human's intention, machine's mind as inferred by the human as well as
human's mind as inferred by the machine. Moreover, most state-of-the-art XAI
frameworks provide attention (or heat map) based explanations. In our work, we
show that these attention based explanations are not sufficient for increasing
human trust in the underlying CNN model. In CX-ToM, we instead use
counterfactual explanations called fault-lines which we define as follows:
given an input image I for which a CNN classification model M predicts class
c_pred, a fault-line identifies the minimal semantic-level features (e.g.,
stripes on zebra, pointed ears of dog), referred to as explainable concepts,
that need to be added to or deleted from I in order to alter the classification
category of I by M to another specified class c_alt. We argue that, due to the
iterative, conceptual and counterfactual nature of CX-ToM explanations, our
framework is practical and more natural for both expert and non-expert users to
understand the internal workings of complex deep learning models. Extensive
quantitative and qualitative experiments verify our hypotheses, demonstrating
that our CX-ToM significantly outperforms the state-of-the-art explainable AI
models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Learning Approach for Hyperspectral Image Demosaicking, Spectral Correction and High-resolution RGB Reconstruction. (arXiv:2109.01403v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01403">
<div class="article-summary-box-inner">
<span><p>Hyperspectral imaging is one of the most promising techniques for
intraoperative tissue characterisation. Snapshot mosaic cameras, which can
capture hyperspectral data in a single exposure, have the potential to make a
real-time hyperspectral imaging system for surgical decision-making possible.
However, optimal exploitation of the captured data requires solving an
ill-posed demosaicking problem and applying additional spectral corrections to
recover spatial and spectral information of the image. In this work, we propose
a deep learning-based image demosaicking algorithm for snapshot hyperspectral
images using supervised learning methods. Due to the lack of publicly available
medical images acquired with snapshot mosaic cameras, a synthetic image
generation approach is proposed to simulate snapshot images from existing
medical image datasets captured by high-resolution, but slow, hyperspectral
imaging devices. Image reconstruction is achieved using convolutional neural
networks for hyperspectral image super-resolution, followed by cross-talk and
leakage correction using a sensor-specific calibration matrix. The resulting
demosaicked images are evaluated both quantitatively and qualitatively, showing
clear improvements in image quality compared to a baseline demosaicking method
using linear interpolation. Moreover, the fast processing time of~45\,ms of our
algorithm to obtain super-resolved RGB or oxygenation saturation maps per image
frame for a state-of-the-art snapshot mosaic camera demonstrates the potential
for its seamless integration into real-time surgical hyperspectral imaging
applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Foot Ulcer segmentation Using an Ensemble of Convolutional Neural Networks. (arXiv:2109.01408v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01408">
<div class="article-summary-box-inner">
<span><p>Foot ulcer is a common complication of diabetes mellitus; it is associated
with substantial morbidity and mortality and remains a major risk factor for
lower leg amputation. Extracting accurate morphological features from the foot
wounds is crucial for proper treatment. Although visual and manual inspection
by medical professionals is the common approach to extract the features, this
method is subjective and error-prone. Computer-mediated approaches are the
alternative solutions to segment the lesions and extract related morphological
features. Among various proposed computer-based approaches for image
segmentation, deep learning-based methods and more specifically convolutional
neural networks (CNN) have shown excellent performances for various image
segmentation tasks including medical image segmentation. In this work, we
proposed an ensemble approach based on two encoder-decoder-based CNN models,
namely LinkNet and UNet, to perform foot ulcer segmentation. To deal with
limited training samples, we used pre-trained weights (EfficientNetB1 for the
LinkNet model and EfficientNetB2 for the UNet model) and further pre-training
by the Medetec dataset. We also applied a number of morphological-based and
colour-based augmentation techniques to train the models. We integrated
five-fold cross-validation, test time augmentation and result fusion in our
proposed ensemble approach to boost the segmentation performance. Applied on a
publicly available foot ulcer segmentation dataset and the MICCAI 2021 Foot
Ulcer Segmentation (FUSeg) Challenge, our method achieved state-of-the-art
data-based Dice scores of 92.07% and 88.80%, respectively. Our developed method
achieved the first rank in the FUSeg challenge leaderboard. The Dockerised
guideline, inference codes and saved trained models are publicly available in
the published GitHub repository:
https://github.com/masih4/Foot_Ulcer_Segmentation
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MitoDet: Simple and robust mitosis detection. (arXiv:2109.01485v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01485">
<div class="article-summary-box-inner">
<span><p>Mitotic figure detection is a challenging task in digital pathology that has
a direct impact on therapeutic decisions. While automated methods often achieve
acceptable results under laboratory conditions, they frequently fail in the
clinical deployment phase. This problem can be mainly attributed to a
phenomenon called domain shift. An important source of a domain shift is
introduced by different microscopes and their camera systems, which noticeably
change the color representation of digitized images. In this method description
we present our submitted algorithm for the Mitosis Domain Generalization
Challenge, which employs a RetinaNet trained with strong data augmentation and
achieves an F1 score of 0.7138 on the preliminary test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Studying the Effects of Self-Attention for Medical Image Analysis. (arXiv:2109.01486v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01486">
<div class="article-summary-box-inner">
<span><p>When the trained physician interprets medical images, they understand the
clinical importance of visual features. By applying cognitive attention, they
apply greater focus onto clinically relevant regions while disregarding
unnecessary features. The use of computer vision to automate the classification
of medical images is widely studied. However, the standard convolutional neural
network (CNN) does not necessarily employ subconscious feature relevancy
evaluation techniques similar to the trained medical specialist and evaluates
features more generally. Self-attention mechanisms enable CNNs to focus more on
semantically important regions or aggregated relevant context with long-range
dependencies. By using attention, medical image analysis systems can
potentially become more robust by focusing on more important clinical feature
regions. In this paper, we provide a comprehensive comparison of various
state-of-the-art self-attention mechanisms across multiple medical image
analysis tasks. Through both quantitative and qualitative evaluations along
with a clinical user-centric survey study, we aim to provide a deeper
understanding of the effects of self-attention in medical computer vision
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ghost Loss to Question the Reliability of Training Data. (arXiv:2109.01504v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01504">
<div class="article-summary-box-inner">
<span><p>Supervised image classification problems rely on training data assumed to
have been correctly annotated; this assumption underpins most works in the
field of deep learning. In consequence, during its training, a network is
forced to match the label provided by the annotator and is not given the
flexibility to choose an alternative to inconsistencies that it might be able
to detect. Therefore, erroneously labeled training images may end up
``correctly'' classified in classes which they do not actually belong to. This
may reduce the performances of the network and thus incite to build more
complex networks without even checking the quality of the training data. In
this work, we question the reliability of the annotated datasets. For that
purpose, we introduce the notion of ghost loss, which can be seen as a regular
loss that is zeroed out for some predicted values in a deterministic way and
that allows the network to choose an alternative to the given label without
being penalized. After a proof of concept experiment, we use the ghost loss
principle to detect confusing images and erroneously labeled images in
well-known training datasets (MNIST, Fashion-MNIST, SVHN, CIFAR10) and we
provide a new tool, called sanity matrix, for summarizing these confusions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Safety-aware Motion Prediction with Unseen Vehicles for Autonomous Driving. (arXiv:2109.01510v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01510">
<div class="article-summary-box-inner">
<span><p>Motion prediction of vehicles is critical but challenging due to the
uncertainties in complex environments and the limited visibility caused by
occlusions and limited sensor ranges. In this paper, we study a new task,
safety-aware motion prediction with unseen vehicles for autonomous driving.
Unlike the existing trajectory prediction task for seen vehicles, we aim at
predicting an occupancy map that indicates the earliest time when each location
can be occupied by either seen and unseen vehicles. The ability to predict
unseen vehicles is critical for safety in autonomous driving. To tackle this
challenging task, we propose a safety-aware deep learning model with three new
loss functions to predict the earliest occupancy map. Experiments on the
large-scale autonomous driving nuScenes dataset show that our proposed model
significantly outperforms the state-of-the-art baselines on the safety-aware
motion prediction task. To the best of our knowledge, our approach is the first
one that can predict the existence of unseen vehicles in most cases. Project
page at {\url{https://github.com/xrenaa/Safety-Aware-Motion-Prediction}}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">UnDeepLIO: Unsupervised Deep Lidar-Inertial Odometry. (arXiv:2109.01533v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01533">
<div class="article-summary-box-inner">
<span><p>Extensive research efforts have been dedicated to deep learning based
odometry. Nonetheless, few efforts are made on the unsupervised deep lidar
odometry. In this paper, we design a novel framework for unsupervised lidar
odometry with the IMU, which is never used in other deep methods. First, a pair
of siamese LSTMs are used to obtain the initial pose from the linear
acceleration and angular velocity of IMU. With the initial pose, we perform the
rigid transform on the current frame and align it closer to the last frame.
Then, we extract vertex and normal features from the transformed point clouds
and its normals. Next a two-branches attention modules are proposed to estimate
residual rotation and translation from the extracted vertex and normal
features, respectively. Finally, our model outputs the sum of initial and
residual poses as the final pose. For unsupervised training, we introduce an
unsupervised loss function which is employed on the voxelized point clouds. The
proposed approach is evaluated on the KITTI odometry estimation benchmark and
achieves comparable performances against other state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Model-Based Parameter Optimization for Ground Texture Based Localization Methods. (arXiv:2109.01559v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01559">
<div class="article-summary-box-inner">
<span><p>A promising approach to accurate positioning of robots is ground texture
based localization. It is based on the observation that visual features of
ground images enable fingerprint-like place recognition. We tackle the issue of
efficient parametrization of such methods, deriving a prediction model for
localization performance, which requires only a small collection of sample
images of an application area. In a first step, we examine whether the model
can predict the effects of changing one of the most important parameters of
feature-based localization methods: the number of extracted features. We
examine two localization methods, and in both cases our evaluation shows that
the predictions are sufficiently accurate. Since this model can be used to find
suitable values for any parameter, we then present a holistic parameter
optimization framework, which finds suitable texture-specific parameter
configurations, using only the model to evaluate the considered parameter
configurations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ordinal Pooling. (arXiv:2109.01561v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01561">
<div class="article-summary-box-inner">
<span><p>In the framework of convolutional neural networks, downsampling is often
performed with an average-pooling, where all the activations are treated
equally, or with a max-pooling operation that only retains an element with
maximum activation while discarding the others. Both of these operations are
restrictive and have previously been shown to be sub-optimal. To address this
issue, a novel pooling scheme, named\emph{ ordinal pooling}, is introduced in
this work. Ordinal pooling rearranges all the elements of a pooling region in a
sequence and assigns a different weight to each element based upon its order in
the sequence. These weights are used to compute the pooling operation as a
weighted sum of the rearranged elements of the pooling region. They are learned
via a standard gradient-based training, allowing to learn a behavior anywhere
in the spectrum of average-pooling to max-pooling in a differentiable manner.
Our experiments suggest that it is advantageous for the networks to perform
different types of pooling operations within a pooling layer and that a hybrid
behavior between average- and max-pooling is often beneficial. More
importantly, they also demonstrate that ordinal pooling leads to consistent
improvements in the accuracy over average- or max-pooling operations while
speeding up the training and alleviating the issue of the choice of the pooling
operations and activation functions to be used in the networks. In particular,
ordinal pooling mainly helps on lightweight or quantized deep learning
architectures, as typically considered e.g. for embedded applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Metric Learning for Ground Images. (arXiv:2109.01569v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01569">
<div class="article-summary-box-inner">
<span><p>Ground texture based localization methods are potential prospects for
low-cost, high-accuracy self-localization solutions for robots. These methods
estimate the pose of a given query image, i.e. the current observation of the
ground from a downward-facing camera, in respect to a set of reference images
whose poses are known in the application area. In this work, we deal with the
initial localization task, in which we have no prior knowledge about the
current robot positioning. In this situation, the localization method would
have to consider all available reference images. However, in order to reduce
computational effort and the risk of receiving a wrong result, we would like to
consider only those reference images that are actually overlapping with the
query image. For this purpose, we propose a deep metric learning approach that
retrieves the most similar reference images to the query image. In contrast to
existing approaches to image retrieval for ground images, our approach achieves
significantly better recall performance and improves the localization
performance of a state-of-the-art ground texture based localization method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Using Topological Framework for the Design of Activation Function and Model Pruning in Deep Neural Networks. (arXiv:2109.01572v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01572">
<div class="article-summary-box-inner">
<span><p>Success of deep neural networks in diverse tasks across domains of computer
vision, speech recognition and natural language processing, has necessitated
understanding the dynamics of training process and also working of trained
models. Two independent contributions of this paper are 1) Novel activation
function for faster training convergence 2) Systematic pruning of filters of
models trained irrespective of activation function. We analyze the topological
transformation of the space of training samples as it gets transformed by each
successive layer during training, by changing the activation function. The
impact of changing activation function on the convergence during training is
reported for the task of binary classification. A novel activation function
aimed at faster convergence for classification tasks is proposed. Here, Betti
numbers are used to quantify topological complexity of data. Results of
experiments on popular synthetic binary classification datasets with large
Betti numbers(&gt;150) using MLPs are reported. Results show that the proposed
activation function results in faster convergence requiring fewer epochs by a
factor of 1.5 to 2, since Betti numbers reduce faster across layers with the
proposed activation function. The proposed methodology was verified on
benchmark image datasets: fashion MNIST, CIFAR-10 and cat-vs-dog images, using
CNNs. Based on empirical results, we propose a novel method for pruning a
trained model. The trained model was pruned by eliminating filters that
transform data to a topological space with large Betti numbers. All filters
with Betti numbers greater than 300 were removed from each layer without
significant reduction in accuracy. This resulted in faster prediction time and
reduced memory size of the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D Human Shape Style Transfer. (arXiv:2109.01587v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01587">
<div class="article-summary-box-inner">
<span><p>We consider the problem of modifying/replacing the shape style of a real
moving character with those of an arbitrary static real source character.
Traditional solutions follow a pose transfer strategy, from the moving
character to the source character shape, that relies on skeletal pose
parametrization. In this paper, we explore an alternative approach that
transfers the source shape style onto the moving character. The expected
benefit is to avoid the inherently difficult pose to shape conversion required
with skeletal parametrization applied on real characters. To this purpose, we
consider image style transfer techniques and investigate how to adapt them to
3D human shapes. Adaptive Instance Normalisation (AdaIN) and SPADE
architectures have been demonstrated to efficiently and accurately transfer the
style of an image onto another while preserving the original image structure.
Where AdaIN contributes with a module to perform style transfer through the
statistics of the subjects and SPADE contribute with a residual block
architecture to refine the quality of the style transfer. We demonstrate that
these approaches are extendable to the 3D shape domain by proposing a
convolutional neural network that applies the same principle of preserving the
shape structure (shape pose) while transferring the style of a new subject
shape. The generated results are supervised through a discriminator module to
evaluate the realism of the shape, whilst enforcing the decoder to synthesise
plausible shapes and improve the style transfer for unseen subjects. Our
experiments demonstrate an average of $\approx 56\%$ qualitative and
quantitative improvements over the baseline in shape transfer through
optimization-based and learning-based methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Human Deformation Transfer. (arXiv:2109.01588v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01588">
<div class="article-summary-box-inner">
<span><p>We consider the problem of human deformation transfer, where the goal is to
retarget poses between different characters. Traditional methods that tackle
this problem require a clear definition of the pose, and use this definition to
transfer poses between characters. In this work, we take a different approach
and transform the identity of a character into a new identity without modifying
the character's pose. This offers the advantage of not having to define
equivalences between 3D human poses, which is not straightforward as poses tend
to change depending on the identity of the character performing them, and as
their meaning is highly contextual. To achieve the deformation transfer, we
propose a neural encoder-decoder architecture where only identity information
is encoded and where the decoder is conditioned on the pose. We use pose
independent representations, such as isometry-invariant shape characteristics,
to represent identity features. Our model uses these features to supervise the
prediction of offsets from the deformed pose to the result of the transfer. We
show experimentally that our method outperforms state-of-the-art methods both
quantitatively and qualitatively, and generalises better to poses not seen
during training. We also introduce a fine-tuning step that allows to obtain
competitive results for extreme identities, and allows to transfer simple
clothing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Super Neurons. (arXiv:2109.01594v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01594">
<div class="article-summary-box-inner">
<span><p>Operational Neural Networks (ONNs) are new generation network models that can
perform any (non-linear) transformation with a proper combination of "nodal"
and "pool" operators. However, they still have a certain restriction, which is
the sole usage of a single nodal operator for all (synaptic) connections of
each neuron. The idea behind the "generative neurons" was born as a remedy for
this restriction where each nodal operator can be "customized" during the
training in order to maximize the learning performance. Self-Organized ONNs
(Self-ONNs) composed with the generative neurons can achieve an utmost level of
diversity even with a compact configuration; however, it still suffers from the
last property that was inherited from the CNNs: localized kernel operations
which imposes a severe limitation to the information flow between layers. It
is, therefore, desirable for the neurons to gather information from a larger
area in the previous layer maps without increasing the kernel size. For certain
applications, it might be even more desirable "to learn" the kernel locations
of each connection during the training process along with the customized nodal
operators so that both can be optimized simultaneously. This study introduces
the super (generative) neuron models that can accomplish this without altering
the kernel sizes and will enable a significant diversity in terms of
information flow. The two models of super neurons proposed in this study vary
on the localization process of the kernels: i) randomly localized kernels
within a bias range set for each layer, ii) optimized locations of each kernel
during the Back-Propagation (BP) training. The extensive set of comparative
evaluations show that Self-ONNs with super-neurons can indeed achieve a
superior learning and generalization capability without any significant rise of
the computational complexity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Representing Shape Collections with Alignment-Aware Linear Models. (arXiv:2109.01605v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01605">
<div class="article-summary-box-inner">
<span><p>In this paper, we revisit the classical representation of 3D point clouds as
linear shape models. Our key insight is to leverage deep learning to represent
a collection of shapes as affine transformations of low-dimensional linear
shape models. Each linear model is characterized by a shape prototype, a
low-dimensional shape basis and two neural networks. The networks take as input
a point cloud and predict the coordinates of a shape in the linear basis and
the affine transformation which best approximate the input. Both linear models
and neural networks are learned end-to-end using a single reconstruction loss.
The main advantage of our approach is that, in contrast to many recent deep
approaches which learn feature-based complex shape representations, our model
is explicit and every operation occurs in 3D space. As a result, our linear
shape models can be easily visualized and annotated, and failure cases can be
visually understood. While our main goal is to introduce a compact and
interpretable representation of shape collections, we show it leads to state of
the art results for few-shot segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Wildfire smoke plume segmentation using geostationary satellite imagery. (arXiv:2109.01637v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01637">
<div class="article-summary-box-inner">
<span><p>Wildfires have increased in frequency and severity over the past two decades,
especially in the Western United States. Beyond physical infrastructure damage
caused by these wildfire events, researchers have increasingly identified
harmful impacts of particulate matter generated by wildfire smoke on
respiratory, cardiovascular, and cognitive health. This inference is difficult
due to the spatial and temporal uncertainty regarding how much particulate
matter is specifically attributable to wildfire smoke. One factor contributing
to this challenge is the reliance on manually drawn smoke plume annotations,
which are often noisy representations limited to the United States. This work
uses deep convolutional neural networks to segment smoke plumes from
geostationary satellite imagery. We compare the performance of predicted plume
segmentations versus the noisy annotations using causal inference methods to
estimate the amount of variation each explains in Environmental Protection
Agency (EPA) measured surface level particulate matter &lt;2.5um in diameter
($\textrm{PM}_{2.5}$).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Instabilities in Plug-and-Play (PnP) algorithms from a learned denoiser. (arXiv:2109.01655v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01655">
<div class="article-summary-box-inner">
<span><p>It's well-known that inverse problems are ill-posed and to solve them
meaningfully, one has to employ regularization methods. Traditionally, popular
regularization methods are the penalized Variational approaches. In recent
years, the classical regularization approaches have been outclassed by the
so-called plug-and-play (PnP) algorithms, which copy the proximal gradient
minimization processes, such as ADMM or FISTA, but with any general denoiser.
However, unlike the traditional proximal gradient methods, the theoretical
underpinnings, convergence, and stability results have been insufficient for
these PnP-algorithms. Hence, the results obtained from these algorithms, though
empirically outstanding, can't always be completely trusted, as they may
contain certain instabilities or (hallucinated) features arising from the
denoiser, especially when using a pre-trained learned denoiser. In fact, in
this paper, we show that a PnP-algorithm can induce hallucinated features, when
using a pre-trained deep-learning-based (DnCNN) denoiser. We show that such
instabilities are quite different than the instabilities inherent to an
ill-posed problem. We also present methods to subdue these instabilities and
significantly improve the recoveries. We compare the advantages and
disadvantages of a learned denoiser over a classical denoiser (here, BM3D), as
well as, the effectiveness of the FISTA-PnP algorithm vs. the ADMM-PnP
algorithm. In addition, we also provide an algorithm to combine these two
denoisers, the learned and the classical, in a weighted fashion to produce even
better results. We conclude with numerical results which validate the developed
theories.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is it Raining Outside? Detection of Rainfall using General-Purpose Surveillance Cameras. (arXiv:1908.04034v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.04034">
<div class="article-summary-box-inner">
<span><p>In integrated surveillance systems based on visual cameras, the mitigation of
adverse weather conditions is an active research topic. Within this field, rain
removal algorithms have been developed that artificially remove rain streaks
from images or video. In order to deploy such rain removal algorithms in a
surveillance setting, one must detect if rain is present in the scene. In this
paper, we design a system for the detection of rainfall by the use of
surveillance cameras. We reimplement the former state-of-the-art method for
rain detection and compare it against a modern CNN-based method by utilizing 3D
convolutions. The two methods are evaluated on our new AAU Visual Rain Dataset
(VIRADA) that consists of 215 hours of general-purpose surveillance video from
two traffic crossings. The results show that the proposed 3D CNN outperforms
the previous state-of-the-art method by a large margin on all metrics, for both
of the traffic crossings. Finally, it is shown that the choice of
region-of-interest has a large influence on performance when trying to
generalize the investigated methods. The AAU VIRADA dataset and our
implementation of the two rain detection algorithms are publicly available at
https://bitbucket.org/aauvap/aau-virada.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Better Generalization: Joint Depth-Pose Learning without PoseNet. (arXiv:2004.01314v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.01314">
<div class="article-summary-box-inner">
<span><p>In this work, we tackle the essential problem of scale inconsistency for
self-supervised joint depth-pose learning. Most existing methods assume that a
consistent scale of depth and pose can be learned across all input samples,
which makes the learning problem harder, resulting in degraded performance and
limited generalization in indoor environments and long-sequence visual odometry
application. To address this issue, we propose a novel system that explicitly
disentangles scale from the network estimation. Instead of relying on PoseNet
architecture, our method recovers relative pose by directly solving fundamental
matrix from dense optical flow correspondence and makes use of a two-view
triangulation module to recover an up-to-scale 3D structure. Then, we align the
scale of the depth prediction with the triangulated point cloud and use the
transformed depth map for depth error computation and dense reprojection check.
Our whole system can be jointly trained end-to-end. Extensive experiments show
that our system not only reaches state-of-the-art performance on KITTI depth
and flow estimation, but also significantly improves the generalization ability
of existing self-supervised depth-pose learning methods under a variety of
challenging scenarios, and achieves state-of-the-art results among
self-supervised learning-based methods on KITTI Odometry and NYUv2 dataset.
Furthermore, we present some interesting findings on the limitation of
PoseNet-based relative pose estimation methods in terms of generalization
ability. Code is available at https://github.com/B1ueber2y/TrianFlow.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Efficient Quantitative Approach for Optimizing Convolutional Neural Networks. (arXiv:2009.05236v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05236">
<div class="article-summary-box-inner">
<span><p>With the increasing popularity of deep learning, Convolutional Neural
Networks (CNNs) have been widely applied in various domains, such as image
classification and object detection, and achieve stunning success in terms of
their high accuracy over the traditional statistical methods. To exploit the
potential of CNN models, a huge amount of research and industry efforts have
been devoted to optimizing CNNs. Among these endeavors, CNN architecture design
has attracted tremendous attention because of its great potential of improving
model accuracy or reducing model complexity. However, existing work either
introduces repeated training overhead in the search process or lacks an
interpretable metric to guide the design. To clear these hurdles, we propose
Information Field (IF), an explainable and easy-to-compute metric, to estimate
the quality of a CNN architecture and guide the search process of designs. To
validate the effectiveness of IF, we build a static optimizer to improve the
CNN architectures at both the stage level and the kernel level. Our optimizer
not only provides a clear and reproducible procedure but also mitigates
unnecessary training efforts in the architecture search process. Extensive
experiments and studies show that the models generated by our optimizer can
achieve up to 5.47% accuracy improvement and up to 65.38% parameters deduction,
compared with state-of-the-art CNN structures like MobileNet and ResNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ground-truth or DAER: Selective Re-query of Secondary Information. (arXiv:2009.07414v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07414">
<div class="article-summary-box-inner">
<span><p>Many vision tasks use secondary information at inference time -- a seed -- to
assist a computer vision model in solving a problem. For example, an initial
bounding box is needed to initialize visual object tracking. To date, all such
work makes the assumption that the seed is a good one. However, in practice,
from crowdsourcing to noisy automated seeds, this is often not the case. We
hence propose the problem of seed rejection -- determining whether to reject a
seed based on the expected performance degradation when it is provided in place
of a gold-standard seed. We provide a formal definition to this problem, and
focus on two meaningful subgoals: understanding causes of error and
understanding the model's response to noisy seeds conditioned on the primary
input. With these goals in mind, we propose a novel training method and
evaluation metrics for the seed rejection problem. We then use seeded versions
of the viewpoint estimation and fine-grained classification tasks to evaluate
these contributions. In these experiments, we show our method can reduce the
number of seeds that need to be reviewed for a target performance by over 23%
compared to strong baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Explanation and Use of Uncertainty Obtained by Bayesian Neural Network Classifiers for Breast Histopathology Images. (arXiv:2010.12575v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12575">
<div class="article-summary-box-inner">
<span><p>Despite the promise of Convolutional neural network (CNN) based
classification models for histopathological images, it is infeasible to
quantify its uncertainties. Moreover, CNNs may suffer from overfitting when the
data is biased. We show that Bayesian-CNN can overcome these limitations by
regularizing automatically and by quantifying the uncertainty. In addition, it
can perform much better than the state-of-the-art transfer learning CNN by
reducing the false negative and false positive by 11% and 7.7% respectively. We
have developed a novel technique to utilize the uncertainties provided by the
Bayesian-CNN that significantly improves the performance on a large fraction of
the test data (about 6% improvement in accuracy on 77% of test data). Further,
we provide a novel explanation for the uncertainty by projecting the data into
a low dimensional space through a nonlinear dimensionality reduction technique.
This dimensionality reduction enables interpretation of the test data through
visualization and reveals the structure of the data in a low dimensional
feature space. Besides, we modify the Bayesian--CNN by introducing a stochastic
adaptive activation function. The modified Bayesian-CNN performs slightly
better than Bayesian-CNN on all performance metrics and significantly reduces
the number of false negatives and false positives (3% reduction for both). This
work shows the advantages of Bayesian-CNN against the state-of-the-art,
explains and utilizes the uncertainties for histopathological images. It should
find applications in various medical image classifications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Where Are You? Localization from Embodied Dialog. (arXiv:2011.08277v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08277">
<div class="article-summary-box-inner">
<span><p>We present Where Are You? (WAY), a dataset of ~6k dialogs in which two humans
-- an Observer and a Locator -- complete a cooperative localization task. The
Observer is spawned at random in a 3D environment and can navigate from
first-person views while answering questions from the Locator. The Locator must
localize the Observer in a detailed top-down map by asking questions and giving
instructions. Based on this dataset, we define three challenging tasks:
Localization from Embodied Dialog or LED (localizing the Observer from dialog
history), Embodied Visual Dialog (modeling the Observer), and Cooperative
Localization (modeling both agents). In this paper, we focus on the LED task --
providing a strong baseline model with detailed ablations characterizing both
dataset biases and the importance of various modeling choices. Our best model
achieves 32.7% success at identifying the Observer's location within 3m in
unseen buildings, vs. 70.4% for human Locators.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Content and Style: Exploring Bias for Unsupervised Disentanglement. (arXiv:2102.10544v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10544">
<div class="article-summary-box-inner">
<span><p>Content and style (C-S) disentanglement intends to decompose the underlying
explanatory factors of objects into two independent subspaces. From the
unsupervised disentanglement perspective, we rethink content and style and
propose a formulation for unsupervised C-S disentanglement based on our
assumption that different factors are of different importance and popularity
for image reconstruction, which serves as a data bias. The corresponding model
inductive bias is introduced by our proposed C-S disentanglement Module (C-S
DisMo), which assigns different and independent roles to content and style when
approximating the real data distributions. Specifically, each content embedding
from the dataset, which encodes the most dominant factors for image
reconstruction, is assumed to be sampled from a shared distribution across the
dataset. The style embedding for a particular image, encoding the remaining
factors, is used to customize the shared distribution through an affine
transformation. The experiments on several popular datasets demonstrate that
our method achieves the state-of-the-art unsupervised C-S disentanglement,
which is comparable or even better than supervised methods. We verify the
effectiveness of our method by downstream tasks: domain translation and
single-view 3D reconstruction. Project page at
https://github.com/xrenaa/CS-DisMo.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The FaCells. An Exploratory Study about LSTM Layers on Face Sketches Classifiers. (arXiv:2102.11361v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11361">
<div class="article-summary-box-inner">
<span><p>Lines are human mental abstractions. A bunch of lines may form a drawing. A
set of drawings can feed an LSTM network input layer, considering each draw as
a list of lines and a line a list of points. This paper proposes the pointless
motive to classify the gender of celebrities' portraits as an excuse for
exploration in a broad, more artistic sense. Investigation results drove
compelling ideas here discussed. The experiments compared different ways to
represent draws to be input in a network and showed that an absolute format of
coordinates (x, y) was a better performer than a relative one (Dx, Dy) with
respect to prior points, most frequent in the reviewed literature. Experiments
also showed that, due to the recurrent nature of LSTMs, the order of lines
forming a drawing is a relevant factor for input in an LSTM classifier not
studied before. A minimum 'pencil' traveled length criteria for line ordering
proved suitable, possible by reducing it to a TSP particular instance. The best
configuration for gender classification appears with an LSTM layer that returns
the hidden state value for each input point step, followed by a global average
layer along the sequence, before the output dense layer. That result guided the
idea of removing the average in the network pipeline and return a per-point
attribute score just by adjusting tensors dimensions. With this trick, the
model detects an attribute in a drawing and also recognizes the points linked
to it. Moreover, by overlapping filtered lines of portraits, an attribute's
visual essence is depicted. Meet the FaCells.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic evaluation of human oocyte developmental potential from microscopy images. (arXiv:2103.00302v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00302">
<div class="article-summary-box-inner">
<span><p>Infertility is becoming an issue for an increasing number of couples. The
most common solution, in vitro fertilization, requires embryologists to
carefully examine light microscopy images of human oocytes to determine their
developmental potential. We propose an automatic system to improve the speed,
repeatability, and accuracy of this process. We first localize individual
oocytes and identify their principal components using CNN (U-Net) segmentation.
Next, we calculate several descriptors based on geometry and texture. The final
step is an SVM classifier. Both the segmentation and classification training is
based on expert annotations. The presented approach leads to a classification
accuracy of 70%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robustness via Cross-Domain Ensembles. (arXiv:2103.10919v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10919">
<div class="article-summary-box-inner">
<span><p>We present a method for making neural network predictions robust to shifts
from the training data distribution. The proposed method is based on making
predictions via a diverse set of cues (called 'middle domains') and ensembling
them into one strong prediction. The premise of the idea is that predictions
made via different cues respond differently to a distribution shift, hence one
should be able to merge them into one robust final prediction. We perform the
merging in a straightforward but principled manner based on the uncertainty
associated with each prediction. The evaluations are performed using multiple
tasks and datasets (Taskonomy, Replica, ImageNet, CIFAR) under a wide range of
adversarial and non-adversarial distribution shifts which demonstrate the
proposed method is considerably more robust than its standard learning
counterpart, conventional deep ensembles, and several other baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automating Augmentation Through Random Unidimensional Search. (arXiv:2106.08756v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08756">
<div class="article-summary-box-inner">
<span><p>It is no secret amongst deep learning researchers that finding the optimal
data augmentation strategy during training can mean the difference between
state-of-the-art performance and a run-of-the-mill result. To that end, the
community has seen many efforts to automate the process of finding the perfect
augmentation procedure for any task at hand. Unfortunately, even recent
cutting-edge methods bring massive computational overhead, requiring as many as
100 full model trainings to settle on an ideal configuration. We show how to
achieve equivalent performance in just 6: with Random Unidimensional
Augmentation. Source code is available at https://github.com/fastestimator/RUA
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Layer Folding: Neural Network Depth Reduction using Activation Linearization. (arXiv:2106.09309v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09309">
<div class="article-summary-box-inner">
<span><p>Despite the increasing prevalence of deep neural networks, their
applicability in resource-constrained devices is limited due to their
computational load. While modern devices exhibit a high level of parallelism,
real-time latency is still highly dependent on networks' depth. Although recent
works show that below a certain depth, the width of shallower networks must
grow exponentially, we presume that neural networks typically exceed this
minimal depth to accelerate convergence and incrementally increase accuracy.
This motivates us to transform pre-trained deep networks that already exploit
such advantages into shallower forms. We propose a method that learns whether
non-linear activations can be removed, allowing to fold consecutive linear
layers into one. We apply our method to networks pre-trained on CIFAR-10 and
CIFAR-100 and find that they can all be transformed into shallower forms that
share a similar depth. Finally, we use our method to provide more efficient
alternatives to MobileNetV2 and EfficientNet-Lite architectures on the ImageNet
classification task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hepatocellular Carcinoma Segmentation from Digital Subtraction Angiography Videos using Learnable Temporal Difference. (arXiv:2107.04306v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04306">
<div class="article-summary-box-inner">
<span><p>Automatic segmentation of hepatocellular carcinoma (HCC) in Digital
Subtraction Angiography (DSA) videos can assist radiologists in efficient
diagnosis of HCC and accurate evaluation of tumors in clinical practice. Few
studies have investigated HCC segmentation from DSA videos. It shows great
challenging due to motion artifacts in filming, ambiguous boundaries of tumor
regions and high similarity in imaging to other anatomical tissues. In this
paper, we raise the problem of HCC segmentation in DSA videos, and build our
own DSA dataset. We also propose a novel segmentation network called
DSA-LTDNet, including a segmentation sub-network, a temporal difference
learning (TDL) module and a liver region segmentation (LRS) sub-network for
providing additional guidance. DSA-LTDNet is preferable for learning the latent
motion information from DSA videos proactively and boosting segmentation
performance. All of experiments are conducted on our self-collected dataset.
Experimental results show that DSA-LTDNet increases the DICE score by nearly 4%
compared to the U-Net baseline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dense Supervision Propagation for Weakly Supervised Semantic Segmentation on 3D Point Clouds. (arXiv:2107.11267v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11267">
<div class="article-summary-box-inner">
<span><p>Semantic segmentation on 3D point clouds is an important task for 3D scene
understanding. While dense labeling on 3D data is expensive and time-consuming,
only a few works address weakly supervised semantic point cloud segmentation
methods to relieve the labeling cost by learning from simpler and cheaper
labels. Meanwhile, there are still huge performance gaps between existing
weakly supervised methods and state-of-the-art fully supervised methods. In
this paper, we train a semantic point cloud segmentation network with only a
small portion of points being labeled. We argue that we can better utilize the
limited supervision information as we densely propagate the supervision signal
from the labeled points to other points within and across the input samples.
Specifically, we propose a cross-sample feature reallocating module to transfer
similar features and therefore re-route the gradients across two samples with
common classes and an intra-sample feature redistribution module to propagate
supervision signals on unlabeled points across and within point cloud samples.
We conduct extensive experiments on public datasets S3DIS and ScanNet. Our
weakly supervised method with only 10\% and 1\% of labels can produce
compatible results with the fully supervised counterpart.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Full-Duplex Strategy for Video Object Segmentation. (arXiv:2108.03151v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03151">
<div class="article-summary-box-inner">
<span><p>Previous video object segmentation approaches mainly focus on using simplex
solutions between appearance and motion, limiting feature collaboration
efficiency among and across these two cues. In this work, we study a novel and
efficient full-duplex strategy network (FSNet) to address this issue, by
considering a better mutual restraint scheme between motion and appearance in
exploiting the cross-modal features from the fusion and decoding stage.
Specifically, we introduce the relational cross-attention module (RCAM) to
achieve bidirectional message propagation across embedding sub-spaces. To
improve the model's robustness and update the inconsistent features from the
spatial-temporal embeddings, we adopt the bidirectional purification module
(BPM) after the RCAM. Extensive experiments on five popular benchmarks show
that our FSNet is robust to various challenging scenarios (e.g., motion blur,
occlusion) and achieves favourable performance against existing cutting-edges
both in the video object segmentation and video salient object detection tasks.
The project is publicly available at: https://dpfan.net/FSNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pattern Recognition in Vital Signs Using Spectrograms. (arXiv:2108.03168v2 [eess.SP] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03168">
<div class="article-summary-box-inner">
<span><p>Spectrograms visualize the frequency components of a given signal which may
be an audio signal or even a time-series signal. Audio signals have higher
sampling rate and high variability of frequency with time. Spectrograms can
capture such variations well. But, vital signs which are time-series signals
have less sampling frequency and low-frequency variability due to which,
spectrograms fail to express variations and patterns. In this paper, we propose
a novel solution to introduce frequency variability using frequency modulation
on vital signs. Then we apply spectrograms on frequency modulated signals to
capture the patterns. The proposed approach has been evaluated on 4 different
medical datasets across both prediction and classification tasks. Significant
results are found showing the efficacy of the approach for vital sign signals.
The results from the proposed approach are promising with an accuracy of 91.55%
and 91.67% in prediction and classification tasks respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">STN PLAD: A Dataset for Multi-Size Power Line Assets Detection in High-Resolution UAV Images. (arXiv:2108.07944v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07944">
<div class="article-summary-box-inner">
<span><p>Many power line companies are using UAVs to perform their inspection
processes instead of putting their workers at risk by making them climb high
voltage power line towers, for instance. A crucial task for the inspection is
to detect and classify assets in the power transmission lines. However, public
data related to power line assets are scarce, preventing a faster evolution of
this area. This work proposes the Power Line Assets Dataset, containing
high-resolution and real-world images of multiple high-voltage power line
components. It has 2,409 annotated objects divided into five classes:
transmission tower, insulator, spacer, tower plate, and Stockbridge damper,
which vary in size (resolution), orientation, illumination, angulation, and
background. This work also presents an evaluation with popular deep object
detection methods, showing considerable room for improvement. The STN PLAD
dataset is publicly available at https://github.com/andreluizbvs/PLAD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning to Discover Reflection Symmetry via Polar Matching Convolution. (arXiv:2108.12952v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12952">
<div class="article-summary-box-inner">
<span><p>The task of reflection symmetry detection remains challenging due to
significant variations and ambiguities of symmetry patterns in the wild.
Furthermore, since the local regions are required to match in reflection for
detecting a symmetry pattern, it is hard for standard convolutional networks,
which are not equivariant to rotation and reflection, to learn the task. To
address the issue, we introduce a new convolutional technique, dubbed the polar
matching convolution, which leverages a polar feature pooling, a
self-similarity encoding, and a systematic kernel design for axes of different
angles. The proposed high-dimensional kernel convolution network effectively
learns to discover symmetry patterns from real-world images, overcoming the
limitations of standard convolution. In addition, we present a new dataset and
introduce a self-supervised learning strategy by augmenting the dataset with
synthesizing images. Experiments demonstrate that our method outperforms
state-of-the-art methods in terms of accuracy and robustness.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Diverse Sample Generation: Pushing the Limit of Data-free Quantization. (arXiv:2109.00212v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00212">
<div class="article-summary-box-inner">
<span><p>Recently, generative data-free quantization emerges as a practical approach
that compresses the neural network to low bit-width without access to real
data. It generates data to quantize the network by utilizing the batch
normalization (BN) statistics of its full-precision counterpart. However, our
study shows that in practice, the synthetic data completely constrained by BN
statistics suffers severe homogenization at distribution and sample level,
which causes serious accuracy degradation of the quantized network. This paper
presents a generic Diverse Sample Generation (DSG) scheme for the generative
data-free post-training quantization and quantization-aware training, to
mitigate the detrimental homogenization. In our DSG, we first slack the
statistics alignment for features in the BN layer to relax the distribution
constraint. Then we strengthen the loss impact of the specific BN layer for
different samples and inhibit the correlation among samples in the generation
process, to diversify samples from the statistical and spatial perspective,
respectively. Extensive experiments show that for large-scale image
classification tasks, our DSG can consistently outperform existing data-free
quantization methods on various neural architectures, especially under
ultra-low bit-width (e.g., 22% gain under W4A4 setting). Moreover, data
diversifying caused by our DSG brings a general gain in various quantization
methods, demonstrating diversity is an important property of high-quality
synthetic data for data-free quantization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Weakly-Supervised Surface Crack Segmentation Method using Localisation with a Classifier and Thresholding. (arXiv:2109.00456v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00456">
<div class="article-summary-box-inner">
<span><p>Surface cracks are a common sight on public infrastructure nowadays. Recent
work has been addressing this problem by supporting structural maintenance
measures using machine learning methods which segment surface cracks from their
background so that they are easy to localize. However, a common issue with
those methods is that to create a well functioning algorithm, the training data
needs to have detailed annotations of pixels that belong to cracks. Our work
proposes a weakly supervised approach which leverages a CNN classifier to
create surface crack segmentation maps. We use this classifier to create a
rough crack localisation map by using its class activation maps and a patch
based classification approach and fuse this with a thresholding based approach
to segment the mostly darker crack pixels. The classifier assists in
suppressing noise from the background regions, which commonly are incorrectly
highlighted as cracks by standard thresholding methods. We focus on the ease of
implementation of our method and it is shown to perform well on several surface
crack datasets, segmenting cracks efficiently even though the only data that
was used for training were simple classification labels.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse to Dense Motion Transfer for Face Image Animation. (arXiv:2109.00471v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00471">
<div class="article-summary-box-inner">
<span><p>Face image animation from a single image has achieved remarkable progress.
However, it remains challenging when only sparse landmarks are available as the
driving signal. Given a source face image and a sequence of sparse face
landmarks, our goal is to generate a video of the face imitating the motion of
landmarks. We develop an efficient and effective method for motion transfer
from sparse landmarks to the face image. We then combine global and local
motion estimation in a unified model to faithfully transfer the motion. The
model can learn to segment the moving foreground from the background and
generate not only global motion, such as rotation and translation of the face,
but also subtle local motion such as the gaze change. We further improve face
landmark detection on videos. With temporally better aligned landmark sequences
for training, our method can generate temporally coherent videos with higher
visual quality. Experiments suggest we achieve results comparable to the
state-of-the-art image driven method on the same identity testing and better
results on cross identity testing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NerfingMVS: Guided Optimization of Neural Radiance Fields for Indoor Multi-view Stereo. (arXiv:2109.01129v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01129">
<div class="article-summary-box-inner">
<span><p>In this work, we present a new multi-view depth estimation method that
utilizes both conventional SfM reconstruction and learning-based priors over
the recently proposed neural radiance fields (NeRF). Unlike existing neural
network based optimization method that relies on estimated correspondences, our
method directly optimizes over implicit volumes, eliminating the challenging
step of matching pixels in indoor scenes. The key to our approach is to utilize
the learning-based priors to guide the optimization process of NeRF. Our system
firstly adapts a monocular depth network over the target scene by finetuning on
its sparse SfM reconstruction. Then, we show that the shape-radiance ambiguity
of NeRF still exists in indoor environments and propose to address the issue by
employing the adapted depth priors to monitor the sampling process of volume
rendering. Finally, a per-pixel confidence map acquired by error computation on
the rendered image can be used to further improve the depth quality.
Experiments show that our proposed framework significantly outperforms
state-of-the-art methods on indoor scenes, with surprising findings presented
on the effectiveness of correspondence-based optimization and NeRF-based
optimization over the adapted depth priors. In addition, we show that the
guided optimization scheme does not sacrifice the original synthesis capability
of neural radiance fields, improving the rendering quality on both seen and
novel views. Code is available at https://github.com/weiyithu/NerfingMVS.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-09-06 08:51:53.040849652 UTC">2021-09-06 08:51:53 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>