<!DOCTYPE html>
<html lang="en">
<head>
<title>M.D.Arxiv</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-12-24T01:30:00Z">12-24</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Evolution and trade-off dynamics of functional load. (arXiv:2112.12224v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12224">
<div class="article-summary-box-inner">
<span><p>Function Load (FL) quantifies the contributions by phonological contrasts to
distinctions made across the lexicon. Previous research has linked particularly
low values of FL to sound change. Here we broaden the scope of enquiry into FL,
to its evolution at all values. We apply phylogenetic methods to examine the
diachronic evolution of FL across 90 languages of the Pama-Nyungan (PN) family
of Australia. We find a high degree of phylogenetic signal in FL. Though
phylogenetic signal has been reported for phonological structures, such as
phonotactics, its detection in measures of phonological function is novel. We
also find a significant, negative correlation between the FL of vowel length
and of the following consonant, that is, a deep-time historical trade-off
dynamic, which we relate to known allophony in modern PN languages and
compensatory sound changes in their past. The finding reveals a historical
dynamic, similar to transphonologization, which we characterize as a flow of
contrastiveness between subsystems of the phonology. Recurring across a
language family which spans a whole continent and many millennia of time depth,
our finding provides one of the most compelling examples yet of Sapir's 'drift'
hypothesis, of non-accidentally parallel development in historically related
languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Morphological classifiers. (arXiv:2112.12262v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12262">
<div class="article-summary-box-inner">
<span><p>This work proposes a new type of classifier called Morphological Classifier
(MC). MCs aggregate concepts from mathematical morphology and supervised
learning. The outcomes of this aggregation are classifiers that may preserve
shape characteristics of classes, subject to the choice of a stopping criterion
and structuring element. MCs are fundamentally based on set theory, and their
classification model can be a mathematical set itself. Two types of
morphological classifiers are proposed in the current work, namely,
Morphological k-NN (MkNN) and Morphological Dilation Classifier (MDC), which
demonstrate the feasibility of the approach. This work provides evidence
regarding the advantages of MCs, e.g., very fast classification times as well
as competitive accuracy rates. The performance of MkNN and MDC was tested using
p -dimensional datasets. MCs tied or outperformed 14 well established
classifiers in 5 out of 8 datasets. In all occasions, the obtained accuracies
were higher than the average accuracy obtained with all classifiers. Moreover,
the proposed implementations utilize the power of the Graphics Processing Units
(GPUs) to speed up processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigating Effect of Dialogue History in Multilingual Task Oriented Dialogue Systems. (arXiv:2112.12318v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12318">
<div class="article-summary-box-inner">
<span><p>While the English virtual assistants have achieved exciting performance with
an enormous amount of training resources, the needs of non-English-speakers
have not been satisfied well. Up to Dec 2021, Alexa, one of the most popular
smart speakers around the world, is able to support 9 different languages [1],
while there are thousands of languages in the world, 91 of which are spoken by
more than 10 million people according to statistics published in 2019 [2].
However, training a virtual assistant in other languages than English is often
more difficult, especially for those low-resource languages. The lack of
high-quality training data restricts the performance of models, resulting in
poor user satisfaction. Therefore, we devise an efficient and effective
training solution for multilingual task-orientated dialogue systems, using the
same dataset generation pipeline and end-to-end dialogue system architecture as
BiToD[5], which adopted some key design choices for a minimalistic natural
language design where formal dialogue states are used in place of natural
language inputs. This reduces the room for error brought by weaker natural
language models, and ensures the model can correctly extract the essential slot
values needed to perform dialogue state tracking (DST). Our goal is to reduce
the amount of natural language encoded at each turn, and the key parameter we
investigate is the number of turns (H) to feed as history to model. We first
explore the turning point where increasing H begins to yield limiting returns
on the overall performance. Then we examine whether the examples a model with
small H gets wrong can be categorized in a way for the model to do few-shot
finetuning on. Lastly, will explore the limitations of this approach, and
whether there is a certain type of examples that this approach will not be able
to resolve.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Making sense of electrical vehicle discussions using sentiment analysis on closely related news and user comments. (arXiv:2112.12327v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12327">
<div class="article-summary-box-inner">
<span><p>We used a token-wise and document-wise sentiment analysis using both
unsupervised and supervised models applied to both news and user reviews
dataset. And our token-wise sentiment analysis found a statistically
significant difference in sentiment between the two groups (both of which were
very large N), our document-wise supervised sentiment analysis found no
significant difference in sentiment.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Do Multi-Lingual Pre-trained Language Models Reveal Consistent Token Attributions in Different Languages?. (arXiv:2112.12356v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12356">
<div class="article-summary-box-inner">
<span><p>During the past several years, a surge of multi-lingual Pre-trained Language
Models (PLMs) has been proposed to achieve state-of-the-art performance in many
cross-lingual downstream tasks. However, the understanding of why multi-lingual
PLMs perform well is still an open domain. For example, it is unclear whether
multi-Lingual PLMs reveal consistent token attributions in different languages.
To address this, in this paper, we propose a Cross-lingual Consistency of Token
Attributions (CCTA) evaluation framework. Extensive experiments in three
downstream tasks demonstrate that multi-lingual PLMs assign significantly
different attributions to multi-lingual synonyms. Moreover, we have the
following observations: 1) the Spanish achieves the most consistent token
attributions in different languages when it is used for training PLMs; 2) the
consistency of token attributions strongly correlates with performance in
downstream tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">S+PAGE: A Speaker and Position-Aware Graph Neural Network Model for Emotion Recognition in Conversation. (arXiv:2112.12389v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12389">
<div class="article-summary-box-inner">
<span><p>Emotion recognition in conversation (ERC) has attracted much attention in
recent years for its necessity in widespread applications. Existing ERC methods
mostly model the self and inter-speaker context separately, posing a major
issue for lacking enough interaction between them. In this paper, we propose a
novel Speaker and Position-Aware Graph neural network model for ERC (S+PAGE),
which contains three stages to combine the benefits of both Transformer and
relational graph convolution network (R-GCN) for better contextual modeling.
Firstly, a two-stream conversational Transformer is presented to extract the
coarse self and inter-speaker contextual features for each utterance. Then, a
speaker and position-aware conversation graph is constructed, and we propose an
enhanced R-GCN model, called PAG, to refine the coarse features guided by a
relative positional encoding. Finally, both of the features from the former two
stages are input into a conditional random field layer to model the emotion
transfer.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sparse-softmax: A Simpler and Faster Alternative Softmax Transformation. (arXiv:2112.12433v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12433">
<div class="article-summary-box-inner">
<span><p>The softmax function is widely used in artificial neural networks for the
multiclass classification problems, where the softmax transformation enforces
the output to be positive and sum to one, and the corresponding loss function
allows to use maximum likelihood principle to optimize the model. However,
softmax leaves a large margin for loss function to conduct optimizing operation
when it comes to high-dimensional classification, which results in
low-performance to some extent. In this paper, we provide an empirical study on
a simple and concise softmax variant, namely sparse-softmax, to alleviate the
problem that occurred in traditional softmax in terms of high-dimensional
classification problems. We evaluate our approach in several interdisciplinary
tasks, the experimental results show that sparse-softmax is simpler, faster,
and produces better results than the baseline models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TOD-DA: Towards Boosting the Robustness of Task-oriented Dialogue Modeling on Spoken Conversations. (arXiv:2112.12441v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12441">
<div class="article-summary-box-inner">
<span><p>Task-oriented dialogue systems have been plagued by the difficulties of
obtaining large-scale and high-quality annotated conversations. Furthermore,
most of the publicly available datasets only include written conversations,
which are insufficient to reflect actual human behaviors in practical spoken
dialogue systems. In this paper, we propose Task-oriented Dialogue Data
Augmentation (TOD-DA), a novel model-agnostic data augmentation paradigm to
boost the robustness of task-oriented dialogue modeling on spoken
conversations. The TOD-DA consists of two modules: 1) Dialogue Enrichment to
expand training data on task-oriented conversations for easing data sparsity
and 2) Spoken Conversation Simulator to imitate oral style expressions and
speech recognition errors in diverse granularities for bridging the gap between
written and spoken conversations. With such designs, our approach ranked first
in both tasks of DSTC10 Track2, a benchmark for task-oriented dialogue modeling
on spoken conversations, demonstrating the superiority and effectiveness of our
proposed TOD-DA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">More Than Words: Towards Better Quality Interpretations of Text Classifiers. (arXiv:2112.12444v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12444">
<div class="article-summary-box-inner">
<span><p>The large size and complex decision mechanisms of state-of-the-art text
classifiers make it difficult for humans to understand their predictions,
leading to a potential lack of trust by the users. These issues have led to the
adoption of methods like SHAP and Integrated Gradients to explain
classification decisions by assigning importance scores to input tokens.
However, prior work, using different randomization tests, has shown that
interpretations generated by these methods may not be robust. For instance,
models making the same predictions on the test set may still lead to different
feature importance rankings. In order to address the lack of robustness of
token-based interpretability, we explore explanations at higher semantic levels
like sentences. We use computational metrics and human subject studies to
compare the quality of sentence-based interpretations against token-based ones.
Our experiments show that higher-level feature attributions offer several
advantages: 1) they are more robust as measured by the randomization tests, 2)
they lead to lower variability when using approximation-based methods like
SHAP, and 3) they are more intelligible to humans in situations where the
linguistic coherence resides at a higher granularity level. Based on these
findings, we show that token-based interpretability, while being a convenient
first choice given the input interfaces of the ML models, is not the most
effective one in all situations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TFW2V: An Enhanced Document Similarity Method for the Morphologically Rich Finnish Language. (arXiv:2112.12489v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12489">
<div class="article-summary-box-inner">
<span><p>Measuring the semantic similarity of different texts has many important
applications in Digital Humanities research such as information retrieval,
document clustering and text summarization. The performance of different
methods depends on the length of the text, the domain and the language. This
study focuses on experimenting with some of the current approaches to Finnish,
which is a morphologically rich language. At the same time, we propose a simple
method, TFW2V, which shows high efficiency in handling both long text documents
and limited amounts of data. Furthermore, we design an objective evaluation
method which can be used as a framework for benchmarking text similarity
approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Augmentation based Consistency Contrastive Pre-training for Automatic Speech Recognition. (arXiv:2112.12522v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12522">
<div class="article-summary-box-inner">
<span><p>Self-supervised acoustic pre-training has achieved amazing results on the
automatic speech recognition (ASR) task. Most of the successful acoustic
pre-training methods use contrastive learning to learn the acoustic
representations by distinguish the representations from different time steps,
ignoring the speaker and environment robustness. As a result, the pre-trained
model could show poor performance when meeting out-of-domain data during
fine-tuning. In this letter, we design a novel consistency contrastive learning
(CCL) method by utilizing data augmentation for acoustic pre-training.
Different kinds of augmentation are applied on the original audios and then the
augmented audios are fed into an encoder. The encoder should not only contrast
the representations within one audio but also maximize the measurement of the
representations across different augmented audios. By this way, the pre-trained
model can learn a text-related representation method which is more robust with
the change of the speaker or the environment.Experiments show that by applying
the CCL method on the Wav2Vec2.0, better results can be realized both on the
in-domain data and the out-of-domain data. Especially for noisy out-of-domain
data, more than 15% relative improvement can be obtained.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are E2E ASR models ready for an industrial usage?. (arXiv:2112.12572v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12572">
<div class="article-summary-box-inner">
<span><p>The Automated Speech Recognition (ASR) community experiences a major turning
point with the rise of the fully-neural (End-to-End, E2E) approaches. At the
same time, the conventional hybrid model remains the standard choice for the
practical usage of ASR. According to previous studies, the adoption of E2E ASR
in real-world applications was hindered by two main limitations: their ability
to generalize on unseen domains and their high operational cost. In this paper,
we investigate both above-mentioned drawbacks by performing a comprehensive
multi-domain benchmark of several contemporary E2E models and a hybrid
baseline. Our experiments demonstrate that E2E models are viable alternatives
for the hybrid approach, and even outperform the baseline both in accuracy and
in operational efficiency. As a result, our study shows that the generalization
and complexity issues are no longer the major obstacle for industrial
integration, and draws the community's attention to other potential limitations
of the E2E approaches in some specific use-cases.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distilling the Knowledge of Romanian BERTs Using Multiple Teachers. (arXiv:2112.12650v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12650">
<div class="article-summary-box-inner">
<span><p>As transfer learning from large-scale pre-trained language models has become
prevalent in Natural Language Processing, running these models in
computationally constrained environments remains a challenging problem yet to
address. Several solutions including knowledge distillation, network
quantization or network pruning have been proposed; however, these approaches
focus mostly on the English language, thus widening the gap when considering
low-resource languages. In this work, we introduce three light and fast
versions of distilled BERT models for the Romanian language:
Distil-BERT-base-ro, Distil-RoBERT-base and DistilMulti-BERT-base-ro. The first
two models resulted from individually distilling the knowledge of the two base
versions of Romanian BERTs available in literature, while the last one was
obtained by distilling their ensemble. To our knowledge, this is the first
attempt to create publicly available Romanian distilled BERT models, which were
thoroughly evaluated on five tasks: part-of-speech tagging, named entity
recognition, sentiment analysis, semantic textual similarity and dialect
identification. The experimental results on these benchmarks proved that our
three distilled models maintain most performance in terms of accuracy with
their teachers, while being twice as fast on a GPU and ~35\% smaller. In
addition, we further test the similarity between our students and their
teachers prediction by measuring their label and probability loyalty, together
with regression loyalty - a new metric introduced in this work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards more patient friendly clinical notes through language models and ontologies. (arXiv:2112.12672v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12672">
<div class="article-summary-box-inner">
<span><p>Clinical notes are an efficient way to record patient information but are
notoriously hard to decipher for non-experts. Automatically simplifying medical
text can empower patients with valuable information about their health, while
saving clinicians time. We present a novel approach to automated simplification
of medical text based on word frequencies and language modelling, grounded on
medical ontologies enriched with layman terms. We release a new dataset of
pairs of publicly available medical sentences and a version of them simplified
by clinicians. Also, we define a novel text simplification metric and
evaluation framework, which we use to conduct a large-scale human evaluation of
our method against the state of the art. Our method based on a language model
trained on medical forum data generates simpler sentences while preserving both
grammar and the original meaning, surpassing the current state of the art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation. (arXiv:2112.12731v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12731">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models have achieved state-of-the-art results in various
Natural Language Processing (NLP) tasks. GPT-3 has shown that scaling up
pre-trained language models can further exploit their enormous potential. A
unified framework named ERNIE 3.0 was recently proposed for pre-training
large-scale knowledge enhanced models and trained a model with 10 billion
parameters. ERNIE 3.0 outperformed the state-of-the-art models on various NLP
tasks. In order to explore the performance of scaling up ERNIE 3.0, we train a
hundred-billion-parameter model called ERNIE 3.0 Titan with up to 260 billion
parameters on the PaddlePaddle platform. Furthermore, we design a
self-supervised adversarial loss and a controllable language modeling loss to
make ERNIE 3.0 Titan generate credible and controllable texts. To reduce the
computation overhead and carbon emission, we propose an online distillation
framework for ERNIE 3.0 Titan, where the teacher model will teach students and
train itself simultaneously. ERNIE 3.0 Titan is the largest Chinese dense
pre-trained model so far. Empirical results show that the ERNIE 3.0 Titan
outperforms the state-of-the-art models on 68 NLP datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sub-Character Tokenization for Chinese Pretrained Language Models. (arXiv:2106.00400v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00400">
<div class="article-summary-box-inner">
<span><p>Tokenization is fundamental to pretrained language models (PLMs). Existing
tokenization methods for Chinese PLMs typically treat each character as an
indivisible token. However, they ignore the unique feature of the Chinese
writing system where additional linguistic information exists below the
character level, i.e., at the sub-character level. To utilize such information,
we propose sub-character (SubChar for short) tokenization. Specifically, we
first encode the input text by converting each Chinese character into a short
sequence based on its glyph or pronunciation, and then construct the vocabulary
based on the encoded text with sub-word tokenization. Experimental results show
that SubChar tokenizers have two main advantages over existing tokenizers: 1)
They can tokenize inputs into much shorter sequences, thus improving the
computational efficiency. 2) Pronunciation-based SubChar tokenizers can encode
Chinese homophones into the same transliteration sequences and produce the same
tokenization output, hence being robust to all homophone typos. At the same
time, models trained with SubChar tokenizers perform competitively on
downstream tasks. We release our code at
https://github.com/thunlp/SubCharTokenization to facilitate future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Primer on Pretrained Multilingual Language Models. (arXiv:2107.00676v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00676">
<div class="article-summary-box-inner">
<span><p>Multilingual Language Models (\MLLMs) such as mBERT, XLM, XLM-R,
\textit{etc.} have emerged as a viable option for bringing the power of
pretraining to a large number of languages. Given their success in zero-shot
transfer learning, there has emerged a large body of work in (i) building
bigger \MLLMs~covering a large number of languages (ii) creating exhaustive
benchmarks covering a wider variety of tasks and languages for evaluating
\MLLMs~ (iii) analysing the performance of \MLLMs~on monolingual, zero-shot
cross-lingual and bilingual tasks (iv) understanding the universal language
patterns (if any) learnt by \MLLMs~ and (v) augmenting the (often) limited
capacity of \MLLMs~ to improve their performance on seen or even unseen
languages. In this survey, we review the existing literature covering the above
broad areas of research pertaining to \MLLMs. Based on our survey, we recommend
some promising directions of future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pre-trained Language Models as Prior Knowledge for Playing Text-based Games. (arXiv:2107.08408v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08408">
<div class="article-summary-box-inner">
<span><p>Recently, text world games have been proposed to enable artificial agents to
understand and reason about real-world scenarios. These text-based games are
challenging for artificial agents, as it requires an understanding of and
interaction using natural language in a partially observable environment.
Agents observe the environment via textual descriptions designed to be
challenging enough for even human players. Past approaches have not paid enough
attention to the language understanding capability of the proposed agents.
Typically, these approaches train from scratch, an agent that learns both
textual representations and the gameplay online during training using a
temporal loss function. Given the sample-inefficiency of RL approaches, it is
inefficient to learn rich enough textual representations to be able to
understand and reason using the textual observation in such a complicated game
environment setting. In this paper, we improve the semantic understanding of
the agent by proposing a simple RL with LM framework where we use
transformer-based language models with Deep RL models. We perform a detailed
study of our framework to demonstrate how our model outperforms all existing
agents on the popular game, Zork1, to achieve a score of 44.7, which is 1.6
higher than the state-of-the-art model. Overall, our proposed approach
outperforms 4 games out of the 14 text-based games, while performing comparable
to the state-of-the-art models on the remaining games.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Fine-Grained Reasoning for Fake News Detection. (arXiv:2110.15064v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.15064">
<div class="article-summary-box-inner">
<span><p>The detection of fake news often requires sophisticated reasoning skills,
such as logically combining information by considering word-level subtle clues.
In this paper, we move towards fine-grained reasoning for fake news detection
by better reflecting the logical processes of human thinking and enabling the
modeling of subtle clues. In particular, we propose a fine-grained reasoning
framework by following the human information-processing model, introduce a
mutual-reinforcement-based method for incorporating human knowledge about which
evidence is more important, and design a prior-aware bi-channel kernel graph
network to model subtle differences between pieces of evidence. Extensive
experiments show that our model outperforms the state-of-the-art methods and
demonstrate the explainability of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERTMap: A BERT-based Ontology Alignment System. (arXiv:2112.02682v2 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.02682">
<div class="article-summary-box-inner">
<span><p>Ontology alignment (a.k.a ontology matching (OM)) plays a critical role in
knowledge integration. Owing to the success of machine learning in many
domains, it has been applied in OM. However, the existing methods, which often
adopt ad-hoc feature engineering or non-contextual word embeddings, have not
yet outperformed rule-based systems especially in an unsupervised setting. In
this paper, we propose a novel OM system named BERTMap which can support both
unsupervised and semi-supervised settings. It first predicts mappings using a
classifier based on fine-tuning the contextual embedding model BERT on text
semantics corpora extracted from ontologies, and then refines the mappings
through extension and repair by utilizing the ontology structure and logic. Our
evaluation with three alignment tasks on biomedical ontologies demonstrates
that BERTMap can often perform better than the leading OM systems LogMap and
AML.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">English-to-Chinese Transliteration with Phonetic Back-transliteration. (arXiv:2112.10321v1 [cs.CL] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.10321">
<div class="article-summary-box-inner">
<span><p>Transliteration is a task of translating named entities from a language to
another, based on phonetic similarity. The task has embraced deep learning
approaches in recent years, yet, most ignore the phonetic features of the
involved languages. In this work, we incorporate phonetic information into
neural networks in two ways: we synthesize extra data using forward and
back-translation but in a phonetic manner; and we pre-train models on a
phonetic task before learning transliteration. Our experiments include three
language pairs and six directions, namely English to and from Chinese, Hebrew
and Thai. Results indicate that our proposed approach brings benefits to the
model and achieves better or similar performance when compared to state of the
art.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
<li class="source">
<section>
<h3 class="source-name">cs.CV updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Recur, Attend or Convolve? Frame Dependency Modeling Matters for Cross-Domain Robustness in Action Recognition. (arXiv:2112.12175v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12175">
<div class="article-summary-box-inner">
<span><p>Most action recognition models today are highly parameterized, and evaluated
on datasets with predominantly spatially distinct classes. Previous results for
single images have shown that 2D Convolutional Neural Networks (CNNs) tend to
be biased toward texture rather than shape for various computer vision tasks
(Geirhos et al., 2019), reducing generalization. Taken together, this raises
suspicion that large video models learn spurious correlations rather than to
track relevant shapes over time and infer generalizable semantics from their
movement. A natural way to avoid parameter explosion when learning visual
patterns over time is to make use of recurrence across the time-axis. In this
article, we empirically study the cross-domain robustness for recurrent,
attention-based and convolutional video models, respectively, to investigate
whether this robustness is influenced by the frame dependency modeling. Our
novel Temporal Shape dataset is proposed as a light-weight dataset to assess
the ability to generalize across temporal shapes which are not revealed from
single frames. We find that when controlling for performance and layer
structure, recurrent models show better out-of-domain generalization ability on
the Temporal Shape dataset than convolution- and attention-based models.
Moreover, our experiments indicate that convolution- and attention-based models
exhibit more texture bias on Diving48 than recurrent models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Personality Recognition using Cross-Attention Transformer and Behaviour Encoding. (arXiv:2112.12180v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12180">
<div class="article-summary-box-inner">
<span><p>Personality computing and affective computing have gained recent interest in
many research areas. The datasets for the task generally have multiple
modalities like video, audio, language and bio-signals. In this paper, we
propose a flexible model for the task which exploits all available data. The
task involves complex relations and to avoid using a large model for video
processing specifically, we propose the use of behaviour encoding which boosts
performance with minimal change to the model. Cross-attention using
transformers has become popular in recent times and is utilised for fusion of
different modalities. Since long term relations may exist, breaking the input
into chunks is not desirable, thus the proposed model processes the entire
input together. Our experiments show the importance of each of the above
contributions
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-grained Multi-Modal Self-Supervised Learning. (arXiv:2112.12182v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12182">
<div class="article-summary-box-inner">
<span><p>Multi-Modal Self-Supervised Learning from videos has been shown to improve
model's performance on various downstream tasks. However, such Self-Supervised
pre-training requires large batch sizes and a large amount of computation
resources due to the noise present in the uncurated data. This is partly due to
the fact that the prevalent training scheme is trained on coarse-grained
setting, in which vectors representing the whole video clips or natural
language sentences are used for computing similarity. Such scheme makes
training noisy as part of the video clips can be totally not correlated with
the other-modality input such as text description. In this paper, we propose a
fine-grained multi-modal self-supervised training scheme that computes the
similarity between embeddings at finer-scale (such as individual feature map
embeddings and embeddings of phrases), and uses attention mechanisms to reduce
noisy pairs' weighting in the loss function. We show that with the proposed
pre-training scheme, we can train smaller models, with smaller batch-size and
much less computational resources to achieve downstream tasks performances
comparable to State-Of-The-Art, for tasks including action recognition and
text-image retrievals.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved 2D Keypoint Detection in Out-of-Balance and Fall Situations -- combining input rotations and a kinematic model. (arXiv:2112.12193v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12193">
<div class="article-summary-box-inner">
<span><p>Injury analysis may be one of the most beneficial applications of deep
learning based human pose estimation. To facilitate further research on this
topic, we provide an injury specific 2D dataset for alpine skiing, covering in
total 533 images. We further propose a post processing routine, that combines
rotational information with a simple kinematic model. We could improve
detection results in fall situations by up to 21% regarding the PCK@0.2 metric.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Maximum Entropy on Erroneous Predictions (MEEP): Improving model calibration for medical image segmentation. (arXiv:2112.12218v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12218">
<div class="article-summary-box-inner">
<span><p>Modern deep neural networks have achieved remarkable progress in medical
image segmentation tasks. However, it has recently been observed that they tend
to produce overconfident estimates, even in situations of high uncertainty,
leading to poorly calibrated and unreliable models. In this work we introduce
Maximum Entropy on Erroneous Predictions (MEEP), a training strategy for
segmentation networks which selectively penalizes overconfident predictions,
focusing only on misclassified pixels. In particular, we design a
regularization term that encourages high entropy posteriors for wrong
predictions, increasing the network uncertainty in complex scenarios. Our
method is agnostic to the neural architecture, does not increase model
complexity and can be coupled with multiple segmentation loss functions. We
benchmark the proposed strategy in two challenging medical image segmentation
tasks: white matter hyperintensity lesions in magnetic resonance images (MRI)
of the brain, and atrial segmentation in cardiac MRI. The experimental results
demonstrate that coupling MEEP with standard segmentation losses leads to
improvements not only in terms of model calibration, but also in segmentation
quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MC-DGCNN: A Novel DNN Architecture for Multi-Category Point Set Classification. (arXiv:2112.12219v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12219">
<div class="article-summary-box-inner">
<span><p>Point set classification aims to build a representation learning model that
distinguishes between spatial and categorical configurations of point set data.
This problem is societally important since in many applications domains such as
immunology, and microbial ecology. This problem is challenging since the
interactions between different categories of points are not always equal; as a
result, the representation learning model must selectively learn the most
relevant multi-categorical relationships. The related works are limited (1) in
learning the importance of different multi-categorical relationships,
especially for high-order interactions, and (2) do not fully exploit the
spatial distribution of points beyond simply measuring relative distance or
applying a feed-forward neural network to coordinates. To overcome these
limitations, we leverage the dynamic graph convolutional neural network (DGCNN)
architecture to design a novel multi-category DGCNN (MC-DGCNN), contributing
location representation and point pair attention layers for multi-categorical
point set classification. MC-DGCNN has the ability to identify the categorical
importance of each point pair and extends this to N-way spatial relationships,
while still preserving all the properties and benefits of DGCNN (e.g.,
differentiability). Experimental results show that the proposed architecture is
computationally efficient and significantly outperforms current deep learning
architectures on real-world datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Leveraging Synthetic Data in Object Detection on Unmanned Aerial Vehicles. (arXiv:2112.12252v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12252">
<div class="article-summary-box-inner">
<span><p>Acquiring data to train deep learning-based object detectors on Unmanned
Aerial Vehicles (UAVs) is expensive, time-consuming and may even be prohibited
by law in specific environments. On the other hand, synthetic data is fast and
cheap to access. In this work, we explore the potential use of synthetic data
in object detection from UAVs across various application environments. For
that, we extend the open-source framework DeepGTAV to work for UAV scenarios.
We capture various large-scale high-resolution synthetic data sets in several
domains to demonstrate their use in real-world object detection from UAVs by
analyzing multiple training strategies across several models. Furthermore, we
analyze several different data generation and sampling parameters to provide
actionable engineering advice for further scientific research. The DeepGTAV
framework is available at https://git.io/Jyf5j.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Human Activity Recognition on wrist-worn accelerometers using self-supervised neural networks. (arXiv:2112.12272v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12272">
<div class="article-summary-box-inner">
<span><p>Measures of Activity of Daily Living (ADL) are an important indicator of
overall health but difficult to measure in-clinic. Automated and accurate human
activity recognition (HAR) using wrist-worn accelerometers enables practical
and cost efficient remote monitoring of ADL. Key obstacles in developing high
quality HAR is the lack of large labeled datasets and the performance loss when
applying models trained on small curated datasets to the continuous stream of
heterogeneous data in real-life. In this work we design a self-supervised
learning paradigm to create a robust representation of accelerometer data that
can generalize across devices and subjects. We demonstrate that this
representation can separate activities of daily living and achieve strong HAR
accuracy (on multiple benchmark datasets) using very few labels. We also
propose a segmentation algorithm which can identify segments of salient
activity and boost HAR accuracy on continuous real-life data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Robust and Precise Facial Landmark Detection by Self-Calibrated Pose Attention Network. (arXiv:2112.12328v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12328">
<div class="article-summary-box-inner">
<span><p>Current fully-supervised facial landmark detection methods have progressed
rapidly and achieved remarkable performance. However, they still suffer when
coping with faces under large poses and heavy occlusions for inaccurate facial
shape constraints and insufficient labeled training samples. In this paper, we
propose a semi-supervised framework, i.e., a Self-Calibrated Pose Attention
Network (SCPAN) to achieve more robust and precise facial landmark detection in
challenging scenarios. To be specific, a Boundary-Aware Landmark Intensity
(BALI) field is proposed to model more effective facial shape constraints by
fusing boundary and landmark intensity field information. Moreover, a
Self-Calibrated Pose Attention (SCPA) model is designed to provide a
self-learned objective function that enforces intermediate supervision without
label information by introducing a self-calibrated mechanism and a pose
attention mask. We show that by integrating the BALI fields and SCPA model into
a novel self-calibrated pose attention network, more facial prior knowledge can
be learned and the detection accuracy and robustness of our method for faces
with large poses and heavy occlusions have been improved. The experimental
results obtained for challenging benchmark datasets demonstrate that our
approach outperforms state-of-the-art methods in the literature.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">More is Better: A Novel Multi-view Framework for Domain Generalization. (arXiv:2112.12329v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12329">
<div class="article-summary-box-inner">
<span><p>Aiming to generalize the model trained in source domains to unseen target
domains, domain generalization (DG) has attracted lots of attention recently.
The key issue of DG is how to prevent overfitting to the observed source
domains because target domain is unavailable during training. We investigate
that overfitting not only causes the inferior generalization ability to unseen
target domains but also leads unstable prediction in the test stage. In this
paper, we observe that both sampling multiple tasks in training stage and
generating augmented images in test stage largely benefit generalization
performance. Thus, by treating tasks and images as different views, we propose
a novel multi-view DG framework. Specifically, in training stage, to enhance
generalization ability, we develop a multi-view regularized meta-learning
algorithm that employs multiple tasks to produce a suitable optimization
direction during updating model. In test stage, to alleviate unstable
prediction, we utilize multiple augmented images to yield multi-view
prediction, which significantly promotes model reliability via fusing the
results of different views of a test image. Extensive experiments on three
benchmark datasets validate our method outperforms several state-of-the-art
approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Revisiting Transformation Invariant Geometric Deep Learning: Are Initial Representations All You Need?. (arXiv:2112.12345v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12345">
<div class="article-summary-box-inner">
<span><p>Geometric deep learning, i.e., designing neural networks to handle the
ubiquitous geometric data such as point clouds and graphs, have achieved great
successes in the last decade. One critical inductive bias is that the model can
maintain invariance towards various transformations such as translation,
rotation, and scaling. The existing graph neural network (GNN) approaches can
only maintain permutation-invariance, failing to guarantee invariance with
respect to other transformations. Besides GNNs, other works design
sophisticated transformation-invariant layers, which are computationally
expensive and difficult to be extended. To solve this problem, we revisit why
the existing neural networks cannot maintain transformation invariance when
handling geometric data. Our findings show that transformation-invariant and
distance-preserving initial representations are sufficient to achieve
transformation invariance rather than needing sophisticated neural layer
designs. Motivated by these findings, we propose Transformation Invariant
Neural Networks (TinvNN), a straightforward and general framework for geometric
data. Specifically, we realize transformation-invariant and distance-preserving
initial point representations by modifying multi-dimensional scaling before
feeding the representations into neural networks. We prove that TinvNN can
strictly guarantee transformation invariance, being general and flexible enough
to be combined with the existing neural networks. Extensive experimental
results on point cloud analysis and combinatorial optimization demonstrate the
effectiveness and general applicability of our proposed method. Based on the
experimental results, we advocate that TinvNN should be considered a new
starting point and an essential baseline for further studies of
transformation-invariant geometric deep learning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Hierarchical Attention for Weakly-supervised Chest X-Ray Abnormality Localization and Diagnosis. (arXiv:2112.12349v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12349">
<div class="article-summary-box-inner">
<span><p>We consider the problem of abnormality localization for clinical
applications. While deep learning has driven much recent progress in medical
imaging, many clinical challenges are not fully addressed, limiting its broader
usage. While recent methods report high diagnostic accuracies, physicians have
concerns trusting these algorithm results for diagnostic decision-making
purposes because of a general lack of algorithm decision reasoning and
interpretability. One potential way to address this problem is to further train
these models to localize abnormalities in addition to just classifying them.
However, doing this accurately will require a large amount of disease
localization annotations by clinical experts, a task that is prohibitively
expensive to accomplish for most applications. In this work, we take a step
towards addressing these issues by means of a new attention-driven weakly
supervised algorithm comprising a hierarchical attention mining framework that
unifies activation- and gradient-based visual attention in a holistic manner.
Our key algorithmic innovations include the design of explicit ordinal
attention constraints, enabling principled model training in a
weakly-supervised fashion, while also facilitating the generation of
visual-attention-driven model explanations by means of localization cues. On
two large-scale chest X-ray datasets (NIH ChestX-ray14 and CheXpert), we
demonstrate significant localization performance improvements over the current
state of the art while also achieving competitive classification performance.
Our code is available on https://github.com/oyxhust/HAM.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Random Point Initialization Approach to Image Segmentation with Variational Level-sets. (arXiv:2112.12355v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12355">
<div class="article-summary-box-inner">
<span><p>Image segmentation is an essential component in many image processing and
computer vision tasks. The primary goal of image segmentation is to simplify an
image for easier analysis, and there are two broad approaches for achieving
this: edge based methods, which extract the boundaries of specific known
objects, and region based methods, which partition the image into regions that
are statistically homogeneous. One of the more prominent edge finding methods,
known as the level set method, evolves a zero-level contour in the image plane
with gradient descent until the contour has converged to the object boundaries.
While the classical level set method and its variants have proved successful in
segmenting real images, they are susceptible to becoming stuck in noisy regions
of the image plane without a priori knowledge of the image and they are unable
to provide details beyond object outer boundary locations. We propose a
modification to the variational level set image segmentation method that can
quickly detect object boundaries by making use of random point initialization.
We demonstrate the efficacy of our approach by comparing the performance of our
method on real images to that of the prominent Canny Method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Dual Path Structural Contrastive Embeddings for Learning Novel Objects. (arXiv:2112.12359v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12359">
<div class="article-summary-box-inner">
<span><p>Learning novel classes from a very few labeled samples has attracted
increasing attention in machine learning areas. Recent research on either
meta-learning based or transfer-learning based paradigm demonstrates that
gaining information on a good feature space can be an effective solution to
achieve favorable performance on few-shot tasks. In this paper, we propose a
simple but effective paradigm that decouples the tasks of learning feature
representations and classifiers and only learns the feature embedding
architecture from base classes via the typical transfer-learning training
strategy. To maintain both the generalization ability across base and novel
classes and discrimination ability within each class, we propose a dual path
feature learning scheme that effectively combines structural similarity with
contrastive feature construction. In this way, both inner-class alignment and
inter-class uniformity can be well balanced, and result in improved
performance. Experiments on three popular benchmarks show that when
incorporated with a simple prototype based classifier, our method can still
achieve promising results for both standard and generalized few-shot problems
in either an inductive or transductive inference setting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Practical Data-Free Approach to One-shot Federated Learning with Heterogeneity. (arXiv:2112.12371v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12371">
<div class="article-summary-box-inner">
<span><p>One-shot Federated Learning (FL) has recently emerged as a promising
approach, which allows the central server to learn a model in a single
communication round. Despite the low communication cost, existing one-shot FL
methods are mostly impractical or face inherent limitations, e.g., a public
dataset is required, clients' models are homogeneous, need to upload additional
data/model information. To overcome these issues, we propose a more practical
data-free approach named FedSyn for one-shot FL framework with heterogeneity.
Our FedSyn trains the global model by a data generation stage and a model
distillation stage. To the best of our knowledge, FedSyn is the first method
that can be practically applied to various real-world applications due to the
following advantages: (1) FedSyn requires no additional information (except the
model parameters) to be transferred between clients and the server; (2) FedSyn
does not require any auxiliary dataset for training; (3) FedSyn is the first to
consider both model and statistical heterogeneities in FL, i.e., the clients'
data are non-iid and different clients may have different model architectures.
Experiments on a variety of real-world datasets demonstrate the superiority of
our FedSyn. For example, FedSyn outperforms the best baseline method Fed-ADI by
5.08% on CIFAR10 dataset when data are non-iid.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DILF-EN framework for Class-Incremental Learning. (arXiv:2112.12385v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12385">
<div class="article-summary-box-inner">
<span><p>Deep learning models suffer from catastrophic forgetting of the classes in
the older phases as they get trained on the classes introduced in the new phase
in the class-incremental learning setting. In this work, we show that the
effect of catastrophic forgetting on the model prediction varies with the
change in orientation of the same image, which is a novel finding. Based on
this, we propose a novel data-ensemble approach that combines the predictions
for the different orientations of the image to help the model retain further
information regarding the previously seen classes and thereby reduce the effect
of forgetting on the model predictions. However, we cannot directly use the
data-ensemble approach if the model is trained using traditional techniques.
Therefore, we also propose a novel dual-incremental learning framework that
involves jointly training the network with two incremental learning objectives,
i.e., the class-incremental learning objective and our proposed
data-incremental learning objective. In the dual-incremental learning
framework, each image belongs to two classes, i.e., the image class (for
class-incremental learning) and the orientation class (for data-incremental
learning). In class-incremental learning, each new phase introduces a new set
of classes, and the model cannot access the complete training data from the
older phases. In our proposed data-incremental learning, the orientation
classes remain the same across all the phases, and the data introduced by the
new phase in class-incremental learning acts as new training data for these
orientation classes. We empirically demonstrate that the dual-incremental
learning framework is vital to the data-ensemble approach. We apply our
proposed approach to state-of-the-art class-incremental learning methods and
empirically show that our framework significantly improves the performance of
these methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">KFWC: A Knowledge-Driven Deep Learning Model for Fine-grained Classification of Wet-AMD. (arXiv:2112.12386v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12386">
<div class="article-summary-box-inner">
<span><p>Automated diagnosis using deep neural networks can help ophthalmologists
detect the blinding eye disease wet Age-related Macular Degeneration (AMD).
Wet-AMD has two similar subtypes, Neovascular AMD and Polypoidal Choroidal
Vessels (PCV). However, due to the difficulty in data collection and the
similarity between images, most studies have only achieved the coarse-grained
classification of wet-AMD rather than a finer-grained one of wet-AMD subtypes.
To solve this issue, in this paper we propose a Knowledge-driven Fine-grained
Wet-AMD Classification Model (KFWC), to classify fine-grained diseases with
insufficient data. With the introduction of a priori knowledge of 10 lesion
signs of input images into the KFWC, we aim to accelerate the KFWC by means of
multi-label classification pre-training, to locate the decisive image features
in the fine-grained disease classification task and therefore achieve better
classification. Simultaneously, the KFWC can also provide good interpretability
and effectively alleviate the pressure of data collection and annotation in the
field of fine-grained disease classification for wet-AMD. The experiments
demonstrate the effectiveness of the KFWC which reaches 99.71% in AU-ROC
scores, and its considerable improvements over the data-driven w/o Knowledge
and ophthalmologists, with the rates of 6.69% over the strongest baseline and
4.14% over ophthalmologists.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DD-NeRF: Double-Diffusion Neural Radiance Field as a Generalizable Implicit Body Representation. (arXiv:2112.12390v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12390">
<div class="article-summary-box-inner">
<span><p>We present DD-NeRF, a novel generalizable implicit field for representing
human body geometry and appearance from arbitrary input views. The core
contribution is a double diffusion mechanism, which leverages the sparse
convolutional neural network to build two volumes that represent a human body
at different levels: a coarse body volume takes advantage of unclothed
deformable mesh to provide the large-scale geometric guidance, and a detail
feature volume learns the intricate geometry from local image features. We also
employ a transformer network to aggregate image features and raw pixels across
views, for computing the final high-fidelity radiance field. Experiments on
various datasets show that the proposed approach outperforms previous works in
both geometry reconstruction and novel view synthesis quality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Iteratively Selecting an Easy Reference Frame Makes Unsupervised Video Object Segmentation Easier. (arXiv:2112.12402v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12402">
<div class="article-summary-box-inner">
<span><p>Unsupervised video object segmentation (UVOS) is a per-pixel binary labeling
problem which aims at separating the foreground object from the background in
the video without using the ground truth (GT) mask of the foreground object.
Most of the previous UVOS models use the first frame or the entire video as a
reference frame to specify the mask of the foreground object. Our question is
why the first frame should be selected as a reference frame or why the entire
video should be used to specify the mask. We believe that we can select a
better reference frame to achieve the better UVOS performance than using only
the first frame or the entire video as a reference frame. In our paper, we
propose Easy Frame Selector (EFS). The EFS enables us to select an 'easy'
reference frame that makes the subsequent VOS become easy, thereby improving
the VOS performance. Furthermore, we propose a new framework named as Iterative
Mask Prediction (IMP). In the framework, we repeat applying EFS to the given
video and selecting an 'easier' reference frame from the video than the
previous iteration, increasing the VOS performance incrementally. The IMP
consists of EFS, Bi-directional Mask Prediction (BMP), and Temporal Information
Updating (TIU). From the proposed framework, we achieve state-of-the-art
performance in three UVOS benchmark sets: DAVIS16, FBMS, and SegTrack-V2.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InstaIndoor and Multi-modal Deep Learning for Indoor Scene Recognition. (arXiv:2112.12409v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12409">
<div class="article-summary-box-inner">
<span><p>Indoor scene recognition is a growing field with great potential for
behaviour understanding, robot localization, and elderly monitoring, among
others. In this study, we approach the task of scene recognition from a novel
standpoint, using multi-modal learning and video data gathered from social
media. The accessibility and variety of social media videos can provide
realistic data for modern scene recognition techniques and applications. We
propose a model based on fusion of transcribed speech to text and visual
features, which is used for classification on a novel dataset of social media
videos of indoor scenes named InstaIndoor. Our model achieves up to 70%
accuracy and 0.7 F1-Score. Furthermore, we highlight the potential of our
approach by benchmarking on a YouTube-8M subset of indoor scenes as well, where
it achieves 74% accuracy and 0.74 F1-Score. We hope the contributions of this
work pave the way to novel research in the challenging field of indoor scene
recognition.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Modeling Against Adversarial Attacks. (arXiv:2112.12431v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12431">
<div class="article-summary-box-inner">
<span><p>Adversarial training, the process of training a deep learning model with
adversarial data, is one of the most successful adversarial defense methods for
deep learning models. We have found that the robustness to white-box attack of
an adversarially trained model can be further improved if we fine tune this
model in inference stage to adapt to the adversarial input, with the extra
information in it. We introduce an algorithm that "post trains" the model at
inference stage between the original output class and a "neighbor" class, with
existing training data. The accuracy of pre-trained Fast-FGSM CIFAR10
classifier base model against white-box projected gradient attack (PGD) can be
significantly improved from 46.8% to 64.5% with our algorithm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Your Face Mirrors Your Deepest Beliefs-Predicting Personality and Morals through Facial Emotion Recognition. (arXiv:2112.12455v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12455">
<div class="article-summary-box-inner">
<span><p>Can we really "read the mind in the eyes"? Moreover, can AI assist us in this
task? This paper answers these two questions by introducing a machine learning
system that predicts personality characteristics of individuals on the basis of
their face. It does so by tracking the emotional response of the individual's
face through facial emotion recognition (FER) while watching a series of 15
short videos of different genres. To calibrate the system, we invited 85 people
to watch the videos, while their emotional responses were analyzed through
their facial expression. At the same time, these individuals also took four
well-validated surveys of personality characteristics and moral values: the
revised NEO FFI personality inventory, the Haidt moral foundations test, the
Schwartz personal value system, and the domain-specific risk-taking scale
(DOSPERT). We found that personality characteristics and moral values of an
individual can be predicted through their emotional response to the videos as
shown in their face, with an accuracy of up to 86% using gradient-boosted
trees. We also found that different personality characteristics are better
predicted by different videos, in other words, there is no single video that
will provide accurate predictions for all personality characteristics, but it
is the response to the mix of different videos that allows for accurate
prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pose Adaptive Dual Mixup for Few-Shot Single-View 3D Reconstruction. (arXiv:2112.12484v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12484">
<div class="article-summary-box-inner">
<span><p>We present a pose adaptive few-shot learning procedure and a two-stage data
interpolation regularization, termed Pose Adaptive Dual Mixup (PADMix), for
single-image 3D reconstruction. While augmentations via interpolating
feature-label pairs are effective in classification tasks, they fall short in
shape predictions potentially due to inconsistencies between interpolated
products of two images and volumes when rendering viewpoints are unknown.
PADMix targets this issue with two sets of mixup procedures performed
sequentially. We first perform an input mixup which, combined with a pose
adaptive learning procedure, is helpful in learning 2D feature extraction and
pose adaptive latent encoding. The stagewise training allows us to build upon
the pose invariant representations to perform a follow-up latent mixup under
one-to-one correspondences between features and ground-truth volumes. PADMix
significantly outperforms previous literature on few-shot settings over the
ShapeNet dataset and sets new benchmarks on the more challenging real-world
Pix3D dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LaTr: Layout-Aware Transformer for Scene-Text VQA. (arXiv:2112.12494v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12494">
<div class="article-summary-box-inner">
<span><p>We propose a novel multimodal architecture for Scene Text Visual Question
Answering (STVQA), named Layout-Aware Transformer (LaTr). The task of STVQA
requires models to reason over different modalities. Thus, we first investigate
the impact of each modality, and reveal the importance of the language module,
especially when enriched with layout information. Accounting for this, we
propose a single objective pre-training scheme that requires only text and
spatial cues. We show that applying this pre-training scheme on scanned
documents has certain advantages over using natural images, despite the domain
gap. Scanned documents are easy to procure, text-dense and have a variety of
layouts, helping the model learn various spatial cues (e.g. left-of, below
etc.) by tying together language and layout information. Compared to existing
approaches, our method performs vocabulary-free decoding and, as shown,
generalizes well beyond the training vocabulary. We further demonstrate that
LaTr improves robustness towards OCR errors, a common reason for failure cases
in STVQA. In addition, by leveraging a vision transformer, we eliminate the
need for an external object detector. LaTr outperforms state-of-the-art STVQA
methods on multiple datasets. In particular, +7.6% on TextVQA, +10.8% on ST-VQA
and +4.0% on OCR-VQA (all absolute accuracy numbers).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FedFR: Joint Optimization Federated Framework for Generic and Personalized Face Recognition. (arXiv:2112.12496v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12496">
<div class="article-summary-box-inner">
<span><p>Current state-of-the-art deep learning based face recognition (FR) models
require a large number of face identities for central training. However, due to
the growing privacy awareness, it is prohibited to access the face images on
user devices to continually improve face recognition models. Federated Learning
(FL) is a technique to address the privacy issue, which can collaboratively
optimize the model without sharing the data between clients. In this work, we
propose a FL based framework called FedFR to improve the generic face
representation in a privacy-aware manner. Besides, the framework jointly
optimizes personalized models for the corresponding clients via the proposed
Decoupled Feature Customization module. The client-specific personalized model
can serve the need of optimized face recognition experience for registered
identities at the local device. To the best of our knowledge, we are the first
to explore the personalized face recognition in FL setup. The proposed
framework is validated to be superior to previous approaches on several generic
and personalized face recognition benchmarks with diverse FL scenarios. The
source codes and our proposed personalized FR benchmark under FL setup are
available at https://github.com/jackie840129/FedFR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Attentive Multi-View Deep Subspace Clustering Net. (arXiv:2112.12506v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12506">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a novel Attentive Multi-View Deep Subspace Nets
(AMVDSN), which deeply explores underlying consistent and view-specific
information from multiple views and fuse them by considering each view's
dynamic contribution obtained by attention mechanism. Unlike most multi-view
subspace learning methods that they directly reconstruct data points on raw
data or only consider consistency or complementarity when learning
representation in deep or shallow space, our proposed method seeks to find a
joint latent representation that explicitly considers both consensus and
view-specific information among multiple views, and then performs subspace
clustering on learned joint latent representation.Besides, different views
contribute differently to representation learning, we therefore introduce
attention mechanism to derive dynamic weight for each view, which performs much
better than previous fusion methods in the field of multi-view subspace
clustering. The proposed algorithm is intuitive and can be easily optimized
just by using Stochastic Gradient Descent (SGD) because of the neural network
framework, which also provides strong non-linear characterization capability
compared with traditional subspace clustering approaches. The experimental
results on seven real-world data sets have demonstrated the effectiveness of
our proposed algorithm against some state-of-the-art subspace learning
approaches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neuroevolution deep learning architecture search for estimation of river surface elevation from photogrammetric Digital Surface Models. (arXiv:2112.12510v1 [cs.NE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12510">
<div class="article-summary-box-inner">
<span><p>Development of the new methods of surface water observation is crucial in the
perspective of increasingly frequent extreme hydrological events related to
global warming and increasing demand for water. Orthophotos and digital surface
models (DSMs) obtained using UAV photogrammetry can be used to determine the
Water Surface Elevation (WSE) of a river. However, this task is difficult due
to disturbances of the water surface on DSMs caused by limitations of
photogrammetric algorithms. In this study, machine learning was used to extract
a WSE value from disturbed photogrammetric data. A brand new dataset has been
prepared specifically for this purpose by hydrology and photogrammetry experts.
The new method is an important step toward automating water surface level
measurements with high spatial and temporal resolution. Such data can be used
to validate and calibrate of hydrological, hydraulic and hydrodynamic models
making hydrological forecasts more accurate, in particular predicting extreme
and dangerous events such as floods or droughts. For our knowledge this is the
first approach in which dataset was created for this purpose and deep learning
models were used for this task. Additionally, neuroevolution algorithm was set
to explore different architectures to find local optimal models and
non-gradient search was performed to fine-tune the model parameters. The
achieved results have better accuracy compared to manual methods of determining
WSE from photogrammetric DSMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PyCIL: A Python Toolbox for Class-Incremental Learning. (arXiv:2112.12533v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12533">
<div class="article-summary-box-inner">
<span><p>Traditional machine learning systems are deployed under the closed-world
setting, which requires the entire training data before the offline training
process. However, real-world applications often face the incoming new classes,
and a model should incorporate them continually. The learning paradigm is
called Class-Incremental Learning (CIL). We propose a Python toolbox that
implements several key algorithms for class-incremental learning to ease the
burden of researchers in the machine learning community. The toolbox contains
implementations of a number of founding works of CIL such as EWC and iCaRL, but
also provides current state-of-the-art algorithms that can be used for
conducting novel fundamental research. This toolbox, named PyCIL for Python
Class-Incremental Learning, is available at https://github.com/G-U-N/PyCIL
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FourierMask: Instance Segmentation using Fourier Mapping in Implicit Neural Networks. (arXiv:2112.12535v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12535">
<div class="article-summary-box-inner">
<span><p>We present FourierMask, which employs Fourier series combined with implicit
neural representations to generate instance segmentation masks. We apply a
Fourier mapping (FM) to the coordinate locations and utilize the mapped
features as inputs to an implicit representation (coordinate-based multi-layer
perceptron (MLP)). FourierMask learns to predict the coefficients of the FM for
a particular instance, and therefore adapts the FM to a specific object. This
allows FourierMask to be generalized to predict instance segmentation masks
from natural images. Since implicit functions are continuous in the domain of
input coordinates, we illustrate that by sub-sampling the input pixel
coordinates, we can generate higher resolution masks during inference.
Furthermore, we train a renderer MLP (FourierRend) on the uncertain predictions
of FourierMask and illustrate that it significantly improves the quality of the
masks. FourierMask shows competitive results on the MS COCO dataset compared to
the baseline Mask R-CNN at the same output resolution and surpasses it on
higher resolution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the relationship between calibrated predictors and unbiased volume estimation. (arXiv:2112.12560v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12560">
<div class="article-summary-box-inner">
<span><p>Machine learning driven medical image segmentation has become standard in
medical image analysis. However, deep learning models are prone to
overconfident predictions. This has led to a renewed focus on calibrated
predictions in the medical imaging and broader machine learning communities.
Calibrated predictions are estimates of the probability of a label that
correspond to the true expected value of the label conditioned on the
confidence. Such calibrated predictions have utility in a range of medical
imaging applications, including surgical planning under uncertainty and active
learning systems. At the same time it is often an accurate volume measurement
that is of real importance for many medical applications. This work
investigates the relationship between model calibration and volume estimation.
We demonstrate both mathematically and empirically that if the predictor is
calibrated per image, we can obtain the correct volume by taking an expectation
of the probability scores per pixel/voxel of the image. Furthermore, we show
that convex combinations of calibrated classifiers preserve volume estimation,
but do not preserve calibration. Therefore, we conclude that having a
calibrated predictor is a sufficient, but not necessary condition for obtaining
an unbiased estimate of the volume. We validate our theoretical findings
empirically on a collection of 18 different (calibrated) training strategies on
the tasks of glioma volume estimation on BraTS 2018, and ischemic stroke lesion
volume estimation on ISLES 2018 datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Generative Zero-Shot Learning by Synthesizing Diverse Features with Attribute Augmentation. (arXiv:2112.12573v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12573">
<div class="article-summary-box-inner">
<span><p>The recent advance in deep generative models outlines a promising perspective
in the realm of Zero-Shot Learning (ZSL). Most generative ZSL methods use
category semantic attributes plus a Gaussian noise to generate visual features.
After generating unseen samples, this family of approaches effectively
transforms the ZSL problem into a supervised classification scheme. However,
the existing models use a single semantic attribute, which contains the
complete attribute information of the category. The generated data also carry
the complete attribute information, but in reality, visual samples usually have
limited attributes. Therefore, the generated data from attribute could have
incomplete semantics. Based on this fact, we propose a novel framework to boost
ZSL by synthesizing diverse features. This method uses augmented semantic
attributes to train the generative model, so as to simulate the real
distribution of visual features. We evaluate the proposed model on four
benchmark datasets, observing significant performance improvement against the
state-of-the-art.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NVS-MonoDepth: Improving Monocular Depth Prediction with Novel View Synthesis. (arXiv:2112.12577v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12577">
<div class="article-summary-box-inner">
<span><p>Building upon the recent progress in novel view synthesis, we propose its
application to improve monocular depth estimation. In particular, we propose a
novel training method split in three main steps. First, the prediction results
of a monocular depth network are warped to an additional view point. Second, we
apply an additional image synthesis network, which corrects and improves the
quality of the warped RGB image. The output of this network is required to look
as similar as possible to the ground-truth view by minimizing the pixel-wise
RGB reconstruction error. Third, we reapply the same monocular depth estimation
onto the synthesized second view point and ensure that the depth predictions
are consistent with the associated ground truth depth. Experimental results
prove that our method achieves state-of-the-art or comparable performance on
the KITTI and NYU-Depth-v2 datasets with a lightweight and simple vanilla U-Net
architecture.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-efficient learning for 3D mirror symmetry detection. (arXiv:2112.12579v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12579">
<div class="article-summary-box-inner">
<span><p>We introduce a geometry-inspired deep learning method for detecting 3D mirror
plane from single-view images. We reduce the demand for massive training data
by explicitly adding 3D mirror geometry into learning as an inductive prior. We
extract semantic features, calculate intra-pixel correlations, and build a 3D
correlation volume for each plane. The correlation volume indicates the extent
to which the input resembles its mirrors at various depth, allowing us to
identify the likelihood of the given plane being a mirror plane. Subsequently,
we treat the correlation volumes as feature descriptors for sampled planes and
map them to a unit hemisphere where the normal of sampled planes lies. Lastly,
we design multi-stage spherical convolutions to identify the optimal mirror
plane in a coarse-to-fine manner. Experiments on both synthetic and real-world
datasets show the benefit of 3D mirror geometry in improving data efficiency
and inference speed (up to 25 FPS).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">INTRPRT: A Systematic Review of and Guidelines for Designing and Validating Transparent AI in Medical Image Analysis. (arXiv:2112.12596v1 [cs.HC])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12596">
<div class="article-summary-box-inner">
<span><p>Transparency in Machine Learning (ML), attempts to reveal the working
mechanisms of complex models. Transparent ML promises to advance human factors
engineering goals of human-centered AI in the target users. From a
human-centered design perspective, transparency is not a property of the ML
model but an affordance, i.e. a relationship between algorithm and user; as a
result, iterative prototyping and evaluation with users is critical to
attaining adequate solutions that afford transparency. However, following
human-centered design principles in healthcare and medical image analysis is
challenging due to the limited availability of and access to end users. To
investigate the state of transparent ML in medical image analysis, we conducted
a systematic review of the literature. Our review reveals multiple severe
shortcomings in the design and validation of transparent ML for medical image
analysis applications. We find that most studies to date approach transparency
as a property of the model itself, similar to task performance, without
considering end users during neither development nor evaluation. Additionally,
the lack of user research, and the sporadic validation of transparency claims
put contemporary research on transparent ML for medical image analysis at risk
of being incomprehensible to users, and thus, clinically irrelevant. To
alleviate these shortcomings in forthcoming research while acknowledging the
challenges of human-centered design in healthcare, we introduce the INTRPRT
guideline, a systematic design directive for transparent ML systems in medical
image analysis. The INTRPRT guideline suggests formative user research as the
first step of transparent model design to understand user needs and domain
requirements. Following this process produces evidence to support design
choices, and ultimately, increases the likelihood that the algorithms afford
transparency.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Universal GAN Image Detection. (arXiv:2112.12606v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12606">
<div class="article-summary-box-inner">
<span><p>The ever higher quality and wide diffusion of fake images have spawn a quest
for reliable forensic tools. Many GAN image detectors have been proposed,
recently. In real world scenarios, however, most of them show limited
robustness and generalization ability. Moreover, they often rely on side
information not available at test time, that is, they are not universal. We
investigate these problems and propose a new GAN image detector based on a
limited sub-sampling architecture and a suitable contrastive learning paradigm.
Experiments carried out in challenging conditions prove the proposed method to
be a first step towards universal GAN image detection, ensuring also good
robustness to common image impairments, and good generalization to unseen
architectures.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predi\c{c}\~ao da Idade Cerebral a partir de Imagens de Resson\^ancia Magn\'etica utilizando Redes Neurais Convolucionais. (arXiv:2112.12609v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12609">
<div class="article-summary-box-inner">
<span><p>In this work, deep learning techniques for brain age prediction from magnetic
resonance images are investigated, aiming to assist in the identification of
biomarkers of the natural aging process. The identification of biomarkers is
useful for detecting an early-stage neurodegenerative process, as well as for
predicting age-related or non-age-related cognitive decline. Two techniques are
implemented and compared in this work: a 3D Convolutional Neural Network
applied to the volumetric image and a 2D Convolutional Neural Network applied
to slices from the axial plane, with subsequent fusion of individual
predictions. The best result was obtained by the 2D model, which achieved a
mean absolute error of 3.83 years.
</p>
<p>--
</p>
<p>Neste trabalho s\~ao investigadas t\'ecnicas de aprendizado profundo para a
predi\c{c}\~ao da idade cerebral a partir de imagens de resson\^ancia
magn\'etica, visando auxiliar na identifica\c{c}\~ao de biomarcadores do
processo natural de envelhecimento. A identifica\c{c}\~ao de biomarcadores \'e
\'util para a detec\c{c}\~ao de um processo neurodegenerativo em est\'agio
inicial, al\'em de possibilitar prever um decl\'inio cognitivo relacionado ou
n\~ao \`a idade. Duas t\'ecnicas s\~ao implementadas e comparadas neste
trabalho: uma Rede Neural Convolucional 3D aplicada na imagem volum\'etrica e
uma Rede Neural Convolucional 2D aplicada a fatias do plano axial, com
posterior fus\~ao das predi\c{c}\~oes individuais. O melhor resultado foi
obtido pelo modelo 2D, que alcan\c{c}ou um erro m\'edio absoluto de 3.83 anos.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PandaSet: Advanced Sensor Suite Dataset for Autonomous Driving. (arXiv:2112.12610v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12610">
<div class="article-summary-box-inner">
<span><p>The accelerating development of autonomous driving technology has placed
greater demands on obtaining large amounts of high-quality data.
Representative, labeled, real world data serves as the fuel for training deep
learning networks, critical for improving self-driving perception algorithms.
In this paper, we introduce PandaSet, the first dataset produced by a complete,
high-precision autonomous vehicle sensor kit with a no-cost commercial license.
The dataset was collected using one 360{\deg} mechanical spinning LiDAR, one
forward-facing, long-range LiDAR, and 6 cameras. The dataset contains more than
100 scenes, each of which is 8 seconds long, and provides 28 types of labels
for object classification and 37 types of labels for semantic segmentation. We
provide baselines for LiDAR-only 3D object detection, LiDAR-camera fusion 3D
object detection and LiDAR point cloud segmentation. For more details about
PandaSet and the development kit, see https://scale.com/open-datasets/pandaset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Disturbance-Free Visual Mobile Manipulation. (arXiv:2112.12612v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12612">
<div class="article-summary-box-inner">
<span><p>Embodied AI has shown promising results on an abundance of robotic tasks in
simulation, including visual navigation and manipulation. The prior work
generally pursues high success rates with shortest paths while largely ignoring
the problems caused by collision during interaction. This lack of
prioritization is understandable: in simulated environments there is no
inherent cost to breaking virtual objects. As a result, well-trained agents
frequently have catastrophic collision with objects despite final success. In
the robotics community, where the cost of collision is large, collision
avoidance is a long-standing and crucial topic to ensure that robots can be
safely deployed in the real world. In this work, we take the first step towards
collision/disturbance-free embodied AI agents for visual mobile manipulation,
facilitating safe deployment in real robots. We develop a new
disturbance-avoidance methodology at the heart of which is the auxiliary task
of disturbance prediction. When combined with a disturbance penalty, our
auxiliary task greatly enhances sample efficiency and final performance by
knowledge distillation of disturbance into the agent. Our experiments on
ManipulaTHOR show that, on testing scenes with novel objects, our method
improves the success rate from 61.7% to 85.6% and the success rate without
disturbance from 29.8% to 50.2% over the original baseline. Extensive ablation
studies show the value of our pipelined approach. Project site is at
https://sites.google.com/view/disturb-free
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Manifold Learning Benefits GANs. (arXiv:2112.12618v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12618">
<div class="article-summary-box-inner">
<span><p>In this paper, we improve Generative Adversarial Networks by incorporating a
manifold learning step into the discriminator. We consider locality-constrained
linear and subspace-based manifolds, and locality-constrained non-linear
manifolds. In our design, the manifold learning and coding steps are
intertwined with layers of the discriminator, with the goal of attracting
intermediate feature representations onto manifolds. We adaptively balance the
discrepancy between feature representations and their manifold view, which
represents a trade-off between denoising on the manifold and refining the
manifold. We conclude that locality-constrained non-linear manifolds have the
upper hand over linear manifolds due to their non-uniform density and
smoothness. We show substantial improvements over different recent
state-of-the-art baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Comparison and Analysis of Image-to-Image Generative Adversarial Networks: A Survey. (arXiv:2112.12625v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12625">
<div class="article-summary-box-inner">
<span><p>Generative Adversarial Networks (GANs) have recently introduced effective
methods of performing Image-to-Image translations. These models can be applied
and generalized to a variety of domains in Image-to-Image translation without
changing any parameters. In this paper, we survey and analyze eight
Image-to-Image Generative Adversarial Networks: Pix2Px, CycleGAN, CoGAN,
StarGAN, MUNIT, StarGAN2, DA-GAN, and Self Attention GAN. Each of these models
presented state-of-the-art results and introduced new techniques to build
Image-to-Image GANs. In addition to a survey of the models, we also survey the
18 datasets they were trained on and the 9 metrics they were evaluated on.
Finally, we present results of a controlled experiment for 6 of these models on
a common set of metrics and datasets. The results were mixed and showed that on
certain datasets, tasks, and metrics some models outperformed others. The last
section of this paper discusses those results and establishes areas of future
research. As researchers continue to innovate new Image-to-Image GANs, it is
important that they gain a good understanding of the existing methods,
datasets, and metrics. This paper provides a comprehensive overview and
discussion to help build this foundation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">InDuDoNet+: A Model-Driven Interpretable Dual Domain Network for Metal Artifact Reduction in CT Images. (arXiv:2112.12660v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12660">
<div class="article-summary-box-inner">
<span><p>During the computed tomography (CT) imaging process, metallic implants within
patients always cause harmful artifacts, which adversely degrade the visual
quality of reconstructed CT images and negatively affect the subsequent
clinical diagnosis. For the metal artifact reduction (MAR) task, current deep
learning based methods have achieved promising performance. However, most of
them share two main common limitations: 1) the CT physical imaging geometry
constraint is not comprehensively incorporated into deep network structures; 2)
the entire framework has weak interpretability for the specific MAR task;
hence, the role of every network module is difficult to be evaluated. To
alleviate these issues, in the paper, we construct a novel interpretable dual
domain network, termed InDuDoNet+, into which CT imaging process is finely
embedded. Concretely, we derive a joint spatial and Radon domain reconstruction
model and propose an optimization algorithm with only simple operators for
solving it. By unfolding the iterative steps involved in the proposed algorithm
into the corresponding network modules, we easily build the InDuDoNet+ with
clear interpretability. Furthermore, we analyze the CT values among different
tissues, and merge the prior observations into a prior network for our
InDuDoNet+, which significantly improve its generalization performance.
Comprehensive experiments on synthesized data and clinical data substantiate
the superiority of the proposed methods as well as the superior generalization
performance beyond the current state-of-the-art (SOTA) MAR methods. Code is
available at \url{https://github.com/hongwang01/InDuDoNet_plus}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Omni-Seg: A Single Dynamic Network for Multi-label Renal Pathology Image Segmentation using Partially Labeled Data. (arXiv:2112.12665v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12665">
<div class="article-summary-box-inner">
<span><p>Computer-assisted quantitative analysis on Giga-pixel pathology images has
provided a new avenue in precision medicine. The innovations have been largely
focused on cancer pathology (i.e., tumor segmentation and characterization). In
non-cancer pathology, the learning algorithms can be asked to examine more
comprehensive tissue types simultaneously, as a multi-label setting. The prior
arts typically needed to train multiple segmentation networks in order to match
the domain-specific knowledge for heterogeneous tissue types (e.g., glomerular
tuft, glomerular unit, proximal tubular, distal tubular, peritubular
capillaries, and arteries). In this paper, we propose a dynamic single
segmentation network (Omni-Seg) that learns to segment multiple tissue types
using partially labeled images (i.e., only one tissue type is labeled for each
training image) for renal pathology. By learning from ~150,000 patch-wise
pathological images from six tissue types, the proposed Omni-Seg network
achieved superior segmentation accuracy and less resource consumption when
compared to the previous the multiple-network and multi-head design. In the
testing stage, the proposed method obtains "completely labeled" tissue
segmentation results using only "partially labeled" training images. The source
code is available at https://github.com/ddrrnn123/Omni-Seg.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">3D Skeleton-based Few-shot Action Recognition with JEANIE is not so Na\"ive. (arXiv:2112.12668v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12668">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose a Few-shot Learning pipeline for 3D skeleton-based
action recognition by Joint tEmporal and cAmera viewpoiNt alIgnmEnt (JEANIE).
To factor out misalignment between query and support sequences of 3D body
joints, we propose an advanced variant of Dynamic Time Warping which jointly
models each smooth path between the query and support frames to achieve
simultaneously the best alignment in the temporal and simulated camera
viewpoint spaces for end-to-end learning under the limited few-shot training
data. Sequences are encoded with a temporal block encoder based on Simple
Spectral Graph Convolution, a lightweight linear Graph Neural Network backbone
(we also include a setting with a transformer). Finally, we propose a
similarity-based loss which encourages the alignment of sequences of the same
class while preventing the alignment of unrelated sequences. We demonstrate
state-of-the-art results on NTU-60, NTU-120, Kinetics-skeleton and UWA3D
Multiview Activity II.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TagLab: A human-centric AI system for interactive semantic segmentation. (arXiv:2112.12702v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12702">
<div class="article-summary-box-inner">
<span><p>Fully automatic semantic segmentation of highly specific semantic classes and
complex shapes may not meet the accuracy standards demanded by scientists. In
such cases, human-centered AI solutions, able to assist operators while
preserving human control over complex tasks, are a good trade-off to speed up
image labeling while maintaining high accuracy levels. TagLab is an open-source
AI-assisted software for annotating large orthoimages which takes advantage of
different degrees of automation; it speeds up image annotation from scratch
through assisted tools, creates custom fully automatic semantic segmentation
models, and, finally, allows the quick edits of automatic predictions. Since
the orthoimages analysis applies to several scientific disciplines, TagLab has
been designed with a flexible labeling pipeline. We report our results in two
different scenarios, marine ecology, and architectural heritage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Digital Editions as Distant Supervision for Layout Analysis of Printed Books. (arXiv:2112.12703v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12703">
<div class="article-summary-box-inner">
<span><p>Archivists, textual scholars, and historians often produce digital editions
of historical documents. Using markup schemes such as those of the Text
Encoding Initiative and EpiDoc, these digital editions often record documents'
semantic regions (such as notes and figures) and physical features (such as
page and line breaks) as well as transcribing their textual content. We
describe methods for exploiting this semantic markup as distant supervision for
training and evaluating layout analysis models. In experiments with several
model architectures on the half-million pages of the Deutsches Textarchiv
(DTA), we find a high correlation of these region-level evaluation methods with
pixel-level and word-level metrics. We discuss the possibilities for improving
accuracy with self-training and the ability of models trained on the DTA to
generalize to other historical printed books.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AI-based Reconstruction for Fast MRI -- A Systematic Review and Meta-analysis. (arXiv:2112.12744v1 [eess.IV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12744">
<div class="article-summary-box-inner">
<span><p>Compressed sensing (CS) has been playing a key role in accelerating the
magnetic resonance imaging (MRI) acquisition process. With the resurgence of
artificial intelligence, deep neural networks and CS algorithms are being
integrated to redefine the state of the art of fast MRI. The past several years
have witnessed substantial growth in the complexity, diversity, and performance
of deep learning-based CS techniques that are dedicated to fast MRI. In this
meta-analysis, we systematically review the deep learning-based CS techniques
for fast MRI, describe key model designs, highlight breakthroughs, and discuss
promising directions. We have also introduced a comprehensive analysis
framework and a classification system to assess the pivotal role of deep
learning in CS-based acceleration for MRI.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Assessing the Impact of Attention and Self-Attention Mechanisms on the Classification of Skin Lesions. (arXiv:2112.12748v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12748">
<div class="article-summary-box-inner">
<span><p>Attention mechanisms have raised significant interest in the research
community, since they promise significant improvements in the performance of
neural network architectures. However, in any specific problem, we still lack a
principled way to choose specific mechanisms and hyper-parameters that lead to
guaranteed improvements. More recently, self-attention has been proposed and
widely used in transformer-like architectures, leading to significant
breakthroughs in some applications. In this work we focus on two forms of
attention mechanisms: attention modules and self-attention. Attention modules
are used to reweight the features of each layer input tensor. Different modules
have different ways to perform this reweighting in fully connected or
convolutional layers. The attention models studied are completely modular and
in this work they will be used with the popular ResNet architecture.
Self-Attention, originally proposed in the area of Natural Language Processing
makes it possible to relate all the items in an input sequence. Self-Attention
is becoming increasingly popular in Computer Vision, where it is sometimes
combined with convolutional layers, although some recent architectures do away
entirely with convolutions. In this work, we study and perform an objective
comparison of a number of different attention mechanisms in a specific computer
vision task, the classification of samples in the widely used Skin Cancer MNIST
dataset. The results show that attention modules do sometimes improve the
performance of convolutional neural network architectures, but also that this
improvement, although noticeable and statistically significant, is not
consistent in different settings. The results obtained with self-attention
mechanisms, on the other hand, show consistent and significant improvements,
leading to the best results even in architectures with a reduced number of
parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SLIP: Self-supervision meets Language-Image Pre-training. (arXiv:2112.12750v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12750">
<div class="article-summary-box-inner">
<span><p>Recent work has shown that self-supervised pre-training leads to improvements
over supervised learning on challenging visual recognition tasks. CLIP, an
exciting new approach to learning with language supervision, demonstrates
promising performance on a wide variety of benchmarks. In this work, we explore
whether self-supervised learning can aid in the use of language supervision for
visual representation learning. We introduce SLIP, a multi-task learning
framework for combining self-supervised learning and CLIP pre-training. After
pre-training with Vision Transformers, we thoroughly evaluate representation
quality and compare performance to both CLIP and self-supervised learning under
three distinct settings: zero-shot transfer, linear classification, and
end-to-end finetuning. Across ImageNet and a battery of additional datasets, we
find that SLIP improves accuracy by a large margin. We validate our results
further with experiments on different model sizes, training schedules, and
pre-training datasets. Our findings show that SLIP enjoys the best of both
worlds: better performance than self-supervision (+8.1% linear accuracy) and
language supervision (+5.2% zero-shot accuracy).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BANMo: Building Animatable 3D Neural Models from Many Casual Videos. (arXiv:2112.12761v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12761">
<div class="article-summary-box-inner">
<span><p>Prior work for articulated 3D shape reconstruction often relies on
specialized sensors (e.g., synchronized multi-camera systems), or pre-built 3D
deformable models (e.g., SMAL or SMPL). Such methods are not able to scale to
diverse sets of objects in the wild. We present BANMo, a method that requires
neither a specialized sensor nor a pre-defined template shape. BANMo builds
high-fidelity, articulated 3D models (including shape and animatable skinning
weights) from many monocular casual videos in a differentiable rendering
framework. While the use of many videos provides more coverage of camera views
and object articulations, they introduce significant challenges in establishing
correspondence across scenes with different backgrounds, illumination
conditions, etc. Our key insight is to merge three schools of thought; (1)
classic deformable shape models that make use of articulated bones and blend
skinning, (2) volumetric neural radiance fields (NeRFs) that are amenable to
gradient-based optimization, and (3) canonical embeddings that generate
correspondences between pixels and an articulated model. We introduce neural
blend skinning models that allow for differentiable and invertible articulated
deformations. When combined with canonical embeddings, such models allow us to
establish dense correspondences across videos that can be self-supervised with
cycle consistency. On real and synthetic datasets, BANMo shows higher-fidelity
3D reconstructions than prior works for humans and animals, with the ability to
render realistic images from novel viewpoints and poses. Project webpage:
banmo-www.github.io .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross Modal Retrieval with Querybank Normalisation. (arXiv:2112.12777v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12777">
<div class="article-summary-box-inner">
<span><p>Profiting from large-scale training datasets, advances in neural architecture
design and efficient inference, joint embeddings have become the dominant
approach for tackling cross-modal retrieval. In this work we first show that,
despite their effectiveness, state-of-the-art joint embeddings suffer
significantly from the longstanding hubness problem in which a small number of
gallery embeddings form the nearest neighbours of many queries. Drawing
inspiration from the NLP literature, we formulate a simple but effective
framework called Querybank Normalisation (QB-Norm) that re-normalises query
similarities to account for hubs in the embedding space. QB-Norm improves
retrieval performance without requiring retraining. Differently from prior
work, we show that QB-Norm works effectively without concurrent access to any
test set queries. Within the QB-Norm framework, we also propose a novel
similarity normalisation method, the Dynamic Inverted Softmax, that is
significantly more robust than existing approaches. We showcase QB-Norm across
a range of cross modal retrieval models and benchmarks where it consistently
enhances strong baselines beyond the state of the art. Code is available at
https://vladbogo.github.io/QB-Norm/.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SeMask: Semantically Masked Transformers for Semantic Segmentation. (arXiv:2112.12782v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12782">
<div class="article-summary-box-inner">
<span><p>Finetuning a pretrained backbone in the encoder part of an image transformer
network has been the traditional approach for the semantic segmentation task.
However, such an approach leaves out the semantic context that an image
provides during the encoding stage. This paper argues that incorporating
semantic information of the image into pretrained hierarchical
transformer-based backbones while finetuning improves the performance
considerably. To achieve this, we propose SeMask, a simple and effective
framework that incorporates semantic information into the encoder with the help
of a semantic attention operation. In addition, we use a lightweight semantic
decoder during training to provide supervision to the intermediate semantic
prior maps at every stage. Our experiments demonstrate that incorporating
semantic priors enhances the performance of the established hierarchical
encoders with a slight increase in the number of FLOPs. We provide empirical
proof by integrating SeMask into each variant of the Swin-Transformer as our
encoder paired with different decoders. Our framework achieves a new
state-of-the-art of 58.22% mIoU on the ADE20K dataset and improvements of over
3% in the mIoU metric on the Cityscapes dataset. The code and checkpoints are
publicly available at
https://github.com/Picsart-AI-Research/SeMask-Segmentation .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NinjaDesc: Content-Concealing Visual Descriptors via Adversarial Learning. (arXiv:2112.12785v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12785">
<div class="article-summary-box-inner">
<span><p>In the light of recent analyses on privacy-concerning scene revelation from
visual descriptors, we develop descriptors that conceal the input image
content. In particular, we propose an adversarial learning framework for
training visual descriptors that prevent image reconstruction, while
maintaining the matching accuracy. We let a feature encoding network and image
reconstruction network compete with each other, such that the feature encoder
tries to impede the image reconstruction with its generated descriptors, while
the reconstructor tries to recover the input image from the descriptors. The
experimental results demonstrate that the visual descriptors obtained with our
method significantly deteriorate the image reconstruction quality with minimal
impact on correspondence matching and camera localization performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ELSA: Enhanced Local Self-Attention for Vision Transformer. (arXiv:2112.12786v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.12786">
<div class="article-summary-box-inner">
<span><p>Self-attention is powerful in modeling long-range dependencies, but it is
weak in local finer-level feature learning. The performance of local
self-attention (LSA) is just on par with convolution and inferior to dynamic
filters, which puzzles researchers on whether to use LSA or its counterparts,
which one is better, and what makes LSA mediocre. To clarify these, we
comprehensively investigate LSA and its counterparts from two sides:
\emph{channel setting} and \emph{spatial processing}. We find that the devil
lies in the generation and application of spatial attention, where relative
position embeddings and the neighboring filter application are key factors.
Based on these findings, we propose the enhanced local self-attention (ELSA)
with Hadamard attention and the ghost head. Hadamard attention introduces the
Hadamard product to efficiently generate attention in the neighboring case,
while maintaining the high-order mapping. The ghost head combines attention
maps with static matrices to increase channel capacity. Experiments demonstrate
the effectiveness of ELSA. Without architecture / hyperparameter modification,
drop-in replacing LSA with ELSA boosts Swin Transformer \cite{swin} by up to
+1.4 on top-1 accuracy. ELSA also consistently benefits VOLO \cite{volo} from
D1 to D5, where ELSA-VOLO-D5 achieves 87.2 on the ImageNet-1K without extra
training images. In addition, we evaluate ELSA in downstream tasks. ELSA
significantly improves the baseline by up to +1.9 box Ap / +1.3 mask Ap on the
COCO, and by up to +1.9 mIoU on the ADE20K. Code is available at
\url{https://github.com/damo-cv/ELSA}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Regularity Normalization: Neuroscience-Inspired Unsupervised Attention across Neural Network Layers. (arXiv:1902.10658v13 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1902.10658">
<div class="article-summary-box-inner">
<span><p>Inspired by the adaptation phenomenon of neuronal firing, we propose the
regularity normalization (RN) as an unsupervised attention mechanism (UAM)
which computes the statistical regularity in the implicit space of neural
networks under the Minimum Description Length (MDL) principle. Treating the
neural network optimization process as a partially observable model selection
problem, the regularity normalization constrains the implicit space by a
normalization factor, the universal code length. We compute this universal code
incrementally across neural network layers and demonstrate the flexibility to
include data priors such as top-down attention and other oracle information.
Empirically, our approach outperforms existing normalization methods in
tackling limited, imbalanced and non-stationary input distribution in image
classification, classic control, procedurally-generated reinforcement learning,
generative modeling, handwriting generation and question answering tasks with
various neural network architectures. Lastly, the unsupervised attention
mechanisms is a useful probing tool for neural networks by tracking the
dependency and critical learning stages across layers and recurrent time steps
of deep networks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SVGA-Net: Sparse Voxel-Graph Attention Network for 3D Object Detection from Point Clouds. (arXiv:2006.04043v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04043">
<div class="article-summary-box-inner">
<span><p>Accurate 3D object detection from point clouds has become a crucial component
in autonomous driving. However, the volumetric representations and the
projection methods in previous works fail to establish the relationships
between the local point sets. In this paper, we propose Sparse Voxel-Graph
Attention Network (SVGA-Net), a novel end-to-end trainable network which mainly
contains voxel-graph module and sparse-to-dense regression module to achieve
comparable 3D detection tasks from raw LIDAR data. Specifically, SVGA-Net
constructs the local complete graph within each divided 3D spherical voxel and
global KNN graph through all voxels. The local and global graphs serve as the
attention mechanism to enhance the extracted features. In addition, the novel
sparse-to-dense regression module enhances the 3D box estimation accuracy
through feature maps aggregation at different levels. Experiments on KITTI
detection benchmark demonstrate the efficiency of extending the graph
representation to 3D object detection and the proposed SVGA-Net can achieve
decent detection accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ego2Hands: A Dataset for Egocentric Two-hand Segmentation and Detection. (arXiv:2011.07252v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07252">
<div class="article-summary-box-inner">
<span><p>Hand segmentation and detection in truly unconstrained RGB-based settings is
important for many applications. However, existing datasets are far from
sufficient in terms of size and variety due to the infeasibility of manual
annotation of large amounts of segmentation and detection data. As a result,
current methods are limited by many underlying assumptions such as constrained
environment, consistent skin color and lighting. In this work, we present
Ego2Hands, a large-scale RGB-based egocentric hand segmentation/detection
dataset that is semi-automatically annotated and a color-invariant
compositing-based data generation technique capable of creating training data
with large quantity and variety. For quantitative analysis, we manually
annotated an evaluation set that significantly exceeds existing benchmarks in
quantity, diversity and annotation accuracy. We provide cross-dataset
evaluation as well as thorough analysis on the performance of state-of-the-art
models on Ego2Hands to show that our dataset and data generation technique can
produce models that generalize to unseen environments without domain
adaptation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpretable COVID-19 Chest X-Ray Classification via Orthogonality Constraint. (arXiv:2102.08360v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08360">
<div class="article-summary-box-inner">
<span><p>Deep neural networks have increasingly been used as an auxiliary tool in
healthcare applications, due to their ability to improve performance of several
diagnosis tasks. However, these methods are not widely adopted in clinical
settings due to the practical limitations in the reliability, generalizability,
and interpretability of deep learning based systems. As a result, methods have
been developed that impose additional constraints during network training to
gain more control as well as improve interpretabilty, facilitating their
acceptance in healthcare community. In this work, we investigate the benefit of
using Orthogonal Spheres (OS) constraint for classification of COVID-19 cases
from chest X-ray images. The OS constraint can be written as a simple
orthonormality term which is used in conjunction with the standard
cross-entropy loss during classification network training. Previous studies
have demonstrated significant benefits in applying such constraints to deep
learning models. Our findings corroborate these observations, indicating that
the orthonormality loss function effectively produces improved semantic
localization via GradCAM visualizations, enhanced classification performance,
and reduced model calibration error. Our approach achieves an improvement in
accuracy of 1.6% and 4.8% for two- and three-class classification,
respectively; similar results are found for models with data augmentation
applied. In addition to these findings, our work also presents a new
application of the OS regularizer in healthcare, increasing the post-hoc
interpretability and performance of deep learning models for COVID-19
classification to facilitate adoption of these methods in clinical settings. We
also identify the limitations of our strategy that can be explored for further
research in future.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">PureGaze: Purifying Gaze Feature for Generalizable Gaze Estimation. (arXiv:2103.13173v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13173">
<div class="article-summary-box-inner">
<span><p>Gaze estimation methods learn eye gaze from facial features. However, among
rich information in the facial image, real gaze-relevant features only
correspond to subtle changes in eye region, while other gaze-irrelevant
features like illumination, personal appearance and even facial expression may
affect the learning in an unexpected way. This is a major reason why existing
methods show significant performance degradation in cross-domain/dataset
evaluation. In this paper, we tackle the cross-domain problem in gaze
estimation. Different from common domain adaption methods, we propose a domain
generalization method to improve the cross-domain performance without touching
target samples. The domain generalization is realized by gaze feature
purification. We eliminate gaze-irrelevant factors such as illumination and
identity to improve the cross-domain performance. We design a plug-and-play
self-adversarial framework for the gaze feature purification. The framework
enhances not only our baseline but also existing gaze estimation methods
directly and significantly. To the best of our knowledge, we are the first to
propose domain generalization methods in gaze estimation. Our method achieves
not only state-of-the-art performance among typical gaze estimation methods but
also competitive results among domain adaption methods. The code is released in
https://github.com/yihuacheng/PureGaze.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Less is More: Pay Less Attention in Vision Transformers. (arXiv:2105.14217v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14217">
<div class="article-summary-box-inner">
<span><p>Transformers have become one of the dominant architectures in deep learning,
particularly as a powerful alternative to convolutional neural networks (CNNs)
in computer vision. However, Transformer training and inference in previous
works can be prohibitively expensive due to the quadratic complexity of
self-attention over a long sequence of representations, especially for
high-resolution dense prediction tasks. To this end, we present a novel Less
attention vIsion Transformer (LIT), building upon the fact that the early
self-attention layers in Transformers still focus on local patterns and bring
minor benefits in recent hierarchical vision Transformers. Specifically, we
propose a hierarchical Transformer where we use pure multi-layer perceptrons
(MLPs) to encode rich local patterns in the early stages while applying
self-attention modules to capture longer dependencies in deeper layers.
Moreover, we further propose a learned deformable token merging module to
adaptively fuse informative patches in a non-uniform manner. The proposed LIT
achieves promising performance on image recognition tasks, including image
classification, object detection and instance segmentation, serving as a strong
backbone for many vision tasks. Code is available at:
https://github.com/zhuang-group/LIT
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Action Transformer: A Self-Attention Model for Short-Time Human Action Recognition. (arXiv:2107.00606v4 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00606">
<div class="article-summary-box-inner">
<span><p>Deep neural networks based purely on attention have been successful across
several domains, relying on minimal architectural priors from the designer. In
Human Action Recognition (HAR), attention mechanisms have been primarily
adopted on top of standard convolutional or recurrent layers, improving the
overall generalization capability. In this work, we introduce Action
Transformer (AcT), a simple, fully self-attentional architecture that
consistently outperforms more elaborated networks that mix convolutional,
recurrent and attentive layers. In order to limit computational and energy
requests, building on previous human action recognition research, the proposed
approach exploits 2D pose representations over small temporal windows,
providing a low latency solution for accurate and effective real-time
performance. Moreover, we open-source MPOSE2021, a new large-scale dataset, as
an attempt to build a formal training and evaluation benchmark for real-time,
short-time HAR. The proposed methodology was extensively tested on MPOSE2021
and compared to several state-of-the-art architectures, proving the
effectiveness of the AcT model and laying the foundations for future work on
HAR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On Measuring and Controlling the Spectral Bias of the Deep Image Prior. (arXiv:2107.01125v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01125">
<div class="article-summary-box-inner">
<span><p>The deep image prior showed that a randomly initialized network with a
suitable architecture can be trained to solve inverse imaging problems by
simply optimizing it's parameters to reconstruct a single degraded image.
However, it suffers from two practical limitations. First, it remains unclear
how to control the prior beyond the choice of the network architecture. Second,
training requires an oracle stopping criterion as during the optimization the
performance degrades after reaching an optimum value. To address these
challenges we introduce a frequency-band correspondence measure to characterize
the spectral bias of the deep image prior, where low-frequency image signals
are learned faster and better than high-frequency counterparts. Based on our
observations, we propose techniques to prevent the eventual performance
degradation and accelerate convergence. We introduce a Lipschitz-controlled
convolution layer and a Gaussian-controlled upsampling layer as plug-in
replacements for layers used in the deep architectures. The experiments show
that with these changes the performance does not degrade during optimization,
relieving us from the need for an oracle stopping criterion. We further outline
a stopping criterion to avoid superfluous computation. Finally, we show that
our approach obtains favorable results compared to current approaches across
various denoising, deblocking, inpainting, super-resolution and detail
enhancement tasks. Code is available at
\url{https://github.com/shizenglin/Measure-and-Control-Spectral-Bias}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">New Pruning Method Based on DenseNet Network for Image Classification. (arXiv:2108.12604v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12604">
<div class="article-summary-box-inner">
<span><p>Deep neural networks have made significant progress in the field of computer
vision. Recent studies have shown that depth, width and shortcut connections of
neural network architectures play a crucial role in their performance. One of
the most advanced neural network architectures, DenseNet, has achieved
excellent convergence rates through dense connections. However, it still has
obvious shortcomings in the usage of amount of memory. In this paper, we
introduce a new type of pruning tool, threshold, which refers to the principle
of the threshold voltage in MOSFET. This work employs this method to connect
blocks of different depths in different ways to reduce the usage of memory. It
is denoted as ThresholdNet. We evaluate ThresholdNet and other different
networks on datasets of CIFAR10. Experiments show that HarDNet is twice as fast
as DenseNet, and on this basis, ThresholdNet is 10% faster and 10% lower error
rate than HarDNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Unsupervised Data Selection for Data-Centric Semi-Supervised Learning. (arXiv:2110.03006v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03006">
<div class="article-summary-box-inner">
<span><p>We study unsupervised data selection for semi-supervised learning (SSL),
where a large-scale unlabeled dataset is available and a small subset of data
is budgeted for label acquisition. Existing SSL methods focus on learning a
model that effectively integrates information from given small labeled data and
large unlabeled data, whereas we focus on selecting the right data to annotate
for SSL without requiring any label or task information. Intuitively, instances
to be labeled shall collectively have maximum diversity and coverage for
downstream tasks, and individually have maximum information propagation utility
for SSL. We formalize these concepts in a three-step data-centric SSL method
that improves FixMatch in stability and accuracy by 8% on CIFAR-10 (0.08%
labeled) and 14% on ImageNet-1K (0.2% labeled). It is also a universal
framework that works with various SSL methods, delivering consistent
performance gains. Our work demonstrates that small computation spent on
carefully selecting data for annotation brings big annotation efficiency and
model performance gain without changing the learning pipeline. Our completely
unsupervised data selection can be easily extended to other weakly supervised
learning settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Model Adaptation: Historical Contrastive Learning for Unsupervised Domain Adaptation without Source Data. (arXiv:2110.03374v5 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.03374">
<div class="article-summary-box-inner">
<span><p>Unsupervised domain adaptation aims to align a labeled source domain and an
unlabeled target domain, but it requires to access the source data which often
raises concerns in data privacy, data portability and data transmission
efficiency. We study unsupervised model adaptation (UMA), or called
Unsupervised Domain Adaptation without Source Data, an alternative setting that
aims to adapt source-trained models towards target distributions without
accessing source data. To this end, we design an innovative historical
contrastive learning (HCL) technique that exploits historical source hypothesis
to make up for the absence of source data in UMA. HCL addresses the UMA
challenge from two perspectives. First, it introduces historical contrastive
instance discrimination (HCID) that learns from target samples by contrasting
their embeddings which are generated by the currently adapted model and the
historical models. With the historical models, HCID encourages UMA to learn
instance-discriminative target representations while preserving the source
hypothesis. Second, it introduces historical contrastive category
discrimination (HCCD) that pseudo-labels target samples to learn
category-discriminative target representations. Specifically, HCCD re-weights
pseudo labels according to their prediction consistency across the current and
historical models. Extensive experiments show that HCL outperforms and
state-of-the-art methods consistently across a variety of visual tasks and
setups.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Capacity of Group-invariant Linear Readouts from Equivariant Representations: How Many Objects can be Linearly Classified Under All Possible Views?. (arXiv:2110.07472v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.07472">
<div class="article-summary-box-inner">
<span><p>Equivariance has emerged as a desirable property of representations of
objects subject to identity-preserving transformations that constitute a group,
such as translations and rotations. However, the expressivity of a
representation constrained by group equivariance is still not fully understood.
We address this gap by providing a generalization of Cover's Function Counting
Theorem that quantifies the number of linearly separable and group-invariant
binary dichotomies that can be assigned to equivariant representations of
objects. We find that the fraction of separable dichotomies is determined by
the dimension of the space that is fixed by the group action. We show how this
relation extends to operations such as convolutions, element-wise
nonlinearities, and global and local pooling. While other operations do not
change the fraction of separable dichotomies, local pooling decreases the
fraction, despite being a highly nonlinear operation. Finally, we test our
theory on intermediate representations of randomly initialized and fully
trained convolutional neural networks and find perfect agreement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Deep Asymmetric Hashing with Dual Semantic Regression and Class Structure Quantization. (arXiv:2110.12478v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.12478">
<div class="article-summary-box-inner">
<span><p>Recently, deep hashing methods have been widely used in image retrieval task.
Most existing deep hashing approaches adopt one-to-one quantization to reduce
information loss. However, such class-unrelated quantization cannot give
discriminative feedback for network training. In addition, these methods only
utilize single label to integrate supervision information of data for hashing
function learning, which may result in inferior network generalization
performance and relatively low-quality hash codes since the inter-class
information of data is totally ignored. In this paper, we propose a dual
semantic asymmetric hashing (DSAH) method, which generates discriminative hash
codes under three-fold constraints. Firstly, DSAH utilizes class prior to
conduct class structure quantization so as to transmit class information during
the quantization process. Secondly, a simple yet effective label mechanism is
designed to characterize both the intra-class compactness and inter-class
separability of data, thereby achieving semantic-sensitive binary code
learning. Finally, a meaningful pairwise similarity preserving loss is devised
to minimize the distances between class-related network outputs based on an
affinity graph. With these three main components, high-quality hash codes can
be generated through network. Extensive experiments conducted on various
datasets demonstrate the superiority of DSAH in comparison with
state-of-the-art deep hashing methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Novel coronavirus pneumonia lesion segmentation in CT images. (arXiv:2110.12827v3 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.12827">
<div class="article-summary-box-inner">
<span><p>Background: The 2019 novel coronavirus disease (COVID-19) has been spread
widely in the world, causing a huge threat to people's living environment.
Objective: Under computed tomography (CT) imaging, the structure features of
COVID-19 lesions are complicated and varied greatly in different cases. To
accurately locate COVID-19 lesions and assist doctors to make the best
diagnosis and treatment plan, a deep-supervised ensemble learning network is
presented for COVID-19 lesion segmentation in CT images. Methods: Considering
the fact that a large number of COVID-19 CT images and the corresponding lesion
annotations are difficult to obtained, a transfer learning strategy is employed
to make up for the shortcoming and alleviate the overfitting problem. Based on
the reality that traditional single deep learning framework is difficult to
extract COVID-19 lesion features effectively, which may cause some lesions to
be undetected. To overcome the problem, a deep-supervised ensemble learning
network is presented to combine with local and global features for COVID-19
lesion segmentation. Results: The performance of the proposed method was
validated in experiments with a publicly available dataset. Compared with
manual annotations, the proposed method acquired a high intersection over union
(IoU) of 0.7279. Conclusion: A deep-supervised ensemble learning network was
presented for coronavirus pneumonia lesion segmentation in CT images. The
effectiveness of the proposed method was verified by visual inspection and
quantitative evaluation. Experimental results shown that the proposed mehtod
has a perfect performance in COVID-19 lesion segmentation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Influential Prototypical Networks for Few Shot Learning: A Dermatological Case Study. (arXiv:2111.00698v4 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2111.00698">
<div class="article-summary-box-inner">
<span><p>Prototypical network (PN) is a simple yet effective few shot learning
strategy. It is a metric-based meta-learning technique where classification is
performed by computing Euclidean distances to prototypical representations of
each class. Conventional PN attributes equal importance to all samples and
generates prototypes by simply averaging the support sample embeddings
belonging to each class. In this work, we propose a novel version of PN that
attributes weights to support samples corresponding to their influence on the
support sample distribution. Influence weights of samples are calculated based
on maximum mean discrepancy (MMD) between the mean embeddings of sample
distributions including and excluding the sample. Comprehensive evaluation of
our proposed influential PN (IPNet) is performed by comparing its performance
with other baseline PNs on three different benchmark dermatological datasets.
IPNet outperforms all baseline models with compelling results across all three
datasets and various N-way, K-shot classification tasks. Findings from
cross-domain adaptation experiments further establish the robustness and
generalizability of IPNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Overcoming the Domain Gap in Neural Action Representations. (arXiv:2112.01176v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.01176">
<div class="article-summary-box-inner">
<span><p>Relating animal behaviors to brain activity is a fundamental goal in
neuroscience, with practical applications in building robust brain-machine
interfaces. However, the domain gap between individuals is a major issue that
prevents the training of general models that work on unlabeled subjects.
</p>
<p>Since 3D pose data can now be reliably extracted from multi-view video
sequences without manual intervention, we propose to use it to guide the
encoding of neural action representations together with a set of neural and
behavioral augmentations exploiting the properties of microscopy imaging. To
reduce the domain gap, during training, we swap neural and behavioral data
across animals that seem to be performing similar actions.
</p>
<p>To demonstrate this, we test our methods on three very different multimodal
datasets; one that features flies and their neural activity, one that contains
human neural Electrocorticography (ECoG) data, and lastly the RGB video data of
human activities from different viewpoints.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learn2Reg: comprehensive multi-task medical image registration challenge, dataset and evaluation in the era of deep learning. (arXiv:2112.04489v2 [eess.IV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.04489">
<div class="article-summary-box-inner">
<span><p>Image registration is a fundamental medical image analysis task, and a wide
variety of approaches have been proposed. However, only a few studies have
comprehensively compared medical image registration approaches on a wide range
of clinically relevant tasks, in part because of the lack of availability of
such diverse data. This limits the development of registration methods, the
adoption of research advances into practice, and a fair benchmark across
competing approaches. The Learn2Reg challenge addresses these limitations by
providing a multi-task medical image registration benchmark for comprehensive
characterisation of deformable registration algorithms. A continuous evaluation
will be possible at https://learn2reg.grand-challenge.org. Learn2Reg covers a
wide range of anatomies (brain, abdomen, and thorax), modalities (ultrasound,
CT, MR), availability of annotations, as well as intra- and inter-patient
registration evaluation. We established an easily accessible framework for
training and validation of 3D registration methods, which enabled the
compilation of results of over 65 individual method submissions from more than
20 unique teams. We used a complementary set of metrics, including robustness,
accuracy, plausibility, and runtime, enabling unique insight into the current
state-of-the-art of medical image registration. This paper describes datasets,
tasks, evaluation methods and results of the challenge, and the results of
further analysis of transferability to new datasets, the importance of label
supervision, and resulting bias.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adaptive Methods for Aggregated Domain Generalization. (arXiv:2112.04766v2 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.04766">
<div class="article-summary-box-inner">
<span><p>Domain generalization involves learning a classifier from a heterogeneous
collection of training sources such that it generalizes to data drawn from
similar unknown target domains, with applications in large-scale learning and
personalized inference. In many settings, privacy concerns prohibit obtaining
domain labels for the training data samples, and instead only have an
aggregated collection of training points. Existing approaches that utilize
domain labels to create domain-invariant feature representations are
inapplicable in this setting, requiring alternative approaches to learn
generalizable classifiers. In this paper, we propose a domain-adaptive approach
to this problem, which operates in two steps: (a) we cluster training data
within a carefully chosen feature space to create pseudo-domains, and (b) using
these pseudo-domains we learn a domain-adaptive classifier that makes
predictions using information about both the input and the pseudo-domain it
belongs to. Our approach achieves state-of-the-art performance on a variety of
domain generalization benchmarks without using domain labels whatsoever.
Furthermore, we provide novel theoretical guarantees on domain generalization
using cluster information. Our approach is amenable to ensemble-based methods
and provides substantial gains even on large-scale benchmark datasets. The code
can be found at: https://github.com/xavierohan/AdaClust_DomainBed
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ScaleNet: A Shallow Architecture for Scale Estimation. (arXiv:2112.04846v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.04846">
<div class="article-summary-box-inner">
<span><p>In this paper, we address the problem of estimating scale factors between
images. We formulate the scale estimation problem as a prediction of a
probability distribution over scale factors. We design a new architecture,
ScaleNet, that exploits dilated convolutions as well as self and
cross-correlation layers to predict the scale between images. We demonstrate
that rectifying images with estimated scales leads to significant performance
improvements for various tasks and methods. Specifically, we show how ScaleNet
can be combined with sparse local features and dense correspondence networks to
improve camera pose estimation, 3D reconstruction, or dense geometric matching
in different benchmarks and datasets. We provide an extensive evaluation on
several tasks and analyze the computational overhead of ScaleNet. The code,
evaluation protocols, and trained models are publicly available at
https://github.com/axelBarroso/ScaleNet.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Paced Deep Regression Forests with Consideration on Ranking Fairness. (arXiv:2112.06455v3 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.06455">
<div class="article-summary-box-inner">
<span><p>Deep discriminative models (DDMs), such as deep regression forests, deep
neural decision forests, have been extensively studied recently to solve
problems like facial age estimation, head pose estimation, gaze estimation and
so forth. Such problems are challenging in part because a large amount of
effective training data without noise and bias is often not available. While
some progress has been achieved through learning more discriminative features,
or reweighting samples, we argue what is more desirable is to learn gradually
to discriminate like human beings. Then, we resort to self-paced learning
(SPL). But a natural question arises: can self-paced regime lead DDMs to
achieve more robust and less biased solutions? A serious problem with SPL,
which is firstly discussed by this work, is it tends to aggravate the bias of
solutions, especially for obvious imbalanced data. To this end, this paper
proposes a new self-paced paradigm for deep discriminative model, which
distinguishes noisy and underrepresented examples according to the output
likelihood and entropy associated with each example, and tackle the fundamental
ranking problem in SPL from a new perspective: fairness. This paradigm is
fundamental, and could be easily combined with a variety of DDMs. Extensive
experiments on three computer vision tasks, such as facial age estimation, head
pose estimation and gaze estimation, demonstrate the efficacy of our paradigm.
To the best of our knowledge, our work is the first paper in the literature of
SPL that considers ranking fairness for self-paced regime construction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improved YOLOv5 network for real-time multi-scale traffic sign detection. (arXiv:2112.08782v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.08782">
<div class="article-summary-box-inner">
<span><p>Traffic sign detection is a challenging task for the unmanned driving system,
especially for the detection of multi-scale targets and the real-time problem
of detection. In the traffic sign detection process, the scale of the targets
changes greatly, which will have a certain impact on the detection accuracy.
Feature pyramid is widely used to solve this problem but it might break the
feature consistency across different scales of traffic signs. Moreover, in
practical application, it is difficult for common methods to improve the
detection accuracy of multi-scale traffic signs while ensuring real-time
detection. In this paper, we propose an improved feature pyramid model, named
AF-FPN, which utilizes the adaptive attention module (AAM) and feature
enhancement module (FEM) to reduce the information loss in the process of
feature map generation and enhance the representation ability of the feature
pyramid. We replaced the original feature pyramid network in YOLOv5 with
AF-FPN, which improves the detection performance for multi-scale targets of the
YOLOv5 network under the premise of ensuring real-time detection. Furthermore,
a new automatic learning data augmentation method is proposed to enrich the
dataset and improve the robustness of the model to make it more suitable for
practical scenarios. Extensive experimental results on the Tsinghua-Tencent
100K (TT100K) dataset demonstrate the effectiveness and superiority of the
proposed method when compared with several state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Align and Prompt: Video-and-Language Pre-training with Entity Prompts. (arXiv:2112.09583v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.09583">
<div class="article-summary-box-inner">
<span><p>Video-and-language pre-training has shown promising improvements on various
downstream tasks. Most previous methods capture cross-modal interactions with a
transformer-based multimodal encoder, not fully addressing the misalignment
between unimodal video and text features. Besides, learning fine-grained
visual-language alignment usually requires off-the-shelf object detectors to
provide object information, which is bottlenecked by the detector's limited
vocabulary and expensive computation cost.
</p>
<p>We propose Align and Prompt: an efficient and effective video-and-language
pre-training framework with better cross-modal alignment. First, we introduce a
video-text contrastive (VTC) loss to align unimodal video-text features at the
instance level, which eases the modeling of cross-modal interactions. Then, we
propose a new visually-grounded pre-training task, prompting entity modeling
(PEM), which aims to learn fine-grained region-entity alignment. To achieve
this, we first introduce an entity prompter module, which is trained with VTC
to produce the similarity between a video crop and text prompts instantiated
with entity names. The PEM task then asks the model to predict the entity
pseudo-labels (i.e~normalized similarity scores) for randomly-selected video
crops. The resulting pre-trained model achieves state-of-the-art performance on
both text-video retrieval and videoQA, outperforming prior work by a
substantial margin. Our code and pre-trained models are available at
https://github.com/salesforce/ALPRO.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SOIT: Segmenting Objects with Instance-Aware Transformers. (arXiv:2112.11037v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.11037">
<div class="article-summary-box-inner">
<span><p>This paper presents an end-to-end instance segmentation framework, termed
SOIT, that Segments Objects with Instance-aware Transformers. Inspired by DETR
\cite{carion2020end}, our method views instance segmentation as a direct set
prediction problem and effectively removes the need for many hand-crafted
components like RoI cropping, one-to-many label assignment, and non-maximum
suppression (NMS). In SOIT, multiple queries are learned to directly reason a
set of object embeddings of semantic category, bounding-box location, and
pixel-wise mask in parallel under the global image context. The class and
bounding-box can be easily embedded by a fixed-length vector. The pixel-wise
mask, especially, is embedded by a group of parameters to construct a
lightweight instance-aware transformer. Afterward, a full-resolution mask is
produced by the instance-aware transformer without involving any RoI-based
operation. Overall, SOIT introduces a simple single-stage instance segmentation
framework that is both RoI- and NMS-free. Experimental results on the MS COCO
dataset demonstrate that SOIT outperforms state-of-the-art instance
segmentation approaches significantly. Moreover, the joint learning of multiple
tasks in a unified query embedding can also substantially improve the detection
performance. Code is available at \url{https://github.com/yuxiaodongHRI/SOIT}.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-12-26 23:06:45.733667360 UTC">2021-12-26 23:06:45 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.9</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>